{"step": 3044, "train_return": -21.0, "train_length": 761.0, "train_total_steps": 761.0, "train_total_episodes": 1.0, "train_loaded_steps": 761.0, "train_loaded_episodes": 1.0}
{"step": 7168, "train_return": -21.0, "train_length": 1031.0, "train_total_steps": 1792.0, "train_total_episodes": 2.0, "train_loaded_steps": 1792.0, "train_loaded_episodes": 2.0}
{"step": 10460, "train_return": -21.0, "train_length": 823.0, "train_total_steps": 2615.0, "train_total_episodes": 3.0, "train_loaded_steps": 2615.0, "train_loaded_episodes": 3.0}
{"step": 14548, "train_return": -19.0, "train_length": 1022.0, "train_total_steps": 3637.0, "train_total_episodes": 4.0, "train_loaded_steps": 3637.0, "train_loaded_episodes": 4.0}
{"step": 19492, "train_return": -18.0, "train_length": 1236.0, "train_total_steps": 4873.0, "train_total_episodes": 5.0, "train_loaded_steps": 4873.0, "train_loaded_episodes": 5.0}
{"step": 23608, "train_return": -21.0, "train_length": 1029.0, "train_total_steps": 5902.0, "train_total_episodes": 6.0, "train_loaded_steps": 5902.0, "train_loaded_episodes": 6.0}
{"step": 27312, "train_return": -20.0, "train_length": 926.0, "train_total_steps": 6828.0, "train_total_episodes": 7.0, "train_loaded_steps": 6828.0, "train_loaded_episodes": 7.0}
{"step": 31088, "train_return": -21.0, "train_length": 944.0, "train_total_steps": 7772.0, "train_total_episodes": 8.0, "train_loaded_steps": 7772.0, "train_loaded_episodes": 8.0}
{"step": 34456, "train_return": -21.0, "train_length": 842.0, "train_total_steps": 8614.0, "train_total_episodes": 9.0, "train_loaded_steps": 8614.0, "train_loaded_episodes": 9.0}
{"step": 38460, "train_return": -19.0, "train_length": 1001.0, "train_total_steps": 9615.0, "train_total_episodes": 10.0, "train_loaded_steps": 9615.0, "train_loaded_episodes": 10.0}
{"step": 41512, "train_return": -21.0, "train_length": 763.0, "train_total_steps": 10378.0, "train_total_episodes": 11.0, "train_loaded_steps": 10378.0, "train_loaded_episodes": 11.0}
{"step": 45592, "train_return": -20.0, "train_length": 1020.0, "train_total_steps": 11398.0, "train_total_episodes": 12.0, "train_loaded_steps": 11398.0, "train_loaded_episodes": 12.0}
{"step": 49320, "train_return": -19.0, "train_length": 932.0, "train_total_steps": 12330.0, "train_total_episodes": 13.0, "train_loaded_steps": 12330.0, "train_loaded_episodes": 13.0}
{"step": 53976, "train_return": -20.0, "train_length": 1164.0, "train_total_steps": 13494.0, "train_total_episodes": 14.0, "train_loaded_steps": 13494.0, "train_loaded_episodes": 14.0}
{"step": 58912, "train_return": -19.0, "train_length": 1234.0, "train_total_steps": 14728.0, "train_total_episodes": 15.0, "train_loaded_steps": 14728.0, "train_loaded_episodes": 15.0}
{"step": 62388, "train_return": -20.0, "train_length": 869.0, "train_total_steps": 15597.0, "train_total_episodes": 16.0, "train_loaded_steps": 15597.0, "train_loaded_episodes": 16.0}
{"step": 65776, "train_return": -21.0, "train_length": 847.0, "train_total_steps": 16444.0, "train_total_episodes": 17.0, "train_loaded_steps": 16444.0, "train_loaded_episodes": 17.0}
{"step": 69172, "train_return": -21.0, "train_length": 849.0, "train_total_steps": 17293.0, "train_total_episodes": 18.0, "train_loaded_steps": 17293.0, "train_loaded_episodes": 18.0}
{"step": 72820, "train_return": -21.0, "train_length": 912.0, "train_total_steps": 18205.0, "train_total_episodes": 19.0, "train_loaded_steps": 18205.0, "train_loaded_episodes": 19.0}
{"step": 76428, "train_return": -21.0, "train_length": 902.0, "train_total_steps": 19107.0, "train_total_episodes": 20.0, "train_loaded_steps": 19107.0, "train_loaded_episodes": 20.0}
{"step": 80032, "train_return": -20.0, "train_length": 901.0, "train_total_steps": 20008.0, "train_total_episodes": 21.0, "train_loaded_steps": 20008.0, "train_loaded_episodes": 21.0}
{"step": 83688, "train_return": -21.0, "train_length": 914.0, "train_total_steps": 20922.0, "train_total_episodes": 22.0, "train_loaded_steps": 20922.0, "train_loaded_episodes": 22.0}
{"step": 87412, "train_return": -19.0, "train_length": 931.0, "train_total_steps": 21853.0, "train_total_episodes": 23.0, "train_loaded_steps": 21853.0, "train_loaded_episodes": 23.0}
{"step": 90460, "train_return": -21.0, "train_length": 762.0, "train_total_steps": 22615.0, "train_total_episodes": 24.0, "train_loaded_steps": 22615.0, "train_loaded_episodes": 24.0}
{"step": 93912, "train_return": -20.0, "train_length": 863.0, "train_total_steps": 23478.0, "train_total_episodes": 25.0, "train_loaded_steps": 23478.0, "train_loaded_episodes": 25.0}
{"step": 98136, "train_return": -21.0, "train_length": 1056.0, "train_total_steps": 24534.0, "train_total_episodes": 26.0, "train_loaded_steps": 24534.0, "train_loaded_episodes": 26.0}
{"step": 101672, "train_return": -21.0, "train_length": 884.0, "train_total_steps": 25418.0, "train_total_episodes": 27.0, "train_loaded_steps": 25418.0, "train_loaded_episodes": 27.0}
{"step": 104728, "train_return": -21.0, "train_length": 764.0, "train_total_steps": 26182.0, "train_total_episodes": 28.0, "train_loaded_steps": 26182.0, "train_loaded_episodes": 28.0}
{"step": 108892, "train_return": -20.0, "train_length": 1041.0, "train_total_steps": 27223.0, "train_total_episodes": 29.0, "train_loaded_steps": 27223.0, "train_loaded_episodes": 29.0}
{"step": 111932, "train_return": -21.0, "train_length": 760.0, "train_total_steps": 27983.0, "train_total_episodes": 30.0, "train_loaded_steps": 27983.0, "train_loaded_episodes": 30.0}
{"step": 115588, "train_return": -21.0, "train_length": 914.0, "train_total_steps": 28897.0, "train_total_episodes": 31.0, "train_loaded_steps": 28897.0, "train_loaded_episodes": 31.0}
{"step": 119500, "train_return": -20.0, "train_length": 978.0, "train_total_steps": 29875.0, "train_total_episodes": 32.0, "train_loaded_steps": 29875.0, "train_loaded_episodes": 32.0}
{"step": 123088, "train_return": -20.0, "train_length": 897.0, "train_total_steps": 30772.0, "train_total_episodes": 33.0, "train_loaded_steps": 30772.0, "train_loaded_episodes": 33.0}
{"step": 126600, "train_return": -21.0, "train_length": 878.0, "train_total_steps": 31650.0, "train_total_episodes": 34.0, "train_loaded_steps": 31650.0, "train_loaded_episodes": 34.0}
{"step": 130520, "train_return": -20.0, "train_length": 980.0, "train_total_steps": 32630.0, "train_total_episodes": 35.0, "train_loaded_steps": 32630.0, "train_loaded_episodes": 35.0}
{"step": 134940, "train_return": -18.0, "train_length": 1105.0, "train_total_steps": 33735.0, "train_total_episodes": 36.0, "train_loaded_steps": 33735.0, "train_loaded_episodes": 36.0}
{"step": 138376, "train_return": -20.0, "train_length": 859.0, "train_total_steps": 34594.0, "train_total_episodes": 37.0, "train_loaded_steps": 34594.0, "train_loaded_episodes": 37.0}
{"step": 141780, "train_return": -21.0, "train_length": 851.0, "train_total_steps": 35445.0, "train_total_episodes": 38.0, "train_loaded_steps": 35445.0, "train_loaded_episodes": 38.0}
{"step": 145148, "train_return": -20.0, "train_length": 842.0, "train_total_steps": 36287.0, "train_total_episodes": 39.0, "train_loaded_steps": 36287.0, "train_loaded_episodes": 39.0}
{"step": 149172, "train_return": -19.0, "train_length": 1006.0, "train_total_steps": 37293.0, "train_total_episodes": 40.0, "train_loaded_steps": 37293.0, "train_loaded_episodes": 40.0}
{"step": 153324, "train_return": -20.0, "train_length": 1038.0, "train_total_steps": 38331.0, "train_total_episodes": 41.0, "train_loaded_steps": 38331.0, "train_loaded_episodes": 41.0}
{"step": 156932, "train_return": -20.0, "train_length": 902.0, "train_total_steps": 39233.0, "train_total_episodes": 42.0, "train_loaded_steps": 39233.0, "train_loaded_episodes": 42.0}
{"step": 160672, "train_return": -21.0, "train_length": 935.0, "train_total_steps": 40168.0, "train_total_episodes": 43.0, "train_loaded_steps": 40168.0, "train_loaded_episodes": 43.0}
{"step": 165320, "train_return": -19.0, "train_length": 1162.0, "train_total_steps": 41330.0, "train_total_episodes": 44.0, "train_loaded_steps": 41330.0, "train_loaded_episodes": 44.0}
{"step": 169224, "train_return": -19.0, "train_length": 976.0, "train_total_steps": 42306.0, "train_total_episodes": 45.0, "train_loaded_steps": 42306.0, "train_loaded_episodes": 45.0}
{"step": 172252, "train_return": -21.0, "train_length": 757.0, "train_total_steps": 43063.0, "train_total_episodes": 46.0, "train_loaded_steps": 43063.0, "train_loaded_episodes": 46.0}
{"step": 175552, "train_return": -21.0, "train_length": 825.0, "train_total_steps": 43888.0, "train_total_episodes": 47.0, "train_loaded_steps": 43888.0, "train_loaded_episodes": 47.0}
{"step": 179576, "train_return": -20.0, "train_length": 1006.0, "train_total_steps": 44894.0, "train_total_episodes": 48.0, "train_loaded_steps": 44894.0, "train_loaded_episodes": 48.0}
{"step": 183036, "train_return": -20.0, "train_length": 865.0, "train_total_steps": 45759.0, "train_total_episodes": 49.0, "train_loaded_steps": 45759.0, "train_loaded_episodes": 49.0}
{"step": 186436, "train_return": -21.0, "train_length": 850.0, "train_total_steps": 46609.0, "train_total_episodes": 50.0, "train_loaded_steps": 46609.0, "train_loaded_episodes": 50.0}
{"step": 189976, "train_return": -20.0, "train_length": 885.0, "train_total_steps": 47494.0, "train_total_episodes": 51.0, "train_loaded_steps": 47494.0, "train_loaded_episodes": 51.0}
{"step": 193828, "train_return": -21.0, "train_length": 963.0, "train_total_steps": 48457.0, "train_total_episodes": 52.0, "train_loaded_steps": 48457.0, "train_loaded_episodes": 52.0}
{"step": 197340, "train_return": -21.0, "train_length": 878.0, "train_total_steps": 49335.0, "train_total_episodes": 53.0, "train_loaded_steps": 49335.0, "train_loaded_episodes": 53.0}
{"step": 200000, "eval_return": -21.0, "eval_length": 908.0, "eval_total_steps": 0.0, "eval_total_episodes": 0.0, "eval_loaded_steps": 0.0, "eval_loaded_episodes": 0.0}
{"step": 201356, "train_return": -19.0, "train_length": 1057.0, "train_total_steps": 50339.0, "train_total_episodes": 54.0, "train_loaded_steps": 50392.0, "train_loaded_episodes": 54.0}
{"step": 201356, "eval_return": -20.0, "eval_length": 839.0, "eval_total_steps": 907.0, "eval_total_episodes": 1.0, "eval_loaded_steps": 908.0, "eval_loaded_episodes": 1.0}
{"step": 201352, "eval_return": -21.0, "eval_length": 822.0, "eval_total_steps": 1745.0, "eval_total_episodes": 2.0, "eval_loaded_steps": 1747.0, "eval_loaded_episodes": 2.0}
{"step": 201356, "kl_loss": 1.381870985031128, "image_loss": 3846.06494140625, "reward_loss": 0.9988292455673218, "discount_loss": 0.7885257005691528, "model_kl": 1.3818708658218384, "prior_ent": 109.9675064086914, "post_ent": 110.45510864257812, "model_loss": 3851.14453125, "model_loss_scale": 8192.0, "model_grad_norm": Infinity, "actor_loss": 0.09728476405143738, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.035144660621881485, "critic_loss": 0.21685603260993958, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.33168232440948486, "reward_mean": 0.21226635575294495, "reward_std": 0.3407071530818939, "reward_normed_mean": 0.21226635575294495, "reward_normed_std": 0.3407071530818939, "critic_slow": 0.06224769726395607, "critic_target": 0.37698617577552795, "actor_ent": 1.7569127082824707, "actor_ent_scale": 0.0010000000474974513, "critic": 0.24852363765239716, "fps": 0.0}
{"step": 204660, "train_return": -21.0, "train_length": 827.0, "train_total_steps": 51165.0, "train_total_episodes": 55.0, "train_loaded_steps": 51219.0, "train_loaded_episodes": 55.0}
{"step": 208324, "train_return": -20.0, "train_length": 916.0, "train_total_steps": 52081.0, "train_total_episodes": 56.0, "train_loaded_steps": 52135.0, "train_loaded_episodes": 56.0}
{"step": 211444, "train_return": -21.0, "train_length": 780.0, "train_total_steps": 52861.0, "train_total_episodes": 57.0, "train_loaded_steps": 52915.0, "train_loaded_episodes": 57.0}
{"step": 215028, "train_return": -20.0, "train_length": 896.0, "train_total_steps": 53757.0, "train_total_episodes": 58.0, "train_loaded_steps": 53811.0, "train_loaded_episodes": 58.0}
{"step": 218132, "train_return": -21.0, "train_length": 776.0, "train_total_steps": 54533.0, "train_total_episodes": 59.0, "train_loaded_steps": 54587.0, "train_loaded_episodes": 59.0}
{"step": 221256, "train_return": -21.0, "train_length": 781.0, "train_total_steps": 55314.0, "train_total_episodes": 60.0, "train_loaded_steps": 55368.0, "train_loaded_episodes": 60.0}
{"step": 224388, "train_return": -21.0, "train_length": 783.0, "train_total_steps": 56097.0, "train_total_episodes": 61.0, "train_loaded_steps": 56151.0, "train_loaded_episodes": 61.0}
{"step": 227748, "train_return": -20.0, "train_length": 840.0, "train_total_steps": 56937.0, "train_total_episodes": 62.0, "train_loaded_steps": 56991.0, "train_loaded_episodes": 62.0}
{"step": 231228, "train_return": -20.0, "train_length": 870.0, "train_total_steps": 57807.0, "train_total_episodes": 63.0, "train_loaded_steps": 57861.0, "train_loaded_episodes": 63.0}
{"step": 235464, "train_return": -20.0, "train_length": 1059.0, "train_total_steps": 58866.0, "train_total_episodes": 64.0, "train_loaded_steps": 58920.0, "train_loaded_episodes": 64.0}
{"step": 239092, "train_return": -21.0, "train_length": 907.0, "train_total_steps": 59773.0, "train_total_episodes": 65.0, "train_loaded_steps": 59827.0, "train_loaded_episodes": 65.0}
{"step": 241356, "kl_loss": 0.12406838176995516, "image_loss": 3773.894938671875, "reward_loss": 0.9272493856430054, "discount_loss": 0.024787644266337155, "model_kl": 0.12406837953925133, "prior_ent": 103.27330465087891, "post_ent": 103.20043404541016, "model_loss": 3774.958535546875, "model_loss_scale": 139.6736, "model_grad_norm": Infinity, "actor_loss": -0.15222251074075466, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.024375516954809426, "critic_loss": 0.9207257545471191, "critic_loss_scale": 32768.0, "critic_grad_norm": 1.0270139413341879, "reward_mean": -0.016502228444127832, "reward_std": 0.02594049468934536, "reward_normed_mean": -0.016502228444127832, "reward_normed_std": 0.02594049468934536, "critic_slow": -0.09405328439623117, "critic_target": -0.19894847626481205, "actor_ent": 1.525356294631958, "actor_ent_scale": 0.0010000000474974513, "critic": -0.193053143298754, "fps": 110.47288001173666}
{"step": 242384, "train_return": -21.0, "train_length": 823.0, "train_total_steps": 60596.0, "train_total_episodes": 66.0, "train_loaded_steps": 60650.0, "train_loaded_episodes": 66.0}
{"step": 245536, "train_return": -21.0, "train_length": 788.0, "train_total_steps": 61384.0, "train_total_episodes": 67.0, "train_loaded_steps": 61438.0, "train_loaded_episodes": 67.0}
{"step": 249232, "train_return": -20.0, "train_length": 924.0, "train_total_steps": 62308.0, "train_total_episodes": 68.0, "train_loaded_steps": 62362.0, "train_loaded_episodes": 68.0}
{"step": 252616, "train_return": -21.0, "train_length": 846.0, "train_total_steps": 63154.0, "train_total_episodes": 69.0, "train_loaded_steps": 63208.0, "train_loaded_episodes": 69.0}
{"step": 256376, "train_return": -20.0, "train_length": 940.0, "train_total_steps": 64094.0, "train_total_episodes": 70.0, "train_loaded_steps": 64148.0, "train_loaded_episodes": 70.0}
{"step": 259524, "train_return": -21.0, "train_length": 787.0, "train_total_steps": 64881.0, "train_total_episodes": 71.0, "train_loaded_steps": 64935.0, "train_loaded_episodes": 71.0}
{"step": 263368, "train_return": -21.0, "train_length": 961.0, "train_total_steps": 65842.0, "train_total_episodes": 72.0, "train_loaded_steps": 65896.0, "train_loaded_episodes": 72.0}
{"step": 266596, "train_return": -21.0, "train_length": 807.0, "train_total_steps": 66649.0, "train_total_episodes": 73.0, "train_loaded_steps": 66703.0, "train_loaded_episodes": 73.0}
{"step": 270624, "train_return": -20.0, "train_length": 1007.0, "train_total_steps": 67656.0, "train_total_episodes": 74.0, "train_loaded_steps": 67710.0, "train_loaded_episodes": 74.0}
{"step": 274328, "train_return": -21.0, "train_length": 926.0, "train_total_steps": 68582.0, "train_total_episodes": 75.0, "train_loaded_steps": 68636.0, "train_loaded_episodes": 75.0}
{"step": 277812, "train_return": -21.0, "train_length": 871.0, "train_total_steps": 69453.0, "train_total_episodes": 76.0, "train_loaded_steps": 69507.0, "train_loaded_episodes": 76.0}
{"step": 280936, "train_return": -21.0, "train_length": 781.0, "train_total_steps": 70234.0, "train_total_episodes": 77.0, "train_loaded_steps": 70288.0, "train_loaded_episodes": 77.0}
{"step": 281356, "kl_loss": 0.013554785367846489, "image_loss": 3772.0, "reward_loss": 0.9262090842247009, "discount_loss": 0.01512821753025055, "model_kl": 0.013554785153269768, "prior_ent": 105.21517930908203, "post_ent": 105.22001147460938, "model_loss": 3773.003205859375, "model_loss_scale": 128.0, "model_grad_norm": 4.883403370475769, "actor_loss": -0.12974230234446005, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.014848061667382718, "critic_loss": 0.9082721653938294, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.5753939557775855, "reward_mean": -0.018381339682100224, "reward_std": 0.017206164973974227, "reward_normed_mean": -0.018381339682100224, "reward_normed_std": 0.017206164973974227, "critic_slow": -0.7900151686668396, "critic_target": -0.8743769934654236, "actor_ent": 1.7045752603530884, "actor_ent_scale": 0.0010000000474974513, "critic": -0.8738142409324646, "fps": 112.7761927815368}
{"step": 284864, "train_return": -20.0, "train_length": 982.0, "train_total_steps": 71216.0, "train_total_episodes": 78.0, "train_loaded_steps": 71270.0, "train_loaded_episodes": 78.0}
{"step": 288012, "train_return": -21.0, "train_length": 787.0, "train_total_steps": 72003.0, "train_total_episodes": 79.0, "train_loaded_steps": 72057.0, "train_loaded_episodes": 79.0}
{"step": 292560, "train_return": -20.0, "train_length": 1137.0, "train_total_steps": 73140.0, "train_total_episodes": 80.0, "train_loaded_steps": 73194.0, "train_loaded_episodes": 80.0}
{"step": 296140, "train_return": -20.0, "train_length": 895.0, "train_total_steps": 74035.0, "train_total_episodes": 81.0, "train_loaded_steps": 74089.0, "train_loaded_episodes": 81.0}
{"step": 299412, "train_return": -21.0, "train_length": 818.0, "train_total_steps": 74853.0, "train_total_episodes": 82.0, "train_loaded_steps": 74907.0, "train_loaded_episodes": 82.0}
{"step": 302692, "train_return": -21.0, "train_length": 820.0, "train_total_steps": 75673.0, "train_total_episodes": 83.0, "train_loaded_steps": 75727.0, "train_loaded_episodes": 83.0}
{"step": 305804, "train_return": -21.0, "train_length": 778.0, "train_total_steps": 76451.0, "train_total_episodes": 84.0, "train_loaded_steps": 76505.0, "train_loaded_episodes": 84.0}
{"step": 308848, "train_return": -21.0, "train_length": 761.0, "train_total_steps": 77212.0, "train_total_episodes": 85.0, "train_loaded_steps": 77266.0, "train_loaded_episodes": 85.0}
{"step": 312980, "train_return": -20.0, "train_length": 1033.0, "train_total_steps": 78245.0, "train_total_episodes": 86.0, "train_loaded_steps": 78299.0, "train_loaded_episodes": 86.0}
{"step": 316648, "train_return": -20.0, "train_length": 917.0, "train_total_steps": 79162.0, "train_total_episodes": 87.0, "train_loaded_steps": 79216.0, "train_loaded_episodes": 87.0}
{"step": 321356, "kl_loss": 0.012776793431490659, "image_loss": 3772.0, "reward_loss": 0.9261488010406494, "discount_loss": 0.014573180387914181, "model_kl": 0.012776793241500854, "prior_ent": 108.88801021728516, "post_ent": 108.89189680175781, "model_loss": 3773.0002953125, "model_loss_scale": 128.0, "model_grad_norm": 4.890925368309021, "actor_loss": -0.03153126904880628, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.010072738552093506, "critic_loss": 0.9028370190620423, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.38904203292131423, "reward_mean": -0.018780230623390525, "reward_std": 0.01667437711954117, "reward_normed_mean": -0.018780230623390525, "reward_normed_std": 0.01667437711954117, "critic_slow": -0.9747429079055786, "critic_target": -1.008558819770813, "actor_ent": 1.7348765285491943, "actor_ent_scale": 0.0010000000474974513, "critic": -1.0085744201660156, "fps": 115.02235442709683}
{"step": 322116, "train_return": -20.0, "train_length": 1367.0, "train_total_steps": 80529.0, "train_total_episodes": 88.0, "train_loaded_steps": 80583.0, "train_loaded_episodes": 88.0}
{"step": 326336, "train_return": -19.0, "train_length": 1055.0, "train_total_steps": 81584.0, "train_total_episodes": 89.0, "train_loaded_steps": 81638.0, "train_loaded_episodes": 89.0}
{"step": 329756, "train_return": -20.0, "train_length": 855.0, "train_total_steps": 82439.0, "train_total_episodes": 90.0, "train_loaded_steps": 82493.0, "train_loaded_episodes": 90.0}
{"step": 333288, "train_return": -21.0, "train_length": 883.0, "train_total_steps": 83322.0, "train_total_episodes": 91.0, "train_loaded_steps": 83376.0, "train_loaded_episodes": 91.0}
{"step": 336680, "train_return": -21.0, "train_length": 848.0, "train_total_steps": 84170.0, "train_total_episodes": 92.0, "train_loaded_steps": 84224.0, "train_loaded_episodes": 92.0}
{"step": 339952, "train_return": -21.0, "train_length": 818.0, "train_total_steps": 84988.0, "train_total_episodes": 93.0, "train_loaded_steps": 85042.0, "train_loaded_episodes": 93.0}
{"step": 343232, "train_return": -21.0, "train_length": 820.0, "train_total_steps": 85808.0, "train_total_episodes": 94.0, "train_loaded_steps": 85862.0, "train_loaded_episodes": 94.0}
{"step": 347248, "train_return": -21.0, "train_length": 1004.0, "train_total_steps": 86812.0, "train_total_episodes": 95.0, "train_loaded_steps": 86866.0, "train_loaded_episodes": 95.0}
{"step": 350520, "train_return": -21.0, "train_length": 818.0, "train_total_steps": 87630.0, "train_total_episodes": 96.0, "train_loaded_steps": 87684.0, "train_loaded_episodes": 96.0}
{"step": 354368, "train_return": -20.0, "train_length": 962.0, "train_total_steps": 88592.0, "train_total_episodes": 97.0, "train_loaded_steps": 88646.0, "train_loaded_episodes": 97.0}
{"step": 357492, "train_return": -21.0, "train_length": 781.0, "train_total_steps": 89373.0, "train_total_episodes": 98.0, "train_loaded_steps": 89427.0, "train_loaded_episodes": 98.0}
{"step": 361356, "kl_loss": 0.017977082340419292, "image_loss": 3772.0, "reward_loss": 0.9260705263137817, "discount_loss": 0.01436643977612257, "model_kl": 0.017977082040905954, "prior_ent": 109.98091499023438, "post_ent": 109.98232181396484, "model_loss": 3772.99969296875, "model_loss_scale": 229.376, "model_grad_norm": 6.119860396766662, "actor_loss": 0.05508178246282041, "actor_loss_scale": 59139.6864, "actor_grad_norm": 0.009434717611968518, "critic_loss": 0.8980364067077636, "critic_loss_scale": 59139.6864, "critic_grad_norm": 0.27229201184362173, "reward_mean": -0.01865089982468635, "reward_std": 0.01592586552798748, "reward_normed_mean": -0.01865089982468635, "reward_normed_std": 0.01592586552798748, "critic_slow": -0.9012316246032714, "critic_target": -0.8932233410835266, "actor_ent": 1.6782967992782594, "actor_ent_scale": 0.0010000000474974513, "critic": -0.892014070224762, "fps": 114.84967010088042}
{"step": 361524, "train_return": -21.0, "train_length": 1008.0, "train_total_steps": 90381.0, "train_total_episodes": 99.0, "train_loaded_steps": 90435.0, "train_loaded_episodes": 99.0}
{"step": 365156, "train_return": -21.0, "train_length": 908.0, "train_total_steps": 91289.0, "train_total_episodes": 100.0, "train_loaded_steps": 91343.0, "train_loaded_episodes": 100.0}
{"step": 368604, "train_return": -20.0, "train_length": 862.0, "train_total_steps": 92151.0, "train_total_episodes": 101.0, "train_loaded_steps": 92205.0, "train_loaded_episodes": 101.0}
{"step": 371884, "train_return": -21.0, "train_length": 820.0, "train_total_steps": 92971.0, "train_total_episodes": 102.0, "train_loaded_steps": 93025.0, "train_loaded_episodes": 102.0}
{"step": 375232, "train_return": -20.0, "train_length": 837.0, "train_total_steps": 93808.0, "train_total_episodes": 103.0, "train_loaded_steps": 93862.0, "train_loaded_episodes": 103.0}
{"step": 378636, "train_return": -21.0, "train_length": 851.0, "train_total_steps": 94659.0, "train_total_episodes": 104.0, "train_loaded_steps": 94713.0, "train_loaded_episodes": 104.0}
{"step": 382880, "train_return": -21.0, "train_length": 1061.0, "train_total_steps": 95720.0, "train_total_episodes": 105.0, "train_loaded_steps": 95774.0, "train_loaded_episodes": 105.0}
{"step": 386164, "train_return": -21.0, "train_length": 821.0, "train_total_steps": 96541.0, "train_total_episodes": 106.0, "train_loaded_steps": 96595.0, "train_loaded_episodes": 106.0}
{"step": 390784, "train_return": -21.0, "train_length": 1155.0, "train_total_steps": 97696.0, "train_total_episodes": 107.0, "train_loaded_steps": 97750.0, "train_loaded_episodes": 107.0}
{"step": 395048, "train_return": -21.0, "train_length": 1066.0, "train_total_steps": 98762.0, "train_total_episodes": 108.0, "train_loaded_steps": 98816.0, "train_loaded_episodes": 108.0}
{"step": 398416, "train_return": -20.0, "train_length": 842.0, "train_total_steps": 99604.0, "train_total_episodes": 109.0, "train_loaded_steps": 99658.0, "train_loaded_episodes": 109.0}
{"step": 401356, "kl_loss": 0.05574787170365453, "image_loss": 3772.0002, "reward_loss": 0.9261246183395385, "discount_loss": 0.014050578533113003, "model_kl": 0.055747870860993864, "prior_ent": 110.15449267578126, "post_ent": 110.11057513427734, "model_loss": 3773.002158203125, "model_loss_scale": 256.0, "model_grad_norm": 2.193279701423645, "actor_loss": -0.018836211126175475, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.008868307368829846, "critic_loss": 0.9064983768463135, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.3335160955965519, "reward_mean": -0.018568879168468992, "reward_std": 0.015150336511433125, "reward_normed_mean": -0.018568879168468992, "reward_normed_std": 0.015150336511433125, "critic_slow": -1.247300051689148, "critic_target": -1.2749167358398437, "actor_ent": 1.7034104600906372, "actor_ent_scale": 0.0010000000474974513, "critic": -1.274650442123413, "fps": 115.14412323776212}
{"step": 401540, "train_return": -21.0, "train_length": 781.0, "train_total_steps": 100385.0, "train_total_episodes": 110.0, "train_loaded_steps": 100439.0, "train_loaded_episodes": 110.0}
{"step": 404820, "train_return": -21.0, "train_length": 820.0, "train_total_steps": 101205.0, "train_total_episodes": 111.0, "train_loaded_steps": 101259.0, "train_loaded_episodes": 111.0}
{"step": 408104, "train_return": -21.0, "train_length": 821.0, "train_total_steps": 102026.0, "train_total_episodes": 112.0, "train_loaded_steps": 102080.0, "train_loaded_episodes": 112.0}
{"step": 411380, "train_return": -21.0, "train_length": 819.0, "train_total_steps": 102845.0, "train_total_episodes": 113.0, "train_loaded_steps": 102899.0, "train_loaded_episodes": 113.0}
{"step": 414912, "train_return": -21.0, "train_length": 883.0, "train_total_steps": 103728.0, "train_total_episodes": 114.0, "train_loaded_steps": 103782.0, "train_loaded_episodes": 114.0}
{"step": 418208, "train_return": -21.0, "train_length": 824.0, "train_total_steps": 104552.0, "train_total_episodes": 115.0, "train_loaded_steps": 104606.0, "train_loaded_episodes": 115.0}
{"step": 421484, "train_return": -21.0, "train_length": 819.0, "train_total_steps": 105371.0, "train_total_episodes": 116.0, "train_loaded_steps": 105425.0, "train_loaded_episodes": 116.0}
{"step": 424652, "train_return": -21.0, "train_length": 792.0, "train_total_steps": 106163.0, "train_total_episodes": 117.0, "train_loaded_steps": 106217.0, "train_loaded_episodes": 117.0}
{"step": 428412, "train_return": -21.0, "train_length": 940.0, "train_total_steps": 107103.0, "train_total_episodes": 118.0, "train_loaded_steps": 107157.0, "train_loaded_episodes": 118.0}
{"step": 431684, "train_return": -21.0, "train_length": 818.0, "train_total_steps": 107921.0, "train_total_episodes": 119.0, "train_loaded_steps": 107975.0, "train_loaded_episodes": 119.0}
{"step": 435528, "train_return": -20.0, "train_length": 961.0, "train_total_steps": 108882.0, "train_total_episodes": 120.0, "train_loaded_steps": 108936.0, "train_loaded_episodes": 120.0}
{"step": 439044, "train_return": -21.0, "train_length": 879.0, "train_total_steps": 109761.0, "train_total_episodes": 121.0, "train_loaded_steps": 109815.0, "train_loaded_episodes": 121.0}
{"step": 441356, "kl_loss": 0.3157431695759296, "image_loss": 3772.000187890625, "reward_loss": 0.9259642181396485, "discount_loss": 0.012356516033411025, "model_kl": 0.3157431647926569, "prior_ent": 90.29396228027343, "post_ent": 89.97113394775391, "model_loss": 3773.019508203125, "model_loss_scale": 256.0, "model_grad_norm": 3.9787372215270995, "actor_loss": -0.007462226722412743, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.008898428582027555, "critic_loss": 0.9078140572547913, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.2848507404498756, "reward_mean": -0.01864224793706089, "reward_std": 0.01605306714475155, "reward_normed_mean": -0.01864224793706089, "reward_normed_std": 0.01605306714475155, "critic_slow": -1.439586307144165, "critic_target": -1.4640192169189452, "actor_ent": 1.6273893152236938, "actor_ent_scale": 0.0010000000474974513, "critic": -1.4623002912521361, "fps": 113.12947353135215}
{"step": 442404, "train_return": -21.0, "train_length": 840.0, "train_total_steps": 110601.0, "train_total_episodes": 122.0, "train_loaded_steps": 110655.0, "train_loaded_episodes": 122.0}
{"step": 446288, "train_return": -21.0, "train_length": 971.0, "train_total_steps": 111572.0, "train_total_episodes": 123.0, "train_loaded_steps": 111626.0, "train_loaded_episodes": 123.0}
{"step": 449440, "train_return": -21.0, "train_length": 788.0, "train_total_steps": 112360.0, "train_total_episodes": 124.0, "train_loaded_steps": 112414.0, "train_loaded_episodes": 124.0}
{"step": 452732, "train_return": -21.0, "train_length": 823.0, "train_total_steps": 113183.0, "train_total_episodes": 125.0, "train_loaded_steps": 113237.0, "train_loaded_episodes": 125.0}
{"step": 456552, "train_return": -20.0, "train_length": 955.0, "train_total_steps": 114138.0, "train_total_episodes": 126.0, "train_loaded_steps": 114192.0, "train_loaded_episodes": 126.0}
{"step": 459584, "train_return": -21.0, "train_length": 758.0, "train_total_steps": 114896.0, "train_total_episodes": 127.0, "train_loaded_steps": 114950.0, "train_loaded_episodes": 127.0}
{"step": 462628, "train_return": -21.0, "train_length": 761.0, "train_total_steps": 115657.0, "train_total_episodes": 128.0, "train_loaded_steps": 115711.0, "train_loaded_episodes": 128.0}
{"step": 465684, "train_return": -21.0, "train_length": 764.0, "train_total_steps": 116421.0, "train_total_episodes": 129.0, "train_loaded_steps": 116475.0, "train_loaded_episodes": 129.0}
{"step": 468712, "train_return": -21.0, "train_length": 757.0, "train_total_steps": 117178.0, "train_total_episodes": 130.0, "train_loaded_steps": 117232.0, "train_loaded_episodes": 130.0}
{"step": 471740, "train_return": -21.0, "train_length": 757.0, "train_total_steps": 117935.0, "train_total_episodes": 131.0, "train_loaded_steps": 117989.0, "train_loaded_episodes": 131.0}
{"step": 474780, "train_return": -21.0, "train_length": 760.0, "train_total_steps": 118695.0, "train_total_episodes": 132.0, "train_loaded_steps": 118749.0, "train_loaded_episodes": 132.0}
{"step": 477836, "train_return": -21.0, "train_length": 764.0, "train_total_steps": 119459.0, "train_total_episodes": 133.0, "train_loaded_steps": 119513.0, "train_loaded_episodes": 133.0}
{"step": 480884, "train_return": -21.0, "train_length": 762.0, "train_total_steps": 120221.0, "train_total_episodes": 134.0, "train_loaded_steps": 120275.0, "train_loaded_episodes": 134.0}
{"step": 481356, "kl_loss": 0.487997327542305, "image_loss": 3772.0, "reward_loss": 0.925511627960205, "discount_loss": 0.010744742687046527, "model_kl": 0.48799731895923615, "prior_ent": 53.86443307495117, "post_ent": 53.371953295898436, "model_loss": 3773.028033203125, "model_loss_scale": 407.552, "model_grad_norm": 3.2477120168685913, "actor_loss": -0.021444417700520718, "actor_loss_scale": 105172.1728, "actor_grad_norm": 0.01019010457880795, "critic_loss": 0.9123889629364014, "critic_loss_scale": 105172.1728, "critic_grad_norm": 0.4364379167586565, "reward_mean": -0.016992528679035057, "reward_std": 0.023873370411992074, "reward_normed_mean": -0.016992528679035057, "reward_normed_std": 0.023873370411992074, "critic_slow": -1.7184061937332153, "critic_target": -1.7552777948379517, "actor_ent": 0.9983295618534088, "actor_ent_scale": 0.0010000000474974513, "critic": -1.7542110778808593, "fps": 115.12456972703143}
{"step": 483940, "train_return": -21.0, "train_length": 764.0, "train_total_steps": 120985.0, "train_total_episodes": 135.0, "train_loaded_steps": 121039.0, "train_loaded_episodes": 135.0}
{"step": 486996, "train_return": -21.0, "train_length": 764.0, "train_total_steps": 121749.0, "train_total_episodes": 136.0, "train_loaded_steps": 121803.0, "train_loaded_episodes": 136.0}
{"step": 490044, "train_return": -21.0, "train_length": 762.0, "train_total_steps": 122511.0, "train_total_episodes": 137.0, "train_loaded_steps": 122565.0, "train_loaded_episodes": 137.0}
{"step": 493072, "train_return": -21.0, "train_length": 757.0, "train_total_steps": 123268.0, "train_total_episodes": 138.0, "train_loaded_steps": 123322.0, "train_loaded_episodes": 138.0}
{"step": 496124, "train_return": -21.0, "train_length": 763.0, "train_total_steps": 124031.0, "train_total_episodes": 139.0, "train_loaded_steps": 124085.0, "train_loaded_episodes": 139.0}
{"step": 499164, "train_return": -21.0, "train_length": 760.0, "train_total_steps": 124791.0, "train_total_episodes": 140.0, "train_loaded_steps": 124845.0, "train_loaded_episodes": 140.0}
{"step": 502200, "train_return": -21.0, "train_length": 759.0, "train_total_steps": 125550.0, "train_total_episodes": 141.0, "train_loaded_steps": 125604.0, "train_loaded_episodes": 141.0}
{"step": 505256, "train_return": -21.0, "train_length": 764.0, "train_total_steps": 126314.0, "train_total_episodes": 142.0, "train_loaded_steps": 126368.0, "train_loaded_episodes": 142.0}
{"step": 508284, "train_return": -21.0, "train_length": 757.0, "train_total_steps": 127071.0, "train_total_episodes": 143.0, "train_loaded_steps": 127125.0, "train_loaded_episodes": 143.0}
{"step": 511328, "train_return": -21.0, "train_length": 761.0, "train_total_steps": 127832.0, "train_total_episodes": 144.0, "train_loaded_steps": 127886.0, "train_loaded_episodes": 144.0}
{"step": 514372, "train_return": -21.0, "train_length": 761.0, "train_total_steps": 128593.0, "train_total_episodes": 145.0, "train_loaded_steps": 128647.0, "train_loaded_episodes": 145.0}
{"step": 517416, "train_return": -21.0, "train_length": 761.0, "train_total_steps": 129354.0, "train_total_episodes": 146.0, "train_loaded_steps": 129408.0, "train_loaded_episodes": 146.0}
{"step": 520472, "train_return": -21.0, "train_length": 764.0, "train_total_steps": 130118.0, "train_total_episodes": 147.0, "train_loaded_steps": 130172.0, "train_loaded_episodes": 147.0}
{"step": 521356, "kl_loss": 1.2127606484413147, "image_loss": 3772.0, "reward_loss": 0.9241064512252808, "discount_loss": 0.009583167289942502, "model_kl": 1.2127606282234191, "prior_ent": 33.5054049041748, "post_ent": 32.24073539428711, "model_loss": 3773.09330078125, "model_loss_scale": 512.0, "model_grad_norm": 3.810668105125427, "actor_loss": -0.013309712160506752, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.014724089677631854, "critic_loss": 0.9232629506111145, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.5475330050110817, "reward_mean": -0.01811148096806137, "reward_std": 0.05716797868609429, "reward_normed_mean": -0.01811148096806137, "reward_normed_std": 0.05716797868609429, "critic_slow": -1.9459297126770019, "critic_target": -1.9833305578231812, "actor_ent": 0.47657566773891447, "actor_ent_scale": 0.0010000000474974513, "critic": -1.9826034719467163, "fps": 114.85001391236972}
{"step": 523508, "train_return": -21.0, "train_length": 759.0, "train_total_steps": 130877.0, "train_total_episodes": 148.0, "train_loaded_steps": 130931.0, "train_loaded_episodes": 148.0}
{"step": 526540, "train_return": -21.0, "train_length": 758.0, "train_total_steps": 131635.0, "train_total_episodes": 149.0, "train_loaded_steps": 131689.0, "train_loaded_episodes": 149.0}
{"step": 529592, "train_return": -21.0, "train_length": 763.0, "train_total_steps": 132398.0, "train_total_episodes": 150.0, "train_loaded_steps": 132452.0, "train_loaded_episodes": 150.0}
{"step": 532636, "train_return": -21.0, "train_length": 761.0, "train_total_steps": 133159.0, "train_total_episodes": 151.0, "train_loaded_steps": 133213.0, "train_loaded_episodes": 151.0}
{"step": 535676, "train_return": -21.0, "train_length": 760.0, "train_total_steps": 133919.0, "train_total_episodes": 152.0, "train_loaded_steps": 133973.0, "train_loaded_episodes": 152.0}
{"step": 538712, "train_return": -21.0, "train_length": 759.0, "train_total_steps": 134678.0, "train_total_episodes": 153.0, "train_loaded_steps": 134732.0, "train_loaded_episodes": 153.0}
{"step": 541764, "train_return": -21.0, "train_length": 763.0, "train_total_steps": 135441.0, "train_total_episodes": 154.0, "train_loaded_steps": 135495.0, "train_loaded_episodes": 154.0}
{"step": 544800, "train_return": -21.0, "train_length": 759.0, "train_total_steps": 136200.0, "train_total_episodes": 155.0, "train_loaded_steps": 136254.0, "train_loaded_episodes": 155.0}
{"step": 547832, "train_return": -21.0, "train_length": 758.0, "train_total_steps": 136958.0, "train_total_episodes": 156.0, "train_loaded_steps": 137012.0, "train_loaded_episodes": 156.0}
{"step": 550880, "train_return": -21.0, "train_length": 762.0, "train_total_steps": 137720.0, "train_total_episodes": 157.0, "train_loaded_steps": 137774.0, "train_loaded_episodes": 157.0}
{"step": 553916, "train_return": -21.0, "train_length": 759.0, "train_total_steps": 138479.0, "train_total_episodes": 158.0, "train_loaded_steps": 138533.0, "train_loaded_episodes": 158.0}
{"step": 556968, "train_return": -21.0, "train_length": 763.0, "train_total_steps": 139242.0, "train_total_episodes": 159.0, "train_loaded_steps": 139296.0, "train_loaded_episodes": 159.0}
{"step": 560012, "train_return": -21.0, "train_length": 761.0, "train_total_steps": 140003.0, "train_total_episodes": 160.0, "train_loaded_steps": 140057.0, "train_loaded_episodes": 160.0}
{"step": 561356, "kl_loss": 1.1390365045547486, "image_loss": 3772.0, "reward_loss": 0.922096131515503, "discount_loss": 0.00889197505787015, "model_kl": 1.1390364987373351, "prior_ent": 27.911785696411133, "post_ent": 26.740757174682617, "model_loss": 3773.080475, "model_loss_scale": 512.0, "model_grad_norm": 3.3238782762527466, "actor_loss": -0.025118627126776847, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.013634758953005076, "critic_loss": 0.9172430252075195, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4280744985342026, "reward_mean": -0.01752532168928301, "reward_std": 0.08505627928376198, "reward_normed_mean": -0.01752532168928301, "reward_normed_std": 0.08505627928376198, "critic_slow": -2.197159363937378, "critic_target": -2.259722798728943, "actor_ent": 0.43739017224311827, "actor_ent_scale": 0.0010000000474974513, "critic": -2.2594731111526487, "fps": 113.71629119342744}
{"step": 563060, "train_return": -21.0, "train_length": 762.0, "train_total_steps": 140765.0, "train_total_episodes": 161.0, "train_loaded_steps": 140819.0, "train_loaded_episodes": 161.0}
{"step": 566112, "train_return": -21.0, "train_length": 763.0, "train_total_steps": 141528.0, "train_total_episodes": 162.0, "train_loaded_steps": 141582.0, "train_loaded_episodes": 162.0}
{"step": 569148, "train_return": -21.0, "train_length": 759.0, "train_total_steps": 142287.0, "train_total_episodes": 163.0, "train_loaded_steps": 142341.0, "train_loaded_episodes": 163.0}
{"step": 572184, "train_return": -21.0, "train_length": 759.0, "train_total_steps": 143046.0, "train_total_episodes": 164.0, "train_loaded_steps": 143100.0, "train_loaded_episodes": 164.0}
{"step": 575228, "train_return": -21.0, "train_length": 761.0, "train_total_steps": 143807.0, "train_total_episodes": 165.0, "train_loaded_steps": 143861.0, "train_loaded_episodes": 165.0}
{"step": 578508, "train_return": -21.0, "train_length": 820.0, "train_total_steps": 144627.0, "train_total_episodes": 166.0, "train_loaded_steps": 144681.0, "train_loaded_episodes": 166.0}
{"step": 581556, "train_return": -21.0, "train_length": 762.0, "train_total_steps": 145389.0, "train_total_episodes": 167.0, "train_loaded_steps": 145443.0, "train_loaded_episodes": 167.0}
{"step": 584588, "train_return": -21.0, "train_length": 758.0, "train_total_steps": 146147.0, "train_total_episodes": 168.0, "train_loaded_steps": 146201.0, "train_loaded_episodes": 168.0}
{"step": 587832, "train_return": -21.0, "train_length": 811.0, "train_total_steps": 146958.0, "train_total_episodes": 169.0, "train_loaded_steps": 147012.0, "train_loaded_episodes": 169.0}
{"step": 591484, "train_return": -21.0, "train_length": 913.0, "train_total_steps": 147871.0, "train_total_episodes": 170.0, "train_loaded_steps": 147925.0, "train_loaded_episodes": 170.0}
{"step": 594596, "train_return": -21.0, "train_length": 778.0, "train_total_steps": 148649.0, "train_total_episodes": 171.0, "train_loaded_steps": 148703.0, "train_loaded_episodes": 171.0}
{"step": 597924, "train_return": -20.0, "train_length": 832.0, "train_total_steps": 149481.0, "train_total_episodes": 172.0, "train_loaded_steps": 149535.0, "train_loaded_episodes": 172.0}
{"step": 601084, "train_return": -21.0, "train_length": 790.0, "train_total_steps": 150271.0, "train_total_episodes": 173.0, "train_loaded_steps": 150325.0, "train_loaded_episodes": 173.0}
{"step": 601356, "kl_loss": 1.1624334645271301, "image_loss": 3772.000380078125, "reward_loss": 0.9213946308135986, "discount_loss": 0.008543511785566806, "model_kl": 1.1624334560394287, "prior_ent": 27.224079458618164, "post_ent": 26.021773971557618, "model_loss": 3773.08073515625, "model_loss_scale": 712.704, "model_grad_norm": 3.0365823596954344, "actor_loss": -0.036513111208705235, "actor_loss_scale": 184129.9456, "actor_grad_norm": 0.020570385862886904, "critic_loss": 0.9189736721992493, "critic_loss_scale": 184129.9456, "critic_grad_norm": 0.4277660341143608, "reward_mean": -0.017454719443223438, "reward_std": 0.0929064357638359, "reward_normed_mean": -0.017454719443223438, "reward_normed_std": 0.0929064357638359, "critic_slow": -2.4787254449844363, "critic_target": -2.538243606567383, "actor_ent": 0.6712610110282898, "actor_ent_scale": 0.0010000000474974513, "critic": -2.538682196998596, "fps": 114.639156274599}
{"step": 604424, "train_return": -20.0, "train_length": 835.0, "train_total_steps": 151106.0, "train_total_episodes": 174.0, "train_loaded_steps": 151160.0, "train_loaded_episodes": 174.0}
{"step": 607768, "train_return": -20.0, "train_length": 836.0, "train_total_steps": 151942.0, "train_total_episodes": 175.0, "train_loaded_steps": 151996.0, "train_loaded_episodes": 175.0}
{"step": 611540, "train_return": -20.0, "train_length": 943.0, "train_total_steps": 152885.0, "train_total_episodes": 176.0, "train_loaded_steps": 152939.0, "train_loaded_episodes": 176.0}
{"step": 615224, "train_return": -20.0, "train_length": 921.0, "train_total_steps": 153806.0, "train_total_episodes": 177.0, "train_loaded_steps": 153860.0, "train_loaded_episodes": 177.0}
{"step": 620100, "train_return": -20.0, "train_length": 1219.0, "train_total_steps": 155025.0, "train_total_episodes": 178.0, "train_loaded_steps": 155079.0, "train_loaded_episodes": 178.0}
{"step": 625792, "train_return": -18.0, "train_length": 1423.0, "train_total_steps": 156448.0, "train_total_episodes": 179.0, "train_loaded_steps": 156502.0, "train_loaded_episodes": 179.0}
{"step": 631216, "train_return": -21.0, "train_length": 1356.0, "train_total_steps": 157804.0, "train_total_episodes": 180.0, "train_loaded_steps": 157858.0, "train_loaded_episodes": 180.0}
{"step": 638416, "train_return": -18.0, "train_length": 1800.0, "train_total_steps": 159604.0, "train_total_episodes": 181.0, "train_loaded_steps": 159658.0, "train_loaded_episodes": 181.0}
{"step": 641356, "kl_loss": 1.2648222313880921, "image_loss": 3772.0, "reward_loss": 0.9211395307540894, "discount_loss": 0.008596451180428266, "model_kl": 1.264822214603424, "prior_ent": 27.1136675201416, "post_ent": 25.809232720947264, "model_loss": 3773.09060703125, "model_loss_scale": 1024.0, "model_grad_norm": 3.0151857995986937, "actor_loss": -0.019719728042915084, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.03283856544792652, "critic_loss": 0.9210029385566711, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.3628908072948456, "reward_mean": -0.01677403800371103, "reward_std": 0.0952670364201069, "reward_normed_mean": -0.01677403800371103, "reward_normed_std": 0.0952670364201069, "critic_slow": -2.4469404987335204, "critic_target": -2.481382399559021, "actor_ent": 0.8006964023590087, "actor_ent_scale": 0.0010000000474974513, "critic": -2.481015942955017, "fps": 113.89745027740376}
{"step": 643896, "train_return": -16.0, "train_length": 1370.0, "train_total_steps": 160974.0, "train_total_episodes": 182.0, "train_loaded_steps": 161028.0, "train_loaded_episodes": 182.0}
{"step": 649332, "train_return": -17.0, "train_length": 1359.0, "train_total_steps": 162333.0, "train_total_episodes": 183.0, "train_loaded_steps": 162387.0, "train_loaded_episodes": 183.0}
{"step": 657868, "train_return": -13.0, "train_length": 2134.0, "train_total_steps": 164467.0, "train_total_episodes": 184.0, "train_loaded_steps": 164521.0, "train_loaded_episodes": 184.0}
{"step": 664860, "train_return": -16.0, "train_length": 1748.0, "train_total_steps": 166215.0, "train_total_episodes": 185.0, "train_loaded_steps": 166269.0, "train_loaded_episodes": 185.0}
{"step": 672336, "train_return": -16.0, "train_length": 1869.0, "train_total_steps": 168084.0, "train_total_episodes": 186.0, "train_loaded_steps": 168138.0, "train_loaded_episodes": 186.0}
{"step": 678244, "train_return": -19.0, "train_length": 1477.0, "train_total_steps": 169561.0, "train_total_episodes": 187.0, "train_loaded_steps": 169615.0, "train_loaded_episodes": 187.0}
{"step": 681356, "kl_loss": 1.2686811796188355, "image_loss": 3772.0, "reward_loss": 0.9208505080223084, "discount_loss": 0.00836845564097166, "model_kl": 1.2686811581611632, "prior_ent": 26.777780557250978, "post_ent": 25.48414613342285, "model_loss": 3773.089569140625, "model_loss_scale": 1024.0, "model_grad_norm": 2.260975597000122, "actor_loss": -0.009481905171979452, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.03062602456510067, "critic_loss": 0.9180924548149109, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.3149004701256752, "reward_mean": -0.0158901645160513, "reward_std": 0.0953555938243866, "reward_normed_mean": -0.0158901645160513, "reward_normed_std": 0.0953555938243866, "critic_slow": -2.5724078750610353, "critic_target": -2.5948921760559083, "actor_ent": 0.6753217054843903, "actor_ent_scale": 0.0010000000474974513, "critic": -2.5944303009033205, "fps": 115.36316627661635}
{"step": 687476, "train_return": -11.0, "train_length": 2308.0, "train_total_steps": 171869.0, "train_total_episodes": 188.0, "train_loaded_steps": 171923.0, "train_loaded_episodes": 188.0}
{"step": 695392, "train_return": -16.0, "train_length": 1979.0, "train_total_steps": 173848.0, "train_total_episodes": 189.0, "train_loaded_steps": 173902.0, "train_loaded_episodes": 189.0}
{"step": 702368, "train_return": -18.0, "train_length": 1744.0, "train_total_steps": 175592.0, "train_total_episodes": 190.0, "train_loaded_steps": 175646.0, "train_loaded_episodes": 190.0}
{"step": 710196, "train_return": -15.0, "train_length": 1957.0, "train_total_steps": 177549.0, "train_total_episodes": 191.0, "train_loaded_steps": 177603.0, "train_loaded_episodes": 191.0}
{"step": 717688, "train_return": -17.0, "train_length": 1873.0, "train_total_steps": 179422.0, "train_total_episodes": 192.0, "train_loaded_steps": 179476.0, "train_loaded_episodes": 192.0}
{"step": 721356, "kl_loss": 1.3172040100097657, "image_loss": 3772.0, "reward_loss": 0.9208184881210327, "discount_loss": 0.008264952514320611, "model_kl": 1.3172039834022522, "prior_ent": 26.7770227935791, "post_ent": 25.451847354125977, "model_loss": 3773.093890625, "model_loss_scale": 1220.608, "model_grad_norm": 2.3811444940567017, "actor_loss": -0.0048157747231176475, "actor_loss_scale": 315831.0912, "actor_grad_norm": 0.03109073119163513, "critic_loss": 0.9191251658439636, "critic_loss_scale": 268435.456, "critic_grad_norm": Infinity, "reward_mean": -0.015233495432062772, "reward_std": 0.09293907183408737, "reward_normed_mean": -0.015233495432062772, "reward_normed_std": 0.09293907183408737, "critic_slow": -2.6111392673492433, "critic_target": -2.630406610870361, "actor_ent": 0.5133413033008576, "actor_ent_scale": 0.0010000000474974513, "critic": -2.629661253738403, "fps": 113.29174179201702}
{"step": 730768, "train_return": -4.0, "train_length": 3270.0, "train_total_steps": 182692.0, "train_total_episodes": 193.0, "train_loaded_steps": 182746.0, "train_loaded_episodes": 193.0}
{"step": 739056, "train_return": -15.0, "train_length": 2072.0, "train_total_steps": 184764.0, "train_total_episodes": 194.0, "train_loaded_steps": 184818.0, "train_loaded_episodes": 194.0}
{"step": 746504, "train_return": -18.0, "train_length": 1862.0, "train_total_steps": 186626.0, "train_total_episodes": 195.0, "train_loaded_steps": 186680.0, "train_loaded_episodes": 195.0}
{"step": 755464, "train_return": -18.0, "train_length": 2240.0, "train_total_steps": 188866.0, "train_total_episodes": 196.0, "train_loaded_steps": 188920.0, "train_loaded_episodes": 196.0}
{"step": 761356, "kl_loss": 1.3060298599243163, "image_loss": 3772.0, "reward_loss": 0.92062328748703, "discount_loss": 0.008118154198676347, "model_kl": 1.3060298367500305, "prior_ent": 27.04379040222168, "post_ent": 25.727646310424806, "model_loss": 3773.091840234375, "model_loss_scale": 2048.0, "model_grad_norm": 2.764262651062012, "actor_loss": -0.00783682323313551, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.027949053648114203, "critic_loss": 0.9165337770462036, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.313817103934288, "reward_mean": -0.014210062472743448, "reward_std": 0.09110094720125199, "reward_normed_mean": -0.014210062472743448, "reward_normed_std": 0.09110094720125199, "critic_slow": -2.608942036628723, "critic_target": -2.628322773551941, "actor_ent": 0.5845371635437012, "actor_ent_scale": 0.0010000000474974513, "critic": -2.6273352695465086, "fps": 114.91017840351871}
{"step": 763796, "train_return": -13.0, "train_length": 2083.0, "train_total_steps": 190949.0, "train_total_episodes": 197.0, "train_loaded_steps": 191003.0, "train_loaded_episodes": 197.0}
{"step": 771840, "train_return": -14.0, "train_length": 2011.0, "train_total_steps": 192960.0, "train_total_episodes": 198.0, "train_loaded_steps": 193014.0, "train_loaded_episodes": 198.0}
{"step": 782344, "train_return": -12.0, "train_length": 2626.0, "train_total_steps": 195586.0, "train_total_episodes": 199.0, "train_loaded_steps": 195640.0, "train_loaded_episodes": 199.0}
{"step": 791448, "train_return": -18.0, "train_length": 2276.0, "train_total_steps": 197862.0, "train_total_episodes": 200.0, "train_loaded_steps": 197916.0, "train_loaded_episodes": 200.0}
{"step": 801356, "kl_loss": 1.3452539053916932, "image_loss": 3772.0, "reward_loss": 0.9206655475616455, "discount_loss": 0.008244285337626934, "model_kl": 1.3452538776397704, "prior_ent": 27.158444076538085, "post_ent": 25.8080860534668, "model_loss": 3773.096430078125, "model_loss_scale": 2048.0, "model_grad_norm": 2.623555097579956, "actor_loss": -0.0006779394464509096, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.02886209193766117, "critic_loss": 0.9176072736740112, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.3347233045399189, "reward_mean": -0.013651893412196659, "reward_std": 0.08848900669813156, "reward_normed_mean": -0.013651893412196659, "reward_normed_std": 0.08848900669813156, "critic_slow": -2.5853562587738037, "critic_target": -2.595187138366699, "actor_ent": 0.6068917689323425, "actor_ent_scale": 0.0010000000474974513, "critic": -2.5943456382751466, "fps": 115.98518742010255}
{"step": 802900, "train_return": -7.0, "train_length": 2863.0, "train_total_steps": 200725.0, "train_total_episodes": 201.0, "train_loaded_steps": 200779.0, "train_loaded_episodes": 201.0}
{"step": 811336, "train_return": -16.0, "train_length": 2109.0, "train_total_steps": 202834.0, "train_total_episodes": 202.0, "train_loaded_steps": 202888.0, "train_loaded_episodes": 202.0}
{"step": 821620, "train_return": -13.0, "train_length": 2571.0, "train_total_steps": 205405.0, "train_total_episodes": 203.0, "train_loaded_steps": 205459.0, "train_loaded_episodes": 203.0}
{"step": 828932, "train_return": -19.0, "train_length": 1828.0, "train_total_steps": 207233.0, "train_total_episodes": 204.0, "train_loaded_steps": 207287.0, "train_loaded_episodes": 204.0}
{"step": 837776, "train_return": -16.0, "train_length": 2211.0, "train_total_steps": 209444.0, "train_total_episodes": 205.0, "train_loaded_steps": 209498.0, "train_loaded_episodes": 205.0}
{"step": 841356, "kl_loss": 1.3333693090438843, "image_loss": 3772.0, "reward_loss": 0.9205255621910096, "discount_loss": 0.008122585713118314, "model_kl": 1.3333692867279052, "prior_ent": 27.367554290771483, "post_ent": 26.027459747314452, "model_loss": 3773.09450703125, "model_loss_scale": 2048.0, "model_grad_norm": 2.2800019711494444, "actor_loss": -0.004784499369142577, "actor_loss_scale": 526804.5824, "actor_grad_norm": 0.0291191607683897, "critic_loss": 0.9174528431892395, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.29855323771834374, "reward_mean": -0.013528344537116937, "reward_std": 0.08967160550355911, "reward_normed_mean": -0.013528344537116937, "reward_normed_std": 0.08967160550355911, "critic_slow": -2.612640154075623, "critic_target": -2.626796057128906, "actor_ent": 0.6433424297332764, "actor_ent_scale": 0.0010000000474974513, "critic": -2.62627516078949, "fps": 113.44279303306341}
{"step": 845892, "train_return": -16.0, "train_length": 2029.0, "train_total_steps": 211473.0, "train_total_episodes": 206.0, "train_loaded_steps": 211527.0, "train_loaded_episodes": 206.0}
{"step": 852752, "train_return": -19.0, "train_length": 1715.0, "train_total_steps": 213188.0, "train_total_episodes": 207.0, "train_loaded_steps": 213242.0, "train_loaded_episodes": 207.0}
{"step": 861136, "train_return": -17.0, "train_length": 2096.0, "train_total_steps": 215284.0, "train_total_episodes": 208.0, "train_loaded_steps": 215338.0, "train_loaded_episodes": 208.0}
{"step": 869372, "train_return": -15.0, "train_length": 2059.0, "train_total_steps": 217343.0, "train_total_episodes": 209.0, "train_loaded_steps": 217397.0, "train_loaded_episodes": 209.0}
{"step": 879468, "train_return": -13.0, "train_length": 2524.0, "train_total_steps": 219867.0, "train_total_episodes": 210.0, "train_loaded_steps": 219921.0, "train_loaded_episodes": 210.0}
{"step": 881356, "kl_loss": 1.353808566093445, "image_loss": 3772.0, "reward_loss": 0.9205327701568603, "discount_loss": 0.008213314550369978, "model_kl": 1.353808540058136, "prior_ent": 27.520566131591796, "post_ent": 26.16280997314453, "model_loss": 3773.09701328125, "model_loss_scale": 4079.616, "model_grad_norm": 2.5764085813522337, "actor_loss": -0.0008104705537960399, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.027312051060795785, "critic_loss": 0.9179551727294922, "critic_loss_scale": 266338.304, "critic_grad_norm": Infinity, "reward_mean": -0.012600067693390884, "reward_std": 0.08687584853172302, "reward_normed_mean": -0.012600067693390884, "reward_normed_std": 0.08687584853172302, "critic_slow": -2.5703695293426514, "critic_target": -2.576846022796631, "actor_ent": 0.4761038176059723, "actor_ent_scale": 0.0010000000474974513, "critic": -2.5767055057525634, "fps": 114.05054906100942}
{"step": 889376, "train_return": -11.0, "train_length": 2477.0, "train_total_steps": 222344.0, "train_total_episodes": 211.0, "train_loaded_steps": 222398.0, "train_loaded_episodes": 211.0}
{"step": 898568, "train_return": -16.0, "train_length": 2298.0, "train_total_steps": 224642.0, "train_total_episodes": 212.0, "train_loaded_steps": 224696.0, "train_loaded_episodes": 212.0}
{"step": 909612, "train_return": -14.0, "train_length": 2761.0, "train_total_steps": 227403.0, "train_total_episodes": 213.0, "train_loaded_steps": 227457.0, "train_loaded_episodes": 213.0}
{"step": 916384, "train_return": -19.0, "train_length": 1693.0, "train_total_steps": 229096.0, "train_total_episodes": 214.0, "train_loaded_steps": 229150.0, "train_loaded_episodes": 214.0}
{"step": 921356, "kl_loss": 1.3531495073318482, "image_loss": 3772.0, "reward_loss": 0.9204981269836425, "discount_loss": 0.008117286562919617, "model_kl": 1.3531494777679443, "prior_ent": 27.706793270874023, "post_ent": 26.354955435180663, "model_loss": 3773.096423828125, "model_loss_scale": 4096.0, "model_grad_norm": 2.5902760166168215, "actor_loss": 0.0023535148789174854, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.028075074851512907, "critic_loss": 0.9170085340499878, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.2967115730881691, "reward_mean": -0.0123417388984235, "reward_std": 0.08629269453287125, "reward_normed_mean": -0.0123417388984235, "reward_normed_std": 0.08629269453287125, "critic_slow": -2.5972065214157105, "critic_target": -2.600127297592163, "actor_ent": 0.5736378901481628, "actor_ent_scale": 0.0010000000474974513, "critic": -2.5995348300933836, "fps": 114.52459250883403}
{"step": 924056, "train_return": -16.0, "train_length": 1918.0, "train_total_steps": 231014.0, "train_total_episodes": 215.0, "train_loaded_steps": 231068.0, "train_loaded_episodes": 215.0}
{"step": 935032, "train_return": -13.0, "train_length": 2744.0, "train_total_steps": 233758.0, "train_total_episodes": 216.0, "train_loaded_steps": 233812.0, "train_loaded_episodes": 216.0}
{"step": 943148, "train_return": -17.0, "train_length": 2029.0, "train_total_steps": 235787.0, "train_total_episodes": 217.0, "train_loaded_steps": 235841.0, "train_loaded_episodes": 217.0}
{"step": 953808, "train_return": -12.0, "train_length": 2665.0, "train_total_steps": 238452.0, "train_total_episodes": 218.0, "train_loaded_steps": 238506.0, "train_loaded_episodes": 218.0}
{"step": 961356, "kl_loss": 1.377923837852478, "image_loss": 3772.0002, "reward_loss": 0.9203946788787842, "discount_loss": 0.008064797949045896, "model_kl": 1.3779238102912903, "prior_ent": 28.04796752319336, "post_ent": 26.684976568603517, "model_loss": 3773.09875, "model_loss_scale": 4096.0, "model_grad_norm": 2.169685277557373, "actor_loss": 0.003239933781884611, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.028351980784535408, "critic_loss": 0.9153306104660034, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.2714439592123032, "reward_mean": -0.012302830363856628, "reward_std": 0.0861174615263939, "reward_normed_mean": -0.012302830363856628, "reward_normed_std": 0.0861174615263939, "critic_slow": -2.605742230987549, "critic_target": -2.607497022628784, "actor_ent": 0.5679396399974823, "actor_ent_scale": 0.0010000000474974513, "critic": -2.6067039016723634, "fps": 112.54342576097696}
{"step": 963756, "train_return": -16.0, "train_length": 2487.0, "train_total_steps": 240939.0, "train_total_episodes": 219.0, "train_loaded_steps": 240993.0, "train_loaded_episodes": 219.0}
{"step": 972272, "train_return": -15.0, "train_length": 2129.0, "train_total_steps": 243068.0, "train_total_episodes": 220.0, "train_loaded_steps": 243122.0, "train_loaded_episodes": 220.0}
{"step": 982096, "train_return": -12.0, "train_length": 2456.0, "train_total_steps": 245524.0, "train_total_episodes": 221.0, "train_loaded_steps": 245578.0, "train_loaded_episodes": 221.0}
{"step": 991484, "train_return": -15.0, "train_length": 2347.0, "train_total_steps": 247871.0, "train_total_episodes": 222.0, "train_loaded_steps": 247925.0, "train_loaded_episodes": 222.0}
{"step": 1000852, "train_return": -13.0, "train_length": 2342.0, "train_total_steps": 250213.0, "train_total_episodes": 223.0, "train_loaded_steps": 250267.0, "train_loaded_episodes": 223.0}
{"step": 1001356, "kl_loss": 1.3701546306610108, "image_loss": 3772.000384375, "reward_loss": 0.920404531955719, "discount_loss": 0.008173740436881781, "model_kl": 1.370154602241516, "prior_ent": 28.132234341430664, "post_ent": 26.759950753784178, "model_loss": 3773.098699609375, "model_loss_scale": 7340.032, "model_grad_norm": 2.6646339853286745, "actor_loss": 0.004987584111298201, "actor_loss_scale": 1892469.9648, "actor_grad_norm": 0.030354661178588867, "critic_loss": 0.914693184375763, "critic_loss_scale": 265080.0128, "critic_grad_norm": Infinity, "reward_mean": -0.011391030692053028, "reward_std": 0.08266104761958122, "reward_normed_mean": -0.011391030692053028, "reward_normed_std": 0.08266104761958122, "critic_slow": -2.6315812019348144, "critic_target": -2.6325075332641603, "actor_ent": 0.6457608772277832, "actor_ent_scale": 0.0010000000474974513, "critic": -2.632353210067749, "fps": 114.78077207464608}
{"step": 1011080, "train_return": -11.0, "train_length": 2557.0, "train_total_steps": 252770.0, "train_total_episodes": 224.0, "train_loaded_steps": 252824.0, "train_loaded_episodes": 224.0}
{"step": 1018868, "train_return": -18.0, "train_length": 1947.0, "train_total_steps": 254717.0, "train_total_episodes": 225.0, "train_loaded_steps": 254771.0, "train_loaded_episodes": 225.0}
{"step": 1026332, "train_return": -20.0, "train_length": 1866.0, "train_total_steps": 256583.0, "train_total_episodes": 226.0, "train_loaded_steps": 256637.0, "train_loaded_episodes": 226.0}
{"step": 1034200, "train_return": -17.0, "train_length": 1967.0, "train_total_steps": 258550.0, "train_total_episodes": 227.0, "train_loaded_steps": 258604.0, "train_loaded_episodes": 227.0}
{"step": 1041356, "kl_loss": 1.363707543849945, "image_loss": 3772.0, "reward_loss": 0.9203249101638794, "discount_loss": 0.008047695875912905, "model_kl": 1.3637075152397156, "prior_ent": 28.342241720581054, "post_ent": 26.985599813842775, "model_loss": 3773.09696015625, "model_loss_scale": 8192.0, "model_grad_norm": 2.5714141752243043, "actor_loss": -0.0018290693610033485, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.027146269181370735, "critic_loss": 0.9137385735511779, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.2565627301096916, "reward_mean": -0.011157374871894717, "reward_std": 0.08252815618515015, "reward_normed_mean": -0.011157374871894717, "reward_normed_std": 0.08252815618515015, "critic_slow": -2.5976132062911987, "critic_target": -2.6042062068939207, "actor_ent": 0.6440699270248413, "actor_ent_scale": 0.0010000000474974513, "critic": -2.603854058265686, "fps": 111.66329386562262}
{"step": 1043092, "train_return": -12.0, "train_length": 2223.0, "train_total_steps": 260773.0, "train_total_episodes": 228.0, "train_loaded_steps": 260827.0, "train_loaded_episodes": 228.0}
{"step": 1051856, "train_return": -18.0, "train_length": 2191.0, "train_total_steps": 262964.0, "train_total_episodes": 229.0, "train_loaded_steps": 263018.0, "train_loaded_episodes": 229.0}
{"step": 1061672, "train_return": -12.0, "train_length": 2454.0, "train_total_steps": 265418.0, "train_total_episodes": 230.0, "train_loaded_steps": 265472.0, "train_loaded_episodes": 230.0}
{"step": 1072128, "train_return": -12.0, "train_length": 2614.0, "train_total_steps": 268032.0, "train_total_episodes": 231.0, "train_loaded_steps": 268086.0, "train_loaded_episodes": 231.0}
{"step": 1081356, "kl_loss": 1.3931027471542359, "image_loss": 3772.0001921875, "reward_loss": 0.9204843711853027, "discount_loss": 0.008153340309113265, "model_kl": 1.3931027177810669, "prior_ent": 28.46130746459961, "post_ent": 27.077530715942384, "model_loss": 3773.10077265625, "model_loss_scale": 8192.0, "model_grad_norm": 2.512581669998169, "actor_loss": 0.00353513540464337, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.026612014743685724, "critic_loss": 0.914471377658844, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.27267975390851495, "reward_mean": -0.010643032621813472, "reward_std": 0.07911981855034828, "reward_normed_mean": -0.010643032621813472, "reward_normed_std": 0.07911981855034828, "critic_slow": -2.706510068511963, "critic_target": -2.704804322052002, "actor_ent": 0.5597888217926026, "actor_ent_scale": 0.0010000000474974513, "critic": -2.7047107494354248, "fps": 111.72257592517431}
{"step": 1083952, "train_return": -10.0, "train_length": 2956.0, "train_total_steps": 270988.0, "train_total_episodes": 232.0, "train_loaded_steps": 271042.0, "train_loaded_episodes": 232.0}
{"step": 1091372, "train_return": -20.0, "train_length": 1855.0, "train_total_steps": 272843.0, "train_total_episodes": 233.0, "train_loaded_steps": 272897.0, "train_loaded_episodes": 233.0}
{"step": 1099136, "train_return": -19.0, "train_length": 1941.0, "train_total_steps": 274784.0, "train_total_episodes": 234.0, "train_loaded_steps": 274838.0, "train_loaded_episodes": 234.0}
{"step": 1108520, "train_return": -16.0, "train_length": 2346.0, "train_total_steps": 277130.0, "train_total_episodes": 235.0, "train_loaded_steps": 277184.0, "train_loaded_episodes": 235.0}
{"step": 1116328, "train_return": -19.0, "train_length": 1952.0, "train_total_steps": 279082.0, "train_total_episodes": 236.0, "train_loaded_steps": 279136.0, "train_loaded_episodes": 236.0}
{"step": 1121356, "kl_loss": 1.3616214487075806, "image_loss": 3772.0002, "reward_loss": 0.9203062481880188, "discount_loss": 0.00801716586202383, "model_kl": 1.3616214218139648, "prior_ent": 28.59417204284668, "post_ent": 27.237065698242187, "model_loss": 3773.096781640625, "model_loss_scale": 12478.0544, "model_grad_norm": Infinity, "actor_loss": 0.0019700369707308708, "actor_loss_scale": 3365509.5296, "actor_grad_norm": 0.02717062279880047, "critic_loss": 0.9134580493927001, "critic_loss_scale": 306603.6224, "critic_grad_norm": Infinity, "reward_mean": -0.010687119359453209, "reward_std": 0.08046626026034355, "reward_normed_mean": -0.010687119359453209, "reward_normed_std": 0.08046626026034355, "critic_slow": -2.6902150356292727, "critic_target": -2.6908434196472166, "actor_ent": 0.6505609790802002, "actor_ent_scale": 0.0010000000474974513, "critic": -2.6906653324127197, "fps": 113.21505596879936}
{"step": 1126188, "train_return": -19.0, "train_length": 2465.0, "train_total_steps": 281547.0, "train_total_episodes": 237.0, "train_loaded_steps": 281601.0, "train_loaded_episodes": 237.0}
{"step": 1137820, "train_return": -8.0, "train_length": 2908.0, "train_total_steps": 284455.0, "train_total_episodes": 238.0, "train_loaded_steps": 284509.0, "train_loaded_episodes": 238.0}
{"step": 1149188, "train_return": -13.0, "train_length": 2842.0, "train_total_steps": 287297.0, "train_total_episodes": 239.0, "train_loaded_steps": 287351.0, "train_loaded_episodes": 239.0}
{"step": 1161016, "train_return": -13.0, "train_length": 2957.0, "train_total_steps": 290254.0, "train_total_episodes": 240.0, "train_loaded_steps": 290308.0, "train_loaded_episodes": 240.0}
{"step": 1161356, "kl_loss": 1.3978275405883789, "image_loss": 3772.0, "reward_loss": 0.9203668921470642, "discount_loss": 0.008142201729118824, "model_kl": 1.3978275104522706, "prior_ent": 28.764677194213867, "post_ent": 27.376748147583008, "model_loss": 3773.100875390625, "model_loss_scale": 8192.0, "model_grad_norm": 2.3551832299232482, "actor_loss": 0.00048752861011380446, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.028549885761737823, "critic_loss": 0.9130329440116882, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.24170147979855539, "reward_mean": -0.010632698405301198, "reward_std": 0.08002451401948929, "reward_normed_mean": -0.010632698405301198, "reward_normed_std": 0.08002451401948929, "critic_slow": -2.647385687637329, "critic_target": -2.6529029930114745, "actor_ent": 0.6890909365653992, "actor_ent_scale": 0.0010000000474974513, "critic": -2.652464412689209, "fps": 111.33908648263325}
{"step": 1174692, "train_return": -9.0, "train_length": 3419.0, "train_total_steps": 293673.0, "train_total_episodes": 241.0, "train_loaded_steps": 293727.0, "train_loaded_episodes": 241.0}
{"step": 1188180, "train_return": -11.0, "train_length": 3372.0, "train_total_steps": 297045.0, "train_total_episodes": 242.0, "train_loaded_steps": 297099.0, "train_loaded_episodes": 242.0}
{"step": 1201000, "train_return": -10.0, "train_length": 3205.0, "train_total_steps": 300250.0, "train_total_episodes": 243.0, "train_loaded_steps": 300304.0, "train_loaded_episodes": 243.0}
{"step": 1201352, "eval_return": -15.0, "eval_length": 2158.0, "eval_total_steps": 2567.0, "eval_total_episodes": 3.0, "eval_loaded_steps": 2569.0, "eval_loaded_episodes": 3.0}
{"step": 1201356, "kl_loss": 1.381446810722351, "image_loss": 3772.0, "reward_loss": 0.9202443140029907, "discount_loss": 0.008040908562391997, "model_kl": 1.3814467809677125, "prior_ent": 28.877747763061524, "post_ent": 27.503406311035157, "model_loss": 3773.09862109375, "model_loss_scale": 8192.0, "model_grad_norm": 2.4298024327278136, "actor_loss": 0.003276470742397942, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.028945980775356293, "critic_loss": 0.9124172803878784, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.23038753868341447, "reward_mean": -0.010450484316406073, "reward_std": 0.08042793815135955, "reward_normed_mean": -0.010450484316406073, "reward_normed_std": 0.08042793815135955, "critic_slow": -2.6465213611602785, "critic_target": -2.650664411354065, "actor_ent": 0.7423157606124878, "actor_ent_scale": 0.0010000000474974513, "critic": -2.650118593978882, "fps": 107.89284183098749}
{"step": 1211068, "train_return": -15.0, "train_length": 2517.0, "train_total_steps": 302767.0, "train_total_episodes": 244.0, "train_loaded_steps": 302821.0, "train_loaded_episodes": 244.0}
{"step": 1220860, "train_return": -13.0, "train_length": 2448.0, "train_total_steps": 305215.0, "train_total_episodes": 245.0, "train_loaded_steps": 305269.0, "train_loaded_episodes": 245.0}
{"step": 1231448, "train_return": -12.0, "train_length": 2647.0, "train_total_steps": 307862.0, "train_total_episodes": 246.0, "train_loaded_steps": 307916.0, "train_loaded_episodes": 246.0}
{"step": 1240812, "train_return": -16.0, "train_length": 2341.0, "train_total_steps": 310203.0, "train_total_episodes": 247.0, "train_loaded_steps": 310257.0, "train_loaded_episodes": 247.0}
{"step": 1241356, "kl_loss": 1.3880542917251586, "image_loss": 3772.0, "reward_loss": 0.9202640768051148, "discount_loss": 0.007998780804127454, "model_kl": 1.3880542655944825, "prior_ent": 28.89809895324707, "post_ent": 27.523845123291014, "model_loss": 3773.099094921875, "model_loss_scale": 8192.0, "model_grad_norm": 2.798843500137329, "actor_loss": 0.0076650145796877045, "actor_loss_scale": 5892158.2592, "actor_grad_norm": 0.029234561109542846, "critic_loss": 0.9128848527908325, "critic_loss_scale": 310378.496, "critic_grad_norm": 0.220295077252388, "reward_mean": -0.009892760879697744, "reward_std": 0.07972136382460594, "reward_normed_mean": -0.009892760879697744, "reward_normed_std": 0.07972136382460594, "critic_slow": -2.6291124586105346, "critic_target": -2.625252815437317, "actor_ent": 0.7708165890693665, "actor_ent_scale": 0.0010000000474974513, "critic": -2.6250955856323244, "fps": 110.92964587952048}
{"step": 1249368, "train_return": -15.0, "train_length": 2139.0, "train_total_steps": 312342.0, "train_total_episodes": 248.0, "train_loaded_steps": 312396.0, "train_loaded_episodes": 248.0}
{"step": 1260040, "train_return": -11.0, "train_length": 2668.0, "train_total_steps": 315010.0, "train_total_episodes": 249.0, "train_loaded_steps": 315064.0, "train_loaded_episodes": 249.0}
{"step": 1270508, "train_return": -12.0, "train_length": 2617.0, "train_total_steps": 317627.0, "train_total_episodes": 250.0, "train_loaded_steps": 317681.0, "train_loaded_episodes": 250.0}
{"step": 1281356, "kl_loss": 1.3570496147155762, "image_loss": 3772.0, "reward_loss": 0.920199165725708, "discount_loss": 0.007924229968339205, "model_kl": 1.3570495864868164, "prior_ent": 28.922481240844725, "post_ent": 27.569424145507814, "model_loss": 3773.095542578125, "model_loss_scale": 8218.2144, "model_grad_norm": Infinity, "actor_loss": 0.006342256803327473, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.028722541093826295, "critic_loss": 0.9133002144813538, "critic_loss_scale": 286051.5328, "critic_grad_norm": Infinity, "reward_mean": -0.010035172460688045, "reward_std": 0.08059590762853622, "reward_normed_mean": -0.010035172460688045, "reward_normed_std": 0.08059590762853622, "critic_slow": -2.551411298370361, "critic_target": -2.5482373495101927, "actor_ent": 0.7307129972457885, "actor_ent_scale": 0.0010000000474974513, "critic": -2.547763178062439, "fps": 111.60242397450496}
{"step": 1282004, "train_return": -11.0, "train_length": 2874.0, "train_total_steps": 320501.0, "train_total_episodes": 251.0, "train_loaded_steps": 320555.0, "train_loaded_episodes": 251.0}
{"step": 1292716, "train_return": -15.0, "train_length": 2678.0, "train_total_steps": 323179.0, "train_total_episodes": 252.0, "train_loaded_steps": 323233.0, "train_loaded_episodes": 252.0}
{"step": 1301732, "train_return": -18.0, "train_length": 2254.0, "train_total_steps": 325433.0, "train_total_episodes": 253.0, "train_loaded_steps": 325487.0, "train_loaded_episodes": 253.0}
{"step": 1313020, "train_return": -15.0, "train_length": 2822.0, "train_total_steps": 328255.0, "train_total_episodes": 254.0, "train_loaded_steps": 328309.0, "train_loaded_episodes": 254.0}
{"step": 1321356, "kl_loss": 1.3835363538742065, "image_loss": 3772.0, "reward_loss": 0.9202638305664063, "discount_loss": 0.007952793614566326, "model_kl": 1.3835363260269165, "prior_ent": 28.91170185546875, "post_ent": 27.538513137817382, "model_loss": 3773.09841796875, "model_loss_scale": 8192.0, "model_grad_norm": 2.6728453824996947, "actor_loss": 0.003746156785362837, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.02995235023200512, "critic_loss": 0.9142836314201355, "critic_loss_scale": 136524.5952, "critic_grad_norm": Infinity, "reward_mean": -0.009767876706365496, "reward_std": 0.07852784000635148, "reward_normed_mean": -0.009767876706365496, "reward_normed_std": 0.07852784000635148, "critic_slow": -2.4718705265045164, "critic_target": -2.474507363319397, "actor_ent": 0.776446836566925, "actor_ent_scale": 0.0010000000474974513, "critic": -2.4749109981536863, "fps": 113.21685068946925}
{"step": 1326508, "train_return": -9.0, "train_length": 3372.0, "train_total_steps": 331627.0, "train_total_episodes": 255.0, "train_loaded_steps": 331681.0, "train_loaded_episodes": 255.0}
{"step": 1337340, "train_return": -12.0, "train_length": 2708.0, "train_total_steps": 334335.0, "train_total_episodes": 256.0, "train_loaded_steps": 334389.0, "train_loaded_episodes": 256.0}
{"step": 1346044, "train_return": -18.0, "train_length": 2176.0, "train_total_steps": 336511.0, "train_total_episodes": 257.0, "train_loaded_steps": 336565.0, "train_loaded_episodes": 257.0}
{"step": 1358080, "train_return": -5.0, "train_length": 3009.0, "train_total_steps": 339520.0, "train_total_episodes": 258.0, "train_loaded_steps": 339574.0, "train_loaded_episodes": 258.0}
{"step": 1361356, "kl_loss": 1.377679328918457, "image_loss": 3772.00037578125, "reward_loss": 0.920159088230133, "discount_loss": 0.007988085406273604, "model_kl": 1.3776792999267577, "prior_ent": 28.919253079223633, "post_ent": 27.550676565551758, "model_loss": 3773.098263671875, "model_loss_scale": 8192.0, "model_grad_norm": 2.9762587705612185, "actor_loss": 0.004255597908236086, "actor_loss_scale": 10106594.9184, "actor_grad_norm": 0.03222078399956226, "critic_loss": 0.9134449404716491, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.20516651635169983, "reward_mean": -0.009916471855127748, "reward_std": 0.08003961519002914, "reward_normed_mean": -0.009916471855127748, "reward_normed_std": 0.08003961519002914, "critic_slow": -2.417803112792969, "critic_target": -2.419564198875427, "actor_ent": 0.8164253934860229, "actor_ent_scale": 0.0010000000474974513, "critic": -2.4193433769226074, "fps": 112.01200569506116}
{"step": 1368308, "train_return": -14.0, "train_length": 2557.0, "train_total_steps": 342077.0, "train_total_episodes": 259.0, "train_loaded_steps": 342131.0, "train_loaded_episodes": 259.0}
{"step": 1376472, "train_return": -17.0, "train_length": 2041.0, "train_total_steps": 344118.0, "train_total_episodes": 260.0, "train_loaded_steps": 344172.0, "train_loaded_episodes": 260.0}
{"step": 1384908, "train_return": -19.0, "train_length": 2109.0, "train_total_steps": 346227.0, "train_total_episodes": 261.0, "train_loaded_steps": 346281.0, "train_loaded_episodes": 261.0}
{"step": 1395340, "train_return": -14.0, "train_length": 2608.0, "train_total_steps": 348835.0, "train_total_episodes": 262.0, "train_loaded_steps": 348889.0, "train_loaded_episodes": 262.0}
{"step": 1401356, "kl_loss": 1.392858615398407, "image_loss": 3772.0, "reward_loss": 0.920142409324646, "discount_loss": 0.008106263331323861, "model_kl": 1.3928585906028748, "prior_ent": 28.944849649047853, "post_ent": 27.562351181030273, "model_loss": 3773.099980078125, "model_loss_scale": 9175.04, "model_grad_norm": Infinity, "actor_loss": 0.0055424396987422365, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.03198897543549538, "critic_loss": 0.9124334453582764, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.19264988887310028, "reward_mean": -0.009731669493438675, "reward_std": 0.07924113920927048, "reward_normed_mean": -0.009731669493438675, "reward_normed_std": 0.07924113920927048, "critic_slow": -2.431601292800903, "critic_target": -2.430956645011902, "actor_ent": 0.800992144203186, "actor_ent_scale": 0.0010000000474974513, "critic": -2.4306774963378905, "fps": 112.89943204867438}
{"step": 1405296, "train_return": -16.0, "train_length": 2489.0, "train_total_steps": 351324.0, "train_total_episodes": 263.0, "train_loaded_steps": 351378.0, "train_loaded_episodes": 263.0}
{"step": 1414548, "train_return": -15.0, "train_length": 2313.0, "train_total_steps": 353637.0, "train_total_episodes": 264.0, "train_loaded_steps": 353691.0, "train_loaded_episodes": 264.0}
{"step": 1426680, "train_return": -7.0, "train_length": 3033.0, "train_total_steps": 356670.0, "train_total_episodes": 265.0, "train_loaded_steps": 356724.0, "train_loaded_episodes": 265.0}
{"step": 1436120, "train_return": -18.0, "train_length": 2360.0, "train_total_steps": 359030.0, "train_total_episodes": 266.0, "train_loaded_steps": 359084.0, "train_loaded_episodes": 266.0}
{"step": 1441356, "kl_loss": 1.375932888507843, "image_loss": 3772.0001921875, "reward_loss": 0.9201301414489746, "discount_loss": 0.007947362139075995, "model_kl": 1.3759328590393067, "prior_ent": 28.90992413330078, "post_ent": 27.543421728515625, "model_loss": 3773.097691796875, "model_loss_scale": 8192.0, "model_grad_norm": 2.9630691783905028, "actor_loss": 0.01017187522338354, "actor_loss_scale": 13462038.1184, "actor_grad_norm": Infinity, "critic_loss": 0.9132638772010804, "critic_loss_scale": 230477.0048, "critic_grad_norm": 0.19053738306760787, "reward_mean": -0.009385414054454304, "reward_std": 0.07880382078886032, "reward_normed_mean": -0.009385414054454304, "reward_normed_std": 0.07880382078886032, "critic_slow": -2.451610903549194, "critic_target": -2.445199418258667, "actor_ent": 0.7962387778282165, "actor_ent_scale": 0.0010000000474974513, "critic": -2.445307879638672, "fps": 115.00967769950553}
{"step": 1447396, "train_return": -14.0, "train_length": 2819.0, "train_total_steps": 361849.0, "train_total_episodes": 267.0, "train_loaded_steps": 361903.0, "train_loaded_episodes": 267.0}
{"step": 1457252, "train_return": -17.0, "train_length": 2464.0, "train_total_steps": 364313.0, "train_total_episodes": 268.0, "train_loaded_steps": 364367.0, "train_loaded_episodes": 268.0}
{"step": 1469720, "train_return": -9.0, "train_length": 3117.0, "train_total_steps": 367430.0, "train_total_episodes": 269.0, "train_loaded_steps": 367484.0, "train_loaded_episodes": 269.0}
{"step": 1478364, "train_return": -19.0, "train_length": 2161.0, "train_total_steps": 369591.0, "train_total_episodes": 270.0, "train_loaded_steps": 369645.0, "train_loaded_episodes": 270.0}
{"step": 1481356, "kl_loss": 1.37931782913208, "image_loss": 3772.0, "reward_loss": 0.9201329595565796, "discount_loss": 0.007912401816248894, "model_kl": 1.3793177997589112, "prior_ent": 28.971368997192382, "post_ent": 27.602145413208007, "model_loss": 3773.097659375, "model_loss_scale": 8192.0, "model_grad_norm": 3.153095973968506, "actor_loss": 0.004268538081087172, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.029632817995548247, "critic_loss": 0.9129679681777955, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.18789924543499947, "reward_mean": -0.00919215609485982, "reward_std": 0.07829567235708236, "reward_normed_mean": -0.00919215609485982, "reward_normed_std": 0.07829567235708236, "critic_slow": -2.4218209783554077, "critic_target": -2.4197733709335325, "actor_ent": 0.800202923488617, "actor_ent_scale": 0.0010000000474974513, "critic": -2.419686085510254, "fps": 114.23883477883274}
{"step": 1490452, "train_return": -10.0, "train_length": 3022.0, "train_total_steps": 372613.0, "train_total_episodes": 271.0, "train_loaded_steps": 372667.0, "train_loaded_episodes": 271.0}
{"step": 1501144, "train_return": -12.0, "train_length": 2673.0, "train_total_steps": 375286.0, "train_total_episodes": 272.0, "train_loaded_steps": 375340.0, "train_loaded_episodes": 272.0}
{"step": 1509576, "train_return": -20.0, "train_length": 2108.0, "train_total_steps": 377394.0, "train_total_episodes": 273.0, "train_loaded_steps": 377448.0, "train_loaded_episodes": 273.0}
{"step": 1520124, "train_return": -15.0, "train_length": 2637.0, "train_total_steps": 380031.0, "train_total_episodes": 274.0, "train_loaded_steps": 380085.0, "train_loaded_episodes": 274.0}
{"step": 1521356, "kl_loss": 1.385778457927704, "image_loss": 3772.0, "reward_loss": 0.9200564817428589, "discount_loss": 0.007995049449801445, "model_kl": 1.3857784275054932, "prior_ent": 28.975460110473634, "post_ent": 27.60309044494629, "model_loss": 3773.098640234375, "model_loss_scale": 11023.1552, "model_grad_norm": 3.116350255393982, "actor_loss": 0.009450908402190544, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.031717034968733786, "critic_loss": 0.913815626335144, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.19083139894008636, "reward_mean": -0.00903735775980167, "reward_std": 0.0782801356613636, "reward_normed_mean": -0.00903735775980167, "reward_normed_std": 0.0782801356613636, "critic_slow": -2.376639338493347, "critic_target": -2.3724480531692507, "actor_ent": 0.7769319396018982, "actor_ent_scale": 0.0010000000474974513, "critic": -2.3725053413391115, "fps": 114.25342312472138}
{"step": 1534048, "train_return": -7.0, "train_length": 3481.0, "train_total_steps": 383512.0, "train_total_episodes": 275.0, "train_loaded_steps": 383566.0, "train_loaded_episodes": 275.0}
{"step": 1544372, "train_return": -16.0, "train_length": 2581.0, "train_total_steps": 386093.0, "train_total_episodes": 276.0, "train_loaded_steps": 386147.0, "train_loaded_episodes": 276.0}
{"step": 1554080, "train_return": -19.0, "train_length": 2427.0, "train_total_steps": 388520.0, "train_total_episodes": 277.0, "train_loaded_steps": 388574.0, "train_loaded_episodes": 277.0}
{"step": 1561356, "kl_loss": 1.3893332522392272, "image_loss": 3772.0, "reward_loss": 0.9200306381225586, "discount_loss": 0.007979422926902771, "model_kl": 1.389333221912384, "prior_ent": 29.023410278320313, "post_ent": 27.644669467163087, "model_loss": 3773.098890234375, "model_loss_scale": 11757.1584, "model_grad_norm": Infinity, "actor_loss": 0.006100138184567914, "actor_loss_scale": 10026064.2816, "actor_grad_norm": 0.031071372851729392, "critic_loss": 0.9133676928520202, "critic_loss_scale": 342674.6368, "critic_grad_norm": Infinity, "reward_mean": -0.009026974877128668, "reward_std": 0.07802377304434777, "reward_normed_mean": -0.009026974877128668, "reward_normed_std": 0.07802377304434777, "critic_slow": -2.3112625747680666, "critic_target": -2.311693419456482, "actor_ent": 0.7777761387825012, "actor_ent_scale": 0.0010000000474974513, "critic": -2.311740362358093, "fps": 112.84678795072797}
{"step": 1564328, "train_return": -13.0, "train_length": 2562.0, "train_total_steps": 391082.0, "train_total_episodes": 278.0, "train_loaded_steps": 391136.0, "train_loaded_episodes": 278.0}
{"step": 1576792, "train_return": -6.0, "train_length": 3116.0, "train_total_steps": 394198.0, "train_total_episodes": 279.0, "train_loaded_steps": 394252.0, "train_loaded_episodes": 279.0}
{"step": 1584520, "train_return": -17.0, "train_length": 1932.0, "train_total_steps": 396130.0, "train_total_episodes": 280.0, "train_loaded_steps": 396184.0, "train_loaded_episodes": 280.0}
{"step": 1596052, "train_return": -10.0, "train_length": 2883.0, "train_total_steps": 399013.0, "train_total_episodes": 281.0, "train_loaded_steps": 399067.0, "train_loaded_episodes": 281.0}
{"step": 1601356, "kl_loss": 1.4148080128669738, "image_loss": 3772.0, "reward_loss": 0.9200115782737732, "discount_loss": 0.007949648480117321, "model_kl": 1.4148079801559448, "prior_ent": 29.046134091186524, "post_ent": 27.643598818969725, "model_loss": 3773.101258203125, "model_loss_scale": 8192.0, "model_grad_norm": 3.2120389255523683, "actor_loss": 0.0009958484854549168, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.030419636887311936, "critic_loss": 0.9130220439910889, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.18889671268463135, "reward_mean": -0.009127008645735624, "reward_std": 0.07856319218873978, "reward_normed_mean": -0.009127008645735624, "reward_normed_std": 0.07856319218873978, "critic_slow": -2.2464802865982056, "critic_target": -2.2501354122161867, "actor_ent": 0.7900224608421326, "actor_ent_scale": 0.0010000000474974513, "critic": -2.2499109928131102, "fps": 112.45973362271232}
{"step": 1606100, "train_return": -15.0, "train_length": 2512.0, "train_total_steps": 401525.0, "train_total_episodes": 282.0, "train_loaded_steps": 401579.0, "train_loaded_episodes": 282.0}
{"step": 1618344, "train_return": -10.0, "train_length": 3061.0, "train_total_steps": 404586.0, "train_total_episodes": 283.0, "train_loaded_steps": 404640.0, "train_loaded_episodes": 283.0}
{"step": 1626748, "train_return": -18.0, "train_length": 2101.0, "train_total_steps": 406687.0, "train_total_episodes": 284.0, "train_loaded_steps": 406741.0, "train_loaded_episodes": 284.0}
{"step": 1639888, "train_return": -8.0, "train_length": 3285.0, "train_total_steps": 409972.0, "train_total_episodes": 285.0, "train_loaded_steps": 410026.0, "train_loaded_episodes": 285.0}
{"step": 1641356, "kl_loss": 1.4124769052505493, "image_loss": 3772.0, "reward_loss": 0.9200634743690491, "discount_loss": 0.00790975274965167, "model_kl": 1.4124768756866455, "prior_ent": 29.0754576751709, "post_ent": 27.67547931213379, "model_loss": 3773.10087265625, "model_loss_scale": 8192.0, "model_grad_norm": 3.5599026266098024, "actor_loss": 0.005196340579446406, "actor_loss_scale": 9140227.2768, "actor_grad_norm": Infinity, "critic_loss": 0.9137116023063659, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.19944108102321625, "reward_mean": -0.009036116970953299, "reward_std": 0.07853055652976036, "reward_normed_mean": -0.009036116970953299, "reward_normed_std": 0.07853055652976036, "critic_slow": -2.24005671005249, "critic_target": -2.2398667219161985, "actor_ent": 0.7767797677993774, "actor_ent_scale": 0.0010000000474974513, "critic": -2.239744713973999, "fps": 110.40404712322571}
{"step": 1655152, "train_return": -8.0, "train_length": 3816.0, "train_total_steps": 413788.0, "train_total_episodes": 286.0, "train_loaded_steps": 413842.0, "train_loaded_episodes": 286.0}
{"step": 1664216, "train_return": -14.0, "train_length": 2266.0, "train_total_steps": 416054.0, "train_total_episodes": 287.0, "train_loaded_steps": 416108.0, "train_loaded_episodes": 287.0}
{"step": 1671860, "train_return": -18.0, "train_length": 1911.0, "train_total_steps": 417965.0, "train_total_episodes": 288.0, "train_loaded_steps": 418019.0, "train_loaded_episodes": 288.0}
{"step": 1681012, "train_return": -19.0, "train_length": 2288.0, "train_total_steps": 420253.0, "train_total_episodes": 289.0, "train_loaded_steps": 420307.0, "train_loaded_episodes": 289.0}
{"step": 1681356, "kl_loss": 1.440070230102539, "image_loss": 3772.0, "reward_loss": 0.9200183470726013, "discount_loss": 0.007955234134942294, "model_kl": 1.4400701990127565, "prior_ent": 29.165147048950196, "post_ent": 27.745347973632814, "model_loss": 3773.103819140625, "model_loss_scale": 11180.4416, "model_grad_norm": 3.5619373764038085, "actor_loss": 0.009301315746817272, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.030831539532542227, "critic_loss": 0.9135722952842712, "critic_loss_scale": 275565.7728, "critic_grad_norm": 0.17646165462732316, "reward_mean": -0.008773449026719027, "reward_std": 0.07753886743187904, "reward_normed_mean": -0.008773449026719027, "reward_normed_std": 0.07753886743187904, "critic_slow": -2.1594271614074705, "critic_target": -2.1543610353469846, "actor_ent": 0.7638992677688599, "actor_ent_scale": 0.0010000000474974513, "critic": -2.1543747442245484, "fps": 112.96460263423585}
{"step": 1692884, "train_return": -15.0, "train_length": 2968.0, "train_total_steps": 423221.0, "train_total_episodes": 290.0, "train_loaded_steps": 423275.0, "train_loaded_episodes": 290.0}
{"step": 1708836, "train_return": -2.0, "train_length": 3988.0, "train_total_steps": 427209.0, "train_total_episodes": 291.0, "train_loaded_steps": 427263.0, "train_loaded_episodes": 291.0}
{"step": 1714840, "train_return": -20.0, "train_length": 1501.0, "train_total_steps": 428710.0, "train_total_episodes": 292.0, "train_loaded_steps": 428764.0, "train_loaded_episodes": 292.0}
{"step": 1721356, "kl_loss": 1.3937728588104248, "image_loss": 3772.0, "reward_loss": 0.9199807759284974, "discount_loss": 0.007931709858030081, "model_kl": 1.3937728282928468, "prior_ent": 29.182853802490236, "post_ent": 27.795222689819337, "model_loss": 3773.099053515625, "model_loss_scale": 13133.4144, "model_grad_norm": Infinity, "actor_loss": 0.004805232889036415, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.02969471447765827, "critic_loss": 0.9138920777320861, "critic_loss_scale": 307442.4832, "critic_grad_norm": Infinity, "reward_mean": -0.008490063019754598, "reward_std": 0.07712947949767113, "reward_normed_mean": -0.008490063019754598, "reward_normed_std": 0.07712947949767113, "critic_slow": -2.1374335117340086, "critic_target": -2.13627279586792, "actor_ent": 0.7605026058197022, "actor_ent_scale": 0.0010000000474974513, "critic": -2.1362166938781737, "fps": 112.8461735199017}
{"step": 1729484, "train_return": -2.0, "train_length": 3661.0, "train_total_steps": 432371.0, "train_total_episodes": 293.0, "train_loaded_steps": 432425.0, "train_loaded_episodes": 293.0}
{"step": 1746440, "train_return": -3.0, "train_length": 4239.0, "train_total_steps": 436610.0, "train_total_episodes": 294.0, "train_loaded_steps": 436664.0, "train_loaded_episodes": 294.0}
{"step": 1758784, "train_return": -6.0, "train_length": 3086.0, "train_total_steps": 439696.0, "train_total_episodes": 295.0, "train_loaded_steps": 439750.0, "train_loaded_episodes": 295.0}
{"step": 1761356, "kl_loss": 1.4529442361831666, "image_loss": 3772.0, "reward_loss": 0.9199634678840637, "discount_loss": 0.007920094839483499, "model_kl": 1.4529442037582398, "prior_ent": 29.223652166748046, "post_ent": 27.795992047119142, "model_loss": 3773.104880078125, "model_loss_scale": 8192.0, "model_grad_norm": 3.575140909290314, "actor_loss": 0.006893602866772562, "actor_loss_scale": 14347875.1232, "actor_grad_norm": 0.031939136970043185, "critic_loss": 0.9143654198646546, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.17499675905108453, "reward_mean": -0.008717325112177059, "reward_std": 0.0785584819495678, "reward_normed_mean": -0.008717325112177059, "reward_normed_std": 0.0785584819495678, "critic_slow": -2.129433002281189, "critic_target": -2.1278352233886717, "actor_ent": 0.782598979473114, "actor_ent_scale": 0.0010000000474974513, "critic": -2.1277681020736696, "fps": 112.64583616674608}
{"step": 1767808, "train_return": -16.0, "train_length": 2256.0, "train_total_steps": 441952.0, "train_total_episodes": 296.0, "train_loaded_steps": 442006.0, "train_loaded_episodes": 296.0}
{"step": 1774332, "train_return": -20.0, "train_length": 1631.0, "train_total_steps": 443583.0, "train_total_episodes": 297.0, "train_loaded_steps": 443637.0, "train_loaded_episodes": 297.0}
{"step": 1789632, "train_return": -4.0, "train_length": 3825.0, "train_total_steps": 447408.0, "train_total_episodes": 298.0, "train_loaded_steps": 447462.0, "train_loaded_episodes": 298.0}
{"step": 1801356, "kl_loss": 1.396477918624878, "image_loss": 3772.0002, "reward_loss": 0.919903307723999, "discount_loss": 0.00785946094095707, "model_kl": 1.3964778876304627, "prior_ent": 29.29336907348633, "post_ent": 27.902733419799805, "model_loss": 3773.0990703125, "model_loss_scale": 8192.0, "model_grad_norm": 3.6317481279373167, "actor_loss": 0.0033445165479613933, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.0320196577578783, "critic_loss": 0.9138790156364441, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.16354993908405305, "reward_mean": -0.008445469378125563, "reward_std": 0.07786374608278275, "reward_normed_mean": -0.008445469378125563, "reward_normed_std": 0.07786374608278275, "critic_slow": -2.170361026382446, "critic_target": -2.1714505836486815, "actor_ent": 0.7919180666923523, "actor_ent_scale": 0.0010000000474974513, "critic": -2.1714286376953127, "fps": 113.06614038273938}
{"step": 1807316, "train_return": -4.0, "train_length": 4421.0, "train_total_steps": 451829.0, "train_total_episodes": 299.0, "train_loaded_steps": 451883.0, "train_loaded_episodes": 299.0}
{"step": 1823480, "train_return": 2.0, "train_length": 4041.0, "train_total_steps": 455870.0, "train_total_episodes": 300.0, "train_loaded_steps": 455924.0, "train_loaded_episodes": 300.0}
{"step": 1834952, "train_return": -15.0, "train_length": 2868.0, "train_total_steps": 458738.0, "train_total_episodes": 301.0, "train_loaded_steps": 458792.0, "train_loaded_episodes": 301.0}
{"step": 1841356, "kl_loss": 1.4163195346832276, "image_loss": 3772.0, "reward_loss": 0.9199176621437073, "discount_loss": 0.0078080231413245205, "model_kl": 1.4163195056915283, "prior_ent": 29.32443166809082, "post_ent": 27.924434884643556, "model_loss": 3773.10060625, "model_loss_scale": 9804.1856, "model_grad_norm": 3.9975870935440065, "actor_loss": 0.0056112118866178205, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.03282624935507775, "critic_loss": 0.9147728722572327, "critic_loss_scale": 263821.7216, "critic_grad_norm": Infinity, "reward_mean": -0.008267584493756294, "reward_std": 0.07753110970258713, "reward_normed_mean": -0.008267584493756294, "reward_normed_std": 0.07753110970258713, "critic_slow": -2.1008709692001344, "critic_target": -2.101588249015808, "actor_ent": 0.7456777729988098, "actor_ent_scale": 0.0010000000474974513, "critic": -2.10137459526062, "fps": 112.87596422699482}
{"step": 1849296, "train_return": -8.0, "train_length": 3586.0, "train_total_steps": 462324.0, "train_total_episodes": 302.0, "train_loaded_steps": 462378.0, "train_loaded_episodes": 302.0}
{"step": 1861980, "train_return": -14.0, "train_length": 3171.0, "train_total_steps": 465495.0, "train_total_episodes": 303.0, "train_loaded_steps": 465549.0, "train_loaded_episodes": 303.0}
{"step": 1880144, "train_return": -4.0, "train_length": 4541.0, "train_total_steps": 470036.0, "train_total_episodes": 304.0, "train_loaded_steps": 470090.0, "train_loaded_episodes": 304.0}
{"step": 1881356, "kl_loss": 1.434399132347107, "image_loss": 3772.0, "reward_loss": 0.9199280053138733, "discount_loss": 0.007945293237268924, "model_kl": 1.4343990975379943, "prior_ent": 29.310006506347655, "post_ent": 27.890830157470702, "model_loss": 3773.10311640625, "model_loss_scale": 16384.0, "model_grad_norm": 3.912524303817749, "actor_loss": -0.002612413729680702, "actor_loss_scale": 16965120.8192, "actor_grad_norm": Infinity, "critic_loss": 0.9142051446914673, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.17244911967515947, "reward_mean": -0.008052590146206785, "reward_std": 0.07620569460391999, "reward_normed_mean": -0.008052590146206785, "reward_normed_std": 0.07620569460391999, "critic_slow": -2.08422535533905, "critic_target": -2.090503297996521, "actor_ent": 0.7792297776222229, "actor_ent_scale": 0.0010000000474974513, "critic": -2.090397438049316, "fps": 112.33489615942628}
{"step": 1892200, "train_return": -8.0, "train_length": 3014.0, "train_total_steps": 473050.0, "train_total_episodes": 305.0, "train_loaded_steps": 473104.0, "train_loaded_episodes": 305.0}
{"step": 1897552, "train_return": -21.0, "train_length": 1338.0, "train_total_steps": 474388.0, "train_total_episodes": 306.0, "train_loaded_steps": 474442.0, "train_loaded_episodes": 306.0}
{"step": 1904516, "train_return": -20.0, "train_length": 1741.0, "train_total_steps": 476129.0, "train_total_episodes": 307.0, "train_loaded_steps": 476183.0, "train_loaded_episodes": 307.0}
{"step": 1920092, "train_return": -8.0, "train_length": 3894.0, "train_total_steps": 480023.0, "train_total_episodes": 308.0, "train_loaded_steps": 480077.0, "train_loaded_episodes": 308.0}
{"step": 1921356, "kl_loss": 1.3802948669433595, "image_loss": 3772.0, "reward_loss": 0.9198256952285767, "discount_loss": 0.007851943992823362, "model_kl": 1.3802948371887207, "prior_ent": 29.267320050048827, "post_ent": 27.893302297973634, "model_loss": 3773.097134375, "model_loss_scale": 11429.4784, "model_grad_norm": Infinity, "actor_loss": 0.011495367746509146, "actor_loss_scale": 11354819.7888, "actor_grad_norm": Infinity, "critic_loss": 0.9146060976982117, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.14797601687610148, "reward_mean": -0.007879058253165386, "reward_std": 0.0770449745118618, "reward_normed_mean": -0.007879058253165386, "reward_normed_std": 0.0770449745118618, "critic_slow": -2.0706359617233274, "critic_target": -2.0622264755249025, "actor_ent": 0.7740405402183532, "actor_ent_scale": 0.0010000000474974513, "critic": -2.0622330575942995, "fps": 113.43617354488251}
{"step": 1937888, "train_return": -4.0, "train_length": 4449.0, "train_total_steps": 484472.0, "train_total_episodes": 309.0, "train_loaded_steps": 484526.0, "train_loaded_episodes": 309.0}
{"step": 1956052, "train_return": -7.0, "train_length": 4541.0, "train_total_steps": 489013.0, "train_total_episodes": 310.0, "train_loaded_steps": 489067.0, "train_loaded_episodes": 310.0}
{"step": 1961356, "kl_loss": 1.3901262794494629, "image_loss": 3772.0, "reward_loss": 0.9198278370857239, "discount_loss": 0.007853498520702124, "model_kl": 1.3901262488365174, "prior_ent": 29.249692651367187, "post_ent": 27.868677505493164, "model_loss": 3773.098137890625, "model_loss_scale": 8192.0, "model_grad_norm": 3.900323603057861, "actor_loss": 0.008536303884594235, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03467826364934445, "critic_loss": 0.914814098072052, "critic_loss_scale": 372454.1952, "critic_grad_norm": 0.15041807377934455, "reward_mean": -0.007891919878683984, "reward_std": 0.07665046243667603, "reward_normed_mean": -0.007891919878683984, "reward_normed_std": 0.07665046243667603, "critic_slow": -1.9881583240509033, "critic_target": -1.9858542015075684, "actor_ent": 0.7735815975189209, "actor_ent_scale": 0.0010000000474974513, "critic": -1.985882211303711, "fps": 114.65536171655273}
{"step": 1965532, "train_return": -19.0, "train_length": 2370.0, "train_total_steps": 491383.0, "train_total_episodes": 311.0, "train_loaded_steps": 491437.0, "train_loaded_episodes": 311.0}
{"step": 1973468, "train_return": -21.0, "train_length": 1984.0, "train_total_steps": 493367.0, "train_total_episodes": 312.0, "train_loaded_steps": 493421.0, "train_loaded_episodes": 312.0}
{"step": 1982112, "train_return": -20.0, "train_length": 2161.0, "train_total_steps": 495528.0, "train_total_episodes": 313.0, "train_loaded_steps": 495582.0, "train_loaded_episodes": 313.0}
{"step": 1999324, "train_return": -3.0, "train_length": 4303.0, "train_total_steps": 499831.0, "train_total_episodes": 314.0, "train_loaded_steps": 499885.0, "train_loaded_episodes": 314.0}
{"step": 2001356, "kl_loss": 1.4011622340202332, "image_loss": 3772.0, "reward_loss": 0.919808863735199, "discount_loss": 0.007797189659625291, "model_kl": 1.4011622054100037, "prior_ent": 29.28132201538086, "post_ent": 27.892944311523436, "model_loss": 3773.098932421875, "model_loss_scale": 8192.0, "model_grad_norm": 4.451942676925659, "actor_loss": 0.004867742837896366, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03400014761686325, "critic_loss": 0.9154548765182495, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.16193529194593428, "reward_mean": -0.007825714356455137, "reward_std": 0.07647512275576591, "reward_normed_mean": -0.007825714356455137, "reward_normed_std": 0.07647512275576591, "critic_slow": -1.941271736907959, "critic_target": -1.9391766921997071, "actor_ent": 0.7572493525505066, "actor_ent_scale": 0.0010000000474974513, "critic": -1.9392824165344238, "fps": 112.47848099054443}
{"step": 2013784, "train_return": -7.0, "train_length": 3615.0, "train_total_steps": 503446.0, "train_total_episodes": 315.0, "train_loaded_steps": 503500.0, "train_loaded_episodes": 315.0}
{"step": 2024644, "train_return": -14.0, "train_length": 2715.0, "train_total_steps": 506161.0, "train_total_episodes": 316.0, "train_loaded_steps": 506215.0, "train_loaded_episodes": 316.0}
{"step": 2041264, "train_return": -6.0, "train_length": 4155.0, "train_total_steps": 510316.0, "train_total_episodes": 317.0, "train_loaded_steps": 510370.0, "train_loaded_episodes": 317.0}
{"step": 2041356, "kl_loss": 1.3721315333366395, "image_loss": 3772.0002, "reward_loss": 0.9197418753623963, "discount_loss": 0.007852441052347421, "model_kl": 1.3721315039634705, "prior_ent": 29.247646041870116, "post_ent": 27.88560002746582, "model_loss": 3773.096437890625, "model_loss_scale": 10236.7232, "model_grad_norm": Infinity, "actor_loss": 0.010985217021188145, "actor_loss_scale": 12133282.6112, "actor_grad_norm": 0.03647400121092796, "critic_loss": 0.9152940672874451, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.15145801795721053, "reward_mean": -0.00805464871518052, "reward_std": 0.07818730440735817, "reward_normed_mean": -0.00805464871518052, "reward_normed_std": 0.07818730440735817, "critic_slow": -1.9124982481002808, "critic_target": -1.9062117059707642, "actor_ent": 0.7784768995285034, "actor_ent_scale": 0.0010000000474974513, "critic": -1.906162183380127, "fps": 114.06270991735143}
{"step": 2054160, "train_return": -14.0, "train_length": 3224.0, "train_total_steps": 513540.0, "train_total_episodes": 318.0, "train_loaded_steps": 513594.0, "train_loaded_episodes": 318.0}
{"step": 2064536, "train_return": -15.0, "train_length": 2594.0, "train_total_steps": 516134.0, "train_total_episodes": 319.0, "train_loaded_steps": 516188.0, "train_loaded_episodes": 319.0}
{"step": 2075524, "train_return": -16.0, "train_length": 2747.0, "train_total_steps": 518881.0, "train_total_episodes": 320.0, "train_loaded_steps": 518935.0, "train_loaded_episodes": 320.0}
{"step": 2081356, "kl_loss": 1.3993255668640137, "image_loss": 3772.0, "reward_loss": 0.9197584525108338, "discount_loss": 0.007824158703535795, "model_kl": 1.3993255376815796, "prior_ent": 29.249103079223634, "post_ent": 27.862809280395506, "model_loss": 3773.098820703125, "model_loss_scale": 8192.0, "model_grad_norm": 4.332571103858948, "actor_loss": 0.010624931417277548, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.037797890233993534, "critic_loss": 0.9146414342880249, "critic_loss_scale": 541065.216, "critic_grad_norm": Infinity, "reward_mean": -0.007848686054097198, "reward_std": 0.07713062563538552, "reward_normed_mean": -0.007848686054097198, "reward_normed_std": 0.07713062563538552, "critic_slow": -1.838576100730896, "critic_target": -1.8314824480056762, "actor_ent": 0.7739294024467468, "actor_ent_scale": 0.0010000000474974513, "critic": -1.831324709892273, "fps": 112.84043690329182}
{"step": 2085944, "train_return": -16.0, "train_length": 2605.0, "train_total_steps": 521486.0, "train_total_episodes": 321.0, "train_loaded_steps": 521540.0, "train_loaded_episodes": 321.0}
{"step": 2099156, "train_return": -5.0, "train_length": 3303.0, "train_total_steps": 524789.0, "train_total_episodes": 322.0, "train_loaded_steps": 524843.0, "train_loaded_episodes": 322.0}
{"step": 2110320, "train_return": -16.0, "train_length": 2791.0, "train_total_steps": 527580.0, "train_total_episodes": 323.0, "train_loaded_steps": 527634.0, "train_loaded_episodes": 323.0}
{"step": 2120948, "train_return": -19.0, "train_length": 2657.0, "train_total_steps": 530237.0, "train_total_episodes": 324.0, "train_loaded_steps": 530291.0, "train_loaded_episodes": 324.0}
{"step": 2121356, "kl_loss": 1.4144604469299316, "image_loss": 3772.0, "reward_loss": 0.9197747468948364, "discount_loss": 0.007886043798923492, "model_kl": 1.4144604179382325, "prior_ent": 29.30700092163086, "post_ent": 27.904392681884765, "model_loss": 3773.10068125, "model_loss_scale": 8192.0, "model_grad_norm": 4.529801758956909, "actor_loss": 0.007741827581776306, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.03633778041005135, "critic_loss": 0.914813506603241, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.15556911066770554, "reward_mean": -0.00784548208853812, "reward_std": 0.07739461064338685, "reward_normed_mean": -0.00784548208853812, "reward_normed_std": 0.07739461064338685, "critic_slow": -1.7939783658981323, "critic_target": -1.7897893815994264, "actor_ent": 0.7524339949607849, "actor_ent_scale": 0.0010000000474974513, "critic": -1.7899530586242676, "fps": 112.33731914049183}
{"step": 2138724, "train_return": -1.0, "train_length": 4444.0, "train_total_steps": 534681.0, "train_total_episodes": 325.0, "train_loaded_steps": 534735.0, "train_loaded_episodes": 325.0}
{"step": 2154808, "train_return": -9.0, "train_length": 4021.0, "train_total_steps": 538702.0, "train_total_episodes": 326.0, "train_loaded_steps": 538756.0, "train_loaded_episodes": 326.0}
{"step": 2161356, "kl_loss": 1.4143118005752564, "image_loss": 3772.0, "reward_loss": 0.9197855564117432, "discount_loss": 0.00783266963288188, "model_kl": 1.4143117673873902, "prior_ent": 29.312084240722655, "post_ent": 27.91101882019043, "model_loss": 3773.10041171875, "model_loss_scale": 8192.0, "model_grad_norm": 4.698246163463592, "actor_loss": 0.011679457616410219, "actor_loss_scale": 16830903.0912, "actor_grad_norm": Infinity, "critic_loss": 0.9152052447319031, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.14090741835832596, "reward_mean": -0.007701214896283636, "reward_std": 0.07755754426121712, "reward_normed_mean": -0.007701214896283636, "reward_normed_std": 0.07755754426121712, "critic_slow": -1.7340440319061279, "critic_target": -1.7273689435958863, "actor_ent": 0.7716932271003724, "actor_ent_scale": 0.0010000000474974513, "critic": -1.72737389793396, "fps": 111.18897759211478}
{"step": 2166500, "train_return": -15.0, "train_length": 2923.0, "train_total_steps": 541625.0, "train_total_episodes": 327.0, "train_loaded_steps": 541679.0, "train_loaded_episodes": 327.0}
{"step": 2184776, "train_return": -3.0, "train_length": 4569.0, "train_total_steps": 546194.0, "train_total_episodes": 328.0, "train_loaded_steps": 546248.0, "train_loaded_episodes": 328.0}
{"step": 2200612, "train_return": -6.0, "train_length": 3959.0, "train_total_steps": 550153.0, "train_total_episodes": 329.0, "train_loaded_steps": 550207.0, "train_loaded_episodes": 329.0}
{"step": 2201352, "eval_return": -16.0, "eval_length": 2696.0, "eval_total_steps": 4725.0, "eval_total_episodes": 4.0, "eval_loaded_steps": 4727.0, "eval_loaded_episodes": 4.0}
{"step": 2201356, "kl_loss": 1.4007749605178832, "image_loss": 3772.0002, "reward_loss": 0.919742529296875, "discount_loss": 0.007873423629999161, "model_kl": 1.4007749292373657, "prior_ent": 29.323344091796876, "post_ent": 27.93359803161621, "model_loss": 3773.09940859375, "model_loss_scale": 10643.0464, "model_grad_norm": Infinity, "actor_loss": 0.00950266917059198, "actor_loss_scale": 16414828.1344, "actor_grad_norm": Infinity, "critic_loss": 0.9161369450569152, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.15496078473329544, "reward_mean": -0.0076138996118766955, "reward_std": 0.07717709176540374, "reward_normed_mean": -0.0076138996118766955, "reward_normed_std": 0.07717709176540374, "critic_slow": -1.6485770210266113, "critic_target": -1.6425977855682372, "actor_ent": 0.7589820818901062, "actor_ent_scale": 0.0010000000474974513, "critic": -1.6428901893615722, "fps": 106.76886457339897}
{"step": 2222304, "train_return": -1.0, "train_length": 5423.0, "train_total_steps": 555576.0, "train_total_episodes": 330.0, "train_loaded_steps": 555630.0, "train_loaded_episodes": 330.0}
{"step": 2237140, "train_return": -5.0, "train_length": 3709.0, "train_total_steps": 559285.0, "train_total_episodes": 331.0, "train_loaded_steps": 559339.0, "train_loaded_episodes": 331.0}
{"step": 2241356, "kl_loss": 1.3972487332344055, "image_loss": 3772.0, "reward_loss": 0.9197593486785889, "discount_loss": 0.007787578006833792, "model_kl": 1.3972487045288087, "prior_ent": 29.301819982910157, "post_ent": 27.913281927490235, "model_loss": 3773.098444140625, "model_loss_scale": 8192.0, "model_grad_norm": 4.474304356384278, "actor_loss": 0.008707244057615754, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.040570228305459026, "critic_loss": 0.9163767680168152, "critic_loss_scale": 653472.5632, "critic_grad_norm": Infinity, "reward_mean": -0.007768837068078574, "reward_std": 0.07755531951785087, "reward_normed_mean": -0.007768837068078574, "reward_normed_std": 0.07755531951785087, "critic_slow": -1.5771927642822265, "critic_target": -1.5710712406158447, "actor_ent": 0.7264951685905456, "actor_ent_scale": 0.0010000000474974513, "critic": -1.5713222887039184, "fps": 111.06536403604491}
{"step": 2248524, "train_return": -15.0, "train_length": 2846.0, "train_total_steps": 562131.0, "train_total_episodes": 332.0, "train_loaded_steps": 562185.0, "train_loaded_episodes": 332.0}
{"step": 2258740, "train_return": -16.0, "train_length": 2554.0, "train_total_steps": 564685.0, "train_total_episodes": 333.0, "train_loaded_steps": 564739.0, "train_loaded_episodes": 333.0}
{"step": 2271176, "train_return": -13.0, "train_length": 3109.0, "train_total_steps": 567794.0, "train_total_episodes": 334.0, "train_loaded_steps": 567848.0, "train_loaded_episodes": 334.0}
{"step": 2281356, "kl_loss": 1.4097683069229126, "image_loss": 3772.0, "reward_loss": 0.9197131737709046, "discount_loss": 0.00782232109233737, "model_kl": 1.4097682758331298, "prior_ent": 29.314269058227538, "post_ent": 27.918795596313476, "model_loss": 3773.09982109375, "model_loss_scale": 8192.0, "model_grad_norm": 5.0870390815734865, "actor_loss": 0.011480974174989387, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.042134412291646, "critic_loss": 0.9165509387016296, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.13987199615240098, "reward_mean": -0.007701192974285004, "reward_std": 0.07772060407996177, "reward_normed_mean": -0.007701192974285004, "reward_normed_std": 0.07772060407996177, "critic_slow": -1.4749163093566895, "critic_target": -1.4642706638336183, "actor_ent": 0.6556929816246033, "actor_ent_scale": 0.0010000000474974513, "critic": -1.4643840032577515, "fps": 111.9763287451388}
{"step": 2283220, "train_return": -17.0, "train_length": 3011.0, "train_total_steps": 570805.0, "train_total_episodes": 335.0, "train_loaded_steps": 570859.0, "train_loaded_episodes": 335.0}
{"step": 2301520, "train_return": -5.0, "train_length": 4575.0, "train_total_steps": 575380.0, "train_total_episodes": 336.0, "train_loaded_steps": 575434.0, "train_loaded_episodes": 336.0}
{"step": 2312548, "train_return": -16.0, "train_length": 2757.0, "train_total_steps": 578137.0, "train_total_episodes": 337.0, "train_loaded_steps": 578191.0, "train_loaded_episodes": 337.0}
{"step": 2321356, "kl_loss": 1.4050807628631592, "image_loss": 3772.0, "reward_loss": 0.9196807049751282, "discount_loss": 0.007777114538103342, "model_kl": 1.4050807333946227, "prior_ent": 29.384180978393555, "post_ent": 27.993160034179688, "model_loss": 3773.099092578125, "model_loss_scale": 10066.3296, "model_grad_norm": Infinity, "actor_loss": 0.007929710000567138, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.04002591575980186, "critic_loss": 0.9168395258903503, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.14193628854751586, "reward_mean": -0.00762057179271942, "reward_std": 0.07762278724908829, "reward_normed_mean": -0.00762057179271942, "reward_normed_std": 0.07762278724908829, "critic_slow": -1.4186653162956238, "critic_target": -1.4101002432823182, "actor_ent": 0.6402368763923645, "actor_ent_scale": 0.0010000000474974513, "critic": -1.4102284708976747, "fps": 114.06807381593306}
{"step": 2327244, "train_return": -11.0, "train_length": 3674.0, "train_total_steps": 581811.0, "train_total_episodes": 338.0, "train_loaded_steps": 581865.0, "train_loaded_episodes": 338.0}
{"step": 2343172, "train_return": -8.0, "train_length": 3982.0, "train_total_steps": 585793.0, "train_total_episodes": 339.0, "train_loaded_steps": 585847.0, "train_loaded_episodes": 339.0}
{"step": 2359868, "train_return": -11.0, "train_length": 4174.0, "train_total_steps": 589967.0, "train_total_episodes": 340.0, "train_loaded_steps": 590021.0, "train_loaded_episodes": 340.0}
{"step": 2361356, "kl_loss": 1.426409714126587, "image_loss": 3772.000587890625, "reward_loss": 0.919689354133606, "discount_loss": 0.007802144683152437, "model_kl": 1.4264096853256225, "prior_ent": 29.40417268371582, "post_ent": 27.991255377197266, "model_loss": 3773.101936328125, "model_loss_scale": 8192.0, "model_grad_norm": 4.965912593650818, "actor_loss": 0.01191752130400273, "actor_loss_scale": 15461882.2656, "actor_grad_norm": 0.0412628648430109, "critic_loss": 0.9175265740394593, "critic_loss_scale": 579652.8128, "critic_grad_norm": Infinity, "reward_mean": -0.007456542642472777, "reward_std": 0.07744924989938735, "reward_normed_mean": -0.007456542642472777, "reward_normed_std": 0.07744924989938735, "critic_slow": -1.2624762411117554, "critic_target": -1.2494980780601501, "actor_ent": 0.6474993063926697, "actor_ent_scale": 0.0010000000474974513, "critic": -1.24999332113266, "fps": 111.98058103780136}
{"step": 2370204, "train_return": -16.0, "train_length": 2584.0, "train_total_steps": 592551.0, "train_total_episodes": 341.0, "train_loaded_steps": 592605.0, "train_loaded_episodes": 341.0}
{"step": 2383812, "train_return": -13.0, "train_length": 3402.0, "train_total_steps": 595953.0, "train_total_episodes": 342.0, "train_loaded_steps": 596007.0, "train_loaded_episodes": 342.0}
{"step": 2398328, "train_return": -12.0, "train_length": 3629.0, "train_total_steps": 599582.0, "train_total_episodes": 343.0, "train_loaded_steps": 599636.0, "train_loaded_episodes": 343.0}
{"step": 2401356, "kl_loss": 1.4043518675804139, "image_loss": 3772.0, "reward_loss": 0.919711701965332, "discount_loss": 0.007745314615219831, "model_kl": 1.4043518362998964, "prior_ent": 29.411182513427736, "post_ent": 28.016325067138673, "model_loss": 3773.098883984375, "model_loss_scale": 8192.0, "model_grad_norm": 5.258801286315918, "actor_loss": 0.009957433000166202, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.04424538378417492, "critic_loss": 0.9187415194511414, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.1437542548596859, "reward_mean": -0.007582548675058934, "reward_std": 0.0776607720375061, "reward_normed_mean": -0.007582548675058934, "reward_normed_std": 0.0776607720375061, "critic_slow": -1.1677375494003297, "critic_target": -1.1589616404533387, "actor_ent": 0.6623798299789428, "actor_ent_scale": 0.0010000000474974513, "critic": -1.158975512123108, "fps": 111.05152350167722}
{"step": 2410836, "train_return": -15.0, "train_length": 3127.0, "train_total_steps": 602709.0, "train_total_episodes": 344.0, "train_loaded_steps": 602763.0, "train_loaded_episodes": 344.0}
{"step": 2423140, "train_return": -13.0, "train_length": 3076.0, "train_total_steps": 605785.0, "train_total_episodes": 345.0, "train_loaded_steps": 605839.0, "train_loaded_episodes": 345.0}
{"step": 2439104, "train_return": -7.0, "train_length": 3991.0, "train_total_steps": 609776.0, "train_total_episodes": 346.0, "train_loaded_steps": 609830.0, "train_loaded_episodes": 346.0}
{"step": 2441356, "kl_loss": 1.4419581142425537, "image_loss": 3772.0, "reward_loss": 0.9196814636230469, "discount_loss": 0.007800021740049123, "model_kl": 1.4419580810546875, "prior_ent": 29.483064932250976, "post_ent": 28.056209649658204, "model_loss": 3773.102898046875, "model_loss_scale": 8414.8224, "model_grad_norm": 4.999893664932251, "actor_loss": 0.009687580160144716, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.04373853704035282, "critic_loss": 0.9191414691925048, "critic_loss_scale": 291084.6976, "critic_grad_norm": Infinity, "reward_mean": -0.007229613650201645, "reward_std": 0.07637204224467277, "reward_normed_mean": -0.007229613650201645, "reward_normed_std": 0.07637204224467277, "critic_slow": -1.0482726309776307, "critic_target": -1.040788195705414, "actor_ent": 0.6222840794563294, "actor_ent_scale": 0.0010000000474974513, "critic": -1.04112342004776, "fps": 111.95004965064578}
{"step": 2451984, "train_return": -15.0, "train_length": 3220.0, "train_total_steps": 612996.0, "train_total_episodes": 347.0, "train_loaded_steps": 613050.0, "train_loaded_episodes": 347.0}
{"step": 2468492, "train_return": -6.0, "train_length": 4127.0, "train_total_steps": 617123.0, "train_total_episodes": 348.0, "train_loaded_steps": 617177.0, "train_loaded_episodes": 348.0}
{"step": 2481356, "kl_loss": 1.4297004505157471, "image_loss": 3772.0, "reward_loss": 0.9196945559501648, "discount_loss": 0.007840055029839277, "model_kl": 1.429700417327881, "prior_ent": 29.469241906738283, "post_ent": 28.055162786865235, "model_loss": 3773.101887109375, "model_loss_scale": 8768.7168, "model_grad_norm": Infinity, "actor_loss": 0.0068246151091705546, "actor_loss_scale": 17045651.456, "actor_grad_norm": Infinity, "critic_loss": 0.920551909828186, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.14486419833302497, "reward_mean": -0.0074821837308816615, "reward_std": 0.0770158734023571, "reward_normed_mean": -0.0074821837308816615, "reward_normed_std": 0.0770158734023571, "critic_slow": -0.9846676912307739, "critic_target": -0.9806905249595642, "actor_ent": 0.6141763818740845, "actor_ent_scale": 0.0010000000474974513, "critic": -0.9809641436576844, "fps": 110.85831492724321}
{"step": 2483292, "train_return": -5.0, "train_length": 3700.0, "train_total_steps": 620823.0, "train_total_episodes": 349.0, "train_loaded_steps": 620877.0, "train_loaded_episodes": 349.0}
{"step": 2496564, "train_return": -9.0, "train_length": 3318.0, "train_total_steps": 624141.0, "train_total_episodes": 350.0, "train_loaded_steps": 624195.0, "train_loaded_episodes": 350.0}
{"step": 2506440, "train_return": -13.0, "train_length": 2469.0, "train_total_steps": 626610.0, "train_total_episodes": 351.0, "train_loaded_steps": 626664.0, "train_loaded_episodes": 351.0}
{"step": 2516424, "train_return": -15.0, "train_length": 2496.0, "train_total_steps": 629106.0, "train_total_episodes": 352.0, "train_loaded_steps": 629160.0, "train_loaded_episodes": 352.0}
{"step": 2521356, "kl_loss": 1.528785906791687, "image_loss": 3772.0, "reward_loss": 0.9196878405570984, "discount_loss": 0.0077901227682828905, "model_kl": 1.5287858774185181, "prior_ent": 29.51608681335449, "post_ent": 28.01044758911133, "model_loss": 3773.111528125, "model_loss_scale": 8192.0, "model_grad_norm": 5.091788706970215, "actor_loss": 0.008581023955193813, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.04844019943475723, "critic_loss": 0.9210656632423401, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.1464181025326252, "reward_mean": -0.007205966454924783, "reward_std": 0.07723909093737602, "reward_normed_mean": -0.007205966454924783, "reward_normed_std": 0.07723909093737602, "critic_slow": -0.8809141554355622, "critic_target": -0.8735626728057861, "actor_ent": 0.6377662117958068, "actor_ent_scale": 0.0010000000474974513, "critic": -0.8735374640464783, "fps": 113.76760546200755}
{"step": 2530972, "train_return": -7.0, "train_length": 3637.0, "train_total_steps": 632743.0, "train_total_episodes": 353.0, "train_loaded_steps": 632797.0, "train_loaded_episodes": 353.0}
{"step": 2545028, "train_return": -7.0, "train_length": 3514.0, "train_total_steps": 636257.0, "train_total_episodes": 354.0, "train_loaded_steps": 636311.0, "train_loaded_episodes": 354.0}
{"step": 2556016, "train_return": -13.0, "train_length": 2747.0, "train_total_steps": 639004.0, "train_total_episodes": 355.0, "train_loaded_steps": 639058.0, "train_loaded_episodes": 355.0}
{"step": 2561356, "kl_loss": 1.42178138256073, "image_loss": 3772.0, "reward_loss": 0.9196790795326233, "discount_loss": 0.007744357412308454, "model_kl": 1.4217813501358032, "prior_ent": 29.56042082824707, "post_ent": 28.14072612915039, "model_loss": 3773.10059140625, "model_loss_scale": 8192.0, "model_grad_norm": 5.368462193489075, "actor_loss": 0.006632951599429362, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.04707869879603386, "critic_loss": 0.920595343875885, "critic_loss_scale": 442918.5024, "critic_grad_norm": 0.14608870559334755, "reward_mean": -0.007357053521439229, "reward_std": 0.0770855714559555, "reward_normed_mean": -0.007357053521439229, "reward_normed_std": 0.0770855714559555, "critic_slow": -0.7917597423553466, "critic_target": -0.7861431438446045, "actor_ent": 0.5793113142967224, "actor_ent_scale": 0.0010000000474974513, "critic": -0.7863841382026673, "fps": 110.46771236957119}
{"step": 2565408, "train_return": -17.0, "train_length": 2348.0, "train_total_steps": 641352.0, "train_total_episodes": 356.0, "train_loaded_steps": 641406.0, "train_loaded_episodes": 356.0}
{"step": 2581548, "train_return": -4.0, "train_length": 4035.0, "train_total_steps": 645387.0, "train_total_episodes": 357.0, "train_loaded_steps": 645441.0, "train_loaded_episodes": 357.0}
{"step": 2595756, "train_return": -10.0, "train_length": 3552.0, "train_total_steps": 648939.0, "train_total_episodes": 358.0, "train_loaded_steps": 648993.0, "train_loaded_episodes": 358.0}
{"step": 2601356, "kl_loss": 1.4821441593170166, "image_loss": 3772.0, "reward_loss": 0.9196816327095032, "discount_loss": 0.007832299110293388, "model_kl": 1.4821441272735596, "prior_ent": 29.607237124633787, "post_ent": 28.137832000732423, "model_loss": 3773.10707734375, "model_loss_scale": 14168.8832, "model_grad_norm": 5.336203490829468, "actor_loss": 0.003281942039419664, "actor_loss_scale": 14589467.0336, "actor_grad_norm": Infinity, "critic_loss": 0.9220818012237549, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.15897238466739655, "reward_mean": -0.007330849578775815, "reward_std": 0.07734697841405869, "reward_normed_mean": -0.007330849578775815, "reward_normed_std": 0.07734697841405869, "critic_slow": -0.7379410346984864, "critic_target": -0.740665399646759, "actor_ent": 0.5750697316169738, "actor_ent_scale": 0.0010000000474974513, "critic": -0.7406975327014923, "fps": 113.1246491757461}
{"step": 2609784, "train_return": -10.0, "train_length": 3507.0, "train_total_steps": 652446.0, "train_total_episodes": 359.0, "train_loaded_steps": 652500.0, "train_loaded_episodes": 359.0}
{"step": 2622248, "train_return": -14.0, "train_length": 3116.0, "train_total_steps": 655562.0, "train_total_episodes": 360.0, "train_loaded_steps": 655616.0, "train_loaded_episodes": 360.0}
{"step": 2637240, "train_return": -12.0, "train_length": 3748.0, "train_total_steps": 659310.0, "train_total_episodes": 361.0, "train_loaded_steps": 659364.0, "train_loaded_episodes": 361.0}
{"step": 2641356, "kl_loss": 1.4247012603759766, "image_loss": 3772.0, "reward_loss": 0.9196246744155884, "discount_loss": 0.0077407359950244425, "model_kl": 1.424701231956482, "prior_ent": 29.544426876831054, "post_ent": 28.126193716430663, "model_loss": 3773.10081015625, "model_loss_scale": 8480.3584, "model_grad_norm": Infinity, "actor_loss": 0.006662819804723767, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.04859540672302246, "critic_loss": 0.9203340424537658, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.14433240224123, "reward_mean": -0.0072041225678513, "reward_std": 0.07712310209274292, "reward_normed_mean": -0.0072041225678513, "reward_normed_std": 0.07712310209274292, "critic_slow": -0.7310700815200806, "critic_target": -0.7265921793460846, "actor_ent": 0.5587194341659546, "actor_ent_scale": 0.0010000000474974513, "critic": -0.7265241987228394, "fps": 111.07073841459493}
{"step": 2650200, "train_return": -14.0, "train_length": 3240.0, "train_total_steps": 662550.0, "train_total_episodes": 362.0, "train_loaded_steps": 662604.0, "train_loaded_episodes": 362.0}
{"step": 2666452, "train_return": -5.0, "train_length": 4063.0, "train_total_steps": 666613.0, "train_total_episodes": 363.0, "train_loaded_steps": 666667.0, "train_loaded_episodes": 363.0}
{"step": 2681356, "kl_loss": 1.5603362337112427, "image_loss": 3772.0, "reward_loss": 0.9196803194999695, "discount_loss": 0.007906287525594234, "model_kl": 1.5603361974716186, "prior_ent": 29.590074932861327, "post_ent": 28.05920400695801, "model_loss": 3773.115262109375, "model_loss_scale": 4148.4288, "model_grad_norm": Infinity, "actor_loss": -0.00025632013863651084, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.044344889113307, "critic_loss": 0.9172404567718506, "critic_loss_scale": 398878.3104, "critic_grad_norm": Infinity, "reward_mean": -0.007172057637677062, "reward_std": 0.07658900416493415, "reward_normed_mean": -0.007172057637677062, "reward_normed_std": 0.07658900416493415, "critic_slow": -0.701002655172348, "critic_target": -0.7043404225826263, "actor_ent": 0.6151004909038543, "actor_ent_scale": 0.0010000000474974513, "critic": -0.7046794098854064, "fps": 110.88882928657085}
{"step": 2681960, "train_return": -2.0, "train_length": 3877.0, "train_total_steps": 670490.0, "train_total_episodes": 364.0, "train_loaded_steps": 670544.0, "train_loaded_episodes": 364.0}
{"step": 2692776, "train_return": -9.0, "train_length": 2704.0, "train_total_steps": 673194.0, "train_total_episodes": 365.0, "train_loaded_steps": 673248.0, "train_loaded_episodes": 365.0}
{"step": 2705820, "train_return": -8.0, "train_length": 3261.0, "train_total_steps": 676455.0, "train_total_episodes": 366.0, "train_loaded_steps": 676509.0, "train_loaded_episodes": 366.0}
{"step": 2719164, "train_return": -7.0, "train_length": 3336.0, "train_total_steps": 679791.0, "train_total_episodes": 367.0, "train_loaded_steps": 679845.0, "train_loaded_episodes": 367.0}
{"step": 2721356, "kl_loss": 1.4452604806900025, "image_loss": 3772.0, "reward_loss": 0.9196680599212647, "discount_loss": 0.007806509325653315, "model_kl": 1.4452604457855225, "prior_ent": 29.62431040649414, "post_ent": 28.18529381713867, "model_loss": 3773.10323984375, "model_loss_scale": 4096.0, "model_grad_norm": 5.526075149726868, "actor_loss": 0.008089014473112183, "actor_loss_scale": 9274445.0048, "actor_grad_norm": 0.0440092633664608, "critic_loss": 0.9183172009468079, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.12839500409960747, "reward_mean": -0.007007965257723117, "reward_std": 0.07704915135502816, "reward_normed_mean": -0.007007965257723117, "reward_normed_std": 0.07704915135502816, "critic_slow": -0.6338775204658509, "critic_target": -0.6327789345264435, "actor_ent": 0.6124023878097534, "actor_ent_scale": 0.0010000000474974513, "critic": -0.6329795624256134, "fps": 110.98298519645552}
{"step": 2733080, "train_return": -3.0, "train_length": 3479.0, "train_total_steps": 683270.0, "train_total_episodes": 368.0, "train_loaded_steps": 683324.0, "train_loaded_episodes": 368.0}
{"step": 2745996, "train_return": -5.0, "train_length": 3229.0, "train_total_steps": 686499.0, "train_total_episodes": 369.0, "train_loaded_steps": 686553.0, "train_loaded_episodes": 369.0}
{"step": 2761356, "kl_loss": 1.4345958890914916, "image_loss": 3772.0, "reward_loss": 0.919625550365448, "discount_loss": 0.00780950174704194, "model_kl": 1.4345958595275878, "prior_ent": 29.62706630554199, "post_ent": 28.19856682739258, "model_loss": 3773.1021625, "model_loss_scale": 4096.0, "model_grad_norm": 5.853956259536743, "actor_loss": -0.004899619842710672, "actor_loss_scale": 9878424.7808, "actor_grad_norm": Infinity, "critic_loss": 0.917296069908142, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.12046493200957775, "reward_mean": -0.007142587764118798, "reward_std": 0.07702165797948837, "reward_normed_mean": -0.007142587764118798, "reward_normed_std": 0.07702165797948837, "critic_slow": -0.6246438591480256, "critic_target": -0.6354438084602356, "actor_ent": 0.6501630682945252, "actor_ent_scale": 0.0010000000474974513, "critic": -0.6353998471260071, "fps": 111.57414275604671}
{"step": 2761528, "train_return": -1.0, "train_length": 3883.0, "train_total_steps": 690382.0, "train_total_episodes": 370.0, "train_loaded_steps": 690436.0, "train_loaded_episodes": 370.0}
{"step": 2774092, "train_return": -7.0, "train_length": 3141.0, "train_total_steps": 693523.0, "train_total_episodes": 371.0, "train_loaded_steps": 693577.0, "train_loaded_episodes": 371.0}
{"step": 2785088, "train_return": -8.0, "train_length": 2749.0, "train_total_steps": 696272.0, "train_total_episodes": 372.0, "train_loaded_steps": 696326.0, "train_loaded_episodes": 372.0}
{"step": 2798708, "train_return": 2.0, "train_length": 3405.0, "train_total_steps": 699677.0, "train_total_episodes": 373.0, "train_loaded_steps": 699731.0, "train_loaded_episodes": 373.0}
{"step": 2801356, "kl_loss": 1.440622032737732, "image_loss": 3772.0, "reward_loss": 0.9196219597816467, "discount_loss": 0.007770106077939272, "model_kl": 1.4406219989776612, "prior_ent": 29.59628514099121, "post_ent": 28.165310174560545, "model_loss": 3773.10255, "model_loss_scale": 7320.3712, "model_grad_norm": 5.383023150634766, "actor_loss": 0.0012932028096256545, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.040946232387423516, "critic_loss": 0.9164146775245666, "critic_loss_scale": 335963.7504, "critic_grad_norm": 0.12202412379682064, "reward_mean": -0.006945991729917295, "reward_std": 0.07689784942269325, "reward_normed_mean": -0.006945991729917295, "reward_normed_std": 0.07689784942269325, "critic_slow": -0.6599052617549896, "critic_target": -0.6621425468444824, "actor_ent": 0.658297552394867, "actor_ent_scale": 0.0010000000474974513, "critic": -0.6622260274887085, "fps": 110.09049683893188}
{"step": 2810140, "train_return": -9.0, "train_length": 2858.0, "train_total_steps": 702535.0, "train_total_episodes": 374.0, "train_loaded_steps": 702589.0, "train_loaded_episodes": 374.0}
{"step": 2828252, "train_return": -1.0, "train_length": 4528.0, "train_total_steps": 707063.0, "train_total_episodes": 375.0, "train_loaded_steps": 707117.0, "train_loaded_episodes": 375.0}
{"step": 2837724, "train_return": -14.0, "train_length": 2368.0, "train_total_steps": 709431.0, "train_total_episodes": 376.0, "train_loaded_steps": 709485.0, "train_loaded_episodes": 376.0}
{"step": 2841356, "kl_loss": 1.4583577785491944, "image_loss": 3772.0, "reward_loss": 0.9196093522071839, "discount_loss": 0.007756188504397869, "model_kl": 1.4583577474594116, "prior_ent": 29.579493197631837, "post_ent": 28.135472283935545, "model_loss": 3773.104246875, "model_loss_scale": 8192.0, "model_grad_norm": 5.845543170547486, "actor_loss": 0.003164341231412254, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.040326330721378326, "critic_loss": 0.9157570962905883, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.11948379918932915, "reward_mean": -0.0068610000438100545, "reward_std": 0.07639182779192924, "reward_normed_mean": -0.0068610000438100545, "reward_normed_std": 0.07639182779192924, "critic_slow": -0.6347674571514129, "critic_target": -0.6374733855247497, "actor_ent": 0.6456544976234436, "actor_ent_scale": 0.0010000000474974513, "critic": -0.637554832983017, "fps": 112.56117729743964}
{"step": 2852040, "train_return": 1.0, "train_length": 3579.0, "train_total_steps": 713010.0, "train_total_episodes": 377.0, "train_loaded_steps": 713064.0, "train_loaded_episodes": 377.0}
{"step": 2864460, "train_return": -5.0, "train_length": 3105.0, "train_total_steps": 716115.0, "train_total_episodes": 378.0, "train_loaded_steps": 716169.0, "train_loaded_episodes": 378.0}
{"step": 2875244, "train_return": -12.0, "train_length": 2696.0, "train_total_steps": 718811.0, "train_total_episodes": 379.0, "train_loaded_steps": 718865.0, "train_loaded_episodes": 379.0}
{"step": 2881356, "kl_loss": 1.6073249755859376, "image_loss": 3772.0, "reward_loss": 0.9196572615623474, "discount_loss": 0.007829629445821046, "model_kl": 1.6073249410629273, "prior_ent": 29.531849475097655, "post_ent": 27.951758016967773, "model_loss": 3773.1195546875, "model_loss_scale": 8192.0, "model_grad_norm": 5.959250251960754, "actor_loss": 0.0009253598216564569, "actor_loss_scale": 13609677.6192, "actor_grad_norm": 0.03962204948663711, "critic_loss": 0.9156643914222717, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.11656081178784371, "reward_mean": -0.006737318137922557, "reward_std": 0.07652854567170143, "reward_normed_mean": -0.006737318137922557, "reward_normed_std": 0.07652854567170143, "critic_slow": -0.6424253885746002, "critic_target": -0.6465108809947967, "actor_ent": 0.6655709881782532, "actor_ent_scale": 0.0010000000474974513, "critic": -0.6465350561141968, "fps": 111.07801640450425}
{"step": 2885812, "train_return": -13.0, "train_length": 2642.0, "train_total_steps": 721453.0, "train_total_episodes": 380.0, "train_loaded_steps": 721507.0, "train_loaded_episodes": 380.0}
{"step": 2897032, "train_return": -10.0, "train_length": 2805.0, "train_total_steps": 724258.0, "train_total_episodes": 381.0, "train_loaded_steps": 724312.0, "train_loaded_episodes": 381.0}
{"step": 2910812, "train_return": -3.0, "train_length": 3445.0, "train_total_steps": 727703.0, "train_total_episodes": 382.0, "train_loaded_steps": 727757.0, "train_loaded_episodes": 382.0}
{"step": 2921356, "kl_loss": 1.4559187655448913, "image_loss": 3772.0, "reward_loss": 0.919586019039154, "discount_loss": 0.0077898462496697905, "model_kl": 1.4559187346458435, "prior_ent": 29.59838278808594, "post_ent": 28.145405822753908, "model_loss": 3773.10414609375, "model_loss_scale": 12871.2704, "model_grad_norm": Infinity, "actor_loss": 0.0047981253958249, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.04094477668106556, "critic_loss": 0.9164808407783508, "critic_loss_scale": 567069.9008, "critic_grad_norm": 0.10175896867513656, "reward_mean": -0.0066598711267462935, "reward_std": 0.07651633269190788, "reward_normed_mean": -0.0066598711267462935, "reward_normed_std": 0.07651633269190788, "critic_slow": -0.6295795588493347, "critic_target": -0.629097365474701, "actor_ent": 0.7057102588653564, "actor_ent_scale": 0.0010000000474974513, "critic": -0.6291087695598603, "fps": 112.4623822716028}
{"step": 2922532, "train_return": -13.0, "train_length": 2930.0, "train_total_steps": 730633.0, "train_total_episodes": 383.0, "train_loaded_steps": 730687.0, "train_loaded_episodes": 383.0}
{"step": 2937348, "train_return": -1.0, "train_length": 3704.0, "train_total_steps": 734337.0, "train_total_episodes": 384.0, "train_loaded_steps": 734391.0, "train_loaded_episodes": 384.0}
{"step": 2955928, "train_return": 1.0, "train_length": 4645.0, "train_total_steps": 738982.0, "train_total_episodes": 385.0, "train_loaded_steps": 739036.0, "train_loaded_episodes": 385.0}
{"step": 2961356, "kl_loss": 1.450209344291687, "image_loss": 3772.0, "reward_loss": 0.9196176003456116, "discount_loss": 0.007791118157655001, "model_kl": 1.4502093095779418, "prior_ent": 29.588636001586913, "post_ent": 28.146928515625, "model_loss": 3773.103609375, "model_loss_scale": 8192.0, "model_grad_norm": 5.913915077209473, "actor_loss": 0.005337736039664014, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.04222085280716419, "critic_loss": 0.9170121722221375, "critic_loss_scale": 550292.6848, "critic_grad_norm": Infinity, "reward_mean": -0.0069321354092215185, "reward_std": 0.07731724506020546, "reward_normed_mean": -0.0069321354092215185, "reward_normed_std": 0.07731724506020546, "critic_slow": -0.5879116567134857, "critic_target": -0.587953114748001, "actor_ent": 0.7004078844070435, "actor_ent_scale": 0.0010000000474974513, "critic": -0.5880574694633484, "fps": 110.6486405123086}
{"step": 2968704, "train_return": -6.0, "train_length": 3194.0, "train_total_steps": 742176.0, "train_total_episodes": 386.0, "train_loaded_steps": 742230.0, "train_loaded_episodes": 386.0}
{"step": 2981696, "train_return": -8.0, "train_length": 3248.0, "train_total_steps": 745424.0, "train_total_episodes": 387.0, "train_loaded_steps": 745478.0, "train_loaded_episodes": 387.0}
{"step": 2999224, "train_return": 1.0, "train_length": 4382.0, "train_total_steps": 749806.0, "train_total_episodes": 388.0, "train_loaded_steps": 749860.0, "train_loaded_episodes": 388.0}
{"step": 3001356, "kl_loss": 1.4814965532302857, "image_loss": 3772.0, "reward_loss": 0.9196151446342469, "discount_loss": 0.0078101934030652045, "model_kl": 1.481496520805359, "prior_ent": 29.595257122802735, "post_ent": 28.127638177490233, "model_loss": 3773.10683515625, "model_loss_scale": 8192.0, "model_grad_norm": 6.1085152254104615, "actor_loss": 0.004683520193968434, "actor_loss_scale": 17260399.8208, "actor_grad_norm": Infinity, "critic_loss": 0.9175162762641906, "critic_loss_scale": 382101.0944, "critic_grad_norm": Infinity, "reward_mean": -0.006697190529841464, "reward_std": 0.07667980821728707, "reward_normed_mean": -0.006697190529841464, "reward_normed_std": 0.07667980821728707, "critic_slow": -0.5597978004455566, "critic_target": -0.5612740657806397, "actor_ent": 0.6864893880844116, "actor_ent_scale": 0.0010000000474974513, "critic": -0.561469488143921, "fps": 111.4568845312388}
{"step": 3012552, "train_return": 6.0, "train_length": 3332.0, "train_total_steps": 753138.0, "train_total_episodes": 389.0, "train_loaded_steps": 753192.0, "train_loaded_episodes": 389.0}
{"step": 3025588, "train_return": -9.0, "train_length": 3259.0, "train_total_steps": 756397.0, "train_total_episodes": 390.0, "train_loaded_steps": 756451.0, "train_loaded_episodes": 390.0}
{"step": 3040604, "train_return": -4.0, "train_length": 3754.0, "train_total_steps": 760151.0, "train_total_episodes": 391.0, "train_loaded_steps": 760205.0, "train_loaded_episodes": 391.0}
{"step": 3041356, "kl_loss": 1.4633897666931153, "image_loss": 3772.0, "reward_loss": 0.9196315272331238, "discount_loss": 0.007845187785476446, "model_kl": 1.463389732170105, "prior_ent": 29.590283294677736, "post_ent": 28.13843417663574, "model_loss": 3773.105217578125, "model_loss_scale": 8192.0, "model_grad_norm": 5.774275192260742, "actor_loss": 0.003388830978723854, "actor_loss_scale": 16079283.8144, "actor_grad_norm": Infinity, "critic_loss": 0.9167859745979309, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.10977485986948013, "reward_mean": -0.006684519350636401, "reward_std": 0.07691082000136376, "reward_normed_mean": -0.006684519350636401, "reward_normed_std": 0.07691082000136376, "critic_slow": -0.5424979866504669, "critic_target": -0.5427620850086212, "actor_ent": 0.666472781944275, "actor_ent_scale": 0.0010000000474974513, "critic": -0.5428627520084381, "fps": 111.44721320919906}
{"step": 3053840, "train_return": -6.0, "train_length": 3309.0, "train_total_steps": 763460.0, "train_total_episodes": 392.0, "train_loaded_steps": 763514.0, "train_loaded_episodes": 392.0}
{"step": 3065336, "train_return": -9.0, "train_length": 2874.0, "train_total_steps": 766334.0, "train_total_episodes": 393.0, "train_loaded_steps": 766388.0, "train_loaded_episodes": 393.0}
{"step": 3079852, "train_return": -4.0, "train_length": 3629.0, "train_total_steps": 769963.0, "train_total_episodes": 394.0, "train_loaded_steps": 770017.0, "train_loaded_episodes": 394.0}
{"step": 3081356, "kl_loss": 1.4904603786468507, "image_loss": 3772.0, "reward_loss": 0.9196202507019043, "discount_loss": 0.007801283390074968, "model_kl": 1.4904603429794312, "prior_ent": 29.590972763061522, "post_ent": 28.117663848876955, "model_loss": 3773.107690234375, "model_loss_scale": 14365.4912, "model_grad_norm": Infinity, "actor_loss": 0.007098936133016832, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.04319579248726368, "critic_loss": 0.9194023785591126, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.11350924254059791, "reward_mean": -0.006571754581119967, "reward_std": 0.07649864992499351, "reward_normed_mean": -0.006571754581119967, "reward_normed_std": 0.07649864992499351, "critic_slow": -0.5341986668109894, "critic_target": -0.5289995836257935, "actor_ent": 0.7000096732139588, "actor_ent_scale": 0.0010000000474974513, "critic": -0.5291547896385193, "fps": 111.03883652737527}
{"step": 3094072, "train_return": 6.0, "train_length": 3555.0, "train_total_steps": 773518.0, "train_total_episodes": 395.0, "train_loaded_steps": 773572.0, "train_loaded_episodes": 395.0}
{"step": 3106884, "train_return": 4.0, "train_length": 3203.0, "train_total_steps": 776721.0, "train_total_episodes": 396.0, "train_loaded_steps": 776775.0, "train_loaded_episodes": 396.0}
{"step": 3121356, "kl_loss": 1.4707422992706298, "image_loss": 3772.0, "reward_loss": 0.9196174956321717, "discount_loss": 0.00779700622856617, "model_kl": 1.4707422651290893, "prior_ent": 29.586226962280275, "post_ent": 28.12482702636719, "model_loss": 3773.105704296875, "model_loss_scale": 8192.0, "model_grad_norm": 6.037696022224426, "actor_loss": 0.005414350283998647, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.046038596653938293, "critic_loss": 0.9198254390716553, "critic_loss_scale": 351902.1056, "critic_grad_norm": 0.11979381596446037, "reward_mean": -0.006581807815664797, "reward_std": 0.07705931811928748, "reward_normed_mean": -0.006581807815664797, "reward_normed_std": 0.07705931811928748, "critic_slow": -0.45314714179039, "critic_target": -0.4561149799823761, "actor_ent": 0.6178462010383606, "actor_ent_scale": 0.0010000000474974513, "critic": -0.4560220417022705, "fps": 112.09393486836406}
{"step": 3121496, "train_return": 1.0, "train_length": 3653.0, "train_total_steps": 780374.0, "train_total_episodes": 397.0, "train_loaded_steps": 780428.0, "train_loaded_episodes": 397.0}
{"step": 3133628, "train_return": 3.0, "train_length": 3033.0, "train_total_steps": 783407.0, "train_total_episodes": 398.0, "train_loaded_steps": 783461.0, "train_loaded_episodes": 398.0}
{"step": 3146344, "train_return": -5.0, "train_length": 3179.0, "train_total_steps": 786586.0, "train_total_episodes": 399.0, "train_loaded_steps": 786640.0, "train_loaded_episodes": 399.0}
{"step": 3158892, "train_return": -6.0, "train_length": 3137.0, "train_total_steps": 789723.0, "train_total_episodes": 400.0, "train_loaded_steps": 789777.0, "train_loaded_episodes": 400.0}
{"step": 3161356, "kl_loss": 1.4825204427719116, "image_loss": 3772.0001921875, "reward_loss": 0.9196259121894836, "discount_loss": 0.007826257746666669, "model_kl": 1.482520408821106, "prior_ent": 29.586472634887695, "post_ent": 28.121406704711916, "model_loss": 3773.107213671875, "model_loss_scale": 8192.0, "model_grad_norm": 5.964332427215576, "actor_loss": -2.9634986254677642e-05, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.04424206693768501, "critic_loss": 0.9190042930603027, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.1244427163720131, "reward_mean": -0.00643231727996681, "reward_std": 0.0767230751335621, "reward_normed_mean": -0.00643231727996681, "reward_normed_std": 0.0767230751335621, "critic_slow": -0.4975727072238922, "critic_target": -0.50319301404953, "actor_ent": 0.6384563743591308, "actor_ent_scale": 0.0010000000474974513, "critic": -0.5032489034891129, "fps": 110.20905062777662}
{"step": 3171384, "train_return": 6.0, "train_length": 3123.0, "train_total_steps": 792846.0, "train_total_episodes": 401.0, "train_loaded_steps": 792900.0, "train_loaded_episodes": 401.0}
{"step": 3186776, "train_return": 1.0, "train_length": 3848.0, "train_total_steps": 796694.0, "train_total_episodes": 402.0, "train_loaded_steps": 796748.0, "train_loaded_episodes": 402.0}
{"step": 3200024, "train_return": -5.0, "train_length": 3312.0, "train_total_steps": 800006.0, "train_total_episodes": 403.0, "train_loaded_steps": 800060.0, "train_loaded_episodes": 403.0}
{"step": 3201352, "eval_return": -2.0, "eval_length": 3514.0, "eval_total_steps": 7421.0, "eval_total_episodes": 5.0, "eval_loaded_steps": 7423.0, "eval_loaded_episodes": 5.0}
{"step": 3201356, "kl_loss": 1.5179112041473388, "image_loss": 3772.0, "reward_loss": 0.9195788382530212, "discount_loss": 0.007801156464219093, "model_kl": 1.5179111700057983, "prior_ent": 29.65063744506836, "post_ent": 28.15064033203125, "model_loss": 3773.1104046875, "model_loss_scale": 8192.0, "model_grad_norm": 5.828158580207825, "actor_loss": 0.007430913242961105, "actor_loss_scale": 15461882.2656, "actor_grad_norm": Infinity, "critic_loss": 0.9199877508163452, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.118954800593853, "reward_mean": -0.0063739384655375035, "reward_std": 0.07684952564835548, "reward_normed_mean": -0.0063739384655375035, "reward_normed_std": 0.07684952564835548, "critic_slow": -0.4673408292293549, "critic_target": -0.4650996296644211, "actor_ent": 0.6991286938667297, "actor_ent_scale": 0.0010000000474974513, "critic": -0.4651005834579468, "fps": 103.91973497864076}
{"step": 3213272, "train_return": 5.0, "train_length": 3312.0, "train_total_steps": 803318.0, "train_total_episodes": 404.0, "train_loaded_steps": 803372.0, "train_loaded_episodes": 404.0}
{"step": 3225024, "train_return": -7.0, "train_length": 2938.0, "train_total_steps": 806256.0, "train_total_episodes": 405.0, "train_loaded_steps": 806310.0, "train_loaded_episodes": 405.0}
{"step": 3237980, "train_return": 5.0, "train_length": 3239.0, "train_total_steps": 809495.0, "train_total_episodes": 406.0, "train_loaded_steps": 809549.0, "train_loaded_episodes": 406.0}
{"step": 3241356, "kl_loss": 1.4743711851119996, "image_loss": 3772.0, "reward_loss": 0.9195696685791016, "discount_loss": 0.007814358960092067, "model_kl": 1.4743711513519286, "prior_ent": 29.626947579956056, "post_ent": 28.160117355346678, "model_loss": 3773.106094921875, "model_loss_scale": 8296.8576, "model_grad_norm": Infinity, "actor_loss": 0.009139647018068353, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.04600246117413044, "critic_loss": 0.9188294253349304, "critic_loss_scale": 558681.2928, "critic_grad_norm": Infinity, "reward_mean": -0.00644199526545126, "reward_std": 0.07726989905238152, "reward_normed_mean": -0.00644199526545126, "reward_normed_std": 0.07726989905238152, "critic_slow": -0.43048166635036467, "critic_target": -0.4281027349472046, "actor_ent": 0.7013657865524292, "actor_ent_scale": 0.0010000000474974513, "critic": -0.4281937171459198, "fps": 109.31839925131759}
{"step": 3250256, "train_return": -4.0, "train_length": 3069.0, "train_total_steps": 812564.0, "train_total_episodes": 407.0, "train_loaded_steps": 812618.0, "train_loaded_episodes": 407.0}
{"step": 3263404, "train_return": 6.0, "train_length": 3287.0, "train_total_steps": 815851.0, "train_total_episodes": 408.0, "train_loaded_steps": 815905.0, "train_loaded_episodes": 408.0}
{"step": 3273568, "train_return": 11.0, "train_length": 2541.0, "train_total_steps": 818392.0, "train_total_episodes": 409.0, "train_loaded_steps": 818446.0, "train_loaded_episodes": 409.0}
{"step": 3281356, "kl_loss": 1.526406247329712, "image_loss": 3772.0, "reward_loss": 0.9196290473937988, "discount_loss": 0.007941087374091148, "model_kl": 1.5264062110900878, "prior_ent": 29.642227349853517, "post_ent": 28.13733609313965, "model_loss": 3773.11199375, "model_loss_scale": 8192.0, "model_grad_norm": 6.209860261535645, "actor_loss": 0.003348923457870842, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.04767150286436081, "critic_loss": 0.921571781539917, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.13130206187963486, "reward_mean": -0.006576897973410087, "reward_std": 0.07725096638798713, "reward_normed_mean": -0.006576897973410087, "reward_normed_std": 0.07725096638798713, "critic_slow": -0.4075477895021439, "critic_target": -0.40989710570573806, "actor_ent": 0.6936704044342041, "actor_ent_scale": 0.0010000000474974513, "critic": -0.4100708827972412, "fps": 111.81417747448268}
{"step": 3286280, "train_return": 4.0, "train_length": 3178.0, "train_total_steps": 821570.0, "train_total_episodes": 410.0, "train_loaded_steps": 821624.0, "train_loaded_episodes": 410.0}
{"step": 3297620, "train_return": 7.0, "train_length": 2835.0, "train_total_steps": 824405.0, "train_total_episodes": 411.0, "train_loaded_steps": 824459.0, "train_loaded_episodes": 411.0}
{"step": 3309728, "train_return": 6.0, "train_length": 3027.0, "train_total_steps": 827432.0, "train_total_episodes": 412.0, "train_loaded_steps": 827486.0, "train_loaded_episodes": 412.0}
{"step": 3318856, "train_return": 14.0, "train_length": 2282.0, "train_total_steps": 829714.0, "train_total_episodes": 413.0, "train_loaded_steps": 829768.0, "train_loaded_episodes": 413.0}
{"step": 3321356, "kl_loss": 1.4732000114440917, "image_loss": 3772.0002, "reward_loss": 0.9195602493286132, "discount_loss": 0.007848139438778162, "model_kl": 1.4731999801635742, "prior_ent": 29.605699380493164, "post_ent": 28.137911721801757, "model_loss": 3773.106342578125, "model_loss_scale": 8192.0, "model_grad_norm": 6.3655889713287355, "actor_loss": 0.012901510949002113, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.0501052139878273, "critic_loss": 0.9228688809394836, "critic_loss_scale": 323380.8384, "critic_grad_norm": Infinity, "reward_mean": -0.006255986052271328, "reward_std": 0.07712567187547684, "reward_normed_mean": -0.006255986052271328, "reward_normed_std": 0.07712567187547684, "critic_slow": -0.34776817061901094, "critic_target": -0.3392002305448055, "actor_ent": 0.6689876586914062, "actor_ent_scale": 0.0010000000474974513, "critic": -0.3393164733886719, "fps": 110.62927590790603}
{"step": 3330624, "train_return": 6.0, "train_length": 2942.0, "train_total_steps": 832656.0, "train_total_episodes": 414.0, "train_loaded_steps": 832710.0, "train_loaded_episodes": 414.0}
{"step": 3340688, "train_return": 8.0, "train_length": 2516.0, "train_total_steps": 835172.0, "train_total_episodes": 415.0, "train_loaded_steps": 835226.0, "train_loaded_episodes": 415.0}
{"step": 3350988, "train_return": 9.0, "train_length": 2575.0, "train_total_steps": 837747.0, "train_total_episodes": 416.0, "train_loaded_steps": 837801.0, "train_loaded_episodes": 416.0}
{"step": 3361356, "kl_loss": 1.4591262811660766, "image_loss": 3772.0, "reward_loss": 0.9195662313461304, "discount_loss": 0.007835611827671528, "model_kl": 1.4591262454986573, "prior_ent": 29.580318475341798, "post_ent": 28.128520736694338, "model_loss": 3773.10467734375, "model_loss_scale": 12084.8384, "model_grad_norm": Infinity, "actor_loss": 0.004322434051143319, "actor_loss_scale": 15435038.72, "actor_grad_norm": 0.04627570498585701, "critic_loss": 0.920723199748993, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.12378025779128074, "reward_mean": -0.0064334682796587, "reward_std": 0.0779207949757576, "reward_normed_mean": -0.0064334682796587, "reward_normed_std": 0.0779207949757576, "critic_slow": -0.31151064674258233, "critic_target": -0.3115990375995636, "actor_ent": 0.6004935628414154, "actor_ent_scale": 0.0010000000474974513, "critic": -0.3116034775018692, "fps": 112.26092075694162}
{"step": 3363076, "train_return": 5.0, "train_length": 3022.0, "train_total_steps": 840769.0, "train_total_episodes": 417.0, "train_loaded_steps": 840823.0, "train_loaded_episodes": 417.0}
{"step": 3373672, "train_return": 9.0, "train_length": 2649.0, "train_total_steps": 843418.0, "train_total_episodes": 418.0, "train_loaded_steps": 843472.0, "train_loaded_episodes": 418.0}
{"step": 3382804, "train_return": 13.0, "train_length": 2283.0, "train_total_steps": 845701.0, "train_total_episodes": 419.0, "train_loaded_steps": 845755.0, "train_loaded_episodes": 419.0}
{"step": 3392996, "train_return": 12.0, "train_length": 2548.0, "train_total_steps": 848249.0, "train_total_episodes": 420.0, "train_loaded_steps": 848303.0, "train_loaded_episodes": 420.0}
{"step": 3401356, "kl_loss": 1.4926708600997924, "image_loss": 3772.0, "reward_loss": 0.9195934016227723, "discount_loss": 0.007885529397428035, "model_kl": 1.4926708250045777, "prior_ent": 29.569451361083985, "post_ent": 28.093393661499025, "model_loss": 3773.108303125, "model_loss_scale": 8192.0, "model_grad_norm": 6.229929632377624, "actor_loss": 0.007370787251865841, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.04497249960899353, "critic_loss": 0.9193942280769348, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.12079394154548645, "reward_mean": -0.00623259757287451, "reward_std": 0.07690465990900994, "reward_normed_mean": -0.00623259757287451, "reward_normed_std": 0.07690465990900994, "critic_slow": -0.3007655746936798, "critic_target": -0.29751979159712794, "actor_ent": 0.6163435156822205, "actor_ent_scale": 0.0010000000474974513, "critic": -0.2975214924097061, "fps": 110.29658946962665}
{"step": 3404696, "train_return": 3.0, "train_length": 2925.0, "train_total_steps": 851174.0, "train_total_episodes": 421.0, "train_loaded_steps": 851228.0, "train_loaded_episodes": 421.0}
{"step": 3416436, "train_return": 3.0, "train_length": 2935.0, "train_total_steps": 854109.0, "train_total_episodes": 422.0, "train_loaded_steps": 854163.0, "train_loaded_episodes": 422.0}
{"step": 3426248, "train_return": 10.0, "train_length": 2453.0, "train_total_steps": 856562.0, "train_total_episodes": 423.0, "train_loaded_steps": 856616.0, "train_loaded_episodes": 423.0}
{"step": 3437820, "train_return": 8.0, "train_length": 2893.0, "train_total_steps": 859455.0, "train_total_episodes": 424.0, "train_loaded_steps": 859509.0, "train_loaded_episodes": 424.0}
{"step": 3441356, "kl_loss": 1.4836648988723755, "image_loss": 3772.0, "reward_loss": 0.9195994265556335, "discount_loss": 0.007861971711367368, "model_kl": 1.483664868927002, "prior_ent": 29.51910486450195, "post_ent": 28.043412521362306, "model_loss": 3773.10730859375, "model_loss_scale": 8192.0, "model_grad_norm": 6.218319118881226, "actor_loss": 0.007206427700146741, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.04462840923070908, "critic_loss": 0.9197999647140503, "critic_loss_scale": 410622.3616, "critic_grad_norm": 0.11806414670944214, "reward_mean": -0.006205509625921695, "reward_std": 0.07763856702446938, "reward_normed_mean": -0.006205509625921695, "reward_normed_std": 0.07763856702446938, "critic_slow": -0.2993234104156494, "critic_target": -0.2949300320222974, "actor_ent": 0.6289181261062622, "actor_ent_scale": 0.0010000000474974513, "critic": -0.2951806448996067, "fps": 109.83485997054964}
{"step": 3447480, "train_return": 10.0, "train_length": 2415.0, "train_total_steps": 861870.0, "train_total_episodes": 425.0, "train_loaded_steps": 861924.0, "train_loaded_episodes": 425.0}
{"step": 3458336, "train_return": 7.0, "train_length": 2714.0, "train_total_steps": 864584.0, "train_total_episodes": 426.0, "train_loaded_steps": 864638.0, "train_loaded_episodes": 426.0}
{"step": 3466532, "train_return": 15.0, "train_length": 2049.0, "train_total_steps": 866633.0, "train_total_episodes": 427.0, "train_loaded_steps": 866687.0, "train_loaded_episodes": 427.0}
{"step": 3477664, "train_return": 9.0, "train_length": 2783.0, "train_total_steps": 869416.0, "train_total_episodes": 428.0, "train_loaded_steps": 869470.0, "train_loaded_episodes": 428.0}
{"step": 3481356, "kl_loss": 1.4899005409240722, "image_loss": 3772.0, "reward_loss": 0.9195841913223266, "discount_loss": 0.007834880526363849, "model_kl": 1.4899005084991455, "prior_ent": 29.51867016296387, "post_ent": 28.040037713623047, "model_loss": 3773.10778203125, "model_loss_scale": 8192.0, "model_grad_norm": 6.418027175140381, "actor_loss": 0.01066152841312578, "actor_loss_scale": 17475148.1856, "actor_grad_norm": Infinity, "critic_loss": 0.9224836068153381, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.13757362753748895, "reward_mean": -0.006070378514903132, "reward_std": 0.07720614613890647, "reward_normed_mean": -0.006070378514903132, "reward_normed_std": 0.07720614613890647, "critic_slow": -0.20065162188988178, "critic_target": -0.19413795384205879, "actor_ent": 0.6043409097194672, "actor_ent_scale": 0.0010000000474974513, "critic": -0.19444522075075657, "fps": 111.96828939764768}
{"step": 3487756, "train_return": 10.0, "train_length": 2523.0, "train_total_steps": 871939.0, "train_total_episodes": 429.0, "train_loaded_steps": 871993.0, "train_loaded_episodes": 429.0}
{"step": 3497336, "train_return": 12.0, "train_length": 2395.0, "train_total_steps": 874334.0, "train_total_episodes": 430.0, "train_loaded_steps": 874388.0, "train_loaded_episodes": 430.0}
{"step": 3506600, "train_return": 10.0, "train_length": 2316.0, "train_total_steps": 876650.0, "train_total_episodes": 431.0, "train_loaded_steps": 876704.0, "train_loaded_episodes": 431.0}
{"step": 3516268, "train_return": 12.0, "train_length": 2417.0, "train_total_steps": 879067.0, "train_total_episodes": 432.0, "train_loaded_steps": 879121.0, "train_loaded_episodes": 432.0}
{"step": 3521356, "kl_loss": 1.4681999254226685, "image_loss": 3772.0, "reward_loss": 0.9195655811309814, "discount_loss": 0.007779332984983921, "model_kl": 1.4681998916625976, "prior_ent": 29.54632571105957, "post_ent": 28.08449520263672, "model_loss": 3773.105304296875, "model_loss_scale": 16174.2848, "model_grad_norm": 6.309652369689942, "actor_loss": 0.010175135133322329, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.0476686605155468, "critic_loss": 0.9235010778427124, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.12466897283196449, "reward_mean": -0.0059777255118140605, "reward_std": 0.07742939901947975, "reward_normed_mean": -0.0059777255118140605, "reward_normed_std": 0.07742939901947975, "critic_slow": -0.14233181691053323, "critic_target": -0.1302420314936695, "actor_ent": 0.5649380619049073, "actor_ent_scale": 0.0010000000474974513, "critic": -0.13047318929200993, "fps": 110.56116089682875}
{"step": 3528360, "train_return": 8.0, "train_length": 3023.0, "train_total_steps": 882090.0, "train_total_episodes": 433.0, "train_loaded_steps": 882144.0, "train_loaded_episodes": 433.0}
{"step": 3538044, "train_return": 11.0, "train_length": 2421.0, "train_total_steps": 884511.0, "train_total_episodes": 434.0, "train_loaded_steps": 884565.0, "train_loaded_episodes": 434.0}
{"step": 3547976, "train_return": 9.0, "train_length": 2483.0, "train_total_steps": 886994.0, "train_total_episodes": 435.0, "train_loaded_steps": 887048.0, "train_loaded_episodes": 435.0}
{"step": 3557520, "train_return": 11.0, "train_length": 2386.0, "train_total_steps": 889380.0, "train_total_episodes": 436.0, "train_loaded_steps": 889434.0, "train_loaded_episodes": 436.0}
{"step": 3561356, "kl_loss": 1.499630419921875, "image_loss": 3772.0, "reward_loss": 0.9195753363609314, "discount_loss": 0.007868030340969563, "model_kl": 1.4996303857803344, "prior_ent": 29.533759921264647, "post_ent": 28.048469821166993, "model_loss": 3773.108906640625, "model_loss_scale": 9515.8272, "model_grad_norm": Infinity, "actor_loss": 0.016472440205916063, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.05243042243123054, "critic_loss": 0.9269909634590149, "critic_loss_scale": 525965.7216, "critic_grad_norm": Infinity, "reward_mean": -0.005741132888192078, "reward_std": 0.07736322657465934, "reward_normed_mean": -0.005741132888192078, "reward_normed_std": 0.07736322657465934, "critic_slow": -0.014629182651266455, "critic_target": -0.00027942271917127075, "actor_ent": 0.5854680321216583, "actor_ent_scale": 0.0010000000474974513, "critic": -0.0008580770041327924, "fps": 113.03692459342196}
{"step": 3566444, "train_return": 13.0, "train_length": 2231.0, "train_total_steps": 891611.0, "train_total_episodes": 437.0, "train_loaded_steps": 891665.0, "train_loaded_episodes": 437.0}
{"step": 3576044, "train_return": 12.0, "train_length": 2400.0, "train_total_steps": 894011.0, "train_total_episodes": 438.0, "train_loaded_steps": 894065.0, "train_loaded_episodes": 438.0}
{"step": 3584840, "train_return": 13.0, "train_length": 2199.0, "train_total_steps": 896210.0, "train_total_episodes": 439.0, "train_loaded_steps": 896264.0, "train_loaded_episodes": 439.0}
{"step": 3593156, "train_return": 15.0, "train_length": 2079.0, "train_total_steps": 898289.0, "train_total_episodes": 440.0, "train_loaded_steps": 898343.0, "train_loaded_episodes": 440.0}
{"step": 3600992, "train_return": 17.0, "train_length": 1959.0, "train_total_steps": 900248.0, "train_total_episodes": 441.0, "train_loaded_steps": 900302.0, "train_loaded_episodes": 441.0}
{"step": 3601356, "kl_loss": 1.4656456176757813, "image_loss": 3772.0, "reward_loss": 0.919552758693695, "discount_loss": 0.0077559162810444835, "model_kl": 1.4656455862045288, "prior_ent": 29.48924638671875, "post_ent": 28.03248118286133, "model_loss": 3773.104923828125, "model_loss_scale": 8192.0, "model_grad_norm": 6.278580388259888, "actor_loss": 0.01689132905031147, "actor_loss_scale": 16804059.5456, "actor_grad_norm": Infinity, "critic_loss": 0.9271361589431762, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.14316190239787102, "reward_mean": -0.005951992636930663, "reward_std": 0.07838315126299858, "reward_normed_mean": -0.005951992636930663, "reward_normed_std": 0.07838315126299858, "critic_slow": 0.16682004745674495, "critic_target": 0.17993484144210817, "actor_ent": 0.571002444267273, "actor_ent_scale": 0.0010000000474974513, "critic": 0.17931679268032313, "fps": 109.09547651512919}
{"step": 3611100, "train_return": 10.0, "train_length": 2527.0, "train_total_steps": 902775.0, "train_total_episodes": 442.0, "train_loaded_steps": 902829.0, "train_loaded_episodes": 442.0}
{"step": 3620828, "train_return": 10.0, "train_length": 2432.0, "train_total_steps": 905207.0, "train_total_episodes": 443.0, "train_loaded_steps": 905261.0, "train_loaded_episodes": 443.0}
{"step": 3630144, "train_return": 13.0, "train_length": 2329.0, "train_total_steps": 907536.0, "train_total_episodes": 444.0, "train_loaded_steps": 907590.0, "train_loaded_episodes": 444.0}
{"step": 3638936, "train_return": 15.0, "train_length": 2198.0, "train_total_steps": 909734.0, "train_total_episodes": 445.0, "train_loaded_steps": 909788.0, "train_loaded_episodes": 445.0}
{"step": 3641356, "kl_loss": 1.484636085319519, "image_loss": 3772.0, "reward_loss": 0.9196026686668396, "discount_loss": 0.00783065736144781, "model_kl": 1.4846360469818116, "prior_ent": 29.5113744934082, "post_ent": 28.03690346984863, "model_loss": 3773.107244140625, "model_loss_scale": 8192.0, "model_grad_norm": 6.690642584228516, "actor_loss": 0.016512811451742892, "actor_loss_scale": 16777216.0, "actor_grad_norm": 0.052637394785881045, "critic_loss": 0.9271345544815064, "critic_loss_scale": 398039.4496, "critic_grad_norm": Infinity, "reward_mean": -0.00586858377859171, "reward_std": 0.07816497629880906, "reward_normed_mean": -0.00586858377859171, "reward_normed_std": 0.07816497629880906, "critic_slow": 0.3653901397973299, "critic_target": 0.3805190947547555, "actor_ent": 0.5908302366256714, "actor_ent_scale": 0.0010000000474974513, "critic": 0.379534683893621, "fps": 112.11049642542888}
{"step": 3650224, "train_return": 6.0, "train_length": 2822.0, "train_total_steps": 912556.0, "train_total_episodes": 446.0, "train_loaded_steps": 912610.0, "train_loaded_episodes": 446.0}
{"step": 3659788, "train_return": 11.0, "train_length": 2391.0, "train_total_steps": 914947.0, "train_total_episodes": 447.0, "train_loaded_steps": 915001.0, "train_loaded_episodes": 447.0}
{"step": 3671304, "train_return": 8.0, "train_length": 2879.0, "train_total_steps": 917826.0, "train_total_episodes": 448.0, "train_loaded_steps": 917880.0, "train_loaded_episodes": 448.0}
{"step": 3681088, "train_return": 14.0, "train_length": 2446.0, "train_total_steps": 920272.0, "train_total_episodes": 449.0, "train_loaded_steps": 920326.0, "train_loaded_episodes": 449.0}
{"step": 3681356, "kl_loss": 1.5075589365005493, "image_loss": 3772.0, "reward_loss": 0.9195722917556762, "discount_loss": 0.007825284451246261, "model_kl": 1.5075588983535766, "prior_ent": 29.493755474853515, "post_ent": 28.004237432861327, "model_loss": 3773.10947890625, "model_loss_scale": 13421.7728, "model_grad_norm": 6.027102815246582, "actor_loss": 0.015538636871287599, "actor_loss_scale": 12495670.4768, "actor_grad_norm": Infinity, "critic_loss": 0.9271843938827514, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.1477851013481617, "reward_mean": -0.005599075813013587, "reward_std": 0.07813014164566993, "reward_normed_mean": -0.005599075813013587, "reward_normed_std": 0.07813014164566993, "critic_slow": 0.47988899531364443, "critic_target": 0.49462942988872527, "actor_ent": 0.5737478284358978, "actor_ent_scale": 0.0010000000474974513, "critic": 0.4942406141996384, "fps": 110.08445932263129}
{"step": 3690756, "train_return": 11.0, "train_length": 2417.0, "train_total_steps": 922689.0, "train_total_episodes": 450.0, "train_loaded_steps": 922743.0, "train_loaded_episodes": 450.0}
{"step": 3699468, "train_return": 15.0, "train_length": 2178.0, "train_total_steps": 924867.0, "train_total_episodes": 451.0, "train_loaded_steps": 924921.0, "train_loaded_episodes": 451.0}
{"step": 3707056, "train_return": 19.0, "train_length": 1897.0, "train_total_steps": 926764.0, "train_total_episodes": 452.0, "train_loaded_steps": 926818.0, "train_loaded_episodes": 452.0}
{"step": 3717788, "train_return": 9.0, "train_length": 2683.0, "train_total_steps": 929447.0, "train_total_episodes": 453.0, "train_loaded_steps": 929501.0, "train_loaded_episodes": 453.0}
{"step": 3721356, "kl_loss": 1.4966445459365845, "image_loss": 3772.0, "reward_loss": 0.9195907015800476, "discount_loss": 0.00781291245520115, "model_kl": 1.4966445106506348, "prior_ent": 29.503779525756837, "post_ent": 28.017568673706055, "model_loss": 3773.108337890625, "model_loss_scale": 14876.672, "model_grad_norm": Infinity, "actor_loss": 0.016365403641038574, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.05380434042215347, "critic_loss": 0.9284531497955322, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.15870575568675996, "reward_mean": -0.00528736895910406, "reward_std": 0.07777602189183234, "reward_normed_mean": -0.00528736895910406, "reward_normed_std": 0.07777602189183234, "critic_slow": 0.6070830771923065, "critic_target": 0.6234443548440933, "actor_ent": 0.5773814505577087, "actor_ent_scale": 0.0010000000474974513, "critic": 0.6227695511817932, "fps": 110.60502490281904}
{"step": 3725296, "train_return": 18.0, "train_length": 1877.0, "train_total_steps": 931324.0, "train_total_episodes": 454.0, "train_loaded_steps": 931378.0, "train_loaded_episodes": 454.0}
{"step": 3737408, "train_return": 4.0, "train_length": 3028.0, "train_total_steps": 934352.0, "train_total_episodes": 455.0, "train_loaded_steps": 934406.0, "train_loaded_episodes": 455.0}
{"step": 3745944, "train_return": 15.0, "train_length": 2134.0, "train_total_steps": 936486.0, "train_total_episodes": 456.0, "train_loaded_steps": 936540.0, "train_loaded_episodes": 456.0}
{"step": 3754908, "train_return": 13.0, "train_length": 2241.0, "train_total_steps": 938727.0, "train_total_episodes": 457.0, "train_loaded_steps": 938781.0, "train_loaded_episodes": 457.0}
{"step": 3761356, "kl_loss": 1.4851011779785157, "image_loss": 3772.0, "reward_loss": 0.9195441463470458, "discount_loss": 0.007823797485232353, "model_kl": 1.4851011470794677, "prior_ent": 29.492862475585937, "post_ent": 28.025102337646484, "model_loss": 3773.107191015625, "model_loss_scale": 8192.0, "model_grad_norm": 6.1482116310119626, "actor_loss": 0.01514693807925214, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.055378668940067294, "critic_loss": 0.9290595151901245, "critic_loss_scale": 335963.7504, "critic_grad_norm": 0.1765006145596504, "reward_mean": -0.00564059028881602, "reward_std": 0.0791173236489296, "reward_normed_mean": -0.00564059028881602, "reward_normed_std": 0.0791173236489296, "critic_slow": 0.7401767247676849, "critic_target": 0.7615939266681672, "actor_ent": 0.48829077248573305, "actor_ent_scale": 0.0010000000474974513, "critic": 0.7610158635139466, "fps": 109.34313604227708}
{"step": 3764680, "train_return": 14.0, "train_length": 2443.0, "train_total_steps": 941170.0, "train_total_episodes": 458.0, "train_loaded_steps": 941224.0, "train_loaded_episodes": 458.0}
{"step": 3772092, "train_return": 18.0, "train_length": 1853.0, "train_total_steps": 943023.0, "train_total_episodes": 459.0, "train_loaded_steps": 943077.0, "train_loaded_episodes": 459.0}
{"step": 3780808, "train_return": 14.0, "train_length": 2179.0, "train_total_steps": 945202.0, "train_total_episodes": 460.0, "train_loaded_steps": 945256.0, "train_loaded_episodes": 460.0}
{"step": 3790840, "train_return": 10.0, "train_length": 2508.0, "train_total_steps": 947710.0, "train_total_episodes": 461.0, "train_loaded_steps": 947764.0, "train_loaded_episodes": 461.0}
{"step": 3798444, "train_return": 17.0, "train_length": 1901.0, "train_total_steps": 949611.0, "train_total_episodes": 462.0, "train_loaded_steps": 949665.0, "train_loaded_episodes": 462.0}
{"step": 3801356, "kl_loss": 1.4846908798217773, "image_loss": 3772.0, "reward_loss": 0.9195544884681701, "discount_loss": 0.007796827095746994, "model_kl": 1.4846908449172973, "prior_ent": 29.49076832885742, "post_ent": 28.01333503112793, "model_loss": 3773.10702734375, "model_loss_scale": 4331.9296, "model_grad_norm": Infinity, "actor_loss": 0.012410415273653053, "actor_loss_scale": 9395240.96, "actor_grad_norm": Infinity, "critic_loss": 0.9296710053443908, "critic_loss_scale": 524288.0, "critic_grad_norm": 0.16734323967695236, "reward_mean": -0.005382327573337534, "reward_std": 0.07758845324516296, "reward_normed_mean": -0.005382327573337534, "reward_normed_std": 0.07758845324516296, "critic_slow": 0.8896382494926452, "critic_target": 0.9027363090991974, "actor_ent": 0.49672957544326785, "actor_ent_scale": 0.0010000000474974513, "critic": 0.9023682531356811, "fps": 110.83398559959971}
{"step": 3808672, "train_return": 10.0, "train_length": 2557.0, "train_total_steps": 952168.0, "train_total_episodes": 463.0, "train_loaded_steps": 952222.0, "train_loaded_episodes": 463.0}
{"step": 3817160, "train_return": 17.0, "train_length": 2122.0, "train_total_steps": 954290.0, "train_total_episodes": 464.0, "train_loaded_steps": 954344.0, "train_loaded_episodes": 464.0}
{"step": 3825924, "train_return": 14.0, "train_length": 2191.0, "train_total_steps": 956481.0, "train_total_episodes": 465.0, "train_loaded_steps": 956535.0, "train_loaded_episodes": 465.0}
{"step": 3834340, "train_return": 15.0, "train_length": 2104.0, "train_total_steps": 958585.0, "train_total_episodes": 466.0, "train_loaded_steps": 958639.0, "train_loaded_episodes": 466.0}
{"step": 3841356, "kl_loss": 1.477525220298767, "image_loss": 3772.0, "reward_loss": 0.9195248507499695, "discount_loss": 0.00781502440571785, "model_kl": 1.4775251873016357, "prior_ent": 29.474272186279297, "post_ent": 28.006989385986326, "model_loss": 3773.106371875, "model_loss_scale": 4096.0, "model_grad_norm": 6.605525602340698, "actor_loss": 0.01762523299244931, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.05996038424968719, "critic_loss": 0.9326298704147339, "critic_loss_scale": 357354.7008, "critic_grad_norm": Infinity, "reward_mean": -0.0053113160750548555, "reward_std": 0.07922333374619484, "reward_normed_mean": -0.0053113160750548555, "reward_normed_std": 0.07922333374619484, "critic_slow": 1.0182809116363525, "critic_target": 1.038510534763336, "actor_ent": 0.517807148361206, "actor_ent_scale": 0.0010000000474974513, "critic": 1.0376938248634338, "fps": 110.45612321173257}
{"step": 3842868, "train_return": 14.0, "train_length": 2132.0, "train_total_steps": 960717.0, "train_total_episodes": 467.0, "train_loaded_steps": 960771.0, "train_loaded_episodes": 467.0}
{"step": 3853060, "train_return": 7.0, "train_length": 2548.0, "train_total_steps": 963265.0, "train_total_episodes": 468.0, "train_loaded_steps": 963319.0, "train_loaded_episodes": 468.0}
{"step": 3861160, "train_return": 17.0, "train_length": 2025.0, "train_total_steps": 965290.0, "train_total_episodes": 469.0, "train_loaded_steps": 965344.0, "train_loaded_episodes": 469.0}
{"step": 3869044, "train_return": 17.0, "train_length": 1971.0, "train_total_steps": 967261.0, "train_total_episodes": 470.0, "train_loaded_steps": 967315.0, "train_loaded_episodes": 470.0}
{"step": 3878852, "train_return": 11.0, "train_length": 2452.0, "train_total_steps": 969713.0, "train_total_episodes": 471.0, "train_loaded_steps": 969767.0, "train_loaded_episodes": 471.0}
{"step": 3881356, "kl_loss": 1.4903047079086305, "image_loss": 3772.0, "reward_loss": 0.919570597076416, "discount_loss": 0.007778196011483669, "model_kl": 1.490304676437378, "prior_ent": 29.417834906005858, "post_ent": 27.937911254882813, "model_loss": 3773.107519921875, "model_loss_scale": 4096.0, "model_grad_norm": 6.320367664146423, "actor_loss": 0.011795716686567176, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.05871728295683861, "critic_loss": 0.932935449886322, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.19515582358837127, "reward_mean": -0.00522830147271452, "reward_std": 0.0790920019686222, "reward_normed_mean": -0.00522830147271452, "reward_normed_std": 0.0790920019686222, "critic_slow": 1.2190777698516846, "critic_target": 1.2331487198829651, "actor_ent": 0.5025577640533447, "actor_ent_scale": 0.0010000000474974513, "critic": 1.2326668957710265, "fps": 111.57345262084559}
{"step": 3887108, "train_return": 16.0, "train_length": 2064.0, "train_total_steps": 971777.0, "train_total_episodes": 472.0, "train_loaded_steps": 971831.0, "train_loaded_episodes": 472.0}
{"step": 3895688, "train_return": 15.0, "train_length": 2145.0, "train_total_steps": 973922.0, "train_total_episodes": 473.0, "train_loaded_steps": 973976.0, "train_loaded_episodes": 473.0}
{"step": 3906116, "train_return": 10.0, "train_length": 2607.0, "train_total_steps": 976529.0, "train_total_episodes": 474.0, "train_loaded_steps": 976583.0, "train_loaded_episodes": 474.0}
{"step": 3915416, "train_return": 12.0, "train_length": 2325.0, "train_total_steps": 978854.0, "train_total_episodes": 475.0, "train_loaded_steps": 978908.0, "train_loaded_episodes": 475.0}
{"step": 3921356, "kl_loss": 1.5036347347259522, "image_loss": 3772.0, "reward_loss": 0.9195316385269166, "discount_loss": 0.00779457708671689, "model_kl": 1.503634698677063, "prior_ent": 29.415831030273438, "post_ent": 27.925347479248046, "model_loss": 3773.1088890625, "model_loss_scale": 7136.8704, "model_grad_norm": 6.5565793336868285, "actor_loss": 0.02097082213428803, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06261155430674553, "critic_loss": 0.9339977201461792, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.19099127550125122, "reward_mean": -0.004879100894258591, "reward_std": 0.07892392449378967, "reward_normed_mean": -0.004879100894258591, "reward_normed_std": 0.07892392449378967, "critic_slow": 1.4261650901794434, "critic_target": 1.452106270313263, "actor_ent": 0.49329378280639646, "actor_ent_scale": 0.0010000000474974513, "critic": 1.4516187255859374, "fps": 110.71621830439956}
{"step": 3924148, "train_return": 15.0, "train_length": 2183.0, "train_total_steps": 981037.0, "train_total_episodes": 476.0, "train_loaded_steps": 981091.0, "train_loaded_episodes": 476.0}
{"step": 3932724, "train_return": 14.0, "train_length": 2144.0, "train_total_steps": 983181.0, "train_total_episodes": 477.0, "train_loaded_steps": 983235.0, "train_loaded_episodes": 477.0}
{"step": 3940380, "train_return": 16.0, "train_length": 1914.0, "train_total_steps": 985095.0, "train_total_episodes": 478.0, "train_loaded_steps": 985149.0, "train_loaded_episodes": 478.0}
{"step": 3948788, "train_return": 15.0, "train_length": 2102.0, "train_total_steps": 987197.0, "train_total_episodes": 479.0, "train_loaded_steps": 987251.0, "train_loaded_episodes": 479.0}
{"step": 3956888, "train_return": 16.0, "train_length": 2025.0, "train_total_steps": 989222.0, "train_total_episodes": 480.0, "train_loaded_steps": 989276.0, "train_loaded_episodes": 480.0}
{"step": 3961356, "kl_loss": 1.4823164957046508, "image_loss": 3772.0, "reward_loss": 0.9195446678161621, "discount_loss": 0.00778844550177455, "model_kl": 1.4823164604187011, "prior_ent": 29.41083876953125, "post_ent": 27.939731866455077, "model_loss": 3773.10674921875, "model_loss_scale": 8192.0, "model_grad_norm": 6.568156393432617, "actor_loss": 0.011709809141512961, "actor_loss_scale": 9972377.1904, "actor_grad_norm": Infinity, "critic_loss": 0.9367927095413208, "critic_loss_scale": 321283.6864, "critic_grad_norm": Infinity, "reward_mean": -0.005273350379162003, "reward_std": 0.0798973434984684, "reward_normed_mean": -0.005273350379162003, "reward_normed_std": 0.0798973434984684, "critic_slow": 1.5966584661483765, "critic_target": 1.6156295711517334, "actor_ent": 0.49510294141769406, "actor_ent_scale": 0.0010000000474974513, "critic": 1.6149080076217652, "fps": 109.25653830048306}
{"step": 3966092, "train_return": 12.0, "train_length": 2301.0, "train_total_steps": 991523.0, "train_total_episodes": 481.0, "train_loaded_steps": 991577.0, "train_loaded_episodes": 481.0}
{"step": 3975440, "train_return": 12.0, "train_length": 2337.0, "train_total_steps": 993860.0, "train_total_episodes": 482.0, "train_loaded_steps": 993914.0, "train_loaded_episodes": 482.0}
{"step": 3985124, "train_return": 11.0, "train_length": 2421.0, "train_total_steps": 996281.0, "train_total_episodes": 483.0, "train_loaded_steps": 996335.0, "train_loaded_episodes": 483.0}
{"step": 3996128, "train_return": 9.0, "train_length": 2751.0, "train_total_steps": 999032.0, "train_total_episodes": 484.0, "train_loaded_steps": 999086.0, "train_loaded_episodes": 484.0}
{"step": 4001356, "kl_loss": 1.4805729265213012, "image_loss": 3772.0, "reward_loss": 0.9195472407341003, "discount_loss": 0.007784657231718302, "model_kl": 1.480572896194458, "prior_ent": 29.41556043701172, "post_ent": 27.95052194519043, "model_loss": 3773.1065515625, "model_loss_scale": 8192.0, "model_grad_norm": 6.460053700256347, "actor_loss": 0.019251833698281554, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06311550366282463, "critic_loss": 0.93767898645401, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.2326477057695389, "reward_mean": -0.005041082163102692, "reward_std": 0.07904090977311135, "reward_normed_mean": -0.005041082163102692, "reward_normed_std": 0.07904090977311135, "critic_slow": 1.7034528685569763, "critic_target": 1.726950243282318, "actor_ent": 0.4999164699077606, "actor_ent_scale": 0.0010000000474974513, "critic": 1.7266855540275574, "fps": 110.29429164191501}
{"step": 4005700, "train_return": 11.0, "train_length": 2393.0, "train_total_steps": 1001425.0, "train_total_episodes": 485.0, "train_loaded_steps": 1001479.0, "train_loaded_episodes": 485.0}
{"step": 4015524, "train_return": 12.0, "train_length": 2456.0, "train_total_steps": 1003881.0, "train_total_episodes": 486.0, "train_loaded_steps": 1003935.0, "train_loaded_episodes": 486.0}
{"step": 4023996, "train_return": 14.0, "train_length": 2118.0, "train_total_steps": 1005999.0, "train_total_episodes": 487.0, "train_loaded_steps": 1006053.0, "train_loaded_episodes": 487.0}
{"step": 4032464, "train_return": 15.0, "train_length": 2117.0, "train_total_steps": 1008116.0, "train_total_episodes": 488.0, "train_loaded_steps": 1008170.0, "train_loaded_episodes": 488.0}
{"step": 4040652, "train_return": 15.0, "train_length": 2047.0, "train_total_steps": 1010163.0, "train_total_episodes": 489.0, "train_loaded_steps": 1010217.0, "train_loaded_episodes": 489.0}
{"step": 4041356, "kl_loss": 1.4705592832565308, "image_loss": 3772.0, "reward_loss": 0.919534753704071, "discount_loss": 0.007769389065355062, "model_kl": 1.4705592473983764, "prior_ent": 29.44149174194336, "post_ent": 27.97551246032715, "model_loss": 3773.1054671875, "model_loss_scale": 11835.8016, "model_grad_norm": Infinity, "actor_loss": 0.014279638171952684, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06464787598848343, "critic_loss": 0.938892676448822, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.23545906507968903, "reward_mean": -0.004750325513340067, "reward_std": 0.07955204458236695, "reward_normed_mean": -0.004750325513340067, "reward_normed_std": 0.07955204458236695, "critic_slow": 1.8601618558883668, "critic_target": 1.8807729473114014, "actor_ent": 0.4853516825675964, "actor_ent_scale": 0.0010000000474974513, "critic": 1.880229588317871, "fps": 110.72916863400854}
{"step": 4049732, "train_return": 13.0, "train_length": 2270.0, "train_total_steps": 1012433.0, "train_total_episodes": 490.0, "train_loaded_steps": 1012487.0, "train_loaded_episodes": 490.0}
{"step": 4057524, "train_return": 18.0, "train_length": 1948.0, "train_total_steps": 1014381.0, "train_total_episodes": 491.0, "train_loaded_steps": 1014435.0, "train_loaded_episodes": 491.0}
{"step": 4066932, "train_return": 12.0, "train_length": 2352.0, "train_total_steps": 1016733.0, "train_total_episodes": 492.0, "train_loaded_steps": 1016787.0, "train_loaded_episodes": 492.0}
{"step": 4075076, "train_return": 17.0, "train_length": 2036.0, "train_total_steps": 1018769.0, "train_total_episodes": 493.0, "train_loaded_steps": 1018823.0, "train_loaded_episodes": 493.0}
{"step": 4081356, "kl_loss": 1.4787102392196656, "image_loss": 3772.0, "reward_loss": 0.9195264647483826, "discount_loss": 0.007792749200761318, "model_kl": 1.4787102060317994, "prior_ent": 29.418969317626953, "post_ent": 27.952362438964844, "model_loss": 3773.10638515625, "model_loss_scale": 8192.0, "model_grad_norm": 6.359212434005737, "actor_loss": 0.016147374261578078, "actor_loss_scale": 9153649.0496, "actor_grad_norm": Infinity, "critic_loss": 0.9418893889427185, "critic_loss_scale": 265080.0128, "critic_grad_norm": 0.24682954938411714, "reward_mean": -0.0049996271243842785, "reward_std": 0.07999734748601914, "reward_normed_mean": -0.0049996271243842785, "reward_normed_std": 0.07999734748601914, "critic_slow": 1.9761753740310668, "critic_target": 1.9978492275238038, "actor_ent": 0.478206019115448, "actor_ent_scale": 0.0010000000474974513, "critic": 1.9975123376846313, "fps": 111.94897806945819}
{"step": 4084116, "train_return": 13.0, "train_length": 2260.0, "train_total_steps": 1021029.0, "train_total_episodes": 494.0, "train_loaded_steps": 1021083.0, "train_loaded_episodes": 494.0}
{"step": 4092504, "train_return": 15.0, "train_length": 2097.0, "train_total_steps": 1023126.0, "train_total_episodes": 495.0, "train_loaded_steps": 1023180.0, "train_loaded_episodes": 495.0}
{"step": 4105148, "train_return": 6.0, "train_length": 3161.0, "train_total_steps": 1026287.0, "train_total_episodes": 496.0, "train_loaded_steps": 1026341.0, "train_loaded_episodes": 496.0}
{"step": 4114300, "train_return": 11.0, "train_length": 2288.0, "train_total_steps": 1028575.0, "train_total_episodes": 497.0, "train_loaded_steps": 1028629.0, "train_loaded_episodes": 497.0}
{"step": 4121356, "kl_loss": 1.4709533475875856, "image_loss": 3772.0, "reward_loss": 0.9195406626701355, "discount_loss": 0.007842634028196335, "model_kl": 1.470953316116333, "prior_ent": 29.365012829589844, "post_ent": 27.904124618530272, "model_loss": 3773.105866015625, "model_loss_scale": 8192.0, "model_grad_norm": 6.483002100372315, "actor_loss": 0.014104516854282701, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.0669736018896103, "critic_loss": 0.9412732398986816, "critic_loss_scale": 275146.3424, "critic_grad_norm": Infinity, "reward_mean": -0.004873769908666145, "reward_std": 0.0801851469874382, "reward_normed_mean": -0.004873769908666145, "reward_normed_std": 0.0801851469874382, "critic_slow": 2.1247075731277465, "critic_target": 2.143698155593872, "actor_ent": 0.4669057677268982, "actor_ent_scale": 0.0010000000474974513, "critic": 2.1433101581573486, "fps": 110.01441384692662}
{"step": 4122136, "train_return": 16.0, "train_length": 1959.0, "train_total_steps": 1030534.0, "train_total_episodes": 498.0, "train_loaded_steps": 1030588.0, "train_loaded_episodes": 498.0}
{"step": 4129932, "train_return": 17.0, "train_length": 1949.0, "train_total_steps": 1032483.0, "train_total_episodes": 499.0, "train_loaded_steps": 1032537.0, "train_loaded_episodes": 499.0}
{"step": 4137640, "train_return": 17.0, "train_length": 1927.0, "train_total_steps": 1034410.0, "train_total_episodes": 500.0, "train_loaded_steps": 1034464.0, "train_loaded_episodes": 500.0}
{"step": 4146820, "train_return": 12.0, "train_length": 2295.0, "train_total_steps": 1036705.0, "train_total_episodes": 501.0, "train_loaded_steps": 1036759.0, "train_loaded_episodes": 501.0}
{"step": 4156424, "train_return": 11.0, "train_length": 2401.0, "train_total_steps": 1039106.0, "train_total_episodes": 502.0, "train_loaded_steps": 1039160.0, "train_loaded_episodes": 502.0}
{"step": 4161356, "kl_loss": 1.4784920225143432, "image_loss": 3772.0, "reward_loss": 0.9195199402809143, "discount_loss": 0.007777981739491224, "model_kl": 1.4784919857025147, "prior_ent": 29.357045281982423, "post_ent": 27.891065713500975, "model_loss": 3773.10628515625, "model_loss_scale": 8192.0, "model_grad_norm": 6.529037972068787, "actor_loss": 0.015362368545914069, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06717446657419204, "critic_loss": 0.9390204427719117, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.238242585003376, "reward_mean": -0.004715482831269037, "reward_std": 0.0797769755601883, "reward_normed_mean": -0.004715482831269037, "reward_normed_std": 0.0797769755601883, "critic_slow": 2.2574803131103516, "critic_target": 2.2781970802307128, "actor_ent": 0.48575554494857787, "actor_ent_scale": 0.0010000000474974513, "critic": 2.2779297428131104, "fps": 111.52784924293262}
{"step": 4165496, "train_return": 13.0, "train_length": 2268.0, "train_total_steps": 1041374.0, "train_total_episodes": 503.0, "train_loaded_steps": 1041428.0, "train_loaded_episodes": 503.0}
{"step": 4173708, "train_return": 15.0, "train_length": 2053.0, "train_total_steps": 1043427.0, "train_total_episodes": 504.0, "train_loaded_steps": 1043481.0, "train_loaded_episodes": 504.0}
{"step": 4181644, "train_return": 16.0, "train_length": 1984.0, "train_total_steps": 1045411.0, "train_total_episodes": 505.0, "train_loaded_steps": 1045465.0, "train_loaded_episodes": 505.0}
{"step": 4189772, "train_return": 16.0, "train_length": 2032.0, "train_total_steps": 1047443.0, "train_total_episodes": 506.0, "train_loaded_steps": 1047497.0, "train_loaded_episodes": 506.0}
{"step": 4198100, "train_return": 16.0, "train_length": 2082.0, "train_total_steps": 1049525.0, "train_total_episodes": 507.0, "train_loaded_steps": 1049579.0, "train_loaded_episodes": 507.0}
{"step": 4201352, "eval_return": 13.0, "eval_length": 2238.0, "eval_total_steps": 10935.0, "eval_total_episodes": 6.0, "eval_loaded_steps": 10937.0, "eval_loaded_episodes": 6.0}
{"step": 4201356, "kl_loss": 1.5100506813049317, "image_loss": 3772.0, "reward_loss": 0.9195523810386658, "discount_loss": 0.007776099117100239, "model_kl": 1.5100506462097167, "prior_ent": 29.31056134643555, "post_ent": 27.824870626831053, "model_loss": 3773.109461328125, "model_loss_scale": 14064.0256, "model_grad_norm": Infinity, "actor_loss": 0.020759851391561095, "actor_loss_scale": 10992431.9232, "actor_grad_norm": 0.07050868655443192, "critic_loss": 0.9412488182067871, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.26843872356414794, "reward_mean": -0.004743736170122429, "reward_std": 0.07975935374498368, "reward_normed_mean": -0.004743736170122429, "reward_normed_std": 0.07975935374498368, "critic_slow": 2.438572770690918, "critic_target": 2.4648557125091552, "actor_ent": 0.4737699434280396, "actor_ent_scale": 0.0010000000474974513, "critic": 2.464149073410034, "fps": 106.58303999355648}
{"step": 4206576, "train_return": 14.0, "train_length": 2119.0, "train_total_steps": 1051644.0, "train_total_episodes": 508.0, "train_loaded_steps": 1051698.0, "train_loaded_episodes": 508.0}
{"step": 4214044, "train_return": 18.0, "train_length": 1867.0, "train_total_steps": 1053511.0, "train_total_episodes": 509.0, "train_loaded_steps": 1053565.0, "train_loaded_episodes": 509.0}
{"step": 4223652, "train_return": 9.0, "train_length": 2402.0, "train_total_steps": 1055913.0, "train_total_episodes": 510.0, "train_loaded_steps": 1055967.0, "train_loaded_episodes": 510.0}
{"step": 4233352, "train_return": 12.0, "train_length": 2425.0, "train_total_steps": 1058338.0, "train_total_episodes": 511.0, "train_loaded_steps": 1058392.0, "train_loaded_episodes": 511.0}
{"step": 4241356, "kl_loss": 1.4799992322921753, "image_loss": 3772.0, "reward_loss": 0.9195392907142639, "discount_loss": 0.0077766180716454985, "model_kl": 1.4799991971969604, "prior_ent": 29.38950323486328, "post_ent": 27.913268881225587, "model_loss": 3773.10644375, "model_loss_scale": 8192.0, "model_grad_norm": 6.537364173316956, "actor_loss": 0.015484672807221067, "actor_loss_scale": 10858214.1952, "actor_grad_norm": Infinity, "critic_loss": 0.9360508612632752, "critic_loss_scale": 447951.6672, "critic_grad_norm": Infinity, "reward_mean": -0.004586490316022537, "reward_std": 0.0798542770564556, "reward_normed_mean": -0.004586490316022537, "reward_normed_std": 0.0798542770564556, "critic_slow": 2.65486878452301, "critic_target": 2.6747388032913206, "actor_ent": 0.4686404914855957, "actor_ent_scale": 0.0010000000474974513, "critic": 2.674150572013855, "fps": 110.03155349785405}
{"step": 4241464, "train_return": 16.0, "train_length": 2028.0, "train_total_steps": 1060366.0, "train_total_episodes": 512.0, "train_loaded_steps": 1060420.0, "train_loaded_episodes": 512.0}
{"step": 4249948, "train_return": 17.0, "train_length": 2121.0, "train_total_steps": 1062487.0, "train_total_episodes": 513.0, "train_loaded_steps": 1062541.0, "train_loaded_episodes": 513.0}
{"step": 4257732, "train_return": 17.0, "train_length": 1946.0, "train_total_steps": 1064433.0, "train_total_episodes": 514.0, "train_loaded_steps": 1064487.0, "train_loaded_episodes": 514.0}
{"step": 4264776, "train_return": 19.0, "train_length": 1761.0, "train_total_steps": 1066194.0, "train_total_episodes": 515.0, "train_loaded_steps": 1066248.0, "train_loaded_episodes": 515.0}
{"step": 4271620, "train_return": 20.0, "train_length": 1711.0, "train_total_steps": 1067905.0, "train_total_episodes": 516.0, "train_loaded_steps": 1067959.0, "train_loaded_episodes": 516.0}
{"step": 4280260, "train_return": 15.0, "train_length": 2160.0, "train_total_steps": 1070065.0, "train_total_episodes": 517.0, "train_loaded_steps": 1070119.0, "train_loaded_episodes": 517.0}
{"step": 4281356, "kl_loss": 1.464058366394043, "image_loss": 3772.0, "reward_loss": 0.9195145833969116, "discount_loss": 0.007817416853457689, "model_kl": 1.464058327102661, "prior_ent": 29.361179776000977, "post_ent": 27.906024365234376, "model_loss": 3773.105033984375, "model_loss_scale": 8192.0, "model_grad_norm": 6.411848403549194, "actor_loss": 0.015887711883103475, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06723433176875114, "critic_loss": 0.9385612016677857, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.26815088654756547, "reward_mean": -0.004366743961501925, "reward_std": 0.07961424136161804, "reward_normed_mean": -0.004366743961501925, "reward_normed_std": 0.07961424136161804, "critic_slow": 2.7313697547912597, "critic_target": 2.7499872020721434, "actor_ent": 0.47259971513748167, "actor_ent_scale": 0.0010000000474974513, "critic": 2.7495959590911867, "fps": 110.92002073622992}
{"step": 4288816, "train_return": 15.0, "train_length": 2139.0, "train_total_steps": 1072204.0, "train_total_episodes": 518.0, "train_loaded_steps": 1072258.0, "train_loaded_episodes": 518.0}
{"step": 4299180, "train_return": 9.0, "train_length": 2591.0, "train_total_steps": 1074795.0, "train_total_episodes": 519.0, "train_loaded_steps": 1074849.0, "train_loaded_episodes": 519.0}
{"step": 4307228, "train_return": 17.0, "train_length": 2012.0, "train_total_steps": 1076807.0, "train_total_episodes": 520.0, "train_loaded_steps": 1076861.0, "train_loaded_episodes": 520.0}
{"step": 4314900, "train_return": 17.0, "train_length": 1918.0, "train_total_steps": 1078725.0, "train_total_episodes": 521.0, "train_loaded_steps": 1078779.0, "train_loaded_episodes": 521.0}
{"step": 4321356, "kl_loss": 1.7213832355499268, "image_loss": 3772.0, "reward_loss": 0.9195474080085755, "discount_loss": 0.008177785671502352, "model_kl": 1.7213832010269166, "prior_ent": 29.30262121887207, "post_ent": 27.614341271972656, "model_loss": 3773.13260546875, "model_loss_scale": 8192.0, "model_grad_norm": 6.601679434967041, "actor_loss": 0.012104104799567722, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.07075021742582321, "critic_loss": 0.9421308903694153, "critic_loss_scale": 177419.0592, "critic_grad_norm": Infinity, "reward_mean": -0.004177587986519211, "reward_std": 0.07938556811213493, "reward_normed_mean": -0.004177587986519211, "reward_normed_std": 0.07938556811213493, "critic_slow": 2.8932085988998413, "critic_target": 2.909659163856506, "actor_ent": 0.47273260860443117, "actor_ent_scale": 0.0010000000474974513, "critic": 2.9087904857635496, "fps": 110.94320529118782}
{"step": 4324204, "train_return": 11.0, "train_length": 2326.0, "train_total_steps": 1081051.0, "train_total_episodes": 522.0, "train_loaded_steps": 1081105.0, "train_loaded_episodes": 522.0}
{"step": 4333048, "train_return": 15.0, "train_length": 2211.0, "train_total_steps": 1083262.0, "train_total_episodes": 523.0, "train_loaded_steps": 1083316.0, "train_loaded_episodes": 523.0}
{"step": 4342588, "train_return": 14.0, "train_length": 2385.0, "train_total_steps": 1085647.0, "train_total_episodes": 524.0, "train_loaded_steps": 1085701.0, "train_loaded_episodes": 524.0}
{"step": 4351132, "train_return": 15.0, "train_length": 2136.0, "train_total_steps": 1087783.0, "train_total_episodes": 525.0, "train_loaded_steps": 1087837.0, "train_loaded_episodes": 525.0}
{"step": 4359168, "train_return": 16.0, "train_length": 2009.0, "train_total_steps": 1089792.0, "train_total_episodes": 526.0, "train_loaded_steps": 1089846.0, "train_loaded_episodes": 526.0}
{"step": 4361356, "kl_loss": 1.4615542495727538, "image_loss": 3772.0, "reward_loss": 0.9194719316482544, "discount_loss": 0.007805821698904037, "model_kl": 1.4615542167663573, "prior_ent": 29.389203924560547, "post_ent": 27.927413439941407, "model_loss": 3773.104677734375, "model_loss_scale": 9188.1472, "model_grad_norm": Infinity, "actor_loss": 0.01524230290063424, "actor_loss_scale": 9717363.5072, "actor_grad_norm": Infinity, "critic_loss": 0.9394020970344543, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2764229072093964, "reward_mean": -0.004397776273416821, "reward_std": 0.08010437511205673, "reward_normed_mean": -0.004397776273416821, "reward_normed_std": 0.08010437511205673, "critic_slow": 3.0301103927612303, "critic_target": 3.0440180561065673, "actor_ent": 0.47285455622673034, "actor_ent_scale": 0.0010000000474974513, "critic": 3.0436788665771486, "fps": 110.45527027399608}
{"step": 4368336, "train_return": 13.0, "train_length": 2292.0, "train_total_steps": 1092084.0, "train_total_episodes": 527.0, "train_loaded_steps": 1092138.0, "train_loaded_episodes": 527.0}
{"step": 4378128, "train_return": 11.0, "train_length": 2448.0, "train_total_steps": 1094532.0, "train_total_episodes": 528.0, "train_loaded_steps": 1094586.0, "train_loaded_episodes": 528.0}
{"step": 4386396, "train_return": 15.0, "train_length": 2067.0, "train_total_steps": 1096599.0, "train_total_episodes": 529.0, "train_loaded_steps": 1096653.0, "train_loaded_episodes": 529.0}
{"step": 4394224, "train_return": 16.0, "train_length": 1957.0, "train_total_steps": 1098556.0, "train_total_episodes": 530.0, "train_loaded_steps": 1098610.0, "train_loaded_episodes": 530.0}
{"step": 4401356, "kl_loss": 1.4465640363693237, "image_loss": 3772.0, "reward_loss": 0.9194918203353882, "discount_loss": 0.00778430994823575, "model_kl": 1.4465640027999878, "prior_ent": 29.33504208984375, "post_ent": 27.89370355834961, "model_loss": 3773.10309609375, "model_loss_scale": 8192.0, "model_grad_norm": 6.684584676742554, "actor_loss": 0.01542945341009763, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06582354409694671, "critic_loss": 0.9391959896087646, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.25557741677761076, "reward_mean": -0.004250029182625076, "reward_std": 0.0795628643155098, "reward_normed_mean": -0.004250029182625076, "reward_normed_std": 0.0795628643155098, "critic_slow": 3.1052735576629638, "critic_target": 3.1239102363586424, "actor_ent": 0.5276175210952759, "actor_ent_scale": 0.0010000000474974513, "critic": 3.123262971496582, "fps": 111.47823385207592}
{"step": 4402008, "train_return": 17.0, "train_length": 1946.0, "train_total_steps": 1100502.0, "train_total_episodes": 531.0, "train_loaded_steps": 1100556.0, "train_loaded_episodes": 531.0}
{"step": 4411736, "train_return": 11.0, "train_length": 2432.0, "train_total_steps": 1102934.0, "train_total_episodes": 532.0, "train_loaded_steps": 1102988.0, "train_loaded_episodes": 532.0}
{"step": 4421992, "train_return": 10.0, "train_length": 2564.0, "train_total_steps": 1105498.0, "train_total_episodes": 533.0, "train_loaded_steps": 1105552.0, "train_loaded_episodes": 533.0}
{"step": 4430104, "train_return": 15.0, "train_length": 2028.0, "train_total_steps": 1107526.0, "train_total_episodes": 534.0, "train_loaded_steps": 1107580.0, "train_loaded_episodes": 534.0}
{"step": 4438692, "train_return": 14.0, "train_length": 2147.0, "train_total_steps": 1109673.0, "train_total_episodes": 535.0, "train_loaded_steps": 1109727.0, "train_loaded_episodes": 535.0}
{"step": 4441356, "kl_loss": 1.463233828353882, "image_loss": 3772.0, "reward_loss": 0.9194900106430054, "discount_loss": 0.007780956215411424, "model_kl": 1.4632337924957275, "prior_ent": 29.37422019042969, "post_ent": 27.921163009643553, "model_loss": 3773.10474453125, "model_loss_scale": 8192.0, "model_grad_norm": 6.624945865058899, "actor_loss": 0.014276354216132313, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06906414530873299, "critic_loss": 0.9423474850654602, "critic_loss_scale": 189582.5408, "critic_grad_norm": 0.2961062061667442, "reward_mean": -0.003929071615883731, "reward_std": 0.08030196550488472, "reward_normed_mean": -0.003929071615883731, "reward_normed_std": 0.08030196550488472, "critic_slow": 3.2608226020812987, "critic_target": 3.2803280986785888, "actor_ent": 0.48669464020729064, "actor_ent_scale": 0.0010000000474974513, "critic": 3.2794267051696777, "fps": 111.58340138057397}
{"step": 4446700, "train_return": 18.0, "train_length": 2002.0, "train_total_steps": 1111675.0, "train_total_episodes": 536.0, "train_loaded_steps": 1111729.0, "train_loaded_episodes": 536.0}
{"step": 4455396, "train_return": 14.0, "train_length": 2174.0, "train_total_steps": 1113849.0, "train_total_episodes": 537.0, "train_loaded_steps": 1113903.0, "train_loaded_episodes": 537.0}
{"step": 4464584, "train_return": 12.0, "train_length": 2297.0, "train_total_steps": 1116146.0, "train_total_episodes": 538.0, "train_loaded_steps": 1116200.0, "train_loaded_episodes": 538.0}
{"step": 4471864, "train_return": 19.0, "train_length": 1820.0, "train_total_steps": 1117966.0, "train_total_episodes": 539.0, "train_loaded_steps": 1118020.0, "train_loaded_episodes": 539.0}
{"step": 4481356, "kl_loss": 1.4836960760116578, "image_loss": 3772.0, "reward_loss": 0.9194960250854493, "discount_loss": 0.007826094654202462, "model_kl": 1.4836960416793823, "prior_ent": 29.35296707458496, "post_ent": 27.88178890991211, "model_loss": 3773.107021875, "model_loss_scale": 11180.4416, "model_grad_norm": Infinity, "actor_loss": 0.0124920889326022, "actor_loss_scale": 9341553.8688, "actor_grad_norm": Infinity, "critic_loss": 0.9408916436195374, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.3040351667046547, "reward_mean": -0.004129520237669931, "reward_std": 0.07993295866847039, "reward_normed_mean": -0.004129520237669931, "reward_normed_std": 0.07993295866847039, "critic_slow": 3.3597572917938234, "critic_target": 3.3730694404602053, "actor_ent": 0.5147510896682739, "actor_ent_scale": 0.0010000000474974513, "critic": 3.3723907207489012, "fps": 111.6265918067585}
{"step": 4481860, "train_return": 11.0, "train_length": 2499.0, "train_total_steps": 1120465.0, "train_total_episodes": 540.0, "train_loaded_steps": 1120519.0, "train_loaded_episodes": 540.0}
{"step": 4491180, "train_return": 10.0, "train_length": 2330.0, "train_total_steps": 1122795.0, "train_total_episodes": 541.0, "train_loaded_steps": 1122849.0, "train_loaded_episodes": 541.0}
{"step": 4500428, "train_return": 14.0, "train_length": 2312.0, "train_total_steps": 1125107.0, "train_total_episodes": 542.0, "train_loaded_steps": 1125161.0, "train_loaded_episodes": 542.0}
{"step": 4508196, "train_return": 18.0, "train_length": 1942.0, "train_total_steps": 1127049.0, "train_total_episodes": 543.0, "train_loaded_steps": 1127103.0, "train_loaded_episodes": 543.0}
{"step": 4516416, "train_return": 15.0, "train_length": 2055.0, "train_total_steps": 1129104.0, "train_total_episodes": 544.0, "train_loaded_steps": 1129158.0, "train_loaded_episodes": 544.0}
{"step": 4521356, "kl_loss": 1.465639907836914, "image_loss": 3772.0, "reward_loss": 0.9194811352729797, "discount_loss": 0.007778724531829357, "model_kl": 1.4656398756027222, "prior_ent": 29.30987944946289, "post_ent": 27.85625524597168, "model_loss": 3773.104968359375, "model_loss_scale": 8192.0, "model_grad_norm": 6.570051034927368, "actor_loss": 0.027039725245535374, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06783549707531929, "critic_loss": 0.940010147190094, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.28863825043439867, "reward_mean": -0.004006167425804324, "reward_std": 0.08045970197319985, "reward_normed_mean": -0.004006167425804324, "reward_normed_std": 0.08045970197319985, "critic_slow": 3.524607648086548, "critic_target": 3.552576847076416, "actor_ent": 0.5361222401142121, "actor_ent_scale": 0.0010000000474974513, "critic": 3.5519220809936525, "fps": 111.37718625134907}
{"step": 4524700, "train_return": 17.0, "train_length": 2071.0, "train_total_steps": 1131175.0, "train_total_episodes": 545.0, "train_loaded_steps": 1131229.0, "train_loaded_episodes": 545.0}
{"step": 4533244, "train_return": 14.0, "train_length": 2136.0, "train_total_steps": 1133311.0, "train_total_episodes": 546.0, "train_loaded_steps": 1133365.0, "train_loaded_episodes": 546.0}
{"step": 4541688, "train_return": 15.0, "train_length": 2111.0, "train_total_steps": 1135422.0, "train_total_episodes": 547.0, "train_loaded_steps": 1135476.0, "train_loaded_episodes": 547.0}
{"step": 4549508, "train_return": 17.0, "train_length": 1955.0, "train_total_steps": 1137377.0, "train_total_episodes": 548.0, "train_loaded_steps": 1137431.0, "train_loaded_episodes": 548.0}
{"step": 4558452, "train_return": 14.0, "train_length": 2236.0, "train_total_steps": 1139613.0, "train_total_episodes": 549.0, "train_loaded_steps": 1139667.0, "train_loaded_episodes": 549.0}
{"step": 4561356, "kl_loss": 1.4586054861068725, "image_loss": 3772.0, "reward_loss": 0.9195021276473999, "discount_loss": 0.007803921988606453, "model_kl": 1.4586054544448852, "prior_ent": 29.288891567993165, "post_ent": 27.842294387817383, "model_loss": 3773.104406640625, "model_loss_scale": 8192.0, "model_grad_norm": 6.582920854568481, "actor_loss": 0.013062670787470415, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06570722052454948, "critic_loss": 0.939228517818451, "critic_loss_scale": 263402.2912, "critic_grad_norm": Infinity, "reward_mean": -0.003885601854806009, "reward_std": 0.08038989638090134, "reward_normed_mean": -0.003885601854806009, "reward_normed_std": 0.08038989638090134, "critic_slow": 3.673639563751221, "critic_target": 3.6886667358398437, "actor_ent": 0.5337255757808685, "actor_ent_scale": 0.0010000000474974513, "critic": 3.68810013999939, "fps": 111.48739121915015}
{"step": 4566020, "train_return": 17.0, "train_length": 1892.0, "train_total_steps": 1141505.0, "train_total_episodes": 550.0, "train_loaded_steps": 1141559.0, "train_loaded_episodes": 550.0}
{"step": 4572968, "train_return": 20.0, "train_length": 1737.0, "train_total_steps": 1143242.0, "train_total_episodes": 551.0, "train_loaded_steps": 1143296.0, "train_loaded_episodes": 551.0}
{"step": 4581540, "train_return": 14.0, "train_length": 2143.0, "train_total_steps": 1145385.0, "train_total_episodes": 552.0, "train_loaded_steps": 1145439.0, "train_loaded_episodes": 552.0}
{"step": 4589200, "train_return": 17.0, "train_length": 1915.0, "train_total_steps": 1147300.0, "train_total_episodes": 553.0, "train_loaded_steps": 1147354.0, "train_loaded_episodes": 553.0}
{"step": 4596472, "train_return": 19.0, "train_length": 1818.0, "train_total_steps": 1149118.0, "train_total_episodes": 554.0, "train_loaded_steps": 1149172.0, "train_loaded_episodes": 554.0}
{"step": 4601356, "kl_loss": 1.4689095796585083, "image_loss": 3772.0, "reward_loss": 0.9194768362998963, "discount_loss": 0.0077703357927501205, "model_kl": 1.4689095453262329, "prior_ent": 29.265554296875, "post_ent": 27.807367044067384, "model_loss": 3773.10525234375, "model_loss_scale": 8965.3248, "model_grad_norm": 6.674558285522461, "actor_loss": 0.017815132369939236, "actor_loss_scale": 5677409.8944, "actor_grad_norm": Infinity, "critic_loss": 0.9381842735290528, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.29797830168008804, "reward_mean": -0.0037295531646339896, "reward_std": 0.08041923252940178, "reward_normed_mean": -0.0037295531646339896, "reward_normed_std": 0.08041923252940178, "critic_slow": 3.807744469833374, "critic_target": 3.8244211040496827, "actor_ent": 0.543328078842163, "actor_ent_scale": 0.0010000000474974513, "critic": 3.823888181686401, "fps": 111.55319282148535}
{"step": 4605324, "train_return": 13.0, "train_length": 2213.0, "train_total_steps": 1151331.0, "train_total_episodes": 555.0, "train_loaded_steps": 1151385.0, "train_loaded_episodes": 555.0}
{"step": 4615000, "train_return": 11.0, "train_length": 2419.0, "train_total_steps": 1153750.0, "train_total_episodes": 556.0, "train_loaded_steps": 1153804.0, "train_loaded_episodes": 556.0}
{"step": 4622480, "train_return": 18.0, "train_length": 1870.0, "train_total_steps": 1155620.0, "train_total_episodes": 557.0, "train_loaded_steps": 1155674.0, "train_loaded_episodes": 557.0}
{"step": 4630976, "train_return": 14.0, "train_length": 2124.0, "train_total_steps": 1157744.0, "train_total_episodes": 558.0, "train_loaded_steps": 1157798.0, "train_loaded_episodes": 558.0}
{"step": 4638584, "train_return": 18.0, "train_length": 1902.0, "train_total_steps": 1159646.0, "train_total_episodes": 559.0, "train_loaded_steps": 1159700.0, "train_loaded_episodes": 559.0}
{"step": 4641356, "kl_loss": 1.4588999387741088, "image_loss": 3772.0, "reward_loss": 0.9194629343032837, "discount_loss": 0.007797873798757791, "model_kl": 1.4588999057769776, "prior_ent": 29.25531037902832, "post_ent": 27.810115478515623, "model_loss": 3773.1043734375, "model_loss_scale": 15387.8528, "model_grad_norm": Infinity, "actor_loss": 0.012628953711080249, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.0626464410662651, "critic_loss": 0.9367243737220764, "critic_loss_scale": 257530.2656, "critic_grad_norm": Infinity, "reward_mean": -0.003704183869681583, "reward_std": 0.08030299046039581, "reward_normed_mean": -0.003704183869681583, "reward_normed_std": 0.08030299046039581, "critic_slow": 3.936501236343384, "critic_target": 3.950057527542114, "actor_ent": 0.5419996382713318, "actor_ent_scale": 0.0010000000474974513, "critic": 3.94942039604187, "fps": 110.93991810567897}
{"step": 4646196, "train_return": 17.0, "train_length": 1903.0, "train_total_steps": 1161549.0, "train_total_episodes": 560.0, "train_loaded_steps": 1161603.0, "train_loaded_episodes": 560.0}
{"step": 4654596, "train_return": 16.0, "train_length": 2100.0, "train_total_steps": 1163649.0, "train_total_episodes": 561.0, "train_loaded_steps": 1163703.0, "train_loaded_episodes": 561.0}
{"step": 4663764, "train_return": 13.0, "train_length": 2292.0, "train_total_steps": 1165941.0, "train_total_episodes": 562.0, "train_loaded_steps": 1165995.0, "train_loaded_episodes": 562.0}
{"step": 4672228, "train_return": 16.0, "train_length": 2116.0, "train_total_steps": 1168057.0, "train_total_episodes": 563.0, "train_loaded_steps": 1168111.0, "train_loaded_episodes": 563.0}
{"step": 4679296, "train_return": 19.0, "train_length": 1767.0, "train_total_steps": 1169824.0, "train_total_episodes": 564.0, "train_loaded_steps": 1169878.0, "train_loaded_episodes": 564.0}
{"step": 4681356, "kl_loss": 1.4587419654846192, "image_loss": 3772.0, "reward_loss": 0.9194757374763489, "discount_loss": 0.007761409462243319, "model_kl": 1.4587419303894043, "prior_ent": 29.274623684692383, "post_ent": 27.827036901855468, "model_loss": 3773.10418515625, "model_loss_scale": 8192.0, "model_grad_norm": 6.495162302970886, "actor_loss": 0.015050900920020649, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.0617004134953022, "critic_loss": 0.9358077388763427, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3068801854014397, "reward_mean": -0.0034866221865740956, "reward_std": 0.08051684910058975, "reward_normed_mean": -0.0034866221865740956, "reward_normed_std": 0.08051684910058975, "critic_slow": 4.102858887481689, "critic_target": 4.115024430465699, "actor_ent": 0.5573499180793762, "actor_ent_scale": 0.0010000000474974513, "critic": 4.114294190597534, "fps": 111.1868452162367}
{"step": 4688556, "train_return": 13.0, "train_length": 2315.0, "train_total_steps": 1172139.0, "train_total_episodes": 565.0, "train_loaded_steps": 1172193.0, "train_loaded_episodes": 565.0}
{"step": 4697072, "train_return": 15.0, "train_length": 2129.0, "train_total_steps": 1174268.0, "train_total_episodes": 566.0, "train_loaded_steps": 1174322.0, "train_loaded_episodes": 566.0}
{"step": 4704484, "train_return": 18.0, "train_length": 1853.0, "train_total_steps": 1176121.0, "train_total_episodes": 567.0, "train_loaded_steps": 1176175.0, "train_loaded_episodes": 567.0}
{"step": 4712696, "train_return": 17.0, "train_length": 2053.0, "train_total_steps": 1178174.0, "train_total_episodes": 568.0, "train_loaded_steps": 1178228.0, "train_loaded_episodes": 568.0}
{"step": 4721296, "train_return": 15.0, "train_length": 2150.0, "train_total_steps": 1180324.0, "train_total_episodes": 569.0, "train_loaded_steps": 1180378.0, "train_loaded_episodes": 569.0}
{"step": 4721356, "kl_loss": 1.4496488189697265, "image_loss": 3772.0, "reward_loss": 0.919419250869751, "discount_loss": 0.007778677660226822, "model_kl": 1.449648787498474, "prior_ent": 29.22812610168457, "post_ent": 27.788599697875977, "model_loss": 3773.10330234375, "model_loss_scale": 8192.0, "model_grad_norm": 6.749484636306763, "actor_loss": 0.01693959202709084, "actor_loss_scale": 6066641.3056, "actor_grad_norm": 0.06079914942383766, "critic_loss": 0.9364375988006591, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.31611742384433744, "reward_mean": -0.003511965865336242, "reward_std": 0.0806525495171547, "reward_normed_mean": -0.003511965865336242, "reward_normed_std": 0.0806525495171547, "critic_slow": 4.247617894744873, "critic_target": 4.258677326965332, "actor_ent": 0.5855824478149414, "actor_ent_scale": 0.0010000000474974513, "critic": 4.258168750381469, "fps": 112.0574241079142}
{"step": 4729768, "train_return": 14.0, "train_length": 2118.0, "train_total_steps": 1182442.0, "train_total_episodes": 570.0, "train_loaded_steps": 1182496.0, "train_loaded_episodes": 570.0}
{"step": 4738764, "train_return": 12.0, "train_length": 2249.0, "train_total_steps": 1184691.0, "train_total_episodes": 571.0, "train_loaded_steps": 1184745.0, "train_loaded_episodes": 571.0}
{"step": 4748792, "train_return": 12.0, "train_length": 2507.0, "train_total_steps": 1187198.0, "train_total_episodes": 572.0, "train_loaded_steps": 1187252.0, "train_loaded_episodes": 572.0}
{"step": 4757896, "train_return": 13.0, "train_length": 2276.0, "train_total_steps": 1189474.0, "train_total_episodes": 573.0, "train_loaded_steps": 1189528.0, "train_loaded_episodes": 573.0}
{"step": 4761356, "kl_loss": 1.4675190181732178, "image_loss": 3772.0002, "reward_loss": 0.919453920841217, "discount_loss": 0.007757411979883909, "model_kl": 1.4675189893722533, "prior_ent": 29.280196084594728, "post_ent": 27.828032373046874, "model_loss": 3773.10521328125, "model_loss_scale": 8192.0, "model_grad_norm": 6.171279722213745, "actor_loss": 0.017626340936360067, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.0635093874156475, "critic_loss": 0.9399437393188477, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3328721557378769, "reward_mean": -0.0032732252019915904, "reward_std": 0.08083334704637528, "reward_normed_mean": -0.0032732252019915904, "reward_normed_std": 0.08083334704637528, "critic_slow": 4.3635807067871095, "critic_target": 4.380080600357056, "actor_ent": 0.5893167754173279, "actor_ent_scale": 0.0010000000474974513, "critic": 4.379620011520386, "fps": 110.79542302861282}
{"step": 4768160, "train_return": 9.0, "train_length": 2566.0, "train_total_steps": 1192040.0, "train_total_episodes": 574.0, "train_loaded_steps": 1192094.0, "train_loaded_episodes": 574.0}
{"step": 4775856, "train_return": 17.0, "train_length": 1924.0, "train_total_steps": 1193964.0, "train_total_episodes": 575.0, "train_loaded_steps": 1194018.0, "train_loaded_episodes": 575.0}
{"step": 4784300, "train_return": 15.0, "train_length": 2111.0, "train_total_steps": 1196075.0, "train_total_episodes": 576.0, "train_loaded_steps": 1196129.0, "train_loaded_episodes": 576.0}
{"step": 4794052, "train_return": 11.0, "train_length": 2438.0, "train_total_steps": 1198513.0, "train_total_episodes": 577.0, "train_loaded_steps": 1198567.0, "train_loaded_episodes": 577.0}
{"step": 4801356, "kl_loss": 1.490881141281128, "image_loss": 3772.0, "reward_loss": 0.9194446202278137, "discount_loss": 0.007759449596703052, "model_kl": 1.4908811080932618, "prior_ent": 29.28016853942871, "post_ent": 27.808470935058594, "model_loss": 3773.10735234375, "model_loss_scale": 9528.9344, "model_grad_norm": Infinity, "actor_loss": 0.01379100360427983, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06590725597739219, "critic_loss": 0.9426394577980042, "critic_loss_scale": 240543.3344, "critic_grad_norm": 0.3385549268245697, "reward_mean": -0.0033342053521773778, "reward_std": 0.08112063654065133, "reward_normed_mean": -0.0033342053521773778, "reward_normed_std": 0.08112063654065133, "critic_slow": 4.481806893539429, "critic_target": 4.489657349395752, "actor_ent": 0.6125621317863464, "actor_ent_scale": 0.0010000000474974513, "critic": 4.488981684494019, "fps": 110.36427306831396}
{"step": 4802484, "train_return": 16.0, "train_length": 2108.0, "train_total_steps": 1200621.0, "train_total_episodes": 578.0, "train_loaded_steps": 1200675.0, "train_loaded_episodes": 578.0}
{"step": 4810928, "train_return": 14.0, "train_length": 2111.0, "train_total_steps": 1202732.0, "train_total_episodes": 579.0, "train_loaded_steps": 1202786.0, "train_loaded_episodes": 579.0}
{"step": 4821288, "train_return": 10.0, "train_length": 2590.0, "train_total_steps": 1205322.0, "train_total_episodes": 580.0, "train_loaded_steps": 1205376.0, "train_loaded_episodes": 580.0}
{"step": 4829508, "train_return": 15.0, "train_length": 2055.0, "train_total_steps": 1207377.0, "train_total_episodes": 581.0, "train_loaded_steps": 1207431.0, "train_loaded_episodes": 581.0}
{"step": 4838060, "train_return": 16.0, "train_length": 2138.0, "train_total_steps": 1209515.0, "train_total_episodes": 582.0, "train_loaded_steps": 1209569.0, "train_loaded_episodes": 582.0}
{"step": 4841356, "kl_loss": 1.4612990762710572, "image_loss": 3772.0, "reward_loss": 0.9194388075828552, "discount_loss": 0.00775689412355423, "model_kl": 1.4612990419387817, "prior_ent": 29.244997732543947, "post_ent": 27.795291540527344, "model_loss": 3773.104379296875, "model_loss_scale": 8192.0, "model_grad_norm": 6.638600175857544, "actor_loss": 0.01243728100080043, "actor_loss_scale": 8965744.2304, "actor_grad_norm": Infinity, "critic_loss": 0.9376276211738587, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.34059685972929, "reward_mean": -0.0032283215604977157, "reward_std": 0.08049075071811676, "reward_normed_mean": -0.0032283215604977157, "reward_normed_std": 0.08049075071811676, "critic_slow": 4.635855243682862, "critic_target": 4.64555966835022, "actor_ent": 0.5923414505958557, "actor_ent_scale": 0.0010000000474974513, "critic": 4.644929235839844, "fps": 111.49286031064467}
{"step": 4847368, "train_return": 13.0, "train_length": 2327.0, "train_total_steps": 1211842.0, "train_total_episodes": 583.0, "train_loaded_steps": 1211896.0, "train_loaded_episodes": 583.0}
{"step": 4857504, "train_return": 10.0, "train_length": 2534.0, "train_total_steps": 1214376.0, "train_total_episodes": 584.0, "train_loaded_steps": 1214430.0, "train_loaded_episodes": 584.0}
{"step": 4866768, "train_return": 13.0, "train_length": 2316.0, "train_total_steps": 1216692.0, "train_total_episodes": 585.0, "train_loaded_steps": 1216746.0, "train_loaded_episodes": 585.0}
{"step": 4876528, "train_return": 10.0, "train_length": 2440.0, "train_total_steps": 1219132.0, "train_total_episodes": 586.0, "train_loaded_steps": 1219186.0, "train_loaded_episodes": 586.0}
{"step": 4881356, "kl_loss": 1.4829680967330932, "image_loss": 3772.0, "reward_loss": 0.9194247017860413, "discount_loss": 0.007804236948490143, "model_kl": 1.482968062400818, "prior_ent": 29.24024998474121, "post_ent": 27.77206096496582, "model_loss": 3773.106766015625, "model_loss_scale": 8192.0, "model_grad_norm": 6.530534597969055, "actor_loss": 0.013642747546813917, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06096860063672066, "critic_loss": 0.9386805871009827, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.3090683423757553, "reward_mean": -0.0033487506647245026, "reward_std": 0.08067613525986672, "reward_normed_mean": -0.0033487506647245026, "reward_normed_std": 0.08067613525986672, "critic_slow": 4.693305505752564, "critic_target": 4.703124848556518, "actor_ent": 0.6237022314071655, "actor_ent_scale": 0.0010000000474974513, "critic": 4.702505616378784, "fps": 110.94403746244583}
{"step": 4887048, "train_return": 9.0, "train_length": 2630.0, "train_total_steps": 1221762.0, "train_total_episodes": 587.0, "train_loaded_steps": 1221816.0, "train_loaded_episodes": 587.0}
{"step": 4895208, "train_return": 14.0, "train_length": 2040.0, "train_total_steps": 1223802.0, "train_total_episodes": 588.0, "train_loaded_steps": 1223856.0, "train_loaded_episodes": 588.0}
{"step": 4903840, "train_return": 16.0, "train_length": 2158.0, "train_total_steps": 1225960.0, "train_total_episodes": 589.0, "train_loaded_steps": 1226014.0, "train_loaded_episodes": 589.0}
{"step": 4910924, "train_return": 19.0, "train_length": 1771.0, "train_total_steps": 1227731.0, "train_total_episodes": 590.0, "train_loaded_steps": 1227785.0, "train_loaded_episodes": 590.0}
{"step": 4919848, "train_return": 13.0, "train_length": 2231.0, "train_total_steps": 1229962.0, "train_total_episodes": 591.0, "train_loaded_steps": 1230016.0, "train_loaded_episodes": 591.0}
{"step": 4921356, "kl_loss": 1.485342523765564, "image_loss": 3772.0, "reward_loss": 0.9194714391708374, "discount_loss": 0.007817136779427528, "model_kl": 1.4853424909591675, "prior_ent": 29.225317614746093, "post_ent": 27.75407065124512, "model_loss": 3773.1071296875, "model_loss_scale": 12766.4128, "model_grad_norm": 6.753745833969116, "actor_loss": 0.011848925586912083, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06111187360882759, "critic_loss": 0.9374496612548828, "critic_loss_scale": 357774.1312, "critic_grad_norm": Infinity, "reward_mean": -0.0031261318725388262, "reward_std": 0.08003852772712708, "reward_normed_mean": -0.0031261318725388262, "reward_normed_std": 0.08003852772712708, "critic_slow": 4.822525100708008, "critic_target": 4.828729359436035, "actor_ent": 0.640202583360672, "actor_ent_scale": 0.0010000000474974513, "critic": 4.8275739959716795, "fps": 110.5779772060813}
{"step": 4927644, "train_return": 17.0, "train_length": 1949.0, "train_total_steps": 1231911.0, "train_total_episodes": 592.0, "train_loaded_steps": 1231965.0, "train_loaded_episodes": 592.0}
{"step": 4935116, "train_return": 18.0, "train_length": 1868.0, "train_total_steps": 1233779.0, "train_total_episodes": 593.0, "train_loaded_steps": 1233833.0, "train_loaded_episodes": 593.0}
{"step": 4941952, "train_return": 20.0, "train_length": 1709.0, "train_total_steps": 1235488.0, "train_total_episodes": 594.0, "train_loaded_steps": 1235542.0, "train_loaded_episodes": 594.0}
{"step": 4950260, "train_return": 15.0, "train_length": 2077.0, "train_total_steps": 1237565.0, "train_total_episodes": 595.0, "train_loaded_steps": 1237619.0, "train_loaded_episodes": 595.0}
{"step": 4958024, "train_return": 18.0, "train_length": 1941.0, "train_total_steps": 1239506.0, "train_total_episodes": 596.0, "train_loaded_steps": 1239560.0, "train_loaded_episodes": 596.0}
{"step": 4961356, "kl_loss": 1.4387058891296387, "image_loss": 3772.0, "reward_loss": 0.9194378399848938, "discount_loss": 0.007774538189172744, "model_kl": 1.4387058568954467, "prior_ent": 29.21327367553711, "post_ent": 27.784649487304687, "model_loss": 3773.10221328125, "model_loss_scale": 11835.8016, "model_grad_norm": Infinity, "actor_loss": 0.01574411005174625, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06050749763250351, "critic_loss": 0.936440406703949, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3228463334798813, "reward_mean": -0.002904057957110672, "reward_std": 0.0806453436613083, "reward_normed_mean": -0.002904057957110672, "reward_normed_std": 0.0806453436613083, "critic_slow": 4.845893381500244, "critic_target": 4.856688669967651, "actor_ent": 0.6560300142288208, "actor_ent_scale": 0.0010000000474974513, "critic": 4.855940436172485, "fps": 110.16087383667369}
{"step": 4965604, "train_return": 17.0, "train_length": 1895.0, "train_total_steps": 1241401.0, "train_total_episodes": 597.0, "train_loaded_steps": 1241455.0, "train_loaded_episodes": 597.0}
{"step": 4973272, "train_return": 17.0, "train_length": 1917.0, "train_total_steps": 1243318.0, "train_total_episodes": 598.0, "train_loaded_steps": 1243372.0, "train_loaded_episodes": 598.0}
{"step": 4981668, "train_return": 15.0, "train_length": 2099.0, "train_total_steps": 1245417.0, "train_total_episodes": 599.0, "train_loaded_steps": 1245471.0, "train_loaded_episodes": 599.0}
{"step": 4989144, "train_return": 18.0, "train_length": 1869.0, "train_total_steps": 1247286.0, "train_total_episodes": 600.0, "train_loaded_steps": 1247340.0, "train_loaded_episodes": 600.0}
{"step": 4997260, "train_return": 16.0, "train_length": 2029.0, "train_total_steps": 1249315.0, "train_total_episodes": 601.0, "train_loaded_steps": 1249369.0, "train_loaded_episodes": 601.0}
{"step": 5001356, "kl_loss": 1.480971670150757, "image_loss": 3772.0, "reward_loss": 0.919447683429718, "discount_loss": 0.007807168798148632, "model_kl": 1.4809716331481935, "prior_ent": 29.29637829589844, "post_ent": 27.830501431274413, "model_loss": 3773.106604296875, "model_loss_scale": 8192.0, "model_grad_norm": 6.402489835357666, "actor_loss": 0.010494888293766052, "actor_loss_scale": 6012954.2144, "actor_grad_norm": Infinity, "critic_loss": 0.9376822557449341, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.37207389110326766, "reward_mean": -0.0032140631617443433, "reward_std": 0.08102290896773338, "reward_normed_mean": -0.0032140631617443433, "reward_normed_std": 0.08102290896773338, "critic_slow": 4.9670629344940185, "critic_target": 4.97282169456482, "actor_ent": 0.6435670614242553, "actor_ent_scale": 0.0010000000474974513, "critic": 4.971591788482666, "fps": 111.42550219878963}
{"step": 5009440, "train_return": 8.0, "train_length": 3045.0, "train_total_steps": 1252360.0, "train_total_episodes": 602.0, "train_loaded_steps": 1252414.0, "train_loaded_episodes": 602.0}
{"step": 5017524, "train_return": 16.0, "train_length": 2021.0, "train_total_steps": 1254381.0, "train_total_episodes": 603.0, "train_loaded_steps": 1254435.0, "train_loaded_episodes": 603.0}
{"step": 5025364, "train_return": 17.0, "train_length": 1960.0, "train_total_steps": 1256341.0, "train_total_episodes": 604.0, "train_loaded_steps": 1256395.0, "train_loaded_episodes": 604.0}
{"step": 5034948, "train_return": 12.0, "train_length": 2396.0, "train_total_steps": 1258737.0, "train_total_episodes": 605.0, "train_loaded_steps": 1258791.0, "train_loaded_episodes": 605.0}
{"step": 5041356, "kl_loss": 1.4307591688156127, "image_loss": 3772.0, "reward_loss": 0.9194109547615051, "discount_loss": 0.007745106165111065, "model_kl": 1.4307591377258302, "prior_ent": 29.225319717407228, "post_ent": 27.801565032958983, "model_loss": 3773.10122734375, "model_loss_scale": 8192.0, "model_grad_norm": 6.542638646697998, "actor_loss": 0.020886975832469762, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06260523788332939, "critic_loss": 0.9366744854927063, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3328689183592796, "reward_mean": -0.0029259623527919756, "reward_std": 0.08087923991084099, "reward_normed_mean": -0.0029259623527919756, "reward_normed_std": 0.08087923991084099, "critic_slow": 5.058954723358155, "critic_target": 5.0709357215881345, "actor_ent": 0.6735540451049805, "actor_ent_scale": 0.0010000000474974513, "critic": 5.069862196350098, "fps": 110.76631812807953}
{"step": 5042100, "train_return": 19.0, "train_length": 1788.0, "train_total_steps": 1260525.0, "train_total_episodes": 606.0, "train_loaded_steps": 1260579.0, "train_loaded_episodes": 606.0}
{"step": 5052572, "train_return": 8.0, "train_length": 2618.0, "train_total_steps": 1263143.0, "train_total_episodes": 607.0, "train_loaded_steps": 1263197.0, "train_loaded_episodes": 607.0}
{"step": 5059520, "train_return": 20.0, "train_length": 1737.0, "train_total_steps": 1264880.0, "train_total_episodes": 608.0, "train_loaded_steps": 1264934.0, "train_loaded_episodes": 608.0}
{"step": 5068776, "train_return": 13.0, "train_length": 2314.0, "train_total_steps": 1267194.0, "train_total_episodes": 609.0, "train_loaded_steps": 1267248.0, "train_loaded_episodes": 609.0}
{"step": 5077240, "train_return": 15.0, "train_length": 2116.0, "train_total_steps": 1269310.0, "train_total_episodes": 610.0, "train_loaded_steps": 1269364.0, "train_loaded_episodes": 610.0}
{"step": 5081356, "kl_loss": 1.4667598892211915, "image_loss": 3772.0, "reward_loss": 0.9194384093284607, "discount_loss": 0.0077663557164371014, "model_kl": 1.4667598558425903, "prior_ent": 29.155702893066405, "post_ent": 27.707086193847655, "model_loss": 3773.10496875, "model_loss_scale": 11101.7984, "model_grad_norm": 6.508426100158691, "actor_loss": 0.015006016049529718, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06515687712430954, "critic_loss": 0.9417708881378174, "critic_loss_scale": 235929.6, "critic_grad_norm": 0.3500133599281311, "reward_mean": -0.002827772507345071, "reward_std": 0.08093376754522323, "reward_normed_mean": -0.002827772507345071, "reward_normed_std": 0.08093376754522323, "critic_slow": 5.198562265777588, "critic_target": 5.207419221115113, "actor_ent": 0.6746807110786438, "actor_ent_scale": 0.0010000000474974513, "critic": 5.20658903427124, "fps": 109.93306476330916}
{"step": 5085764, "train_return": 15.0, "train_length": 2131.0, "train_total_steps": 1271441.0, "train_total_episodes": 611.0, "train_loaded_steps": 1271495.0, "train_loaded_episodes": 611.0}
{"step": 5093956, "train_return": 16.0, "train_length": 2048.0, "train_total_steps": 1273489.0, "train_total_episodes": 612.0, "train_loaded_steps": 1273543.0, "train_loaded_episodes": 612.0}
{"step": 5101780, "train_return": 16.0, "train_length": 1956.0, "train_total_steps": 1275445.0, "train_total_episodes": 613.0, "train_loaded_steps": 1275499.0, "train_loaded_episodes": 613.0}
{"step": 5109840, "train_return": 16.0, "train_length": 2015.0, "train_total_steps": 1277460.0, "train_total_episodes": 614.0, "train_loaded_steps": 1277514.0, "train_loaded_episodes": 614.0}
{"step": 5118724, "train_return": 13.0, "train_length": 2221.0, "train_total_steps": 1279681.0, "train_total_episodes": 615.0, "train_loaded_steps": 1279735.0, "train_loaded_episodes": 615.0}
{"step": 5121356, "kl_loss": 1.462451795387268, "image_loss": 3772.0, "reward_loss": 0.9194273936271667, "discount_loss": 0.007755509480088949, "model_kl": 1.4624517595291138, "prior_ent": 29.156401657104492, "post_ent": 27.70804111328125, "model_loss": 3773.104472265625, "model_loss_scale": 8218.2144, "model_grad_norm": Infinity, "actor_loss": 0.01008578750823508, "actor_loss_scale": 5784784.0768, "actor_grad_norm": 0.06512157024145127, "critic_loss": 0.9404483243942261, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.3779741281032562, "reward_mean": -0.0026644087711698377, "reward_std": 0.08143619505763054, "reward_normed_mean": -0.0026644087711698377, "reward_normed_std": 0.08143619505763054, "critic_slow": 5.3660855339050295, "critic_target": 5.371466729736328, "actor_ent": 0.627258899974823, "actor_ent_scale": 0.0010000000474974513, "critic": 5.3707877571105955, "fps": 112.06084491704516}
{"step": 5128136, "train_return": 12.0, "train_length": 2353.0, "train_total_steps": 1282034.0, "train_total_episodes": 616.0, "train_loaded_steps": 1282088.0, "train_loaded_episodes": 616.0}
{"step": 5136484, "train_return": 14.0, "train_length": 2087.0, "train_total_steps": 1284121.0, "train_total_episodes": 617.0, "train_loaded_steps": 1284175.0, "train_loaded_episodes": 617.0}
{"step": 5143432, "train_return": 20.0, "train_length": 1737.0, "train_total_steps": 1285858.0, "train_total_episodes": 618.0, "train_loaded_steps": 1285912.0, "train_loaded_episodes": 618.0}
{"step": 5151872, "train_return": 16.0, "train_length": 2110.0, "train_total_steps": 1287968.0, "train_total_episodes": 619.0, "train_loaded_steps": 1288022.0, "train_loaded_episodes": 619.0}
{"step": 5161024, "train_return": 14.0, "train_length": 2288.0, "train_total_steps": 1290256.0, "train_total_episodes": 620.0, "train_loaded_steps": 1290310.0, "train_loaded_episodes": 620.0}
{"step": 5161356, "kl_loss": 1.4596260206222533, "image_loss": 3772.0, "reward_loss": 0.919402809715271, "discount_loss": 0.007770613118261099, "model_kl": 1.4596259840011596, "prior_ent": 29.13261317138672, "post_ent": 27.687094155883788, "model_loss": 3773.104243359375, "model_loss_scale": 8192.0, "model_grad_norm": 6.580363453292847, "actor_loss": 0.018862738066639576, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06660487005710602, "critic_loss": 0.9402076703071595, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.3488883719444275, "reward_mean": -0.0027121564757737362, "reward_std": 0.08138258256912231, "reward_normed_mean": -0.0027121564757737362, "reward_normed_std": 0.08138258256912231, "critic_slow": 5.439261688995361, "critic_target": 5.44892360534668, "actor_ent": 0.6322397047042847, "actor_ent_scale": 0.0010000000474974513, "critic": 5.448566937255859, "fps": 110.83083967209653}
{"step": 5168512, "train_return": 18.0, "train_length": 1872.0, "train_total_steps": 1292128.0, "train_total_episodes": 621.0, "train_loaded_steps": 1292182.0, "train_loaded_episodes": 621.0}
{"step": 5176408, "train_return": 15.0, "train_length": 1974.0, "train_total_steps": 1294102.0, "train_total_episodes": 622.0, "train_loaded_steps": 1294156.0, "train_loaded_episodes": 622.0}
{"step": 5183964, "train_return": 17.0, "train_length": 1889.0, "train_total_steps": 1295991.0, "train_total_episodes": 623.0, "train_loaded_steps": 1296045.0, "train_loaded_episodes": 623.0}
{"step": 5192216, "train_return": 15.0, "train_length": 2063.0, "train_total_steps": 1298054.0, "train_total_episodes": 624.0, "train_loaded_steps": 1298108.0, "train_loaded_episodes": 624.0}
{"step": 5201352, "eval_return": 12.0, "eval_length": 2410.0, "eval_total_steps": 13173.0, "eval_total_episodes": 7.0, "eval_loaded_steps": 13175.0, "eval_loaded_episodes": 7.0}
{"step": 5201356, "kl_loss": 1.4786061321258546, "image_loss": 3772.0004, "reward_loss": 0.919434627532959, "discount_loss": 0.007875910080969334, "model_kl": 1.4786060966491699, "prior_ent": 29.12773332824707, "post_ent": 27.668647787475585, "model_loss": 3773.107097265625, "model_loss_scale": 8192.0, "model_grad_norm": 6.355215258026123, "actor_loss": 0.004390599046100396, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06386459740400315, "critic_loss": 0.9403203834533691, "critic_loss_scale": 239704.4736, "critic_grad_norm": Infinity, "reward_mean": -0.0026794840034242953, "reward_std": 0.08112236512899398, "reward_normed_mean": -0.0026794840034242953, "reward_normed_std": 0.08112236512899398, "critic_slow": 5.542640508270264, "critic_target": 5.5445096328735355, "actor_ent": 0.6409839085578919, "actor_ent_scale": 0.0010000000474974513, "critic": 5.543864842987061, "fps": 104.43137652119005}
{"step": 5201868, "train_return": 11.0, "train_length": 2413.0, "train_total_steps": 1300467.0, "train_total_episodes": 625.0, "train_loaded_steps": 1300521.0, "train_loaded_episodes": 625.0}
{"step": 5211048, "train_return": 12.0, "train_length": 2295.0, "train_total_steps": 1302762.0, "train_total_episodes": 626.0, "train_loaded_steps": 1302816.0, "train_loaded_episodes": 626.0}
{"step": 5219540, "train_return": 16.0, "train_length": 2123.0, "train_total_steps": 1304885.0, "train_total_episodes": 627.0, "train_loaded_steps": 1304939.0, "train_loaded_episodes": 627.0}
{"step": 5228008, "train_return": 15.0, "train_length": 2117.0, "train_total_steps": 1307002.0, "train_total_episodes": 628.0, "train_loaded_steps": 1307056.0, "train_loaded_episodes": 628.0}
{"step": 5236456, "train_return": 17.0, "train_length": 2112.0, "train_total_steps": 1309114.0, "train_total_episodes": 629.0, "train_loaded_steps": 1309168.0, "train_loaded_episodes": 629.0}
{"step": 5241356, "kl_loss": 1.4424706092834472, "image_loss": 3772.0001921875, "reward_loss": 0.9193986039161682, "discount_loss": 0.0077795261204242705, "model_kl": 1.4424705728530884, "prior_ent": 29.162908255004883, "post_ent": 27.72649006652832, "model_loss": 3773.10276171875, "model_loss_scale": 9555.1488, "model_grad_norm": Infinity, "actor_loss": 0.012131985293292383, "actor_loss_scale": 6972610.9696, "actor_grad_norm": Infinity, "critic_loss": 0.9383064440727233, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.366190880215168, "reward_mean": -0.002267620100099521, "reward_std": 0.08059183382987976, "reward_normed_mean": -0.002267620100099521, "reward_normed_std": 0.08059183382987976, "critic_slow": 5.645261700439453, "critic_target": 5.65109518737793, "actor_ent": 0.6391388030052185, "actor_ent_scale": 0.0010000000474974513, "critic": 5.65046498336792, "fps": 109.93775998770904}
{"step": 5246424, "train_return": 8.0, "train_length": 2492.0, "train_total_steps": 1311606.0, "train_total_episodes": 630.0, "train_loaded_steps": 1311660.0, "train_loaded_episodes": 630.0}
{"step": 5253916, "train_return": 18.0, "train_length": 1873.0, "train_total_steps": 1313479.0, "train_total_episodes": 631.0, "train_loaded_steps": 1313533.0, "train_loaded_episodes": 631.0}
{"step": 5262452, "train_return": 13.0, "train_length": 2134.0, "train_total_steps": 1315613.0, "train_total_episodes": 632.0, "train_loaded_steps": 1315667.0, "train_loaded_episodes": 632.0}
{"step": 5269876, "train_return": 19.0, "train_length": 1856.0, "train_total_steps": 1317469.0, "train_total_episodes": 633.0, "train_loaded_steps": 1317523.0, "train_loaded_episodes": 633.0}
{"step": 5277748, "train_return": 17.0, "train_length": 1968.0, "train_total_steps": 1319437.0, "train_total_episodes": 634.0, "train_loaded_steps": 1319491.0, "train_loaded_episodes": 634.0}
{"step": 5281356, "kl_loss": 1.4330823602676392, "image_loss": 3772.0, "reward_loss": 0.9193881673812866, "discount_loss": 0.007741598661988974, "model_kl": 1.433082328224182, "prior_ent": 29.143251403808595, "post_ent": 27.71858450012207, "model_loss": 3773.101421875, "model_loss_scale": 8192.0, "model_grad_norm": 6.2288962789535525, "actor_loss": 0.010916158013080712, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06208292859196663, "critic_loss": 0.9368224188804627, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.36457739405632017, "reward_mean": -0.0024927235110051697, "reward_std": 0.0810844995200634, "reward_normed_mean": -0.0024927235110051697, "reward_normed_std": 0.0810844995200634, "critic_slow": 5.744760550689698, "critic_target": 5.750065145111084, "actor_ent": 0.6776156200408936, "actor_ent_scale": 0.0010000000474974513, "critic": 5.749656642150879, "fps": 110.54557345276058}
{"step": 5285636, "train_return": 17.0, "train_length": 1972.0, "train_total_steps": 1321409.0, "train_total_episodes": 635.0, "train_loaded_steps": 1321463.0, "train_loaded_episodes": 635.0}
{"step": 5294804, "train_return": 13.0, "train_length": 2292.0, "train_total_steps": 1323701.0, "train_total_episodes": 636.0, "train_loaded_steps": 1323755.0, "train_loaded_episodes": 636.0}
{"step": 5302052, "train_return": 18.0, "train_length": 1812.0, "train_total_steps": 1325513.0, "train_total_episodes": 637.0, "train_loaded_steps": 1325567.0, "train_loaded_episodes": 637.0}
{"step": 5310116, "train_return": 16.0, "train_length": 2016.0, "train_total_steps": 1327529.0, "train_total_episodes": 638.0, "train_loaded_steps": 1327583.0, "train_loaded_episodes": 638.0}
{"step": 5319164, "train_return": 14.0, "train_length": 2262.0, "train_total_steps": 1329791.0, "train_total_episodes": 639.0, "train_loaded_steps": 1329845.0, "train_loaded_episodes": 639.0}
{"step": 5321356, "kl_loss": 1.4556497751235962, "image_loss": 3772.0, "reward_loss": 0.9194235706329346, "discount_loss": 0.0077946396864950656, "model_kl": 1.4556497407913207, "prior_ent": 29.102929220581053, "post_ent": 27.6610277923584, "model_loss": 3773.103979296875, "model_loss_scale": 8192.0, "model_grad_norm": 6.586519893836975, "actor_loss": 0.013151441594521748, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06374655066132545, "critic_loss": 0.9395471125602722, "critic_loss_scale": 116706.5088, "critic_grad_norm": Infinity, "reward_mean": -0.002417442266023136, "reward_std": 0.08087563512921334, "reward_normed_mean": -0.002417442266023136, "reward_normed_std": 0.08087563512921334, "critic_slow": 5.809404014587402, "critic_target": 5.815937197875977, "actor_ent": 0.67380387134552, "actor_ent_scale": 0.0010000000474974513, "critic": 5.815483164978027, "fps": 110.56875722438849}
{"step": 5326864, "train_return": 17.0, "train_length": 1925.0, "train_total_steps": 1331716.0, "train_total_episodes": 640.0, "train_loaded_steps": 1331770.0, "train_loaded_episodes": 640.0}
{"step": 5335072, "train_return": 15.0, "train_length": 2052.0, "train_total_steps": 1333768.0, "train_total_episodes": 641.0, "train_loaded_steps": 1333822.0, "train_loaded_episodes": 641.0}
{"step": 5343860, "train_return": 14.0, "train_length": 2197.0, "train_total_steps": 1335965.0, "train_total_episodes": 642.0, "train_loaded_steps": 1336019.0, "train_loaded_episodes": 642.0}
{"step": 5351320, "train_return": 19.0, "train_length": 1865.0, "train_total_steps": 1337830.0, "train_total_episodes": 643.0, "train_loaded_steps": 1337884.0, "train_loaded_episodes": 643.0}
{"step": 5360080, "train_return": 13.0, "train_length": 2190.0, "train_total_steps": 1340020.0, "train_total_episodes": 644.0, "train_loaded_steps": 1340074.0, "train_loaded_episodes": 644.0}
{"step": 5361356, "kl_loss": 1.450524912929535, "image_loss": 3772.000187890625, "reward_loss": 0.9193841115951538, "discount_loss": 0.0077420832850039, "model_kl": 1.4505248795509338, "prior_ent": 29.101484686279296, "post_ent": 27.662282754516603, "model_loss": 3773.10335859375, "model_loss_scale": 11717.8368, "model_grad_norm": 6.261483620262146, "actor_loss": 0.009985054909007158, "actor_loss_scale": 4771440.2304, "actor_grad_norm": 0.06539075365662575, "critic_loss": 0.9409825385093689, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.37681432504653933, "reward_mean": -0.0021896329842569684, "reward_std": 0.0811343585073948, "reward_normed_mean": -0.0021896329842569684, "reward_normed_std": 0.0811343585073948, "critic_slow": 5.872092070007324, "critic_target": 5.8746043373107915, "actor_ent": 0.665341287612915, "actor_ent_scale": 0.0010000000474974513, "critic": 5.874018241882324, "fps": 110.05782204904092}
{"step": 5368008, "train_return": 17.0, "train_length": 1982.0, "train_total_steps": 1342002.0, "train_total_episodes": 645.0, "train_loaded_steps": 1342056.0, "train_loaded_episodes": 645.0}
{"step": 5375980, "train_return": 16.0, "train_length": 1993.0, "train_total_steps": 1343995.0, "train_total_episodes": 646.0, "train_loaded_steps": 1344049.0, "train_loaded_episodes": 646.0}
{"step": 5384956, "train_return": 14.0, "train_length": 2244.0, "train_total_steps": 1346239.0, "train_total_episodes": 647.0, "train_loaded_steps": 1346293.0, "train_loaded_episodes": 647.0}
{"step": 5392788, "train_return": 16.0, "train_length": 1958.0, "train_total_steps": 1348197.0, "train_total_episodes": 648.0, "train_loaded_steps": 1348251.0, "train_loaded_episodes": 648.0}
{"step": 5401096, "train_return": 18.0, "train_length": 2077.0, "train_total_steps": 1350274.0, "train_total_episodes": 649.0, "train_loaded_steps": 1350328.0, "train_loaded_episodes": 649.0}
{"step": 5401356, "kl_loss": 1.5498778005599976, "image_loss": 3772.0, "reward_loss": 0.9194238909721375, "discount_loss": 0.00792965408116579, "model_kl": 1.5498777654647826, "prior_ent": 29.031070483398437, "post_ent": 27.518866134643556, "model_loss": 3773.114081640625, "model_loss_scale": 10577.5104, "model_grad_norm": Infinity, "actor_loss": 0.009517307748808525, "actor_loss_scale": 7247757.312, "actor_grad_norm": Infinity, "critic_loss": 0.9434223522186279, "critic_loss_scale": 54630.8096, "critic_grad_norm": Infinity, "reward_mean": -0.0022118142467006693, "reward_std": 0.08173766704201699, "reward_normed_mean": -0.0022118142467006693, "reward_normed_std": 0.08173766704201699, "critic_slow": 5.96901067199707, "critic_target": 5.979891776275635, "actor_ent": 0.6755199099540711, "actor_ent_scale": 0.0010000000474974513, "critic": 5.979384891510009, "fps": 110.8553491989825}
{"step": 5409428, "train_return": 14.0, "train_length": 2083.0, "train_total_steps": 1352357.0, "train_total_episodes": 650.0, "train_loaded_steps": 1352411.0, "train_loaded_episodes": 650.0}
{"step": 5419008, "train_return": 11.0, "train_length": 2395.0, "train_total_steps": 1354752.0, "train_total_episodes": 651.0, "train_loaded_steps": 1354806.0, "train_loaded_episodes": 651.0}
{"step": 5428308, "train_return": 12.0, "train_length": 2325.0, "train_total_steps": 1357077.0, "train_total_episodes": 652.0, "train_loaded_steps": 1357131.0, "train_loaded_episodes": 652.0}
{"step": 5437020, "train_return": 13.0, "train_length": 2178.0, "train_total_steps": 1359255.0, "train_total_episodes": 653.0, "train_loaded_steps": 1359309.0, "train_loaded_episodes": 653.0}
{"step": 5441356, "kl_loss": 1.5097766494750977, "image_loss": 3772.0, "reward_loss": 0.9193950923919678, "discount_loss": 0.007815214029699563, "model_kl": 1.5097766176223755, "prior_ent": 29.195511404418944, "post_ent": 27.699142419433592, "model_loss": 3773.109475390625, "model_loss_scale": 8192.0, "model_grad_norm": 6.378122726631164, "actor_loss": 0.00954241150796006, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06715465540885926, "critic_loss": 0.9422538655281066, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.395202437877655, "reward_mean": -0.0021279271561696076, "reward_std": 0.08159258111715317, "reward_normed_mean": -0.0021279271561696076, "reward_normed_std": 0.08159258111715317, "critic_slow": 6.083309383392334, "critic_target": 6.082471103668213, "actor_ent": 0.6784737535476685, "actor_ent_scale": 0.0010000000474974513, "critic": 6.082033739471435, "fps": 111.28779561522178}
{"step": 5445460, "train_return": 14.0, "train_length": 2110.0, "train_total_steps": 1361365.0, "train_total_episodes": 654.0, "train_loaded_steps": 1361419.0, "train_loaded_episodes": 654.0}
{"step": 5454768, "train_return": 12.0, "train_length": 2327.0, "train_total_steps": 1363692.0, "train_total_episodes": 655.0, "train_loaded_steps": 1363746.0, "train_loaded_episodes": 655.0}
{"step": 5463948, "train_return": 13.0, "train_length": 2295.0, "train_total_steps": 1365987.0, "train_total_episodes": 656.0, "train_loaded_steps": 1366041.0, "train_loaded_episodes": 656.0}
{"step": 5473596, "train_return": 12.0, "train_length": 2412.0, "train_total_steps": 1368399.0, "train_total_episodes": 657.0, "train_loaded_steps": 1368453.0, "train_loaded_episodes": 657.0}
{"step": 5481356, "kl_loss": 1.4435256908416747, "image_loss": 3772.0, "reward_loss": 0.9194070692062378, "discount_loss": 0.007782367441058159, "model_kl": 1.4435256563186645, "prior_ent": 29.166925399780272, "post_ent": 27.726461392211913, "model_loss": 3773.102701953125, "model_loss_scale": 8192.0, "model_grad_norm": 6.502371318435669, "actor_loss": 0.014593444547044055, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06379475668668746, "critic_loss": 0.9389360049247741, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.46842700865268705, "reward_mean": -0.0019414704631111818, "reward_std": 0.08168921020627022, "reward_normed_mean": -0.0019414704631111818, "reward_normed_std": 0.08168921020627022, "critic_slow": 6.199708804321289, "critic_target": 6.2021065536499025, "actor_ent": 0.6840307664871216, "actor_ent_scale": 0.0010000000474974513, "critic": 6.201344202423096, "fps": 111.73312411983119}
{"step": 5481868, "train_return": 15.0, "train_length": 2068.0, "train_total_steps": 1370467.0, "train_total_episodes": 658.0, "train_loaded_steps": 1370521.0, "train_loaded_episodes": 658.0}
{"step": 5490868, "train_return": 12.0, "train_length": 2250.0, "train_total_steps": 1372717.0, "train_total_episodes": 659.0, "train_loaded_steps": 1372771.0, "train_loaded_episodes": 659.0}
{"step": 5498840, "train_return": 16.0, "train_length": 1993.0, "train_total_steps": 1374710.0, "train_total_episodes": 660.0, "train_loaded_steps": 1374764.0, "train_loaded_episodes": 660.0}
{"step": 5506700, "train_return": 16.0, "train_length": 1965.0, "train_total_steps": 1376675.0, "train_total_episodes": 661.0, "train_loaded_steps": 1376729.0, "train_loaded_episodes": 661.0}
{"step": 5516396, "train_return": 13.0, "train_length": 2424.0, "train_total_steps": 1379099.0, "train_total_episodes": 662.0, "train_loaded_steps": 1379153.0, "train_loaded_episodes": 662.0}
{"step": 5521356, "kl_loss": 1.437484623336792, "image_loss": 3772.0, "reward_loss": 0.9193723237991333, "discount_loss": 0.007767720055580139, "model_kl": 1.437484589958191, "prior_ent": 29.15293796386719, "post_ent": 27.72185256652832, "model_loss": 3773.101987109375, "model_loss_scale": 10944.512, "model_grad_norm": Infinity, "actor_loss": 0.0037325632338994184, "actor_loss_scale": 4496293.888, "actor_grad_norm": 0.05916686590909958, "critic_loss": 0.9350087430000306, "critic_loss_scale": 37119.5904, "critic_grad_norm": 0.40142034553289413, "reward_mean": -0.002096502353280084, "reward_std": 0.08174088813662529, "reward_normed_mean": -0.002096502353280084, "reward_normed_std": 0.08174088813662529, "critic_slow": 6.206548711395263, "critic_target": 6.20506962966919, "actor_ent": 0.7158105814933777, "actor_ent_scale": 0.0010000000474974513, "critic": 6.204544393157959, "fps": 110.3963502811369}
{"step": 5524628, "train_return": 15.0, "train_length": 2058.0, "train_total_steps": 1381157.0, "train_total_episodes": 663.0, "train_loaded_steps": 1381211.0, "train_loaded_episodes": 663.0}
{"step": 5533640, "train_return": 15.0, "train_length": 2253.0, "train_total_steps": 1383410.0, "train_total_episodes": 664.0, "train_loaded_steps": 1383464.0, "train_loaded_episodes": 664.0}
{"step": 5542516, "train_return": 14.0, "train_length": 2219.0, "train_total_steps": 1385629.0, "train_total_episodes": 665.0, "train_loaded_steps": 1385683.0, "train_loaded_episodes": 665.0}
{"step": 5551416, "train_return": 13.0, "train_length": 2225.0, "train_total_steps": 1387854.0, "train_total_episodes": 666.0, "train_loaded_steps": 1387908.0, "train_loaded_episodes": 666.0}
{"step": 5559080, "train_return": 18.0, "train_length": 1916.0, "train_total_steps": 1389770.0, "train_total_episodes": 667.0, "train_loaded_steps": 1389824.0, "train_loaded_episodes": 667.0}
{"step": 5561356, "kl_loss": 1.4352640090942383, "image_loss": 3772.0, "reward_loss": 0.9193798550605774, "discount_loss": 0.007743224843591452, "model_kl": 1.4352639749526979, "prior_ent": 29.07312936706543, "post_ent": 27.644810794067382, "model_loss": 3773.1016453125, "model_loss_scale": 8192.0, "model_grad_norm": 6.399261830902099, "actor_loss": 0.010932400735869305, "actor_loss_scale": 8093328.9984, "actor_grad_norm": Infinity, "critic_loss": 0.9348380062103272, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.36568586374521256, "reward_mean": -0.001976455824439472, "reward_std": 0.0807338919699192, "reward_normed_mean": -0.001976455824439472, "reward_normed_std": 0.0807338919699192, "critic_slow": 6.238239854431153, "critic_target": 6.238227537536621, "actor_ent": 0.7494859799385071, "actor_ent_scale": 0.0010000000474974513, "critic": 6.23783311843872, "fps": 111.23136405042658}
{"step": 5566708, "train_return": 17.0, "train_length": 1907.0, "train_total_steps": 1391677.0, "train_total_episodes": 668.0, "train_loaded_steps": 1391731.0, "train_loaded_episodes": 668.0}
{"step": 5573896, "train_return": 19.0, "train_length": 1797.0, "train_total_steps": 1393474.0, "train_total_episodes": 669.0, "train_loaded_steps": 1393528.0, "train_loaded_episodes": 669.0}
{"step": 5582232, "train_return": 15.0, "train_length": 2084.0, "train_total_steps": 1395558.0, "train_total_episodes": 670.0, "train_loaded_steps": 1395612.0, "train_loaded_episodes": 670.0}
{"step": 5590736, "train_return": 14.0, "train_length": 2126.0, "train_total_steps": 1397684.0, "train_total_episodes": 671.0, "train_loaded_steps": 1397738.0, "train_loaded_episodes": 671.0}
{"step": 5598648, "train_return": 16.0, "train_length": 1978.0, "train_total_steps": 1399662.0, "train_total_episodes": 672.0, "train_loaded_steps": 1399716.0, "train_loaded_episodes": 672.0}
{"step": 5601356, "kl_loss": 1.4366168416976928, "image_loss": 3772.0, "reward_loss": 0.9193518369674682, "discount_loss": 0.007741771524399519, "model_kl": 1.436616806602478, "prior_ent": 28.999231646728514, "post_ent": 27.575432791137697, "model_loss": 3773.1017453125, "model_loss_scale": 8192.0, "model_grad_norm": 6.578826128005981, "actor_loss": 0.013622461857146119, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.05815151673555374, "critic_loss": 0.9331920230865478, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.33997057482004167, "reward_mean": -0.0017603375659389713, "reward_std": 0.08131270876526833, "reward_normed_mean": -0.0017603375659389713, "reward_normed_std": 0.08131270876526833, "critic_slow": 6.313901806640625, "critic_target": 6.317653652191162, "actor_ent": 0.7647140369415283, "actor_ent_scale": 0.0010000000474974513, "critic": 6.316945754241943, "fps": 111.25271595171871}
{"step": 5606464, "train_return": 17.0, "train_length": 1954.0, "train_total_steps": 1401616.0, "train_total_episodes": 673.0, "train_loaded_steps": 1401670.0, "train_loaded_episodes": 673.0}
{"step": 5614944, "train_return": 15.0, "train_length": 2120.0, "train_total_steps": 1403736.0, "train_total_episodes": 674.0, "train_loaded_steps": 1403790.0, "train_loaded_episodes": 674.0}
{"step": 5622224, "train_return": 18.0, "train_length": 1820.0, "train_total_steps": 1405556.0, "train_total_episodes": 675.0, "train_loaded_steps": 1405610.0, "train_loaded_episodes": 675.0}
{"step": 5632872, "train_return": 7.0, "train_length": 2662.0, "train_total_steps": 1408218.0, "train_total_episodes": 676.0, "train_loaded_steps": 1408272.0, "train_loaded_episodes": 676.0}
{"step": 5641356, "kl_loss": 1.4388617721557617, "image_loss": 3772.0, "reward_loss": 0.9193595493316651, "discount_loss": 0.007742348791658879, "model_kl": 1.4388617399215697, "prior_ent": 28.96264716796875, "post_ent": 27.536391943359376, "model_loss": 3773.1019765625, "model_loss_scale": 8192.0, "model_grad_norm": 6.429944417953491, "actor_loss": 0.009815278841322288, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.059347205618023875, "critic_loss": 0.9351898901939392, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4061958040833473, "reward_mean": -0.002010823413450271, "reward_std": 0.08134812884926795, "reward_normed_mean": -0.002010823413450271, "reward_normed_std": 0.08134812884926795, "critic_slow": 6.372628556060791, "critic_target": 6.37101286239624, "actor_ent": 0.8032816373825074, "actor_ent_scale": 0.0010000000474974513, "critic": 6.370709097290039, "fps": 111.82378216117746}
{"step": 5642852, "train_return": 12.0, "train_length": 2495.0, "train_total_steps": 1410713.0, "train_total_episodes": 677.0, "train_loaded_steps": 1410767.0, "train_loaded_episodes": 677.0}
{"step": 5652096, "train_return": 11.0, "train_length": 2311.0, "train_total_steps": 1413024.0, "train_total_episodes": 678.0, "train_loaded_steps": 1413078.0, "train_loaded_episodes": 678.0}
{"step": 5660844, "train_return": 14.0, "train_length": 2187.0, "train_total_steps": 1415211.0, "train_total_episodes": 679.0, "train_loaded_steps": 1415265.0, "train_loaded_episodes": 679.0}
{"step": 5669444, "train_return": 16.0, "train_length": 2150.0, "train_total_steps": 1417361.0, "train_total_episodes": 680.0, "train_loaded_steps": 1417415.0, "train_loaded_episodes": 680.0}
{"step": 5679344, "train_return": 10.0, "train_length": 2475.0, "train_total_steps": 1419836.0, "train_total_episodes": 681.0, "train_loaded_steps": 1419890.0, "train_loaded_episodes": 681.0}
{"step": 5681356, "kl_loss": 1.4181011167526245, "image_loss": 3772.0002, "reward_loss": 0.9193386494636535, "discount_loss": 0.0077563855767250065, "model_kl": 1.418101083946228, "prior_ent": 28.961058364868165, "post_ent": 27.55201647644043, "model_loss": 3773.100148046875, "model_loss_scale": 16161.1776, "model_grad_norm": 6.915893604850769, "actor_loss": 0.014897604760737159, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06089961743354797, "critic_loss": 0.9377642520904541, "critic_loss_scale": 126667.9808, "critic_grad_norm": 0.40667314738035204, "reward_mean": -0.002064795680099496, "reward_std": 0.08223096273541451, "reward_normed_mean": -0.002064795680099496, "reward_normed_std": 0.08223096273541451, "critic_slow": 6.332721508789063, "critic_target": 6.335246440124512, "actor_ent": 0.7791079688072204, "actor_ent_scale": 0.0010000000474974513, "critic": 6.334645440673828, "fps": 110.63409419034708}
{"step": 5688032, "train_return": 15.0, "train_length": 2172.0, "train_total_steps": 1422008.0, "train_total_episodes": 682.0, "train_loaded_steps": 1422062.0, "train_loaded_episodes": 682.0}
{"step": 5695400, "train_return": 18.0, "train_length": 1842.0, "train_total_steps": 1423850.0, "train_total_episodes": 683.0, "train_loaded_steps": 1423904.0, "train_loaded_episodes": 683.0}
{"step": 5703476, "train_return": 16.0, "train_length": 2019.0, "train_total_steps": 1425869.0, "train_total_episodes": 684.0, "train_loaded_steps": 1425923.0, "train_loaded_episodes": 684.0}
{"step": 5711396, "train_return": 16.0, "train_length": 1980.0, "train_total_steps": 1427849.0, "train_total_episodes": 685.0, "train_loaded_steps": 1427903.0, "train_loaded_episodes": 685.0}
{"step": 5719352, "train_return": 16.0, "train_length": 1989.0, "train_total_steps": 1429838.0, "train_total_episodes": 686.0, "train_loaded_steps": 1429892.0, "train_loaded_episodes": 686.0}
{"step": 5721356, "kl_loss": 1.4860398803710937, "image_loss": 3772.0, "reward_loss": 0.9193715383529663, "discount_loss": 0.007807496072351932, "model_kl": 1.4860398454666137, "prior_ent": 28.99063401184082, "post_ent": 27.52623346862793, "model_loss": 3773.107041796875, "model_loss_scale": 11888.2304, "model_grad_norm": Infinity, "actor_loss": 0.0025257117511311663, "actor_loss_scale": 7845026.2016, "actor_grad_norm": 0.060222574156522754, "critic_loss": 0.9377754744529724, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.40577534815073013, "reward_mean": -0.0018188876471132971, "reward_std": 0.08104753884077072, "reward_normed_mean": -0.0018188876471132971, "reward_normed_std": 0.08104753884077072, "critic_slow": 6.327969404602051, "critic_target": 6.324871822357178, "actor_ent": 0.7931446692466736, "actor_ent_scale": 0.0010000000474974513, "critic": 6.324083348846435, "fps": 111.00930738894989}
{"step": 5726992, "train_return": 17.0, "train_length": 1910.0, "train_total_steps": 1431748.0, "train_total_episodes": 687.0, "train_loaded_steps": 1431802.0, "train_loaded_episodes": 687.0}
{"step": 5735152, "train_return": 15.0, "train_length": 2040.0, "train_total_steps": 1433788.0, "train_total_episodes": 688.0, "train_loaded_steps": 1433842.0, "train_loaded_episodes": 688.0}
{"step": 5744948, "train_return": 11.0, "train_length": 2449.0, "train_total_steps": 1436237.0, "train_total_episodes": 689.0, "train_loaded_steps": 1436291.0, "train_loaded_episodes": 689.0}
{"step": 5752240, "train_return": 19.0, "train_length": 1823.0, "train_total_steps": 1438060.0, "train_total_episodes": 690.0, "train_loaded_steps": 1438114.0, "train_loaded_episodes": 690.0}
{"step": 5760652, "train_return": 15.0, "train_length": 2103.0, "train_total_steps": 1440163.0, "train_total_episodes": 691.0, "train_loaded_steps": 1440217.0, "train_loaded_episodes": 691.0}
{"step": 5761356, "kl_loss": 1.4740209558486939, "image_loss": 3772.0, "reward_loss": 0.9193778985023499, "discount_loss": 0.007821661669015885, "model_kl": 1.4740209236145019, "prior_ent": 28.95940948791504, "post_ent": 27.50232691040039, "model_loss": 3773.105931640625, "model_loss_scale": 8192.0, "model_grad_norm": 6.187605359268188, "actor_loss": 0.011511090850968322, "actor_loss_scale": 4449317.6832, "actor_grad_norm": Infinity, "critic_loss": 0.937257621383667, "critic_loss_scale": 120900.8128, "critic_grad_norm": Infinity, "reward_mean": -0.00145436707551562, "reward_std": 0.0807653496146202, "reward_normed_mean": -0.00145436707551562, "reward_normed_std": 0.0807653496146202, "critic_slow": 6.432836053466797, "critic_target": 6.435643650817871, "actor_ent": 0.7671404898643494, "actor_ent_scale": 0.0010000000474974513, "critic": 6.435293482971192, "fps": 110.60155882072809}
{"step": 5767808, "train_return": 19.0, "train_length": 1789.0, "train_total_steps": 1441952.0, "train_total_episodes": 692.0, "train_loaded_steps": 1442006.0, "train_loaded_episodes": 692.0}
{"step": 5774940, "train_return": 19.0, "train_length": 1783.0, "train_total_steps": 1443735.0, "train_total_episodes": 693.0, "train_loaded_steps": 1443789.0, "train_loaded_episodes": 693.0}
{"step": 5783220, "train_return": 16.0, "train_length": 2070.0, "train_total_steps": 1445805.0, "train_total_episodes": 694.0, "train_loaded_steps": 1445859.0, "train_loaded_episodes": 694.0}
{"step": 5791196, "train_return": 17.0, "train_length": 1994.0, "train_total_steps": 1447799.0, "train_total_episodes": 695.0, "train_loaded_steps": 1447853.0, "train_loaded_episodes": 695.0}
{"step": 5799456, "train_return": 13.0, "train_length": 2065.0, "train_total_steps": 1449864.0, "train_total_episodes": 696.0, "train_loaded_steps": 1449918.0, "train_loaded_episodes": 696.0}
{"step": 5801356, "kl_loss": 1.4229418560028075, "image_loss": 3772.0, "reward_loss": 0.9193285401344299, "discount_loss": 0.00774200165271759, "model_kl": 1.4229418237686158, "prior_ent": 28.921195751953125, "post_ent": 27.506227005004884, "model_loss": 3773.100360546875, "model_loss_scale": 8192.0, "model_grad_norm": 6.595772358703614, "actor_loss": 0.018434500493481755, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.05930147714018822, "critic_loss": 0.9369212073326111, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.41642165545225146, "reward_mean": -0.0015065783405370894, "reward_std": 0.08122163043022156, "reward_normed_mean": -0.0015065783405370894, "reward_normed_std": 0.08122163043022156, "critic_slow": 6.548245824432373, "critic_target": 6.553204476165772, "actor_ent": 0.8041293375015259, "actor_ent_scale": 0.0010000000474974513, "critic": 6.55267961730957, "fps": 111.84499730117837}
{"step": 5807232, "train_return": 18.0, "train_length": 1944.0, "train_total_steps": 1451808.0, "train_total_episodes": 697.0, "train_loaded_steps": 1451862.0, "train_loaded_episodes": 697.0}
{"step": 5815704, "train_return": 13.0, "train_length": 2118.0, "train_total_steps": 1453926.0, "train_total_episodes": 698.0, "train_loaded_steps": 1453980.0, "train_loaded_episodes": 698.0}
{"step": 5823696, "train_return": 16.0, "train_length": 1998.0, "train_total_steps": 1455924.0, "train_total_episodes": 699.0, "train_loaded_steps": 1455978.0, "train_loaded_episodes": 699.0}
{"step": 5831292, "train_return": 18.0, "train_length": 1899.0, "train_total_steps": 1457823.0, "train_total_episodes": 700.0, "train_loaded_steps": 1457877.0, "train_loaded_episodes": 700.0}
{"step": 5839220, "train_return": 15.0, "train_length": 1982.0, "train_total_steps": 1459805.0, "train_total_episodes": 701.0, "train_loaded_steps": 1459859.0, "train_loaded_episodes": 701.0}
{"step": 5841356, "kl_loss": 1.4817562154769897, "image_loss": 3772.0, "reward_loss": 0.919367343044281, "discount_loss": 0.00774710166528821, "model_kl": 1.4817561841964721, "prior_ent": 28.927856460571288, "post_ent": 27.46616584777832, "model_loss": 3773.106292578125, "model_loss_scale": 11049.3696, "model_grad_norm": 6.555607304382324, "actor_loss": 0.007318706444942654, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.060768346393108366, "critic_loss": 0.938444978427887, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4338811373114586, "reward_mean": -0.0016042553791390673, "reward_std": 0.08232207248806954, "reward_normed_mean": -0.0016042553791390673, "reward_normed_std": 0.08232207248806954, "critic_slow": 6.5749297645568845, "critic_target": 6.579033336639404, "actor_ent": 0.7827613856315613, "actor_ent_scale": 0.0010000000474974513, "critic": 6.578460218811035, "fps": 110.76196019061742}
{"step": 5848240, "train_return": 12.0, "train_length": 2255.0, "train_total_steps": 1462060.0, "train_total_episodes": 702.0, "train_loaded_steps": 1462114.0, "train_loaded_episodes": 702.0}
{"step": 5856280, "train_return": 17.0, "train_length": 2010.0, "train_total_steps": 1464070.0, "train_total_episodes": 703.0, "train_loaded_steps": 1464124.0, "train_loaded_episodes": 703.0}
{"step": 5864428, "train_return": 17.0, "train_length": 2037.0, "train_total_steps": 1466107.0, "train_total_episodes": 704.0, "train_loaded_steps": 1466161.0, "train_loaded_episodes": 704.0}
{"step": 5872168, "train_return": 17.0, "train_length": 1935.0, "train_total_steps": 1468042.0, "train_total_episodes": 705.0, "train_loaded_steps": 1468096.0, "train_loaded_episodes": 705.0}
{"step": 5880376, "train_return": 15.0, "train_length": 2052.0, "train_total_steps": 1470094.0, "train_total_episodes": 706.0, "train_loaded_steps": 1470148.0, "train_loaded_episodes": 706.0}
{"step": 5881356, "kl_loss": 1.435190774154663, "image_loss": 3772.0, "reward_loss": 0.9193525766372681, "discount_loss": 0.007762869105488062, "model_kl": 1.4351907367706298, "prior_ent": 28.927849475097656, "post_ent": 27.5035772064209, "model_loss": 3773.10170625, "model_loss_scale": 14588.3136, "model_grad_norm": Infinity, "actor_loss": 0.022893052882596385, "actor_loss_scale": 7294733.5168, "actor_grad_norm": 0.060399439278244975, "critic_loss": 0.938187184047699, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.44099034185409547, "reward_mean": -0.0013769480814400596, "reward_std": 0.08141784510612488, "reward_normed_mean": -0.0013769480814400596, "reward_normed_std": 0.08141784510612488, "critic_slow": 6.612073611450195, "critic_target": 6.616180403137207, "actor_ent": 0.8074865387916565, "actor_ent_scale": 0.0010000000474974513, "critic": 6.6158548240661625, "fps": 111.13697266737704}
{"step": 5888820, "train_return": 13.0, "train_length": 2111.0, "train_total_steps": 1472205.0, "train_total_episodes": 707.0, "train_loaded_steps": 1472259.0, "train_loaded_episodes": 707.0}
{"step": 5896196, "train_return": 18.0, "train_length": 1844.0, "train_total_steps": 1474049.0, "train_total_episodes": 708.0, "train_loaded_steps": 1474103.0, "train_loaded_episodes": 708.0}
{"step": 5903872, "train_return": 16.0, "train_length": 1919.0, "train_total_steps": 1475968.0, "train_total_episodes": 709.0, "train_loaded_steps": 1476022.0, "train_loaded_episodes": 709.0}
{"step": 5910948, "train_return": 19.0, "train_length": 1769.0, "train_total_steps": 1477737.0, "train_total_episodes": 710.0, "train_loaded_steps": 1477791.0, "train_loaded_episodes": 710.0}
{"step": 5918820, "train_return": 15.0, "train_length": 1968.0, "train_total_steps": 1479705.0, "train_total_episodes": 711.0, "train_loaded_steps": 1479759.0, "train_loaded_episodes": 711.0}
{"step": 5921356, "kl_loss": 1.4268073120117188, "image_loss": 3772.0002, "reward_loss": 0.9193415070533753, "discount_loss": 0.007803022382408381, "model_kl": 1.42680728225708, "prior_ent": 28.880962701416017, "post_ent": 27.462039538574217, "model_loss": 3773.10126015625, "model_loss_scale": 8192.0, "model_grad_norm": 6.408629534721374, "actor_loss": 0.005574999341618968, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.057905558705329895, "critic_loss": 0.9368389386177063, "critic_loss_scale": 115762.7904, "critic_grad_norm": Infinity, "reward_mean": -0.001274610632348049, "reward_std": 0.08191077371835709, "reward_normed_mean": -0.001274610632348049, "reward_normed_std": 0.08191077371835709, "critic_slow": 6.594319653320312, "critic_target": 6.5929574867248535, "actor_ent": 0.8055156098365783, "actor_ent_scale": 0.0010000000474974513, "critic": 6.592598979949951, "fps": 109.22385386799245}
{"step": 5927012, "train_return": 15.0, "train_length": 2048.0, "train_total_steps": 1481753.0, "train_total_episodes": 712.0, "train_loaded_steps": 1481807.0, "train_loaded_episodes": 712.0}
{"step": 5935760, "train_return": 14.0, "train_length": 2187.0, "train_total_steps": 1483940.0, "train_total_episodes": 713.0, "train_loaded_steps": 1483994.0, "train_loaded_episodes": 713.0}
{"step": 5943348, "train_return": 17.0, "train_length": 1897.0, "train_total_steps": 1485837.0, "train_total_episodes": 714.0, "train_loaded_steps": 1485891.0, "train_loaded_episodes": 714.0}
{"step": 5951340, "train_return": 15.0, "train_length": 1998.0, "train_total_steps": 1487835.0, "train_total_episodes": 715.0, "train_loaded_steps": 1487889.0, "train_loaded_episodes": 715.0}
{"step": 5959452, "train_return": 16.0, "train_length": 2028.0, "train_total_steps": 1489863.0, "train_total_episodes": 716.0, "train_loaded_steps": 1489917.0, "train_loaded_episodes": 716.0}
{"step": 5961356, "kl_loss": 1.4613015935897826, "image_loss": 3772.0002, "reward_loss": 0.9193278779029846, "discount_loss": 0.007762864602357149, "model_kl": 1.461301556968689, "prior_ent": 28.919608908081056, "post_ent": 27.476058959960938, "model_loss": 3773.104494921875, "model_loss_scale": 8192.0, "model_grad_norm": 6.46695485458374, "actor_loss": 0.016100349425146123, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.058261574530601504, "critic_loss": 0.9364507682800293, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4337129267930985, "reward_mean": -0.0016021261343885272, "reward_std": 0.08177797171473503, "reward_normed_mean": -0.0016021261343885272, "reward_normed_std": 0.08177797171473503, "critic_slow": 6.641719664001465, "critic_target": 6.640245481109619, "actor_ent": 0.7986432195663452, "actor_ent_scale": 0.0010000000474974513, "critic": 6.639809604644776, "fps": 111.95904105858148}
{"step": 5967360, "train_return": 16.0, "train_length": 1977.0, "train_total_steps": 1491840.0, "train_total_episodes": 717.0, "train_loaded_steps": 1491894.0, "train_loaded_episodes": 717.0}
{"step": 5975168, "train_return": 16.0, "train_length": 1952.0, "train_total_steps": 1493792.0, "train_total_episodes": 718.0, "train_loaded_steps": 1493846.0, "train_loaded_episodes": 718.0}
{"step": 5982852, "train_return": 17.0, "train_length": 1921.0, "train_total_steps": 1495713.0, "train_total_episodes": 719.0, "train_loaded_steps": 1495767.0, "train_loaded_episodes": 719.0}
{"step": 5990212, "train_return": 18.0, "train_length": 1840.0, "train_total_steps": 1497553.0, "train_total_episodes": 720.0, "train_loaded_steps": 1497607.0, "train_loaded_episodes": 720.0}
{"step": 5997688, "train_return": 17.0, "train_length": 1869.0, "train_total_steps": 1499422.0, "train_total_episodes": 721.0, "train_loaded_steps": 1499476.0, "train_loaded_episodes": 721.0}
{"step": 6001356, "kl_loss": 1.4409466875076293, "image_loss": 3772.0, "reward_loss": 0.9193269682884216, "discount_loss": 0.007748333093523979, "model_kl": 1.4409466548919678, "prior_ent": 28.851482247924803, "post_ent": 27.42159268798828, "model_loss": 3773.102176171875, "model_loss_scale": 8349.2864, "model_grad_norm": 6.721269392776489, "actor_loss": 0.0022578073621421935, "actor_loss_scale": 8428873.3184, "actor_grad_norm": Infinity, "critic_loss": 0.9401001990318298, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4830117493867874, "reward_mean": -0.0011571820966579252, "reward_std": 0.08196182563900947, "reward_normed_mean": -0.0011571820966579252, "reward_normed_std": 0.08196182563900947, "critic_slow": 6.678433261871338, "critic_target": 6.6741116317749025, "actor_ent": 0.8203491515159607, "actor_ent_scale": 0.0010000000474974513, "critic": 6.673402127075195, "fps": 111.2810022836283}
{"step": 6005312, "train_return": 17.0, "train_length": 1906.0, "train_total_steps": 1501328.0, "train_total_episodes": 722.0, "train_loaded_steps": 1501382.0, "train_loaded_episodes": 722.0}
{"step": 6014484, "train_return": 12.0, "train_length": 2293.0, "train_total_steps": 1503621.0, "train_total_episodes": 723.0, "train_loaded_steps": 1503675.0, "train_loaded_episodes": 723.0}
{"step": 6022736, "train_return": 16.0, "train_length": 2063.0, "train_total_steps": 1505684.0, "train_total_episodes": 724.0, "train_loaded_steps": 1505738.0, "train_loaded_episodes": 724.0}
{"step": 6030836, "train_return": 16.0, "train_length": 2025.0, "train_total_steps": 1507709.0, "train_total_episodes": 725.0, "train_loaded_steps": 1507763.0, "train_loaded_episodes": 725.0}
{"step": 6039564, "train_return": 14.0, "train_length": 2182.0, "train_total_steps": 1509891.0, "train_total_episodes": 726.0, "train_loaded_steps": 1509945.0, "train_loaded_episodes": 726.0}
{"step": 6041356, "kl_loss": 1.5177352346420288, "image_loss": 3772.0, "reward_loss": 0.9193695538520813, "discount_loss": 0.00779620394706726, "model_kl": 1.5177352003097535, "prior_ent": 28.818880044555662, "post_ent": 27.32628432006836, "model_loss": 3773.11014453125, "model_loss_scale": 15545.1392, "model_grad_norm": Infinity, "actor_loss": 0.01789553225763375, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06276594254970551, "critic_loss": 0.9411040989875793, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4566593097925186, "reward_mean": -0.0010693101913951978, "reward_std": 0.08064292020201683, "reward_normed_mean": -0.0010693101913951978, "reward_normed_std": 0.08064292020201683, "critic_slow": 6.779421104431153, "critic_target": 6.780223288726806, "actor_ent": 0.802950350856781, "actor_ent_scale": 0.0010000000474974513, "critic": 6.77993293762207, "fps": 109.91315986186996}
{"step": 6048628, "train_return": 11.0, "train_length": 2266.0, "train_total_steps": 1512157.0, "train_total_episodes": 727.0, "train_loaded_steps": 1512211.0, "train_loaded_episodes": 727.0}
{"step": 6055904, "train_return": 18.0, "train_length": 1819.0, "train_total_steps": 1513976.0, "train_total_episodes": 728.0, "train_loaded_steps": 1514030.0, "train_loaded_episodes": 728.0}
{"step": 6064100, "train_return": 15.0, "train_length": 2049.0, "train_total_steps": 1516025.0, "train_total_episodes": 729.0, "train_loaded_steps": 1516079.0, "train_loaded_episodes": 729.0}
{"step": 6071564, "train_return": 18.0, "train_length": 1866.0, "train_total_steps": 1517891.0, "train_total_episodes": 730.0, "train_loaded_steps": 1517945.0, "train_loaded_episodes": 730.0}
{"step": 6079236, "train_return": 18.0, "train_length": 1918.0, "train_total_steps": 1519809.0, "train_total_episodes": 731.0, "train_loaded_steps": 1519863.0, "train_loaded_episodes": 731.0}
{"step": 6081356, "kl_loss": 1.420444277191162, "image_loss": 3772.0, "reward_loss": 0.9193501442909241, "discount_loss": 0.007852790802717209, "model_kl": 1.4204442405700684, "prior_ent": 28.87474069519043, "post_ent": 27.460825479125976, "model_loss": 3773.10068828125, "model_loss_scale": 8192.0, "model_grad_norm": 6.573232712936401, "actor_loss": 0.006545647099524468, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.05981384871304035, "critic_loss": 0.9367138061523438, "critic_loss_scale": 130337.9968, "critic_grad_norm": 0.4289824771761894, "reward_mean": -0.0015565155142478943, "reward_std": 0.0813542744398117, "reward_normed_mean": -0.0015565155142478943, "reward_normed_std": 0.0813542744398117, "critic_slow": 6.798660980224609, "critic_target": 6.7963892883300785, "actor_ent": 0.7895611861228943, "actor_ent_scale": 0.0010000000474974513, "critic": 6.795720032501221, "fps": 109.1729745306634}
{"step": 6087124, "train_return": 16.0, "train_length": 1972.0, "train_total_steps": 1521781.0, "train_total_episodes": 732.0, "train_loaded_steps": 1521835.0, "train_loaded_episodes": 732.0}
{"step": 6094880, "train_return": 17.0, "train_length": 1939.0, "train_total_steps": 1523720.0, "train_total_episodes": 733.0, "train_loaded_steps": 1523774.0, "train_loaded_episodes": 733.0}
{"step": 6102612, "train_return": 18.0, "train_length": 1933.0, "train_total_steps": 1525653.0, "train_total_episodes": 734.0, "train_loaded_steps": 1525707.0, "train_loaded_episodes": 734.0}
{"step": 6110988, "train_return": 14.0, "train_length": 2094.0, "train_total_steps": 1527747.0, "train_total_episodes": 735.0, "train_loaded_steps": 1527801.0, "train_loaded_episodes": 735.0}
{"step": 6118536, "train_return": 17.0, "train_length": 1887.0, "train_total_steps": 1529634.0, "train_total_episodes": 736.0, "train_loaded_steps": 1529688.0, "train_loaded_episodes": 736.0}
{"step": 6121356, "kl_loss": 1.4722142475128175, "image_loss": 3772.0, "reward_loss": 0.9193380338668823, "discount_loss": 0.007767267520725727, "model_kl": 1.4722142166137695, "prior_ent": 28.860679266357423, "post_ent": 27.411601525878908, "model_loss": 3773.105421484375, "model_loss_scale": 8192.0, "model_grad_norm": 6.56099995803833, "actor_loss": 0.01142427338425623, "actor_loss_scale": 9354975.6416, "actor_grad_norm": Infinity, "critic_loss": 0.9372253739356995, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4239222926735878, "reward_mean": -0.0010568317739845952, "reward_std": 0.08143109495639801, "reward_normed_mean": -0.0010568317739845952, "reward_normed_std": 0.08143109495639801, "critic_slow": 6.893919099426269, "critic_target": 6.894840671539306, "actor_ent": 0.783746074295044, "actor_ent_scale": 0.0010000000474974513, "critic": 6.894277306365967, "fps": 111.7209526560913}
{"step": 6127396, "train_return": 12.0, "train_length": 2215.0, "train_total_steps": 1531849.0, "train_total_episodes": 737.0, "train_loaded_steps": 1531903.0, "train_loaded_episodes": 737.0}
{"step": 6134456, "train_return": 20.0, "train_length": 1765.0, "train_total_steps": 1533614.0, "train_total_episodes": 738.0, "train_loaded_steps": 1533668.0, "train_loaded_episodes": 738.0}
{"step": 6142824, "train_return": 13.0, "train_length": 2092.0, "train_total_steps": 1535706.0, "train_total_episodes": 739.0, "train_loaded_steps": 1535760.0, "train_loaded_episodes": 739.0}
{"step": 6150992, "train_return": 16.0, "train_length": 2042.0, "train_total_steps": 1537748.0, "train_total_episodes": 740.0, "train_loaded_steps": 1537802.0, "train_loaded_episodes": 740.0}
{"step": 6158232, "train_return": 18.0, "train_length": 1810.0, "train_total_steps": 1539558.0, "train_total_episodes": 741.0, "train_loaded_steps": 1539612.0, "train_loaded_episodes": 741.0}
{"step": 6161356, "kl_loss": 1.422379617881775, "image_loss": 3772.0002, "reward_loss": 0.9192954901695252, "discount_loss": 0.007764824679493904, "model_kl": 1.4223795890808106, "prior_ent": 28.865176766967775, "post_ent": 27.450277935791014, "model_loss": 3773.10058125, "model_loss_scale": 8192.0, "model_grad_norm": 6.39637176399231, "actor_loss": 0.006228492128835933, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.058970020812749865, "critic_loss": 0.9352613928794861, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.39793094630241393, "reward_mean": -0.0008602607836819515, "reward_std": 0.08154449644684791, "reward_normed_mean": -0.0008602607836819515, "reward_normed_std": 0.08154449644684791, "critic_slow": 6.950557734680176, "critic_target": 6.943622895812989, "actor_ent": 0.789806964969635, "actor_ent_scale": 0.0010000000474974513, "critic": 6.943234311676026, "fps": 111.02901042356605}
{"step": 6168020, "train_return": 11.0, "train_length": 2447.0, "train_total_steps": 1542005.0, "train_total_episodes": 742.0, "train_loaded_steps": 1542059.0, "train_loaded_episodes": 742.0}
{"step": 6175188, "train_return": 19.0, "train_length": 1792.0, "train_total_steps": 1543797.0, "train_total_episodes": 743.0, "train_loaded_steps": 1543851.0, "train_loaded_episodes": 743.0}
{"step": 6183600, "train_return": 15.0, "train_length": 2103.0, "train_total_steps": 1545900.0, "train_total_episodes": 744.0, "train_loaded_steps": 1545954.0, "train_loaded_episodes": 744.0}
{"step": 6191424, "train_return": 17.0, "train_length": 1956.0, "train_total_steps": 1547856.0, "train_total_episodes": 745.0, "train_loaded_steps": 1547910.0, "train_loaded_episodes": 745.0}
{"step": 6198980, "train_return": 17.0, "train_length": 1889.0, "train_total_steps": 1549745.0, "train_total_episodes": 746.0, "train_loaded_steps": 1549799.0, "train_loaded_episodes": 746.0}
{"step": 6201352, "eval_return": 18.0, "eval_length": 1898.0, "eval_total_steps": 15583.0, "eval_total_episodes": 8.0, "eval_loaded_steps": 15585.0, "eval_loaded_episodes": 8.0}
{"step": 6201356, "kl_loss": 1.4147499773025514, "image_loss": 3772.0, "reward_loss": 0.9193416167259216, "discount_loss": 0.007741322918236255, "model_kl": 1.4147499460220336, "prior_ent": 28.827053036499024, "post_ent": 27.419614715576174, "model_loss": 3773.0995484375, "model_loss_scale": 15584.4608, "model_grad_norm": 6.847251250076294, "actor_loss": 0.008704855871605105, "actor_loss_scale": 6509559.808, "actor_grad_norm": Infinity, "critic_loss": 0.9375815690040589, "critic_loss_scale": 170288.7424, "critic_grad_norm": Infinity, "reward_mean": -0.000886932967906614, "reward_std": 0.08153945914506912, "reward_normed_mean": -0.000886932967906614, "reward_normed_std": 0.08153945914506912, "critic_slow": 6.92668797454834, "critic_target": 6.92460513381958, "actor_ent": 0.7751893057823181, "actor_ent_scale": 0.0010000000474974513, "critic": 6.92420341873169, "fps": 106.60662595081384}
{"step": 6207560, "train_return": 15.0, "train_length": 2145.0, "train_total_steps": 1551890.0, "train_total_episodes": 747.0, "train_loaded_steps": 1551944.0, "train_loaded_episodes": 747.0}
{"step": 6215036, "train_return": 18.0, "train_length": 1869.0, "train_total_steps": 1553759.0, "train_total_episodes": 748.0, "train_loaded_steps": 1553813.0, "train_loaded_episodes": 748.0}
{"step": 6223192, "train_return": 15.0, "train_length": 2039.0, "train_total_steps": 1555798.0, "train_total_episodes": 749.0, "train_loaded_steps": 1555852.0, "train_loaded_episodes": 749.0}
{"step": 6230140, "train_return": 20.0, "train_length": 1737.0, "train_total_steps": 1557535.0, "train_total_episodes": 750.0, "train_loaded_steps": 1557589.0, "train_loaded_episodes": 750.0}
{"step": 6238224, "train_return": 15.0, "train_length": 2021.0, "train_total_steps": 1559556.0, "train_total_episodes": 751.0, "train_loaded_steps": 1559610.0, "train_loaded_episodes": 751.0}
{"step": 6241356, "kl_loss": 1.4139758529663087, "image_loss": 3772.0, "reward_loss": 0.9192866527557373, "discount_loss": 0.007747520909458399, "model_kl": 1.4139758195877075, "prior_ent": 28.82841883544922, "post_ent": 27.426166400146485, "model_loss": 3773.09944921875, "model_loss_scale": 16384.0, "model_grad_norm": 6.45294168586731, "actor_loss": 0.005665543843014166, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.05844704983532429, "critic_loss": 0.9357347846984864, "critic_loss_scale": 121949.3888, "critic_grad_norm": Infinity, "reward_mean": -0.0008550936034705956, "reward_std": 0.0815040124118328, "reward_normed_mean": -0.0008550936034705956, "reward_normed_std": 0.0815040124118328, "critic_slow": 6.865879106140136, "critic_target": 6.861557457733154, "actor_ent": 0.8099647268295288, "actor_ent_scale": 0.0010000000474974513, "critic": 6.860835489654541, "fps": 109.998785380424}
{"step": 6247456, "train_return": 13.0, "train_length": 2308.0, "train_total_steps": 1561864.0, "train_total_episodes": 752.0, "train_loaded_steps": 1561918.0, "train_loaded_episodes": 752.0}
{"step": 6255480, "train_return": 17.0, "train_length": 2006.0, "train_total_steps": 1563870.0, "train_total_episodes": 753.0, "train_loaded_steps": 1563924.0, "train_loaded_episodes": 753.0}
{"step": 6263024, "train_return": 17.0, "train_length": 1886.0, "train_total_steps": 1565756.0, "train_total_episodes": 754.0, "train_loaded_steps": 1565810.0, "train_loaded_episodes": 754.0}
{"step": 6271060, "train_return": 15.0, "train_length": 2009.0, "train_total_steps": 1567765.0, "train_total_episodes": 755.0, "train_loaded_steps": 1567819.0, "train_loaded_episodes": 755.0}
{"step": 6278548, "train_return": 17.0, "train_length": 1872.0, "train_total_steps": 1569637.0, "train_total_episodes": 756.0, "train_loaded_steps": 1569691.0, "train_loaded_episodes": 756.0}
{"step": 6281356, "kl_loss": 1.4094119268417358, "image_loss": 3772.000387890625, "reward_loss": 0.9192973657608032, "discount_loss": 0.007755977368354797, "model_kl": 1.4094118923187255, "prior_ent": 28.867522091674804, "post_ent": 27.46878178100586, "model_loss": 3773.099429296875, "model_loss_scale": 14798.0288, "model_grad_norm": Infinity, "actor_loss": 0.010984782059886494, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06061363716125488, "critic_loss": 0.9368452403068542, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4590309982419014, "reward_mean": -0.0009660925332107581, "reward_std": 0.08185546028614044, "reward_normed_mean": -0.0009660925332107581, "reward_normed_std": 0.08185546028614044, "critic_slow": 6.846311522674561, "critic_target": 6.845093819427491, "actor_ent": 0.831973573589325, "actor_ent_scale": 0.0010000000474974513, "critic": 6.844649179840088, "fps": 111.91083246444133}
{"step": 6286252, "train_return": 18.0, "train_length": 1926.0, "train_total_steps": 1571563.0, "train_total_episodes": 757.0, "train_loaded_steps": 1571617.0, "train_loaded_episodes": 757.0}
{"step": 6294096, "train_return": 17.0, "train_length": 1961.0, "train_total_steps": 1573524.0, "train_total_episodes": 758.0, "train_loaded_steps": 1573578.0, "train_loaded_episodes": 758.0}
{"step": 6301632, "train_return": 18.0, "train_length": 1884.0, "train_total_steps": 1575408.0, "train_total_episodes": 759.0, "train_loaded_steps": 1575462.0, "train_loaded_episodes": 759.0}
{"step": 6308916, "train_return": 18.0, "train_length": 1821.0, "train_total_steps": 1577229.0, "train_total_episodes": 760.0, "train_loaded_steps": 1577283.0, "train_loaded_episodes": 760.0}
{"step": 6317520, "train_return": 15.0, "train_length": 2151.0, "train_total_steps": 1579380.0, "train_total_episodes": 761.0, "train_loaded_steps": 1579434.0, "train_loaded_episodes": 761.0}
{"step": 6321356, "kl_loss": 1.4342046941757203, "image_loss": 3772.0, "reward_loss": 0.9193219221115112, "discount_loss": 0.007764292296767235, "model_kl": 1.4342046600341798, "prior_ent": 28.866192102050782, "post_ent": 27.443979986572266, "model_loss": 3773.101586328125, "model_loss_scale": 8192.0, "model_grad_norm": 6.048931184768676, "actor_loss": 0.006743391577666625, "actor_loss_scale": 5234491.392, "actor_grad_norm": 0.0606674536049366, "critic_loss": 0.9369464291572571, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4385416058778763, "reward_mean": -0.0009378585429818486, "reward_std": 0.08162515719532967, "reward_normed_mean": -0.0009378585429818486, "reward_normed_std": 0.08162515719532967, "critic_slow": 6.859307969665528, "critic_target": 6.855895024871826, "actor_ent": 0.8196145047187805, "actor_ent_scale": 0.0010000000474974513, "critic": 6.855382171630859, "fps": 109.3042259851029}
{"step": 6326648, "train_return": 12.0, "train_length": 2282.0, "train_total_steps": 1581662.0, "train_total_episodes": 762.0, "train_loaded_steps": 1581716.0, "train_loaded_episodes": 762.0}
{"step": 6334328, "train_return": 18.0, "train_length": 1920.0, "train_total_steps": 1583582.0, "train_total_episodes": 763.0, "train_loaded_steps": 1583636.0, "train_loaded_episodes": 763.0}
{"step": 6342832, "train_return": 14.0, "train_length": 2126.0, "train_total_steps": 1585708.0, "train_total_episodes": 764.0, "train_loaded_steps": 1585762.0, "train_loaded_episodes": 764.0}
{"step": 6350824, "train_return": 16.0, "train_length": 1998.0, "train_total_steps": 1587706.0, "train_total_episodes": 765.0, "train_loaded_steps": 1587760.0, "train_loaded_episodes": 765.0}
{"step": 6359284, "train_return": 13.0, "train_length": 2115.0, "train_total_steps": 1589821.0, "train_total_episodes": 766.0, "train_loaded_steps": 1589875.0, "train_loaded_episodes": 766.0}
{"step": 6361356, "kl_loss": 1.4191922328948974, "image_loss": 3772.0, "reward_loss": 0.9193150570869446, "discount_loss": 0.0077445434153079985, "model_kl": 1.4191922010421754, "prior_ent": 28.80579971923828, "post_ent": 27.398154910278322, "model_loss": 3773.0999828125, "model_loss_scale": 8192.0, "model_grad_norm": 6.428842959594727, "actor_loss": 0.013308101166191045, "actor_loss_scale": 6294811.4432, "actor_grad_norm": Infinity, "critic_loss": 0.9372849297523499, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.42496601482629776, "reward_mean": -0.0007695221843569015, "reward_std": 0.08182513883709908, "reward_normed_mean": -0.0007695221843569015, "reward_normed_std": 0.08182513883709908, "critic_slow": 6.854307080078125, "critic_target": 6.852595909118652, "actor_ent": 0.8392422695159912, "actor_ent_scale": 0.0010000000474974513, "critic": 6.852104578399659, "fps": 110.84472103873902}
{"step": 6368132, "train_return": 12.0, "train_length": 2212.0, "train_total_steps": 1592033.0, "train_total_episodes": 767.0, "train_loaded_steps": 1592087.0, "train_loaded_episodes": 767.0}
{"step": 6376360, "train_return": 16.0, "train_length": 2057.0, "train_total_steps": 1594090.0, "train_total_episodes": 768.0, "train_loaded_steps": 1594144.0, "train_loaded_episodes": 768.0}
{"step": 6384116, "train_return": 16.0, "train_length": 1939.0, "train_total_steps": 1596029.0, "train_total_episodes": 769.0, "train_loaded_steps": 1596083.0, "train_loaded_episodes": 769.0}
{"step": 6391508, "train_return": 17.0, "train_length": 1848.0, "train_total_steps": 1597877.0, "train_total_episodes": 770.0, "train_loaded_steps": 1597931.0, "train_loaded_episodes": 770.0}
{"step": 6400920, "train_return": 12.0, "train_length": 2353.0, "train_total_steps": 1600230.0, "train_total_episodes": 771.0, "train_loaded_steps": 1600284.0, "train_loaded_episodes": 771.0}
{"step": 6401356, "kl_loss": 1.4835336874008178, "image_loss": 3772.0, "reward_loss": 0.9193159507751465, "discount_loss": 0.007742239166796208, "model_kl": 1.4835336511611938, "prior_ent": 28.792657962036134, "post_ent": 27.33146259765625, "model_loss": 3773.10639375, "model_loss_scale": 8192.0, "model_grad_norm": 6.722457595062256, "actor_loss": 0.010548223405989484, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06224398063421249, "critic_loss": 0.9380485456466675, "critic_loss_scale": 127087.4112, "critic_grad_norm": 0.4399644466996193, "reward_mean": -0.00045431760166538877, "reward_std": 0.08043206483125687, "reward_normed_mean": -0.00045431760166538877, "reward_normed_std": 0.08043206483125687, "critic_slow": 6.89508673248291, "critic_target": 6.892675749969483, "actor_ent": 0.8161030135154724, "actor_ent_scale": 0.0010000000474974513, "critic": 6.892124383544922, "fps": 111.2103860548683}
{"step": 6408700, "train_return": 18.0, "train_length": 1945.0, "train_total_steps": 1602175.0, "train_total_episodes": 772.0, "train_loaded_steps": 1602229.0, "train_loaded_episodes": 772.0}
{"step": 6416516, "train_return": 16.0, "train_length": 1954.0, "train_total_steps": 1604129.0, "train_total_episodes": 773.0, "train_loaded_steps": 1604183.0, "train_loaded_episodes": 773.0}
{"step": 6424756, "train_return": 16.0, "train_length": 2060.0, "train_total_steps": 1606189.0, "train_total_episodes": 774.0, "train_loaded_steps": 1606243.0, "train_loaded_episodes": 774.0}
{"step": 6431928, "train_return": 19.0, "train_length": 1793.0, "train_total_steps": 1607982.0, "train_total_episodes": 775.0, "train_loaded_steps": 1608036.0, "train_loaded_episodes": 775.0}
{"step": 6439768, "train_return": 18.0, "train_length": 1960.0, "train_total_steps": 1609942.0, "train_total_episodes": 776.0, "train_loaded_steps": 1609996.0, "train_loaded_episodes": 776.0}
{"step": 6441356, "kl_loss": 1.4206786033630372, "image_loss": 3772.0, "reward_loss": 0.9193464793205262, "discount_loss": 0.007772144931554794, "model_kl": 1.420678572845459, "prior_ent": 28.770494503784178, "post_ent": 27.358585858154296, "model_loss": 3773.100294921875, "model_loss_scale": 16331.5712, "model_grad_norm": 6.407199461364746, "actor_loss": 0.006337303640047321, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.061900303107500075, "critic_loss": 0.9370244421958923, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.48394407781362536, "reward_mean": -0.00047258672531243066, "reward_std": 0.08133669936656952, "reward_normed_mean": -0.00047258672531243066, "reward_normed_std": 0.08133669936656952, "critic_slow": 6.858593870544434, "critic_target": 6.856630269622802, "actor_ent": 0.7679830017089844, "actor_ent_scale": 0.0010000000474974513, "critic": 6.856269955444336, "fps": 111.41381716714258}
{"step": 6447528, "train_return": 17.0, "train_length": 1940.0, "train_total_steps": 1611882.0, "train_total_episodes": 777.0, "train_loaded_steps": 1611936.0, "train_loaded_episodes": 777.0}
{"step": 6456820, "train_return": 12.0, "train_length": 2323.0, "train_total_steps": 1614205.0, "train_total_episodes": 778.0, "train_loaded_steps": 1614259.0, "train_loaded_episodes": 778.0}
{"step": 6464456, "train_return": 17.0, "train_length": 1909.0, "train_total_steps": 1616114.0, "train_total_episodes": 779.0, "train_loaded_steps": 1616168.0, "train_loaded_episodes": 779.0}
{"step": 6472368, "train_return": 16.0, "train_length": 1978.0, "train_total_steps": 1618092.0, "train_total_episodes": 780.0, "train_loaded_steps": 1618146.0, "train_loaded_episodes": 780.0}
{"step": 6479200, "train_return": 20.0, "train_length": 1708.0, "train_total_steps": 1619800.0, "train_total_episodes": 781.0, "train_loaded_steps": 1619854.0, "train_loaded_episodes": 781.0}
{"step": 6481356, "kl_loss": 1.420948447036743, "image_loss": 3772.0, "reward_loss": 0.9193049545288086, "discount_loss": 0.007758016531169414, "model_kl": 1.4209484134674073, "prior_ent": 28.719389492797852, "post_ent": 27.309585089111327, "model_loss": 3773.100214453125, "model_loss_scale": 16003.8912, "model_grad_norm": Infinity, "actor_loss": 0.005889591832115548, "actor_loss_scale": 4932501.504, "actor_grad_norm": Infinity, "critic_loss": 0.9381002626419067, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4733795315861702, "reward_mean": -0.0006495137790721856, "reward_std": 0.08223656581044197, "reward_normed_mean": -0.0006495137790721856, "reward_normed_std": 0.08223656581044197, "critic_slow": 6.868800397491455, "critic_target": 6.864951988220215, "actor_ent": 0.7902133372306823, "actor_ent_scale": 0.0010000000474974513, "critic": 6.864616371154785, "fps": 111.57360769832685}
{"step": 6486916, "train_return": 16.0, "train_length": 1929.0, "train_total_steps": 1621729.0, "train_total_episodes": 782.0, "train_loaded_steps": 1621783.0, "train_loaded_episodes": 782.0}
{"step": 6495528, "train_return": 14.0, "train_length": 2153.0, "train_total_steps": 1623882.0, "train_total_episodes": 783.0, "train_loaded_steps": 1623936.0, "train_loaded_episodes": 783.0}
{"step": 6503740, "train_return": 15.0, "train_length": 2053.0, "train_total_steps": 1625935.0, "train_total_episodes": 784.0, "train_loaded_steps": 1625989.0, "train_loaded_episodes": 784.0}
{"step": 6512228, "train_return": 15.0, "train_length": 2122.0, "train_total_steps": 1628057.0, "train_total_episodes": 785.0, "train_loaded_steps": 1628111.0, "train_loaded_episodes": 785.0}
{"step": 6521356, "kl_loss": 1.4090068342208861, "image_loss": 3772.0, "reward_loss": 0.9192851300239563, "discount_loss": 0.007787159221619368, "model_kl": 1.4090068016052246, "prior_ent": 28.709392776489256, "post_ent": 27.309776565551758, "model_loss": 3773.09914765625, "model_loss_scale": 8192.0, "model_grad_norm": 6.2923971355438235, "actor_loss": 0.013626885799044976, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.059244828721880916, "critic_loss": 0.9340225675582886, "critic_loss_scale": 227960.4224, "critic_grad_norm": 0.4021896031022072, "reward_mean": -7.822798508677807e-05, "reward_std": 0.08168445171713828, "reward_normed_mean": -7.822798508677807e-05, "reward_normed_std": 0.08168445171713828, "critic_slow": 6.854218576049805, "critic_target": 6.85249847869873, "actor_ent": 0.8190822531700134, "actor_ent_scale": 0.0010000000474974513, "critic": 6.852007195281982, "fps": 110.97734284794707}
{"step": 6522076, "train_return": 10.0, "train_length": 2462.0, "train_total_steps": 1630519.0, "train_total_episodes": 786.0, "train_loaded_steps": 1630573.0, "train_loaded_episodes": 786.0}
{"step": 6529316, "train_return": 18.0, "train_length": 1810.0, "train_total_steps": 1632329.0, "train_total_episodes": 787.0, "train_loaded_steps": 1632383.0, "train_loaded_episodes": 787.0}
{"step": 6539164, "train_return": 9.0, "train_length": 2462.0, "train_total_steps": 1634791.0, "train_total_episodes": 788.0, "train_loaded_steps": 1634845.0, "train_loaded_episodes": 788.0}
{"step": 6547268, "train_return": 16.0, "train_length": 2026.0, "train_total_steps": 1636817.0, "train_total_episodes": 789.0, "train_loaded_steps": 1636871.0, "train_loaded_episodes": 789.0}
{"step": 6554652, "train_return": 18.0, "train_length": 1846.0, "train_total_steps": 1638663.0, "train_total_episodes": 790.0, "train_loaded_steps": 1638717.0, "train_loaded_episodes": 790.0}
{"step": 6561356, "kl_loss": 1.462445598220825, "image_loss": 3772.000187890625, "reward_loss": 0.9193275149345398, "discount_loss": 0.007838310123234988, "model_kl": 1.462445566177368, "prior_ent": 28.753801272583008, "post_ent": 27.31303412780762, "model_loss": 3773.1049734375, "model_loss_scale": 8192.0, "model_grad_norm": 6.30198246307373, "actor_loss": 0.0043409112130830185, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06099085508286953, "critic_loss": 0.9380176863670349, "critic_loss_scale": 114609.3568, "critic_grad_norm": Infinity, "reward_mean": -0.00020929405364440755, "reward_std": 0.08062286610007285, "reward_normed_mean": -0.00020929405364440755, "reward_normed_std": 0.08062286610007285, "critic_slow": 6.797454460144043, "critic_target": 6.792220622253418, "actor_ent": 0.7810242663383484, "actor_ent_scale": 0.0010000000474974513, "critic": 6.79227427520752, "fps": 109.65323861039866}
{"step": 6563400, "train_return": 13.0, "train_length": 2187.0, "train_total_steps": 1640850.0, "train_total_episodes": 791.0, "train_loaded_steps": 1640904.0, "train_loaded_episodes": 791.0}
{"step": 6571368, "train_return": 16.0, "train_length": 1992.0, "train_total_steps": 1642842.0, "train_total_episodes": 792.0, "train_loaded_steps": 1642896.0, "train_loaded_episodes": 792.0}
{"step": 6578216, "train_return": 20.0, "train_length": 1712.0, "train_total_steps": 1644554.0, "train_total_episodes": 793.0, "train_loaded_steps": 1644608.0, "train_loaded_episodes": 793.0}
{"step": 6585304, "train_return": 20.0, "train_length": 1772.0, "train_total_steps": 1646326.0, "train_total_episodes": 794.0, "train_loaded_steps": 1646380.0, "train_loaded_episodes": 794.0}
{"step": 6592544, "train_return": 18.0, "train_length": 1810.0, "train_total_steps": 1648136.0, "train_total_episodes": 795.0, "train_loaded_steps": 1648190.0, "train_loaded_episodes": 795.0}
{"step": 6600412, "train_return": 18.0, "train_length": 1967.0, "train_total_steps": 1650103.0, "train_total_episodes": 796.0, "train_loaded_steps": 1650157.0, "train_loaded_episodes": 796.0}
{"step": 6601356, "kl_loss": 1.4458381372451783, "image_loss": 3772.0, "reward_loss": 0.9193321032524109, "discount_loss": 0.0077748236313462254, "model_kl": 1.4458381008148193, "prior_ent": 28.70813992919922, "post_ent": 27.282369342041015, "model_loss": 3773.102812109375, "model_loss_scale": 8192.0, "model_grad_norm": 6.420262076187134, "actor_loss": 0.015403577356296591, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.05961121330857277, "critic_loss": 0.9346503747940064, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.3990653467655182, "reward_mean": -0.0004157022583822254, "reward_std": 0.08094320608377456, "reward_normed_mean": -0.0004157022583822254, "reward_normed_std": 0.08094320608377456, "critic_slow": 6.83363537979126, "critic_target": 6.8341531044006345, "actor_ent": 0.8377062248229981, "actor_ent_scale": 0.0010000000474974513, "critic": 6.833458373260498, "fps": 110.41952113337334}
{"step": 6608324, "train_return": 17.0, "train_length": 1978.0, "train_total_steps": 1652081.0, "train_total_episodes": 797.0, "train_loaded_steps": 1652135.0, "train_loaded_episodes": 797.0}
{"step": 6615912, "train_return": 17.0, "train_length": 1897.0, "train_total_steps": 1653978.0, "train_total_episodes": 798.0, "train_loaded_steps": 1654032.0, "train_loaded_episodes": 798.0}
{"step": 6623836, "train_return": 16.0, "train_length": 1981.0, "train_total_steps": 1655959.0, "train_total_episodes": 799.0, "train_loaded_steps": 1656013.0, "train_loaded_episodes": 799.0}
{"step": 6631772, "train_return": 18.0, "train_length": 1984.0, "train_total_steps": 1657943.0, "train_total_episodes": 800.0, "train_loaded_steps": 1657997.0, "train_loaded_episodes": 800.0}
{"step": 6640584, "train_return": 14.0, "train_length": 2203.0, "train_total_steps": 1660146.0, "train_total_episodes": 801.0, "train_loaded_steps": 1660200.0, "train_loaded_episodes": 801.0}
{"step": 6641356, "kl_loss": 1.4104491920471192, "image_loss": 3772.0, "reward_loss": 0.9193097416877747, "discount_loss": 0.007741814205795526, "model_kl": 1.4104491565704347, "prior_ent": 28.760628256225587, "post_ent": 27.359145709228514, "model_loss": 3773.099084765625, "model_loss_scale": 15125.7088, "model_grad_norm": 6.54152935180664, "actor_loss": 0.005907039698201697, "actor_loss_scale": 5751229.6448, "actor_grad_norm": Infinity, "critic_loss": 0.9357995517730713, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.46137952370643615, "reward_mean": -0.00024181855936185456, "reward_std": 0.08111406663060189, "reward_normed_mean": -0.00024181855936185456, "reward_normed_std": 0.08111406663060189, "critic_slow": 6.845169000244141, "critic_target": 6.8394674339294435, "actor_ent": 0.8380330625534058, "actor_ent_scale": 0.0010000000474974513, "critic": 6.838979124450684, "fps": 109.28554389769434}
{"step": 6647992, "train_return": 18.0, "train_length": 1852.0, "train_total_steps": 1661998.0, "train_total_episodes": 802.0, "train_loaded_steps": 1662052.0, "train_loaded_episodes": 802.0}
{"step": 6657888, "train_return": 12.0, "train_length": 2474.0, "train_total_steps": 1664472.0, "train_total_episodes": 803.0, "train_loaded_steps": 1664526.0, "train_loaded_episodes": 803.0}
{"step": 6665980, "train_return": 15.0, "train_length": 2023.0, "train_total_steps": 1666495.0, "train_total_episodes": 804.0, "train_loaded_steps": 1666549.0, "train_loaded_episodes": 804.0}
{"step": 6674988, "train_return": 12.0, "train_length": 2252.0, "train_total_steps": 1668747.0, "train_total_episodes": 805.0, "train_loaded_steps": 1668801.0, "train_loaded_episodes": 805.0}
{"step": 6681356, "kl_loss": 1.4032186458587645, "image_loss": 3772.0, "reward_loss": 0.9192828357696533, "discount_loss": 0.007742928306013345, "model_kl": 1.4032186178207398, "prior_ent": 28.68556991882324, "post_ent": 27.29240927429199, "model_loss": 3773.098336328125, "model_loss_scale": 16384.0, "model_grad_norm": 6.366999485397339, "actor_loss": 0.002935809885512572, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06158137862980366, "critic_loss": 0.9347041326522827, "critic_loss_scale": 100558.4384, "critic_grad_norm": 0.443129164147377, "reward_mean": -0.0002726952464698115, "reward_std": 0.08155560395121575, "reward_normed_mean": -0.0002726952464698115, "reward_normed_std": 0.08155560395121575, "critic_slow": 6.8397508819580075, "critic_target": 6.835673850250244, "actor_ent": 0.8712756247520447, "actor_ent_scale": 0.0010000000474974513, "critic": 6.835355677032471, "fps": 111.7396272292945}
{"step": 6684400, "train_return": 13.0, "train_length": 2353.0, "train_total_steps": 1671100.0, "train_total_episodes": 806.0, "train_loaded_steps": 1671154.0, "train_loaded_episodes": 806.0}
{"step": 6691848, "train_return": 19.0, "train_length": 1862.0, "train_total_steps": 1672962.0, "train_total_episodes": 807.0, "train_loaded_steps": 1673016.0, "train_loaded_episodes": 807.0}
{"step": 6699204, "train_return": 19.0, "train_length": 1839.0, "train_total_steps": 1674801.0, "train_total_episodes": 808.0, "train_loaded_steps": 1674855.0, "train_loaded_episodes": 808.0}
{"step": 6707880, "train_return": 13.0, "train_length": 2169.0, "train_total_steps": 1676970.0, "train_total_episodes": 809.0, "train_loaded_steps": 1677024.0, "train_loaded_episodes": 809.0}
{"step": 6715488, "train_return": 17.0, "train_length": 1902.0, "train_total_steps": 1678872.0, "train_total_episodes": 810.0, "train_loaded_steps": 1678926.0, "train_loaded_episodes": 810.0}
{"step": 6721356, "kl_loss": 1.492744257926941, "image_loss": 3772.0, "reward_loss": 0.9192836972236633, "discount_loss": 0.007873159191757441, "model_kl": 1.4927442253112793, "prior_ent": 28.685914672851563, "post_ent": 27.214241326904297, "model_loss": 3773.107962109375, "model_loss_scale": 9987.6864, "model_grad_norm": Infinity, "actor_loss": 0.001608015979762422, "actor_loss_scale": 2576980.3776, "actor_grad_norm": Infinity, "critic_loss": 0.9374375224113465, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4455356347084045, "reward_mean": -0.00036785921098280594, "reward_std": 0.08155812142491341, "reward_normed_mean": -0.00036785921098280594, "reward_normed_std": 0.08155812142491341, "critic_slow": 6.82152519607544, "critic_target": 6.81269204788208, "actor_ent": 0.874525417137146, "actor_ent_scale": 0.0010000000474974513, "critic": 6.812158250427246, "fps": 109.84923247161534}
{"step": 6722792, "train_return": 19.0, "train_length": 1826.0, "train_total_steps": 1680698.0, "train_total_episodes": 811.0, "train_loaded_steps": 1680752.0, "train_loaded_episodes": 811.0}
{"step": 6730556, "train_return": 18.0, "train_length": 1941.0, "train_total_steps": 1682639.0, "train_total_episodes": 812.0, "train_loaded_steps": 1682693.0, "train_loaded_episodes": 812.0}
{"step": 6738656, "train_return": 17.0, "train_length": 2025.0, "train_total_steps": 1684664.0, "train_total_episodes": 813.0, "train_loaded_steps": 1684718.0, "train_loaded_episodes": 813.0}
{"step": 6746516, "train_return": 17.0, "train_length": 1965.0, "train_total_steps": 1686629.0, "train_total_episodes": 814.0, "train_loaded_steps": 1686683.0, "train_loaded_episodes": 814.0}
{"step": 6754552, "train_return": 13.0, "train_length": 2009.0, "train_total_steps": 1688638.0, "train_total_episodes": 815.0, "train_loaded_steps": 1688692.0, "train_loaded_episodes": 815.0}
{"step": 6761356, "kl_loss": 1.3937092531204223, "image_loss": 3772.0, "reward_loss": 0.9192959337234498, "discount_loss": 0.007747064206749201, "model_kl": 1.3937092199325563, "prior_ent": 28.659752337646484, "post_ent": 27.2726382232666, "model_loss": 3773.0974265625, "model_loss_scale": 8192.0, "model_grad_norm": 6.717894244766235, "actor_loss": 0.005579526836131117, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.06098062388598919, "critic_loss": 0.9337461030006409, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.44511986733675, "reward_mean": -0.00025967062321369667, "reward_std": 0.08165300278067589, "reward_normed_mean": -0.00025967062321369667, "reward_normed_std": 0.08165300278067589, "critic_slow": 6.741656544494629, "critic_target": 6.736151630401611, "actor_ent": 0.8744175333023071, "actor_ent_scale": 0.0010000000474974513, "critic": 6.7355443916320805, "fps": 110.9878084945044}
{"step": 6763196, "train_return": 14.0, "train_length": 2161.0, "train_total_steps": 1690799.0, "train_total_episodes": 816.0, "train_loaded_steps": 1690853.0, "train_loaded_episodes": 816.0}
{"step": 6770400, "train_return": 19.0, "train_length": 1801.0, "train_total_steps": 1692600.0, "train_total_episodes": 817.0, "train_loaded_steps": 1692654.0, "train_loaded_episodes": 817.0}
{"step": 6779264, "train_return": 14.0, "train_length": 2216.0, "train_total_steps": 1694816.0, "train_total_episodes": 818.0, "train_loaded_steps": 1694870.0, "train_loaded_episodes": 818.0}
{"step": 6786996, "train_return": 18.0, "train_length": 1933.0, "train_total_steps": 1696749.0, "train_total_episodes": 819.0, "train_loaded_steps": 1696803.0, "train_loaded_episodes": 819.0}
{"step": 6795732, "train_return": 11.0, "train_length": 2184.0, "train_total_steps": 1698933.0, "train_total_episodes": 820.0, "train_loaded_steps": 1698987.0, "train_loaded_episodes": 820.0}
{"step": 6801356, "kl_loss": 1.4126061759948731, "image_loss": 3772.0, "reward_loss": 0.9192861727714539, "discount_loss": 0.00777376009747386, "model_kl": 1.4126061449050904, "prior_ent": 28.63191942138672, "post_ent": 27.23131934814453, "model_loss": 3773.0994375, "model_loss_scale": 8192.0, "model_grad_norm": 6.066681970024109, "actor_loss": 0.007305808658777096, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.06042664294838905, "critic_loss": 0.9341473287582397, "critic_loss_scale": 174902.4768, "critic_grad_norm": 0.4273041968345642, "reward_mean": 9.655772320256801e-05, "reward_std": 0.08118854854106904, "reward_normed_mean": 9.655772320256801e-05, "reward_normed_std": 0.08118854854106904, "critic_slow": 6.658912641906738, "critic_target": 6.655115644073486, "actor_ent": 0.8749038364410401, "actor_ent_scale": 0.0010000000474974513, "critic": 6.654624802398682, "fps": 111.77642124346582}
{"step": 6804640, "train_return": 12.0, "train_length": 2227.0, "train_total_steps": 1701160.0, "train_total_episodes": 821.0, "train_loaded_steps": 1701214.0, "train_loaded_episodes": 821.0}
{"step": 6811772, "train_return": 20.0, "train_length": 1783.0, "train_total_steps": 1702943.0, "train_total_episodes": 822.0, "train_loaded_steps": 1702997.0, "train_loaded_episodes": 822.0}
{"step": 6819592, "train_return": 17.0, "train_length": 1955.0, "train_total_steps": 1704898.0, "train_total_episodes": 823.0, "train_loaded_steps": 1704952.0, "train_loaded_episodes": 823.0}
{"step": 6827416, "train_return": 18.0, "train_length": 1956.0, "train_total_steps": 1706854.0, "train_total_episodes": 824.0, "train_loaded_steps": 1706908.0, "train_loaded_episodes": 824.0}
{"step": 6834132, "train_return": 20.0, "train_length": 1679.0, "train_total_steps": 1708533.0, "train_total_episodes": 825.0, "train_loaded_steps": 1708587.0, "train_loaded_episodes": 825.0}
{"step": 6841356, "kl_loss": 1.411794956588745, "image_loss": 3772.0, "reward_loss": 0.919300098323822, "discount_loss": 0.007749303385615349, "model_kl": 1.4117949226379394, "prior_ent": 28.673312713623048, "post_ent": 27.27001055603027, "model_loss": 3773.09925078125, "model_loss_scale": 12949.9136, "model_grad_norm": 6.644022164154053, "actor_loss": 0.008130244272673736, "actor_loss_scale": 3295045.2224, "actor_grad_norm": 0.06170251662731171, "critic_loss": 0.9357084756851196, "critic_loss_scale": 173853.9008, "critic_grad_norm": Infinity, "reward_mean": 6.256688090215902e-05, "reward_std": 0.08077266982197762, "reward_normed_mean": 6.256688090215902e-05, "reward_normed_std": 0.08077266982197762, "critic_slow": 6.593791160583496, "critic_target": 6.5899800758361815, "actor_ent": 0.8447702204704285, "actor_ent_scale": 0.0010000000474974513, "critic": 6.589395352935791, "fps": 109.78087303346436}
{"step": 6842528, "train_return": 16.0, "train_length": 2099.0, "train_total_steps": 1710632.0, "train_total_episodes": 826.0, "train_loaded_steps": 1710686.0, "train_loaded_episodes": 826.0}
{"step": 6851348, "train_return": 14.0, "train_length": 2205.0, "train_total_steps": 1712837.0, "train_total_episodes": 827.0, "train_loaded_steps": 1712891.0, "train_loaded_episodes": 827.0}
{"step": 6860612, "train_return": 15.0, "train_length": 2316.0, "train_total_steps": 1715153.0, "train_total_episodes": 828.0, "train_loaded_steps": 1715207.0, "train_loaded_episodes": 828.0}
{"step": 6868488, "train_return": 17.0, "train_length": 1969.0, "train_total_steps": 1717122.0, "train_total_episodes": 829.0, "train_loaded_steps": 1717176.0, "train_loaded_episodes": 829.0}
{"step": 6876272, "train_return": 17.0, "train_length": 1946.0, "train_total_steps": 1719068.0, "train_total_episodes": 830.0, "train_loaded_steps": 1719122.0, "train_loaded_episodes": 830.0}
{"step": 6881356, "kl_loss": 1.421758664703369, "image_loss": 3772.0, "reward_loss": 0.919294704914093, "discount_loss": 0.007773939035832882, "model_kl": 1.4217586309432984, "prior_ent": 28.628776181030272, "post_ent": 27.224233309936523, "model_loss": 3773.100366015625, "model_loss_scale": 16384.0, "model_grad_norm": 6.192727381515503, "actor_loss": 0.007223252457741182, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06141614511013031, "critic_loss": 0.9350016300201416, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4769278520822525, "reward_mean": 4.958381249452941e-05, "reward_std": 0.08095626103878022, "reward_normed_mean": 4.958381249452941e-05, "reward_normed_std": 0.08095626103878022, "critic_slow": 6.625432278442383, "critic_target": 6.620362505340577, "actor_ent": 0.8120741357803345, "actor_ent_scale": 0.0010000000474974513, "critic": 6.619814476013183, "fps": 108.89085549185792}
{"step": 6884608, "train_return": 14.0, "train_length": 2084.0, "train_total_steps": 1721152.0, "train_total_episodes": 831.0, "train_loaded_steps": 1721206.0, "train_loaded_episodes": 831.0}
{"step": 6891636, "train_return": 19.0, "train_length": 1757.0, "train_total_steps": 1722909.0, "train_total_episodes": 832.0, "train_loaded_steps": 1722963.0, "train_loaded_episodes": 832.0}
{"step": 6899388, "train_return": 18.0, "train_length": 1938.0, "train_total_steps": 1724847.0, "train_total_episodes": 833.0, "train_loaded_steps": 1724901.0, "train_loaded_episodes": 833.0}
{"step": 6907368, "train_return": 15.0, "train_length": 1995.0, "train_total_steps": 1726842.0, "train_total_episodes": 834.0, "train_loaded_steps": 1726896.0, "train_loaded_episodes": 834.0}
{"step": 6916396, "train_return": 11.0, "train_length": 2257.0, "train_total_steps": 1729099.0, "train_total_episodes": 835.0, "train_loaded_steps": 1729153.0, "train_loaded_episodes": 835.0}
{"step": 6921356, "kl_loss": 1.4180339139938354, "image_loss": 3772.0, "reward_loss": 0.9192765410423279, "discount_loss": 0.007778536315262318, "model_kl": 1.4180338777542114, "prior_ent": 28.57574631652832, "post_ent": 27.169546060180664, "model_loss": 3773.1000015625, "model_loss_scale": 16384.0, "model_grad_norm": 6.368771974945068, "actor_loss": 0.006523531355173327, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06087874753773213, "critic_loss": 0.9346351549148559, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3903969148874283, "reward_mean": 7.107186279445159e-05, "reward_std": 0.08090749505758285, "reward_normed_mean": 7.107186279445159e-05, "reward_normed_std": 0.08090749505758285, "critic_slow": 6.6563059494018555, "critic_target": 6.6536624778747555, "actor_ent": 0.8169538049697876, "actor_ent_scale": 0.0010000000474974513, "critic": 6.652841520690918, "fps": 110.17703041886259}
{"step": 6924728, "train_return": 14.0, "train_length": 2083.0, "train_total_steps": 1731182.0, "train_total_episodes": 836.0, "train_loaded_steps": 1731236.0, "train_loaded_episodes": 836.0}
{"step": 6933156, "train_return": 14.0, "train_length": 2107.0, "train_total_steps": 1733289.0, "train_total_episodes": 837.0, "train_loaded_steps": 1733343.0, "train_loaded_episodes": 837.0}
{"step": 6940740, "train_return": 17.0, "train_length": 1896.0, "train_total_steps": 1735185.0, "train_total_episodes": 838.0, "train_loaded_steps": 1735239.0, "train_loaded_episodes": 838.0}
{"step": 6948664, "train_return": 16.0, "train_length": 1981.0, "train_total_steps": 1737166.0, "train_total_episodes": 839.0, "train_loaded_steps": 1737220.0, "train_loaded_episodes": 839.0}
{"step": 6955928, "train_return": 18.0, "train_length": 1816.0, "train_total_steps": 1738982.0, "train_total_episodes": 840.0, "train_loaded_steps": 1739036.0, "train_loaded_episodes": 840.0}
{"step": 6961356, "kl_loss": 1.4292340650558473, "image_loss": 3772.0002, "reward_loss": 0.9193223943710327, "discount_loss": 0.007784709118306637, "model_kl": 1.4292340322494508, "prior_ent": 28.603921603393555, "post_ent": 27.18826893310547, "model_loss": 3773.1013984375, "model_loss_scale": 21626.88, "model_grad_norm": Infinity, "actor_loss": 0.00911947092266637, "actor_loss_scale": 5751229.6448, "actor_grad_norm": 0.06387513491511344, "critic_loss": 0.936591784954071, "critic_loss_scale": 172595.6096, "critic_grad_norm": Infinity, "reward_mean": 0.00010525608074385673, "reward_std": 0.08093708200454712, "reward_normed_mean": 0.00010525608074385673, "reward_normed_std": 0.08093708200454712, "critic_slow": 6.686558149719239, "critic_target": 6.6805301071167, "actor_ent": 0.7974574014663697, "actor_ent_scale": 0.0010000000474974513, "critic": 6.67961752243042, "fps": 110.316297001506}
{"step": 6964836, "train_return": 15.0, "train_length": 2227.0, "train_total_steps": 1741209.0, "train_total_episodes": 841.0, "train_loaded_steps": 1741263.0, "train_loaded_episodes": 841.0}
{"step": 6973060, "train_return": 16.0, "train_length": 2056.0, "train_total_steps": 1743265.0, "train_total_episodes": 842.0, "train_loaded_steps": 1743319.0, "train_loaded_episodes": 842.0}
{"step": 6981204, "train_return": 16.0, "train_length": 2036.0, "train_total_steps": 1745301.0, "train_total_episodes": 843.0, "train_loaded_steps": 1745355.0, "train_loaded_episodes": 843.0}
{"step": 6989204, "train_return": 17.0, "train_length": 2000.0, "train_total_steps": 1747301.0, "train_total_episodes": 844.0, "train_loaded_steps": 1747355.0, "train_loaded_episodes": 844.0}
{"step": 6996904, "train_return": 18.0, "train_length": 1925.0, "train_total_steps": 1749226.0, "train_total_episodes": 845.0, "train_loaded_steps": 1749280.0, "train_loaded_episodes": 845.0}
{"step": 7001356, "kl_loss": 1.4191754640579224, "image_loss": 3772.0, "reward_loss": 0.9192729244232177, "discount_loss": 0.007753573156893253, "model_kl": 1.4191754293441772, "prior_ent": 28.541762368774414, "post_ent": 27.136879751586914, "model_loss": 3773.099980078125, "model_loss_scale": 13290.7008, "model_grad_norm": Infinity, "actor_loss": 0.007811463922144321, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.061180729514360425, "critic_loss": 0.9343880336761474, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.463146030318737, "reward_mean": 0.00018147406947464334, "reward_std": 0.08129799700975418, "reward_normed_mean": 0.00018147406947464334, "reward_normed_std": 0.08129799700975418, "critic_slow": 6.733278428649903, "critic_target": 6.730931996154785, "actor_ent": 0.8293182903289795, "actor_ent_scale": 0.0010000000474974513, "critic": 6.730286041259766, "fps": 110.76767031819493}
{"step": 7005524, "train_return": 14.0, "train_length": 2155.0, "train_total_steps": 1751381.0, "train_total_episodes": 846.0, "train_loaded_steps": 1751435.0, "train_loaded_episodes": 846.0}
{"step": 7013992, "train_return": 15.0, "train_length": 2117.0, "train_total_steps": 1753498.0, "train_total_episodes": 847.0, "train_loaded_steps": 1753552.0, "train_loaded_episodes": 847.0}
{"step": 7021612, "train_return": 17.0, "train_length": 1905.0, "train_total_steps": 1755403.0, "train_total_episodes": 848.0, "train_loaded_steps": 1755457.0, "train_loaded_episodes": 848.0}
{"step": 7031008, "train_return": 10.0, "train_length": 2349.0, "train_total_steps": 1757752.0, "train_total_episodes": 849.0, "train_loaded_steps": 1757806.0, "train_loaded_episodes": 849.0}
{"step": 7040152, "train_return": 11.0, "train_length": 2286.0, "train_total_steps": 1760038.0, "train_total_episodes": 850.0, "train_loaded_steps": 1760092.0, "train_loaded_episodes": 850.0}
{"step": 7041356, "kl_loss": 1.398042504119873, "image_loss": 3772.0002, "reward_loss": 0.9192827610969544, "discount_loss": 0.007742039629071951, "model_kl": 1.3980424728393555, "prior_ent": 28.595733142089845, "post_ent": 27.208161264038086, "model_loss": 3773.098016015625, "model_loss_scale": 8192.0, "model_grad_norm": 6.412941490364075, "actor_loss": 0.010554858784988755, "actor_loss_scale": 5898869.1456, "actor_grad_norm": Infinity, "critic_loss": 0.937620368862152, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4246417948961258, "reward_mean": 0.00014282684032659745, "reward_std": 0.08117872586846352, "reward_normed_mean": 0.00014282684032659745, "reward_normed_std": 0.08117872586846352, "critic_slow": 6.7267719871521, "critic_target": 6.725533692169189, "actor_ent": 0.7905964668273926, "actor_ent_scale": 0.0010000000474974513, "critic": 6.725244005584717, "fps": 108.6726527049223}
{"step": 7047552, "train_return": 19.0, "train_length": 1850.0, "train_total_steps": 1761888.0, "train_total_episodes": 851.0, "train_loaded_steps": 1761942.0, "train_loaded_episodes": 851.0}
{"step": 7056068, "train_return": 15.0, "train_length": 2129.0, "train_total_steps": 1764017.0, "train_total_episodes": 852.0, "train_loaded_steps": 1764071.0, "train_loaded_episodes": 852.0}
{"step": 7063152, "train_return": 19.0, "train_length": 1771.0, "train_total_steps": 1765788.0, "train_total_episodes": 853.0, "train_loaded_steps": 1765842.0, "train_loaded_episodes": 853.0}
{"step": 7070520, "train_return": 18.0, "train_length": 1842.0, "train_total_steps": 1767630.0, "train_total_episodes": 854.0, "train_loaded_steps": 1767684.0, "train_loaded_episodes": 854.0}
{"step": 7078680, "train_return": 16.0, "train_length": 2040.0, "train_total_steps": 1769670.0, "train_total_episodes": 855.0, "train_loaded_steps": 1769724.0, "train_loaded_episodes": 855.0}
{"step": 7081356, "kl_loss": 1.428804907798767, "image_loss": 3772.0001921875, "reward_loss": 0.9192726782798767, "discount_loss": 0.007741616643220186, "model_kl": 1.4288048753738403, "prior_ent": 28.556461553955078, "post_ent": 27.14864743041992, "model_loss": 3773.10107421875, "model_loss_scale": 8192.0, "model_grad_norm": 6.215351100158691, "actor_loss": 0.009233031706913607, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06560216310024261, "critic_loss": 0.9399938484191894, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.45691372389793394, "reward_mean": 0.0002478983719620373, "reward_std": 0.08192127140760422, "reward_normed_mean": 0.0002478983719620373, "reward_normed_std": 0.08192127140760422, "critic_slow": 6.783267392730713, "critic_target": 6.783081412506103, "actor_ent": 0.8146314455032349, "actor_ent_scale": 0.0010000000474974513, "critic": 6.782498554992676, "fps": 109.83013945099972}
{"step": 7085940, "train_return": 18.0, "train_length": 1815.0, "train_total_steps": 1771485.0, "train_total_episodes": 856.0, "train_loaded_steps": 1771539.0, "train_loaded_episodes": 856.0}
{"step": 7093056, "train_return": 19.0, "train_length": 1779.0, "train_total_steps": 1773264.0, "train_total_episodes": 857.0, "train_loaded_steps": 1773318.0, "train_loaded_episodes": 857.0}
{"step": 7101108, "train_return": 17.0, "train_length": 2013.0, "train_total_steps": 1775277.0, "train_total_episodes": 858.0, "train_loaded_steps": 1775331.0, "train_loaded_episodes": 858.0}
{"step": 7108248, "train_return": 19.0, "train_length": 1785.0, "train_total_steps": 1777062.0, "train_total_episodes": 859.0, "train_loaded_steps": 1777116.0, "train_loaded_episodes": 859.0}
{"step": 7115876, "train_return": 17.0, "train_length": 1907.0, "train_total_steps": 1778969.0, "train_total_episodes": 860.0, "train_loaded_steps": 1779023.0, "train_loaded_episodes": 860.0}
{"step": 7121356, "kl_loss": 1.3962862604141235, "image_loss": 3772.0, "reward_loss": 0.9192659572601318, "discount_loss": 0.007741361946612597, "model_kl": 1.3962862279891968, "prior_ent": 28.460029318237304, "post_ent": 27.072074533081054, "model_loss": 3773.09762265625, "model_loss_scale": 9646.8992, "model_grad_norm": 6.3570901294708255, "actor_loss": 0.015433446651272243, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06726004631519318, "critic_loss": 0.9402349922180175, "critic_loss_scale": 256481.6896, "critic_grad_norm": 0.44884524502754214, "reward_mean": 0.00027294857344186313, "reward_std": 0.08146540977358818, "reward_normed_mean": 0.00027294857344186313, "reward_normed_std": 0.08146540977358818, "critic_slow": 6.786480484008789, "critic_target": 6.78620092086792, "actor_ent": 0.8110795804023743, "actor_ent_scale": 0.0010000000474974513, "critic": 6.785946309661865, "fps": 110.39189770618499}
{"step": 7124008, "train_return": 17.0, "train_length": 2033.0, "train_total_steps": 1781002.0, "train_total_episodes": 861.0, "train_loaded_steps": 1781056.0, "train_loaded_episodes": 861.0}
{"step": 7133176, "train_return": 12.0, "train_length": 2292.0, "train_total_steps": 1783294.0, "train_total_episodes": 862.0, "train_loaded_steps": 1783348.0, "train_loaded_episodes": 862.0}
{"step": 7140444, "train_return": 19.0, "train_length": 1817.0, "train_total_steps": 1785111.0, "train_total_episodes": 863.0, "train_loaded_steps": 1785165.0, "train_loaded_episodes": 863.0}
{"step": 7147732, "train_return": 18.0, "train_length": 1822.0, "train_total_steps": 1786933.0, "train_total_episodes": 864.0, "train_loaded_steps": 1786987.0, "train_loaded_episodes": 864.0}
{"step": 7156728, "train_return": 14.0, "train_length": 2249.0, "train_total_steps": 1789182.0, "train_total_episodes": 865.0, "train_loaded_steps": 1789236.0, "train_loaded_episodes": 865.0}
{"step": 7161356, "kl_loss": 1.4104690393447876, "image_loss": 3772.0, "reward_loss": 0.9193022041320801, "discount_loss": 0.007740775944292545, "model_kl": 1.4104690069198609, "prior_ent": 28.526805200195312, "post_ent": 27.129999060058594, "model_loss": 3773.099072265625, "model_loss_scale": 16384.0, "model_grad_norm": 6.439381443023682, "actor_loss": 0.0045159496118169044, "actor_loss_scale": 5308311.1424, "actor_grad_norm": Infinity, "critic_loss": 0.9377191282272339, "critic_loss_scale": 227121.5616, "critic_grad_norm": Infinity, "reward_mean": 0.00017536044570788363, "reward_std": 0.08194356140494347, "reward_normed_mean": 0.00017536044570788363, "reward_normed_std": 0.08194356140494347, "critic_slow": 6.700637146759033, "critic_target": 6.695220217895508, "actor_ent": 0.8283753497123718, "actor_ent_scale": 0.0010000000474974513, "critic": 6.69495693283081, "fps": 109.908659631174}
{"step": 7164672, "train_return": 16.0, "train_length": 1986.0, "train_total_steps": 1791168.0, "train_total_episodes": 866.0, "train_loaded_steps": 1791222.0, "train_loaded_episodes": 866.0}
{"step": 7173152, "train_return": 12.0, "train_length": 2120.0, "train_total_steps": 1793288.0, "train_total_episodes": 867.0, "train_loaded_steps": 1793342.0, "train_loaded_episodes": 867.0}
{"step": 7180764, "train_return": 17.0, "train_length": 1903.0, "train_total_steps": 1795191.0, "train_total_episodes": 868.0, "train_loaded_steps": 1795245.0, "train_loaded_episodes": 868.0}
{"step": 7189856, "train_return": 13.0, "train_length": 2273.0, "train_total_steps": 1797464.0, "train_total_episodes": 869.0, "train_loaded_steps": 1797518.0, "train_loaded_episodes": 869.0}
{"step": 7198248, "train_return": 14.0, "train_length": 2098.0, "train_total_steps": 1799562.0, "train_total_episodes": 870.0, "train_loaded_steps": 1799616.0, "train_loaded_episodes": 870.0}
{"step": 7201352, "eval_return": 15.0, "eval_length": 2038.0, "eval_total_steps": 17481.0, "eval_total_episodes": 9.0, "eval_loaded_steps": 17483.0, "eval_loaded_episodes": 9.0}
{"step": 7201356, "kl_loss": 1.3869443542480469, "image_loss": 3772.0, "reward_loss": 0.9192682272911071, "discount_loss": 0.007752542546391487, "model_kl": 1.3869443267822266, "prior_ent": 28.461722375488282, "post_ent": 27.08438662414551, "model_loss": 3773.096747265625, "model_loss_scale": 16384.0, "model_grad_norm": 6.4357960964202885, "actor_loss": 0.007033634967559192, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06546250762939453, "critic_loss": 0.9387446034431457, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4217527538061142, "reward_mean": 0.0003061874213661213, "reward_std": 0.08133373520374299, "reward_normed_mean": 0.0003061874213661213, "reward_normed_std": 0.08133373520374299, "critic_slow": 6.675004644012451, "critic_target": 6.673471603393555, "actor_ent": 0.8465334546089173, "actor_ent_scale": 0.0010000000474974513, "critic": 6.673412718963623, "fps": 104.87327540847531}
{"step": 7206584, "train_return": 14.0, "train_length": 2084.0, "train_total_steps": 1801646.0, "train_total_episodes": 871.0, "train_loaded_steps": 1801700.0, "train_loaded_episodes": 871.0}
{"step": 7215860, "train_return": 12.0, "train_length": 2319.0, "train_total_steps": 1803965.0, "train_total_episodes": 872.0, "train_loaded_steps": 1804019.0, "train_loaded_episodes": 872.0}
{"step": 7225352, "train_return": 13.0, "train_length": 2373.0, "train_total_steps": 1806338.0, "train_total_episodes": 873.0, "train_loaded_steps": 1806392.0, "train_loaded_episodes": 873.0}
{"step": 7232960, "train_return": 17.0, "train_length": 1902.0, "train_total_steps": 1808240.0, "train_total_episodes": 874.0, "train_loaded_steps": 1808294.0, "train_loaded_episodes": 874.0}
{"step": 7240868, "train_return": 16.0, "train_length": 1977.0, "train_total_steps": 1810217.0, "train_total_episodes": 875.0, "train_loaded_steps": 1810271.0, "train_loaded_episodes": 875.0}
{"step": 7241356, "kl_loss": 1.5385914072036744, "image_loss": 3772.0, "reward_loss": 0.919283577632904, "discount_loss": 0.007802462925761938, "model_kl": 1.5385913677215577, "prior_ent": 28.56527864074707, "post_ent": 27.075057498168945, "model_loss": 3773.1121765625, "model_loss_scale": 10590.6176, "model_grad_norm": Infinity, "actor_loss": 0.003946700921099546, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.0679817271053791, "critic_loss": 0.9399252245903015, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4979017475962639, "reward_mean": 0.0005150189005144057, "reward_std": 0.08150078043937684, "reward_normed_mean": 0.0005150189005144057, "reward_normed_std": 0.08150078043937684, "critic_slow": 6.736323332214355, "critic_target": 6.728565940856933, "actor_ent": 0.7861385326385498, "actor_ent_scale": 0.0010000000474974513, "critic": 6.727979048919678, "fps": 109.3141867644535}
{"step": 7247936, "train_return": 19.0, "train_length": 1767.0, "train_total_steps": 1811984.0, "train_total_episodes": 876.0, "train_loaded_steps": 1812038.0, "train_loaded_episodes": 876.0}
{"step": 7255336, "train_return": 17.0, "train_length": 1850.0, "train_total_steps": 1813834.0, "train_total_episodes": 877.0, "train_loaded_steps": 1813888.0, "train_loaded_episodes": 877.0}
{"step": 7264736, "train_return": 10.0, "train_length": 2350.0, "train_total_steps": 1816184.0, "train_total_episodes": 878.0, "train_loaded_steps": 1816238.0, "train_loaded_episodes": 878.0}
{"step": 7272388, "train_return": 17.0, "train_length": 1913.0, "train_total_steps": 1818097.0, "train_total_episodes": 879.0, "train_loaded_steps": 1818151.0, "train_loaded_episodes": 879.0}
{"step": 7280064, "train_return": 16.0, "train_length": 1919.0, "train_total_steps": 1820016.0, "train_total_episodes": 880.0, "train_loaded_steps": 1820070.0, "train_loaded_episodes": 880.0}
{"step": 7281356, "kl_loss": 1.3925325454711914, "image_loss": 3772.0, "reward_loss": 0.9192647573471069, "discount_loss": 0.007741791361570358, "model_kl": 1.3925325145721437, "prior_ent": 28.671721835327148, "post_ent": 27.283401605224608, "model_loss": 3773.09726015625, "model_loss_scale": 8192.0, "model_grad_norm": 6.312657543563843, "actor_loss": 0.002798340485393419, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06399571726918221, "critic_loss": 0.9370665091514587, "critic_loss_scale": 139880.0384, "critic_grad_norm": 0.4517723974108696, "reward_mean": 0.0003925597542256582, "reward_std": 0.08131156411170959, "reward_normed_mean": 0.0003925597542256582, "reward_normed_std": 0.08131156411170959, "critic_slow": 6.7252358612060545, "critic_target": 6.719553484344482, "actor_ent": 0.8088993631362915, "actor_ent_scale": 0.0010000000474974513, "critic": 6.719314630126953, "fps": 110.87059785787467}
{"step": 7287748, "train_return": 19.0, "train_length": 1921.0, "train_total_steps": 1821937.0, "train_total_episodes": 881.0, "train_loaded_steps": 1821991.0, "train_loaded_episodes": 881.0}
{"step": 7297100, "train_return": 13.0, "train_length": 2338.0, "train_total_steps": 1824275.0, "train_total_episodes": 882.0, "train_loaded_steps": 1824329.0, "train_loaded_episodes": 882.0}
{"step": 7305840, "train_return": 14.0, "train_length": 2185.0, "train_total_steps": 1826460.0, "train_total_episodes": 883.0, "train_loaded_steps": 1826514.0, "train_loaded_episodes": 883.0}
{"step": 7313020, "train_return": 19.0, "train_length": 1795.0, "train_total_steps": 1828255.0, "train_total_episodes": 884.0, "train_loaded_steps": 1828309.0, "train_loaded_episodes": 884.0}
{"step": 7320920, "train_return": 14.0, "train_length": 1975.0, "train_total_steps": 1830230.0, "train_total_episodes": 885.0, "train_loaded_steps": 1830284.0, "train_loaded_episodes": 885.0}
{"step": 7321356, "kl_loss": 1.3997524425506591, "image_loss": 3772.0, "reward_loss": 0.9192847693443298, "discount_loss": 0.007755234418809414, "model_kl": 1.3997524116516114, "prior_ent": 28.596900982666014, "post_ent": 27.203139208984375, "model_loss": 3773.098062890625, "model_loss_scale": 8192.0, "model_grad_norm": 6.429490970420837, "actor_loss": 0.0018656091501774881, "actor_loss_scale": 8086618.112, "actor_grad_norm": 0.06171515259742737, "critic_loss": 0.9367586796760559, "critic_loss_scale": 162738.9952, "critic_grad_norm": Infinity, "reward_mean": 0.00014158359631874192, "reward_std": 0.08115846024155617, "reward_normed_mean": 0.00014158359631874192, "reward_normed_std": 0.08115846024155617, "critic_slow": 6.661827476501465, "critic_target": 6.655136923980713, "actor_ent": 0.8932947134017944, "actor_ent_scale": 0.0010000000474974513, "critic": 6.654883319091797, "fps": 110.37797142742761}
{"step": 7327872, "train_return": 20.0, "train_length": 1738.0, "train_total_steps": 1831968.0, "train_total_episodes": 886.0, "train_loaded_steps": 1832022.0, "train_loaded_episodes": 886.0}
{"step": 7335556, "train_return": 17.0, "train_length": 1921.0, "train_total_steps": 1833889.0, "train_total_episodes": 887.0, "train_loaded_steps": 1833943.0, "train_loaded_episodes": 887.0}
{"step": 7342932, "train_return": 19.0, "train_length": 1844.0, "train_total_steps": 1835733.0, "train_total_episodes": 888.0, "train_loaded_steps": 1835787.0, "train_loaded_episodes": 888.0}
{"step": 7351536, "train_return": 14.0, "train_length": 2151.0, "train_total_steps": 1837884.0, "train_total_episodes": 889.0, "train_loaded_steps": 1837938.0, "train_loaded_episodes": 889.0}
{"step": 7359332, "train_return": 18.0, "train_length": 1949.0, "train_total_steps": 1839833.0, "train_total_episodes": 890.0, "train_loaded_steps": 1839887.0, "train_loaded_episodes": 890.0}
{"step": 7361356, "kl_loss": 1.4296333864212036, "image_loss": 3772.0, "reward_loss": 0.9192803404808044, "discount_loss": 0.007768805854022503, "model_kl": 1.4296333564758301, "prior_ent": 28.528831338500975, "post_ent": 27.111568225097656, "model_loss": 3773.10111484375, "model_loss_scale": 12346.9824, "model_grad_norm": 6.5486578830718996, "actor_loss": 0.006099421638250351, "actor_loss_scale": 5361998.2336, "actor_grad_norm": Infinity, "critic_loss": 0.9408945064544678, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.5254071140289307, "reward_mean": 0.0006749981934088282, "reward_std": 0.0810770967900753, "reward_normed_mean": 0.0006749981934088282, "reward_normed_std": 0.0810770967900753, "critic_slow": 6.6085207023620605, "critic_target": 6.603539870452881, "actor_ent": 0.876762386226654, "actor_ent_scale": 0.0010000000474974513, "critic": 6.6034106300354, "fps": 110.61341888969712}
{"step": 7369568, "train_return": 14.0, "train_length": 2559.0, "train_total_steps": 1842392.0, "train_total_episodes": 891.0, "train_loaded_steps": 1842446.0, "train_loaded_episodes": 891.0}
{"step": 7377628, "train_return": 16.0, "train_length": 2015.0, "train_total_steps": 1844407.0, "train_total_episodes": 892.0, "train_loaded_steps": 1844461.0, "train_loaded_episodes": 892.0}
{"step": 7385556, "train_return": 17.0, "train_length": 1982.0, "train_total_steps": 1846389.0, "train_total_episodes": 893.0, "train_loaded_steps": 1846443.0, "train_loaded_episodes": 893.0}
{"step": 7393736, "train_return": 16.0, "train_length": 2045.0, "train_total_steps": 1848434.0, "train_total_episodes": 894.0, "train_loaded_steps": 1848488.0, "train_loaded_episodes": 894.0}
{"step": 7401356, "kl_loss": 1.4170558811187743, "image_loss": 3772.0, "reward_loss": 0.9192765448570251, "discount_loss": 0.007742534930258989, "model_kl": 1.4170558488845826, "prior_ent": 28.53968480834961, "post_ent": 27.134927978515623, "model_loss": 3773.09972109375, "model_loss_scale": 16384.0, "model_grad_norm": 6.556450040626526, "actor_loss": 0.004819080973189557, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06433236534297467, "critic_loss": 0.9375368563652039, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4972646413087845, "reward_mean": 0.0007353663320966006, "reward_std": 0.08090658456683159, "reward_normed_mean": 0.0007353663320966006, "reward_normed_std": 0.08090658456683159, "critic_slow": 6.687594237518311, "critic_target": 6.680217619323731, "actor_ent": 0.8546202172279358, "actor_ent_scale": 0.0010000000474974513, "critic": 6.679991161346435, "fps": 110.11515170151952}
{"step": 7401584, "train_return": 17.0, "train_length": 1962.0, "train_total_steps": 1850396.0, "train_total_episodes": 895.0, "train_loaded_steps": 1850450.0, "train_loaded_episodes": 895.0}
{"step": 7409372, "train_return": 17.0, "train_length": 1947.0, "train_total_steps": 1852343.0, "train_total_episodes": 896.0, "train_loaded_steps": 1852397.0, "train_loaded_episodes": 896.0}
{"step": 7417640, "train_return": 17.0, "train_length": 2067.0, "train_total_steps": 1854410.0, "train_total_episodes": 897.0, "train_loaded_steps": 1854464.0, "train_loaded_episodes": 897.0}
{"step": 7425664, "train_return": 16.0, "train_length": 2006.0, "train_total_steps": 1856416.0, "train_total_episodes": 898.0, "train_loaded_steps": 1856470.0, "train_loaded_episodes": 898.0}
{"step": 7434788, "train_return": 11.0, "train_length": 2281.0, "train_total_steps": 1858697.0, "train_total_episodes": 899.0, "train_loaded_steps": 1858751.0, "train_loaded_episodes": 899.0}
{"step": 7441356, "kl_loss": 1.4047804470062255, "image_loss": 3772.000187890625, "reward_loss": 0.9192958526611328, "discount_loss": 0.007818243849277496, "model_kl": 1.4047804145812988, "prior_ent": 28.5795141784668, "post_ent": 27.18602041015625, "model_loss": 3773.099088671875, "model_loss_scale": 16384.0, "model_grad_norm": 6.290995362091064, "actor_loss": 0.006608101163315587, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06411795981526375, "critic_loss": 0.9379974625587464, "critic_loss_scale": 150156.0832, "critic_grad_norm": Infinity, "reward_mean": 0.0005842816982876684, "reward_std": 0.08159110303521157, "reward_normed_mean": 0.0005842816982876684, "reward_normed_std": 0.08159110303521157, "critic_slow": 6.6146962959289555, "critic_target": 6.609620748901367, "actor_ent": 0.8219742939949035, "actor_ent_scale": 0.0010000000474974513, "critic": 6.609058470916748, "fps": 111.1361567402468}
{"step": 7442700, "train_return": 17.0, "train_length": 1978.0, "train_total_steps": 1860675.0, "train_total_episodes": 900.0, "train_loaded_steps": 1860729.0, "train_loaded_episodes": 900.0}
{"step": 7450172, "train_return": 18.0, "train_length": 1868.0, "train_total_steps": 1862543.0, "train_total_episodes": 901.0, "train_loaded_steps": 1862597.0, "train_loaded_episodes": 901.0}
{"step": 7457264, "train_return": 19.0, "train_length": 1773.0, "train_total_steps": 1864316.0, "train_total_episodes": 902.0, "train_loaded_steps": 1864370.0, "train_loaded_episodes": 902.0}
{"step": 7465340, "train_return": 16.0, "train_length": 2019.0, "train_total_steps": 1866335.0, "train_total_episodes": 903.0, "train_loaded_steps": 1866389.0, "train_loaded_episodes": 903.0}
{"step": 7473976, "train_return": 13.0, "train_length": 2159.0, "train_total_steps": 1868494.0, "train_total_episodes": 904.0, "train_loaded_steps": 1868548.0, "train_loaded_episodes": 904.0}
{"step": 7481356, "kl_loss": 1.459862167930603, "image_loss": 3772.0001921875, "reward_loss": 0.9192627230644226, "discount_loss": 0.007743797782808542, "model_kl": 1.4598621389389037, "prior_ent": 28.44520567932129, "post_ent": 27.008089419555663, "model_loss": 3773.10418984375, "model_loss_scale": 13369.344, "model_grad_norm": Infinity, "actor_loss": 0.00409458062320191, "actor_loss_scale": 6382052.9664, "actor_grad_norm": 0.06357283038794995, "critic_loss": 0.9376291289329529, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4243686474084854, "reward_mean": 0.0004708093253342668, "reward_std": 0.08105062680244446, "reward_normed_mean": 0.0004708093253342668, "reward_normed_std": 0.08105062680244446, "critic_slow": 6.587725904846192, "critic_target": 6.583879410552979, "actor_ent": 0.8623092793464661, "actor_ent_scale": 0.0010000000474974513, "critic": 6.583915665435791, "fps": 110.33991429347505}
{"step": 7483576, "train_return": 11.0, "train_length": 2400.0, "train_total_steps": 1870894.0, "train_total_episodes": 905.0, "train_loaded_steps": 1870948.0, "train_loaded_episodes": 905.0}
{"step": 7492072, "train_return": 13.0, "train_length": 2124.0, "train_total_steps": 1873018.0, "train_total_episodes": 906.0, "train_loaded_steps": 1873072.0, "train_loaded_episodes": 906.0}
{"step": 7501680, "train_return": 11.0, "train_length": 2402.0, "train_total_steps": 1875420.0, "train_total_episodes": 907.0, "train_loaded_steps": 1875474.0, "train_loaded_episodes": 907.0}
{"step": 7509168, "train_return": 19.0, "train_length": 1872.0, "train_total_steps": 1877292.0, "train_total_episodes": 908.0, "train_loaded_steps": 1877346.0, "train_loaded_episodes": 908.0}
{"step": 7517188, "train_return": 16.0, "train_length": 2005.0, "train_total_steps": 1879297.0, "train_total_episodes": 909.0, "train_loaded_steps": 1879351.0, "train_loaded_episodes": 909.0}
{"step": 7521356, "kl_loss": 1.491830326461792, "image_loss": 3772.0, "reward_loss": 0.9192924153327942, "discount_loss": 0.007796904584765434, "model_kl": 1.4918302940368653, "prior_ent": 28.639860565185547, "post_ent": 27.168392364501955, "model_loss": 3773.107480859375, "model_loss_scale": 8192.0, "model_grad_norm": 5.896885292434693, "actor_loss": 0.006714695984900754, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.07087546818852425, "critic_loss": 0.9436550946235657, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.5081930559873581, "reward_mean": 0.0004881642924781772, "reward_std": 0.08132354852557182, "reward_normed_mean": 0.0004881642924781772, "reward_normed_std": 0.08132354852557182, "critic_slow": 6.567412730407715, "critic_target": 6.565136658477783, "actor_ent": 0.8054179279327393, "actor_ent_scale": 0.0010000000474974513, "critic": 6.5650857772827145, "fps": 110.13555734211332}
{"step": 7525008, "train_return": 17.0, "train_length": 1955.0, "train_total_steps": 1881252.0, "train_total_episodes": 910.0, "train_loaded_steps": 1881306.0, "train_loaded_episodes": 910.0}
{"step": 7535016, "train_return": 10.0, "train_length": 2502.0, "train_total_steps": 1883754.0, "train_total_episodes": 911.0, "train_loaded_steps": 1883808.0, "train_loaded_episodes": 911.0}
{"step": 7543268, "train_return": 14.0, "train_length": 2063.0, "train_total_steps": 1885817.0, "train_total_episodes": 912.0, "train_loaded_steps": 1885871.0, "train_loaded_episodes": 912.0}
{"step": 7551684, "train_return": 16.0, "train_length": 2104.0, "train_total_steps": 1887921.0, "train_total_episodes": 913.0, "train_loaded_steps": 1887975.0, "train_loaded_episodes": 913.0}
{"step": 7560288, "train_return": 15.0, "train_length": 2151.0, "train_total_steps": 1890072.0, "train_total_episodes": 914.0, "train_loaded_steps": 1890126.0, "train_loaded_episodes": 914.0}
{"step": 7561356, "kl_loss": 1.4159610452651978, "image_loss": 3772.0, "reward_loss": 0.9192657358169556, "discount_loss": 0.007742418041825294, "model_kl": 1.4159610164642333, "prior_ent": 28.538653323364258, "post_ent": 27.137864846801758, "model_loss": 3773.0996015625, "model_loss_scale": 8192.0, "model_grad_norm": 6.468539247894287, "actor_loss": 0.006750489206757629, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06609034956693649, "critic_loss": 0.9398399834632873, "critic_loss_scale": 135685.7344, "critic_grad_norm": Infinity, "reward_mean": 0.0005084857020527124, "reward_std": 0.08164245603084565, "reward_normed_mean": 0.0005084857020527124, "reward_normed_std": 0.08164245603084565, "critic_slow": 6.62370344619751, "critic_target": 6.622352615356445, "actor_ent": 0.8287895303726196, "actor_ent_scale": 0.0010000000474974513, "critic": 6.622057991790771, "fps": 110.80454195581792}
{"step": 7567968, "train_return": 17.0, "train_length": 1920.0, "train_total_steps": 1891992.0, "train_total_episodes": 915.0, "train_loaded_steps": 1892046.0, "train_loaded_episodes": 915.0}
{"step": 7575412, "train_return": 18.0, "train_length": 1861.0, "train_total_steps": 1893853.0, "train_total_episodes": 916.0, "train_loaded_steps": 1893907.0, "train_loaded_episodes": 916.0}
{"step": 7583552, "train_return": 16.0, "train_length": 2035.0, "train_total_steps": 1895888.0, "train_total_episodes": 917.0, "train_loaded_steps": 1895942.0, "train_loaded_episodes": 917.0}
{"step": 7591504, "train_return": 16.0, "train_length": 1988.0, "train_total_steps": 1897876.0, "train_total_episodes": 918.0, "train_loaded_steps": 1897930.0, "train_loaded_episodes": 918.0}
{"step": 7599724, "train_return": 16.0, "train_length": 2055.0, "train_total_steps": 1899931.0, "train_total_episodes": 919.0, "train_loaded_steps": 1899985.0, "train_loaded_episodes": 919.0}
{"step": 7601356, "kl_loss": 1.399752195930481, "image_loss": 3772.0, "reward_loss": 0.9192627069473267, "discount_loss": 0.00774241486787796, "model_kl": 1.399752165222168, "prior_ent": 28.558357958984374, "post_ent": 27.169561755371095, "model_loss": 3773.0979734375, "model_loss_scale": 9568.256, "model_grad_norm": 5.994105893325806, "actor_loss": 0.01284645691300393, "actor_loss_scale": 8415451.5456, "actor_grad_norm": Infinity, "critic_loss": 0.9394859780311584, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.49998826470375063, "reward_mean": 0.0007120450384714786, "reward_std": 0.08144198740124703, "reward_normed_mean": 0.0007120450384714786, "reward_normed_std": 0.08144198740124703, "critic_slow": 6.600064495849609, "critic_target": 6.5992636993408205, "actor_ent": 0.8395419413566589, "actor_ent_scale": 0.0010000000474974513, "critic": 6.59907043762207, "fps": 109.74259080658113}
{"step": 7607936, "train_return": 16.0, "train_length": 2053.0, "train_total_steps": 1901984.0, "train_total_episodes": 920.0, "train_loaded_steps": 1902038.0, "train_loaded_episodes": 920.0}
{"step": 7615212, "train_return": 19.0, "train_length": 1819.0, "train_total_steps": 1903803.0, "train_total_episodes": 921.0, "train_loaded_steps": 1903857.0, "train_loaded_episodes": 921.0}
{"step": 7623320, "train_return": 16.0, "train_length": 2027.0, "train_total_steps": 1905830.0, "train_total_episodes": 922.0, "train_loaded_steps": 1905884.0, "train_loaded_episodes": 922.0}
{"step": 7630172, "train_return": 20.0, "train_length": 1713.0, "train_total_steps": 1907543.0, "train_total_episodes": 923.0, "train_loaded_steps": 1907597.0, "train_loaded_episodes": 923.0}
{"step": 7637428, "train_return": 18.0, "train_length": 1814.0, "train_total_steps": 1909357.0, "train_total_episodes": 924.0, "train_loaded_steps": 1909411.0, "train_loaded_episodes": 924.0}
{"step": 7641356, "kl_loss": 1.3866325382232667, "image_loss": 3772.0, "reward_loss": 0.9192772018432617, "discount_loss": 0.007741723605245352, "model_kl": 1.3866325090408325, "prior_ent": 28.472028045654298, "post_ent": 27.093469989013673, "model_loss": 3773.09665859375, "model_loss_scale": 11901.3376, "model_grad_norm": Infinity, "actor_loss": 0.0077459623266051495, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06501964644193649, "critic_loss": 0.9380284973144531, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.47716881748437884, "reward_mean": 0.0005830157997130299, "reward_std": 0.08178259738087654, "reward_normed_mean": 0.0005830157997130299, "reward_normed_std": 0.08178259738087654, "critic_slow": 6.603528769683838, "critic_target": 6.600697072601318, "actor_ent": 0.8198558494567871, "actor_ent_scale": 0.0010000000474974513, "critic": 6.600369880676269, "fps": 110.68562104373932}
{"step": 7644660, "train_return": 19.0, "train_length": 1808.0, "train_total_steps": 1911165.0, "train_total_episodes": 925.0, "train_loaded_steps": 1911219.0, "train_loaded_episodes": 925.0}
{"step": 7651720, "train_return": 19.0, "train_length": 1765.0, "train_total_steps": 1912930.0, "train_total_episodes": 926.0, "train_loaded_steps": 1912984.0, "train_loaded_episodes": 926.0}
{"step": 7659272, "train_return": 17.0, "train_length": 1888.0, "train_total_steps": 1914818.0, "train_total_episodes": 927.0, "train_loaded_steps": 1914872.0, "train_loaded_episodes": 927.0}
{"step": 7667084, "train_return": 16.0, "train_length": 1953.0, "train_total_steps": 1916771.0, "train_total_episodes": 928.0, "train_loaded_steps": 1916825.0, "train_loaded_episodes": 928.0}
{"step": 7675052, "train_return": 15.0, "train_length": 1992.0, "train_total_steps": 1918763.0, "train_total_episodes": 929.0, "train_loaded_steps": 1918817.0, "train_loaded_episodes": 929.0}
{"step": 7681356, "kl_loss": 1.7306677972793578, "image_loss": 3772.0, "reward_loss": 0.919307253074646, "discount_loss": 0.00791574667468667, "model_kl": 1.7306677642822266, "prior_ent": 28.316875216674806, "post_ent": 26.675042572021486, "model_loss": 3773.131981640625, "model_loss_scale": 8192.0, "model_grad_norm": 6.558834594917298, "actor_loss": 0.008067128417160712, "actor_loss_scale": 6992743.6288, "actor_grad_norm": Infinity, "critic_loss": 0.9461956334114074, "critic_loss_scale": 107583.8976, "critic_grad_norm": Infinity, "reward_mean": 0.0006930126735622252, "reward_std": 0.08050403060913086, "reward_normed_mean": 0.0006930126735622252, "reward_normed_std": 0.08050403060913086, "critic_slow": 6.6819812866210935, "critic_target": 6.6780137359619145, "actor_ent": 0.81128273229599, "actor_ent_scale": 0.0010000000474974513, "critic": 6.67784017868042, "fps": 111.01351116025924}
{"step": 7683988, "train_return": 11.0, "train_length": 2234.0, "train_total_steps": 1920997.0, "train_total_episodes": 930.0, "train_loaded_steps": 1921051.0, "train_loaded_episodes": 930.0}
{"step": 7691396, "train_return": 19.0, "train_length": 1852.0, "train_total_steps": 1922849.0, "train_total_episodes": 931.0, "train_loaded_steps": 1922903.0, "train_loaded_episodes": 931.0}
{"step": 7701500, "train_return": 5.0, "train_length": 2526.0, "train_total_steps": 1925375.0, "train_total_episodes": 932.0, "train_loaded_steps": 1925429.0, "train_loaded_episodes": 932.0}
{"step": 7709692, "train_return": 16.0, "train_length": 2048.0, "train_total_steps": 1927423.0, "train_total_episodes": 933.0, "train_loaded_steps": 1927477.0, "train_loaded_episodes": 933.0}
{"step": 7716880, "train_return": 20.0, "train_length": 1797.0, "train_total_steps": 1929220.0, "train_total_episodes": 934.0, "train_loaded_steps": 1929274.0, "train_loaded_episodes": 934.0}
{"step": 7721356, "kl_loss": 1.4203964778900147, "image_loss": 3772.0004, "reward_loss": 0.9192646513938904, "discount_loss": 0.0077436695337295535, "model_kl": 1.420396443939209, "prior_ent": 28.462506985473635, "post_ent": 27.04249114074707, "model_loss": 3773.100446484375, "model_loss_scale": 8192.0, "model_grad_norm": 5.931597952079773, "actor_loss": 0.010267536394503259, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06428178297877311, "critic_loss": 0.939364344882965, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.43789006115198137, "reward_mean": 0.0005424045539075451, "reward_std": 0.08125992625951767, "reward_normed_mean": 0.0005424045539075451, "reward_normed_std": 0.08125992625951767, "critic_slow": 6.651761959075928, "critic_target": 6.651861156463623, "actor_ent": 0.8031951753616333, "actor_ent_scale": 0.0010000000474974513, "critic": 6.651521072387696, "fps": 109.16625558176383}
{"step": 7723812, "train_return": 20.0, "train_length": 1733.0, "train_total_steps": 1930953.0, "train_total_episodes": 935.0, "train_loaded_steps": 1931007.0, "train_loaded_episodes": 935.0}
{"step": 7731640, "train_return": 16.0, "train_length": 1957.0, "train_total_steps": 1932910.0, "train_total_episodes": 936.0, "train_loaded_steps": 1932964.0, "train_loaded_episodes": 936.0}
{"step": 7738436, "train_return": 21.0, "train_length": 1699.0, "train_total_steps": 1934609.0, "train_total_episodes": 937.0, "train_loaded_steps": 1934663.0, "train_loaded_episodes": 937.0}
{"step": 7746732, "train_return": 15.0, "train_length": 2074.0, "train_total_steps": 1936683.0, "train_total_episodes": 938.0, "train_loaded_steps": 1936737.0, "train_loaded_episodes": 938.0}
{"step": 7754308, "train_return": 18.0, "train_length": 1894.0, "train_total_steps": 1938577.0, "train_total_episodes": 939.0, "train_loaded_steps": 1938631.0, "train_loaded_episodes": 939.0}
{"step": 7761356, "kl_loss": 1.3840762809753417, "image_loss": 3772.0, "reward_loss": 0.9192731642723083, "discount_loss": 0.007750538218021393, "model_kl": 1.384076249885559, "prior_ent": 28.49998839416504, "post_ent": 27.117589959716796, "model_loss": 3773.09646171875, "model_loss_scale": 11036.2624, "model_grad_norm": 5.945896685791015, "actor_loss": 0.008090100439306115, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.062480541110038756, "critic_loss": 0.9355037227630615, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4213081319451332, "reward_mean": 0.0008079785613542299, "reward_std": 0.08137017686367035, "reward_normed_mean": 0.0008079785613542299, "reward_normed_std": 0.08137017686367035, "critic_slow": 6.728091698455811, "critic_target": 6.72756701965332, "actor_ent": 0.7772765104293823, "actor_ent_scale": 0.0010000000474974513, "critic": 6.726472129058838, "fps": 110.728611613812}
{"step": 7761524, "train_return": 19.0, "train_length": 1804.0, "train_total_steps": 1940381.0, "train_total_episodes": 940.0, "train_loaded_steps": 1940435.0, "train_loaded_episodes": 940.0}
{"step": 7768176, "train_return": 21.0, "train_length": 1663.0, "train_total_steps": 1942044.0, "train_total_episodes": 941.0, "train_loaded_steps": 1942098.0, "train_loaded_episodes": 941.0}
{"step": 7776484, "train_return": 13.0, "train_length": 2077.0, "train_total_steps": 1944121.0, "train_total_episodes": 942.0, "train_loaded_steps": 1944175.0, "train_loaded_episodes": 942.0}
{"step": 7784836, "train_return": 15.0, "train_length": 2088.0, "train_total_steps": 1946209.0, "train_total_episodes": 943.0, "train_loaded_steps": 1946263.0, "train_loaded_episodes": 943.0}
{"step": 7794240, "train_return": 14.0, "train_length": 2351.0, "train_total_steps": 1948560.0, "train_total_episodes": 944.0, "train_loaded_steps": 1948614.0, "train_loaded_episodes": 944.0}
{"step": 7801336, "train_return": 19.0, "train_length": 1774.0, "train_total_steps": 1950334.0, "train_total_episodes": 945.0, "train_loaded_steps": 1950388.0, "train_loaded_episodes": 945.0}
{"step": 7801356, "kl_loss": 1.3690331979751587, "image_loss": 3772.0, "reward_loss": 0.9192576096534729, "discount_loss": 0.007740764978528023, "model_kl": 1.3690331691741944, "prior_ent": 28.458961376953123, "post_ent": 27.092584130859375, "model_loss": 3773.094886328125, "model_loss_scale": 16384.0, "model_grad_norm": 6.1077115447998045, "actor_loss": 0.0076171914498670956, "actor_loss_scale": 4751307.5712, "actor_grad_norm": 0.05913811889886856, "critic_loss": 0.9336863083839416, "critic_loss_scale": 75916.9024, "critic_grad_norm": 0.4457885452628136, "reward_mean": 0.0008514508548032609, "reward_std": 0.081496669703722, "reward_normed_mean": 0.0008514508548032609, "reward_normed_std": 0.081496669703722, "critic_slow": 6.718331529998779, "critic_target": 6.717425043487549, "actor_ent": 0.8365772452354431, "actor_ent_scale": 0.0010000000474974513, "critic": 6.715651929473877, "fps": 111.33774269315421}
{"step": 7809172, "train_return": 16.0, "train_length": 1959.0, "train_total_steps": 1952293.0, "train_total_episodes": 946.0, "train_loaded_steps": 1952347.0, "train_loaded_episodes": 946.0}
{"step": 7817204, "train_return": 15.0, "train_length": 2008.0, "train_total_steps": 1954301.0, "train_total_episodes": 947.0, "train_loaded_steps": 1954355.0, "train_loaded_episodes": 947.0}
{"step": 7825084, "train_return": 16.0, "train_length": 1970.0, "train_total_steps": 1956271.0, "train_total_episodes": 948.0, "train_loaded_steps": 1956325.0, "train_loaded_episodes": 948.0}
{"step": 7833112, "train_return": 15.0, "train_length": 2007.0, "train_total_steps": 1958278.0, "train_total_episodes": 949.0, "train_loaded_steps": 1958332.0, "train_loaded_episodes": 949.0}
{"step": 7840620, "train_return": 17.0, "train_length": 1877.0, "train_total_steps": 1960155.0, "train_total_episodes": 950.0, "train_loaded_steps": 1960209.0, "train_loaded_episodes": 950.0}
{"step": 7841356, "kl_loss": 1.4088407815933228, "image_loss": 3772.0, "reward_loss": 0.9192564491271973, "discount_loss": 0.007749792886525392, "model_kl": 1.4088407455444336, "prior_ent": 28.481494744873046, "post_ent": 27.0860364654541, "model_loss": 3773.098915234375, "model_loss_scale": 16384.0, "model_grad_norm": 6.125459982299804, "actor_loss": -0.0002679518322023796, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06018669989705086, "critic_loss": 0.9336235182762146, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.46382926268577573, "reward_mean": 0.0008627320091000001, "reward_std": 0.08112428381443024, "reward_normed_mean": 0.0008627320091000001, "reward_normed_std": 0.08112428381443024, "critic_slow": 6.689574156188965, "critic_target": 6.681367211914062, "actor_ent": 0.8175796917915344, "actor_ent_scale": 0.0010000000474974513, "critic": 6.680125302124023, "fps": 110.242690938804}
{"step": 7847992, "train_return": 19.0, "train_length": 1843.0, "train_total_steps": 1961998.0, "train_total_episodes": 951.0, "train_loaded_steps": 1962052.0, "train_loaded_episodes": 951.0}
{"step": 7855796, "train_return": 17.0, "train_length": 1951.0, "train_total_steps": 1963949.0, "train_total_episodes": 952.0, "train_loaded_steps": 1964003.0, "train_loaded_episodes": 952.0}
{"step": 7863180, "train_return": 19.0, "train_length": 1846.0, "train_total_steps": 1965795.0, "train_total_episodes": 953.0, "train_loaded_steps": 1965849.0, "train_loaded_episodes": 953.0}
{"step": 7871068, "train_return": 18.0, "train_length": 1972.0, "train_total_steps": 1967767.0, "train_total_episodes": 954.0, "train_loaded_steps": 1967821.0, "train_loaded_episodes": 954.0}
{"step": 7879660, "train_return": 13.0, "train_length": 2148.0, "train_total_steps": 1969915.0, "train_total_episodes": 955.0, "train_loaded_steps": 1969969.0, "train_loaded_episodes": 955.0}
{"step": 7881356, "kl_loss": 1.3815393472671509, "image_loss": 3772.0, "reward_loss": 0.9192870017051696, "discount_loss": 0.007780887953191996, "model_kl": 1.3815393133163452, "prior_ent": 28.459057998657226, "post_ent": 27.084824816894532, "model_loss": 3773.096373046875, "model_loss_scale": 8336.1792, "model_grad_norm": Infinity, "actor_loss": 0.006168806317340932, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.058965669012069705, "critic_loss": 0.9340776118278503, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4604728685498238, "reward_mean": 0.0011860396446816595, "reward_std": 0.08057540363669395, "reward_normed_mean": 0.0011860396446816595, "reward_normed_std": 0.08057540363669395, "critic_slow": 6.642110669708252, "critic_target": 6.640260887145996, "actor_ent": 0.8012910847663879, "actor_ent_scale": 0.0010000000474974513, "critic": 6.639008997344971, "fps": 111.76117361031113}
{"step": 7888076, "train_return": 15.0, "train_length": 2104.0, "train_total_steps": 1972019.0, "train_total_episodes": 956.0, "train_loaded_steps": 1972073.0, "train_loaded_episodes": 956.0}
{"step": 7895168, "train_return": 20.0, "train_length": 1773.0, "train_total_steps": 1973792.0, "train_total_episodes": 957.0, "train_loaded_steps": 1973846.0, "train_loaded_episodes": 957.0}
{"step": 7903488, "train_return": 16.0, "train_length": 2080.0, "train_total_steps": 1975872.0, "train_total_episodes": 958.0, "train_loaded_steps": 1975926.0, "train_loaded_episodes": 958.0}
{"step": 7911428, "train_return": 17.0, "train_length": 1985.0, "train_total_steps": 1977857.0, "train_total_episodes": 959.0, "train_loaded_steps": 1977911.0, "train_loaded_episodes": 959.0}
{"step": 7919136, "train_return": 17.0, "train_length": 1927.0, "train_total_steps": 1979784.0, "train_total_episodes": 960.0, "train_loaded_steps": 1979838.0, "train_loaded_episodes": 960.0}
{"step": 7921356, "kl_loss": 1.4421272953033448, "image_loss": 3772.0, "reward_loss": 0.9192533017158508, "discount_loss": 0.007741779419779778, "model_kl": 1.4421272632598876, "prior_ent": 28.34420531311035, "post_ent": 26.928586837768556, "model_loss": 3773.1021953125, "model_loss_scale": 8192.0, "model_grad_norm": 6.000744771575928, "actor_loss": 0.0026076067225978476, "actor_loss_scale": 6603512.2176, "actor_grad_norm": Infinity, "critic_loss": 0.9357350425720214, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.5021162042975426, "reward_mean": 0.001160456581535982, "reward_std": 0.08069084060192108, "reward_normed_mean": 0.001160456581535982, "reward_normed_std": 0.08069084060192108, "critic_slow": 6.64472626953125, "critic_target": 6.638439811706543, "actor_ent": 0.7816618660926818, "actor_ent_scale": 0.0010000000474974513, "critic": 6.6375646484375, "fps": 109.74188674897829}
{"step": 7926292, "train_return": 20.0, "train_length": 1789.0, "train_total_steps": 1981573.0, "train_total_episodes": 961.0, "train_loaded_steps": 1981627.0, "train_loaded_episodes": 961.0}
{"step": 7935328, "train_return": 16.0, "train_length": 2259.0, "train_total_steps": 1983832.0, "train_total_episodes": 962.0, "train_loaded_steps": 1983886.0, "train_loaded_episodes": 962.0}
{"step": 7942968, "train_return": 17.0, "train_length": 1910.0, "train_total_steps": 1985742.0, "train_total_episodes": 963.0, "train_loaded_steps": 1985796.0, "train_loaded_episodes": 963.0}
{"step": 7950884, "train_return": 17.0, "train_length": 1979.0, "train_total_steps": 1987721.0, "train_total_episodes": 964.0, "train_loaded_steps": 1987775.0, "train_loaded_episodes": 964.0}
{"step": 7957940, "train_return": 19.0, "train_length": 1764.0, "train_total_steps": 1989485.0, "train_total_episodes": 965.0, "train_loaded_steps": 1989539.0, "train_loaded_episodes": 965.0}
{"step": 7961356, "kl_loss": 1.38357347240448, "image_loss": 3772.0, "reward_loss": 0.91926481924057, "discount_loss": 0.007741092651337385, "model_kl": 1.38357344455719, "prior_ent": 28.310945108032225, "post_ent": 26.934492111206055, "model_loss": 3773.096351171875, "model_loss_scale": 8192.0, "model_grad_norm": 6.089608314704895, "actor_loss": 0.0012261437107619713, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.05933190486431122, "critic_loss": 0.933812225818634, "critic_loss_scale": 133169.152, "critic_grad_norm": Infinity, "reward_mean": 0.0013196682737296214, "reward_std": 0.08083434973955154, "reward_normed_mean": 0.0013196682737296214, "reward_normed_std": 0.08083434973955154, "critic_slow": 6.627748812103271, "critic_target": 6.623037452697754, "actor_ent": 0.8184967024803161, "actor_ent_scale": 0.0010000000474974513, "critic": 6.622221446990967, "fps": 112.50525284869597}
{"step": 7965308, "train_return": 18.0, "train_length": 1842.0, "train_total_steps": 1991327.0, "train_total_episodes": 966.0, "train_loaded_steps": 1991381.0, "train_loaded_episodes": 966.0}
{"step": 7973480, "train_return": 15.0, "train_length": 2043.0, "train_total_steps": 1993370.0, "train_total_episodes": 967.0, "train_loaded_steps": 1993424.0, "train_loaded_episodes": 967.0}
{"step": 7981352, "train_return": 17.0, "train_length": 1968.0, "train_total_steps": 1995338.0, "train_total_episodes": 968.0, "train_loaded_steps": 1995392.0, "train_loaded_episodes": 968.0}
{"step": 7989104, "train_return": 17.0, "train_length": 1938.0, "train_total_steps": 1997276.0, "train_total_episodes": 969.0, "train_loaded_steps": 1997330.0, "train_loaded_episodes": 969.0}
{"step": 7996824, "train_return": 18.0, "train_length": 1930.0, "train_total_steps": 1999206.0, "train_total_episodes": 970.0, "train_loaded_steps": 1999260.0, "train_loaded_episodes": 970.0}
{"step": 8001356, "kl_loss": 1.3920901058197022, "image_loss": 3772.0, "reward_loss": 0.919263462638855, "discount_loss": 0.007756360827386379, "model_kl": 1.3920900789260864, "prior_ent": 28.312637689208984, "post_ent": 26.929638967895507, "model_loss": 3773.097280078125, "model_loss_scale": 14601.4208, "model_grad_norm": 6.175076885604859, "actor_loss": 0.006090036344213877, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.05796787494122982, "critic_loss": 0.9335865334510803, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.46341149349212646, "reward_mean": 0.0013764502133097266, "reward_std": 0.0803245979130268, "reward_normed_mean": 0.0013764502133097266, "reward_normed_std": 0.0803245979130268, "critic_slow": 6.606591911315918, "critic_target": 6.604625986480713, "actor_ent": 0.8210231431961059, "actor_ent_scale": 0.0010000000474974513, "critic": 6.603790425109863, "fps": 111.45326615889145}
{"step": 8003480, "train_return": 21.0, "train_length": 1664.0, "train_total_steps": 2000870.0, "train_total_episodes": 971.0, "train_loaded_steps": 1999132.0, "train_loaded_episodes": 969.0}
{"step": 8010344, "train_return": 20.0, "train_length": 1716.0, "train_total_steps": 2002586.0, "train_total_episodes": 972.0, "train_loaded_steps": 1999003.0, "train_loaded_episodes": 968.0}
{"step": 8018088, "train_return": 17.0, "train_length": 1936.0, "train_total_steps": 2004522.0, "train_total_episodes": 973.0, "train_loaded_steps": 1999703.0, "train_loaded_episodes": 968.0}
{"step": 8026712, "train_return": 13.0, "train_length": 2156.0, "train_total_steps": 2006678.0, "train_total_episodes": 974.0, "train_loaded_steps": 1999904.0, "train_loaded_episodes": 967.0}
{"step": 8034072, "train_return": 18.0, "train_length": 1840.0, "train_total_steps": 2008518.0, "train_total_episodes": 975.0, "train_loaded_steps": 1999958.0, "train_loaded_episodes": 966.0}
{"step": 8041356, "kl_loss": 1.4097731950759889, "image_loss": 3772.0, "reward_loss": 0.9192805294036865, "discount_loss": 0.007841450800001622, "model_kl": 1.4097731657028199, "prior_ent": 28.44940194091797, "post_ent": 27.05367135925293, "model_loss": 3773.099497265625, "model_loss_scale": 16384.0, "model_grad_norm": 6.096334233474732, "actor_loss": 0.0041689860251965, "actor_loss_scale": 5140538.9824, "actor_grad_norm": 0.058096371561288836, "critic_loss": 0.9367306123733521, "critic_loss_scale": 78223.7696, "critic_grad_norm": Infinity, "reward_mean": 0.0013058151857403572, "reward_std": 0.08082422753572464, "reward_normed_mean": 0.0013058151857403572, "reward_normed_std": 0.08082422753572464, "critic_slow": 6.591372342681884, "critic_target": 6.587867727661132, "actor_ent": 0.8306807242393494, "actor_ent_scale": 0.0010000000474974513, "critic": 6.587055268859864, "fps": 112.03748848841647}
{"step": 8043692, "train_return": 11.0, "train_length": 2405.0, "train_total_steps": 2010923.0, "train_total_episodes": 976.0, "train_loaded_steps": 1999579.0, "train_loaded_episodes": 964.0}
{"step": 8051848, "train_return": 16.0, "train_length": 2039.0, "train_total_steps": 2012962.0, "train_total_episodes": 977.0, "train_loaded_steps": 1999522.0, "train_loaded_episodes": 963.0}
{"step": 8060616, "train_return": 15.0, "train_length": 2192.0, "train_total_steps": 2015154.0, "train_total_episodes": 978.0, "train_loaded_steps": 1999611.0, "train_loaded_episodes": 962.0}
{"step": 8069440, "train_return": 13.0, "train_length": 2206.0, "train_total_steps": 2017360.0, "train_total_episodes": 979.0, "train_loaded_steps": 1999209.0, "train_loaded_episodes": 960.0}
{"step": 8077136, "train_return": 19.0, "train_length": 1924.0, "train_total_steps": 2019284.0, "train_total_episodes": 980.0, "train_loaded_steps": 1999330.0, "train_loaded_episodes": 959.0}
{"step": 8081356, "kl_loss": 1.4031357595443725, "image_loss": 3772.0, "reward_loss": 0.9192609552383423, "discount_loss": 0.007742752020061016, "model_kl": 1.4031357224464416, "prior_ent": 28.312947122192384, "post_ent": 26.923169525146484, "model_loss": 3773.0983078125, "model_loss_scale": 8375.5008, "model_grad_norm": Infinity, "actor_loss": 0.001129960511586796, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.058705381792783735, "critic_loss": 0.9338327965736389, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.43427159905433654, "reward_mean": 0.0013392382296005963, "reward_std": 0.08146275188922882, "reward_normed_mean": 0.0013392382296005963, "reward_normed_std": 0.08146275188922882, "critic_slow": 6.506901414489746, "critic_target": 6.503415212249756, "actor_ent": 0.7873327995300293, "actor_ent_scale": 0.0010000000474974513, "critic": 6.503114701080322, "fps": 110.38124747267732}
{"step": 8085464, "train_return": 17.0, "train_length": 2082.0, "train_total_steps": 2021366.0, "train_total_episodes": 981.0, "train_loaded_steps": 1999567.0, "train_loaded_episodes": 958.0}
{"step": 8094152, "train_return": 16.0, "train_length": 2172.0, "train_total_steps": 2023538.0, "train_total_episodes": 982.0, "train_loaded_steps": 1999058.0, "train_loaded_episodes": 956.0}
{"step": 8101932, "train_return": 17.0, "train_length": 1945.0, "train_total_steps": 2025483.0, "train_total_episodes": 983.0, "train_loaded_steps": 1999355.0, "train_loaded_episodes": 955.0}
{"step": 8110072, "train_return": 16.0, "train_length": 2035.0, "train_total_steps": 2027518.0, "train_total_episodes": 984.0, "train_loaded_steps": 1999589.0, "train_loaded_episodes": 954.0}
{"step": 8119016, "train_return": 15.0, "train_length": 2236.0, "train_total_steps": 2029754.0, "train_total_episodes": 985.0, "train_loaded_steps": 1999933.0, "train_loaded_episodes": 953.0}
{"step": 8121356, "kl_loss": 1.496529132461548, "image_loss": 3772.0, "reward_loss": 0.9193172617912293, "discount_loss": 0.007761429860442877, "model_kl": 1.4965290979385375, "prior_ent": 28.30388080444336, "post_ent": 26.83793469543457, "model_loss": 3773.10780078125, "model_loss_scale": 8192.0, "model_grad_norm": 6.000327843284607, "actor_loss": 0.008972118601106922, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.06219766276478767, "critic_loss": 0.9369208355903625, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.5129753650307656, "reward_mean": 0.0016547498741652817, "reward_std": 0.08025895144939423, "reward_normed_mean": 0.0016547498741652817, "reward_normed_std": 0.08025895144939423, "critic_slow": 6.528663942718506, "critic_target": 6.529830571746826, "actor_ent": 0.776890126132965, "actor_ent_scale": 0.0010000000474974513, "critic": 6.529474474334717, "fps": 110.00893187325114}
{"step": 8126188, "train_return": 20.0, "train_length": 1793.0, "train_total_steps": 2031547.0, "train_total_episodes": 986.0, "train_loaded_steps": 1999951.0, "train_loaded_episodes": 952.0}
{"step": 8133460, "train_return": 18.0, "train_length": 1818.0, "train_total_steps": 2033365.0, "train_total_episodes": 987.0, "train_loaded_steps": 1999684.0, "train_loaded_episodes": 951.0}
{"step": 8141256, "train_return": 16.0, "train_length": 1949.0, "train_total_steps": 2035314.0, "train_total_episodes": 988.0, "train_loaded_steps": 1999923.0, "train_loaded_episodes": 950.0}
{"step": 8148648, "train_return": 20.0, "train_length": 1848.0, "train_total_steps": 2037162.0, "train_total_episodes": 989.0, "train_loaded_steps": 1999923.0, "train_loaded_episodes": 949.0}
{"step": 8156380, "train_return": 18.0, "train_length": 1933.0, "train_total_steps": 2039095.0, "train_total_episodes": 990.0, "train_loaded_steps": 1999916.0, "train_loaded_episodes": 948.0}
{"step": 8161356, "kl_loss": 1.4267744297027587, "image_loss": 3772.000187890625, "reward_loss": 0.9193013048171997, "discount_loss": 0.007782341161370277, "model_kl": 1.4267743934631347, "prior_ent": 28.377570153808595, "post_ent": 26.955127951049803, "model_loss": 3773.1011046875, "model_loss_scale": 8192.0, "model_grad_norm": 6.148640468025207, "actor_loss": 0.007158511222360539, "actor_loss_scale": 8563091.0464, "actor_grad_norm": Infinity, "critic_loss": 0.9360107845306397, "critic_loss_scale": 105277.0304, "critic_grad_norm": 0.45792599297761916, "reward_mean": 0.001606146265823918, "reward_std": 0.07982564564943313, "reward_normed_mean": 0.001606146265823918, "reward_normed_std": 0.07982564564943313, "critic_slow": 6.629149229431152, "critic_target": 6.628686562347412, "actor_ent": 0.8037572370529175, "actor_ent_scale": 0.0010000000474974513, "critic": 6.62842784576416, "fps": 110.03269361294055}
{"step": 8164968, "train_return": 15.0, "train_length": 2147.0, "train_total_steps": 2041242.0, "train_total_episodes": 991.0, "train_loaded_steps": 1999966.0, "train_loaded_episodes": 947.0}
{"step": 8173164, "train_return": 15.0, "train_length": 2049.0, "train_total_steps": 2043291.0, "train_total_episodes": 992.0, "train_loaded_steps": 1999457.0, "train_loaded_episodes": 945.0}
{"step": 8182388, "train_return": 11.0, "train_length": 2306.0, "train_total_steps": 2045597.0, "train_total_episodes": 993.0, "train_loaded_steps": 1999892.0, "train_loaded_episodes": 944.0}
{"step": 8189800, "train_return": 17.0, "train_length": 1853.0, "train_total_steps": 2047450.0, "train_total_episodes": 994.0, "train_loaded_steps": 1999047.0, "train_loaded_episodes": 942.0}
{"step": 8198256, "train_return": 18.0, "train_length": 2114.0, "train_total_steps": 2049564.0, "train_total_episodes": 995.0, "train_loaded_steps": 1999226.0, "train_loaded_episodes": 941.0}
{"step": 8201352, "eval_return": 14.0, "eval_length": 2395.0, "eval_total_steps": 19519.0, "eval_total_episodes": 10.0, "eval_loaded_steps": 19521.0, "eval_loaded_episodes": 10.0}
{"step": 8201356, "kl_loss": 1.3969119777679444, "image_loss": 3772.0, "reward_loss": 0.9192540843963624, "discount_loss": 0.007741148379445076, "model_kl": 1.3969119432449342, "prior_ent": 28.308693353271483, "post_ent": 26.919020123291016, "model_loss": 3773.09767578125, "model_loss_scale": 14562.0992, "model_grad_norm": 6.03175389328003, "actor_loss": 0.005798734582448378, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.05990696866512298, "critic_loss": 0.9348097781181336, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.47664547976255417, "reward_mean": 0.0018439646453145542, "reward_std": 0.08051718854308128, "reward_normed_mean": 0.0018439646453145542, "reward_normed_std": 0.08051718854308128, "critic_slow": 6.566433627319336, "critic_target": 6.568317523956299, "actor_ent": 0.8165743762016296, "actor_ent_scale": 0.0010000000474974513, "critic": 6.567865375518799, "fps": 104.2711818061492}
{"step": 8206140, "train_return": 16.0, "train_length": 1971.0, "train_total_steps": 2051535.0, "train_total_episodes": 996.0, "train_loaded_steps": 1999454.0, "train_loaded_episodes": 940.0}
{"step": 8212756, "train_return": 21.0, "train_length": 1654.0, "train_total_steps": 2053189.0, "train_total_episodes": 997.0, "train_loaded_steps": 1999432.0, "train_loaded_episodes": 939.0}
{"step": 8221324, "train_return": 14.0, "train_length": 2142.0, "train_total_steps": 2055331.0, "train_total_episodes": 998.0, "train_loaded_steps": 1999234.0, "train_loaded_episodes": 937.0}
{"step": 8230348, "train_return": 14.0, "train_length": 2256.0, "train_total_steps": 2057587.0, "train_total_episodes": 999.0, "train_loaded_steps": 1999780.0, "train_loaded_episodes": 936.0}
{"step": 8238380, "train_return": 17.0, "train_length": 2008.0, "train_total_steps": 2059595.0, "train_total_episodes": 1000.0, "train_loaded_steps": 1999822.0, "train_loaded_episodes": 935.0}
{"step": 8241356, "kl_loss": 1.3866976358413696, "image_loss": 3772.0, "reward_loss": 0.9192426251411439, "discount_loss": 0.007750161395967007, "model_kl": 1.3866976081848144, "prior_ent": 28.306646676635744, "post_ent": 26.93280559387207, "model_loss": 3773.096690625, "model_loss_scale": 16384.0, "model_grad_norm": 6.1045551731109615, "actor_loss": 0.0066549683845776595, "actor_loss_scale": 4865392.64, "actor_grad_norm": Infinity, "critic_loss": 0.933500324344635, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.505438441169262, "reward_mean": 0.0019218067111534765, "reward_std": 0.08010376486182212, "reward_normed_mean": 0.0019218067111534765, "reward_normed_std": 0.08010376486182212, "critic_slow": 6.629144871520996, "critic_target": 6.628422579193115, "actor_ent": 0.8510324279785156, "actor_ent_scale": 0.0010000000474974513, "critic": 6.627933506774903, "fps": 109.47331403440074}
{"step": 8246892, "train_return": 13.0, "train_length": 2128.0, "train_total_steps": 2061723.0, "train_total_episodes": 1001.0, "train_loaded_steps": 1999415.0, "train_loaded_episodes": 933.0}
{"step": 8253904, "train_return": 20.0, "train_length": 1753.0, "train_total_steps": 2063476.0, "train_total_episodes": 1002.0, "train_loaded_steps": 1999382.0, "train_loaded_episodes": 932.0}
{"step": 8261456, "train_return": 18.0, "train_length": 1888.0, "train_total_steps": 2065364.0, "train_total_episodes": 1003.0, "train_loaded_steps": 1999522.0, "train_loaded_episodes": 931.0}
{"step": 8270308, "train_return": 15.0, "train_length": 2213.0, "train_total_steps": 2067577.0, "train_total_episodes": 1004.0, "train_loaded_steps": 1999921.0, "train_loaded_episodes": 930.0}
{"step": 8278108, "train_return": 17.0, "train_length": 1950.0, "train_total_steps": 2069527.0, "train_total_episodes": 1005.0, "train_loaded_steps": 1999293.0, "train_loaded_episodes": 928.0}
{"step": 8281356, "kl_loss": 1.3842490301132202, "image_loss": 3772.0, "reward_loss": 0.9193167117118836, "discount_loss": 0.007746107954531908, "model_kl": 1.3842489967346192, "prior_ent": 28.221763162231444, "post_ent": 26.848198861694335, "model_loss": 3773.096505078125, "model_loss_scale": 16384.0, "model_grad_norm": 6.152361581039429, "actor_loss": 0.002019458383890742, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.058193721359968184, "critic_loss": 0.935834626865387, "critic_loss_scale": 73190.6048, "critic_grad_norm": Infinity, "reward_mean": 0.0023596705310777906, "reward_std": 0.07921783308386803, "reward_normed_mean": 0.0023596705310777906, "reward_normed_std": 0.07921783308386803, "critic_slow": 6.645285641479492, "critic_target": 6.644564875030517, "actor_ent": 0.9046077719688416, "actor_ent_scale": 0.0010000000474974513, "critic": 6.644456871032715, "fps": 112.14772493975957}
{"step": 8285628, "train_return": 19.0, "train_length": 1880.0, "train_total_steps": 2071407.0, "train_total_episodes": 1006.0, "train_loaded_steps": 1999404.0, "train_loaded_episodes": 927.0}
{"step": 8294508, "train_return": 14.0, "train_length": 2220.0, "train_total_steps": 2073627.0, "train_total_episodes": 1007.0, "train_loaded_steps": 1999592.0, "train_loaded_episodes": 926.0}
{"step": 8302632, "train_return": 15.0, "train_length": 2031.0, "train_total_steps": 2075658.0, "train_total_episodes": 1008.0, "train_loaded_steps": 1999985.0, "train_loaded_episodes": 925.0}
{"step": 8310684, "train_return": 18.0, "train_length": 2013.0, "train_total_steps": 2077671.0, "train_total_episodes": 1009.0, "train_loaded_steps": 1999426.0, "train_loaded_episodes": 923.0}
{"step": 8318224, "train_return": 18.0, "train_length": 1885.0, "train_total_steps": 2079556.0, "train_total_episodes": 1010.0, "train_loaded_steps": 1999027.0, "train_loaded_episodes": 922.0}
{"step": 8321356, "kl_loss": 1.381963384437561, "image_loss": 3772.0002, "reward_loss": 0.9192667193412781, "discount_loss": 0.007748399565368891, "model_kl": 1.381963348197937, "prior_ent": 28.149155612182618, "post_ent": 26.776219580078124, "model_loss": 3773.096433203125, "model_loss_scale": 18586.0096, "model_grad_norm": Infinity, "actor_loss": 0.001834906326897908, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06003660832643509, "critic_loss": 0.9355827748298645, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.46922950892448423, "reward_mean": 0.0023274053349217868, "reward_std": 0.07930688957571984, "reward_normed_mean": 0.0023274053349217868, "reward_normed_std": 0.07930688957571984, "critic_slow": 6.634564476776123, "critic_target": 6.632977755737305, "actor_ent": 0.8949741973876953, "actor_ent_scale": 0.0010000000474974513, "critic": 6.632633129882812, "fps": 111.35202981059551}
{"step": 8327644, "train_return": 13.0, "train_length": 2355.0, "train_total_steps": 2081911.0, "train_total_episodes": 1011.0, "train_loaded_steps": 1999472.0, "train_loaded_episodes": 921.0}
{"step": 8334900, "train_return": 19.0, "train_length": 1814.0, "train_total_steps": 2083725.0, "train_total_episodes": 1012.0, "train_loaded_steps": 1999555.0, "train_loaded_episodes": 920.0}
{"step": 8342956, "train_return": 16.0, "train_length": 2014.0, "train_total_steps": 2085739.0, "train_total_episodes": 1013.0, "train_loaded_steps": 1999931.0, "train_loaded_episodes": 919.0}
{"step": 8351536, "train_return": 16.0, "train_length": 2145.0, "train_total_steps": 2087884.0, "train_total_episodes": 1014.0, "train_loaded_steps": 1999292.0, "train_loaded_episodes": 917.0}
{"step": 8360304, "train_return": 14.0, "train_length": 2192.0, "train_total_steps": 2090076.0, "train_total_episodes": 1015.0, "train_loaded_steps": 1999695.0, "train_loaded_episodes": 916.0}
{"step": 8361356, "kl_loss": 1.4194885347366333, "image_loss": 3772.0, "reward_loss": 0.9192574112892151, "discount_loss": 0.007787921945005655, "model_kl": 1.4194885019302368, "prior_ent": 28.286808279418945, "post_ent": 26.88309230041504, "model_loss": 3773.10016953125, "model_loss_scale": 8192.0, "model_grad_norm": 5.862133152389526, "actor_loss": 0.0046137735337601045, "actor_loss_scale": 4731174.912, "actor_grad_norm": Infinity, "critic_loss": 0.9371866057395936, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.5094388190150261, "reward_mean": 0.0027390820131404326, "reward_std": 0.07974903324246406, "reward_normed_mean": 0.0027390820131404326, "reward_normed_std": 0.07974903324246406, "critic_slow": 6.698261526489258, "critic_target": 6.693158039093017, "actor_ent": 0.8592202369689942, "actor_ent_scale": 0.0010000000474974513, "critic": 6.692524179840088, "fps": 110.45836393588763}
{"step": 8367264, "train_return": 20.0, "train_length": 1740.0, "train_total_steps": 2091816.0, "train_total_episodes": 1016.0, "train_loaded_steps": 1999665.0, "train_loaded_episodes": 915.0}
{"step": 8375068, "train_return": 16.0, "train_length": 1951.0, "train_total_steps": 2093767.0, "train_total_episodes": 1017.0, "train_loaded_steps": 1999959.0, "train_loaded_episodes": 914.0}
{"step": 8382792, "train_return": 17.0, "train_length": 1931.0, "train_total_steps": 2095698.0, "train_total_episodes": 1018.0, "train_loaded_steps": 1999978.0, "train_loaded_episodes": 913.0}
{"step": 8390516, "train_return": 17.0, "train_length": 1931.0, "train_total_steps": 2097629.0, "train_total_episodes": 1019.0, "train_loaded_steps": 1999933.0, "train_loaded_episodes": 912.0}
{"step": 8397212, "train_return": 20.0, "train_length": 1674.0, "train_total_steps": 2099303.0, "train_total_episodes": 1020.0, "train_loaded_steps": 1999699.0, "train_loaded_episodes": 911.0}
{"step": 8401356, "kl_loss": 1.4103110023498535, "image_loss": 3772.0, "reward_loss": 0.9192643001556396, "discount_loss": 0.007778261484205723, "model_kl": 1.4103109697341918, "prior_ent": 28.24668517150879, "post_ent": 26.857066122436525, "model_loss": 3773.099225, "model_loss_scale": 8192.0, "model_grad_norm": 6.117722233963013, "actor_loss": -0.0031512762641184963, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.058329805478453636, "critic_loss": 0.935408948135376, "critic_loss_scale": 110310.1952, "critic_grad_norm": 0.4844627934336662, "reward_mean": 0.0028487899524276146, "reward_std": 0.07933701114654541, "reward_normed_mean": 0.0028487899524276146, "reward_normed_std": 0.07933701114654541, "critic_slow": 6.608551732635498, "critic_target": 6.602157994842529, "actor_ent": 0.8759047041893006, "actor_ent_scale": 0.0010000000474974513, "critic": 6.601646990203857, "fps": 111.27763593125782}
{"step": 8405808, "train_return": 16.0, "train_length": 2149.0, "train_total_steps": 2101452.0, "train_total_episodes": 1021.0, "train_loaded_steps": 1999426.0, "train_loaded_episodes": 909.0}
{"step": 8415124, "train_return": 15.0, "train_length": 2329.0, "train_total_steps": 2103781.0, "train_total_episodes": 1022.0, "train_loaded_steps": 1999229.0, "train_loaded_episodes": 907.0}
{"step": 8422036, "train_return": 20.0, "train_length": 1728.0, "train_total_steps": 2105509.0, "train_total_episodes": 1023.0, "train_loaded_steps": 1999346.0, "train_loaded_episodes": 906.0}
{"step": 8429320, "train_return": 20.0, "train_length": 1821.0, "train_total_steps": 2107330.0, "train_total_episodes": 1024.0, "train_loaded_steps": 1999409.0, "train_loaded_episodes": 905.0}
{"step": 8436836, "train_return": 17.0, "train_length": 1879.0, "train_total_steps": 2109209.0, "train_total_episodes": 1025.0, "train_loaded_steps": 1999448.0, "train_loaded_episodes": 904.0}
{"step": 8441356, "kl_loss": 1.4266733751296996, "image_loss": 3772.0, "reward_loss": 0.9192282605171204, "discount_loss": 0.0077776750735938545, "model_kl": 1.4266733459472656, "prior_ent": 28.076421194458007, "post_ent": 26.6640174407959, "model_loss": 3773.100816796875, "model_loss_scale": 8192.0, "model_grad_norm": 6.039530463027954, "actor_loss": 0.0013444327721783339, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.05802167367935181, "critic_loss": 0.9344397315979004, "critic_loss_scale": 68576.8704, "critic_grad_norm": Infinity, "reward_mean": 0.003022327368911647, "reward_std": 0.07925903694033623, "reward_normed_mean": 0.003022327368911647, "reward_normed_std": 0.07925903694033623, "critic_slow": 6.618318037414551, "critic_target": 6.614855013275147, "actor_ent": 0.9242462130546569, "actor_ent_scale": 0.0010000000474974513, "critic": 6.614665686798095, "fps": 111.4584869553525}
{"step": 8445936, "train_return": 12.0, "train_length": 2275.0, "train_total_steps": 2111484.0, "train_total_episodes": 1026.0, "train_loaded_steps": 1999912.0, "train_loaded_episodes": 903.0}
{"step": 8453580, "train_return": 18.0, "train_length": 1911.0, "train_total_steps": 2113395.0, "train_total_episodes": 1027.0, "train_loaded_steps": 1999257.0, "train_loaded_episodes": 901.0}
{"step": 8461476, "train_return": 18.0, "train_length": 1974.0, "train_total_steps": 2115369.0, "train_total_episodes": 1028.0, "train_loaded_steps": 1999712.0, "train_loaded_episodes": 900.0}
{"step": 8468680, "train_return": 19.0, "train_length": 1801.0, "train_total_steps": 2117170.0, "train_total_episodes": 1029.0, "train_loaded_steps": 1999992.0, "train_loaded_episodes": 899.0}
{"step": 8476680, "train_return": 16.0, "train_length": 2000.0, "train_total_steps": 2119170.0, "train_total_episodes": 1030.0, "train_loaded_steps": 1999711.0, "train_loaded_episodes": 897.0}
{"step": 8481356, "kl_loss": 1.4036653619766235, "image_loss": 3772.0, "reward_loss": 0.9192408433914184, "discount_loss": 0.007755779922008515, "model_kl": 1.403665326499939, "prior_ent": 28.14120031738281, "post_ent": 26.74948704223633, "model_loss": 3773.09841796875, "model_loss_scale": 8414.8224, "model_grad_norm": Infinity, "actor_loss": -0.0018465670547215267, "actor_loss_scale": 5502926.848, "actor_grad_norm": 0.05570072378516197, "critic_loss": 0.9341995662689209, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4715207546234131, "reward_mean": 0.0032307262232832727, "reward_std": 0.07949801594018936, "reward_normed_mean": 0.0032307262232832727, "reward_normed_std": 0.07949801594018936, "critic_slow": 6.678577851867676, "critic_target": 6.6735712387084964, "actor_ent": 0.9472935765266418, "actor_ent_scale": 0.0010000000474974513, "critic": 6.67312755203247, "fps": 110.91546195202949}
{"step": 8483756, "train_return": 20.0, "train_length": 1769.0, "train_total_steps": 2120939.0, "train_total_episodes": 1031.0, "train_loaded_steps": 1999954.0, "train_loaded_episodes": 896.0}
{"step": 8491752, "train_return": 15.0, "train_length": 1999.0, "train_total_steps": 2122938.0, "train_total_episodes": 1032.0, "train_loaded_steps": 1999670.0, "train_loaded_episodes": 894.0}
{"step": 8499952, "train_return": 15.0, "train_length": 2050.0, "train_total_steps": 2124988.0, "train_total_episodes": 1033.0, "train_loaded_steps": 1999438.0, "train_loaded_episodes": 892.0}
{"step": 8506656, "train_return": 20.0, "train_length": 1676.0, "train_total_steps": 2126664.0, "train_total_episodes": 1034.0, "train_loaded_steps": 1999593.0, "train_loaded_episodes": 891.0}
{"step": 8514216, "train_return": 18.0, "train_length": 1890.0, "train_total_steps": 2128554.0, "train_total_episodes": 1035.0, "train_loaded_steps": 1999961.0, "train_loaded_episodes": 890.0}
{"step": 8521356, "kl_loss": 1.417682944869995, "image_loss": 3772.0, "reward_loss": 0.9192510020256043, "discount_loss": 0.0077718242824077605, "model_kl": 1.4176829135894775, "prior_ent": 28.11649047241211, "post_ent": 26.710560916137695, "model_loss": 3773.09990546875, "model_loss_scale": 8192.0, "model_grad_norm": 6.237206093788147, "actor_loss": -0.001018815448868554, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.056753232634067535, "critic_loss": 0.9355428663253784, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.44593180533647536, "reward_mean": 0.0034107083811046324, "reward_std": 0.07818047857284546, "reward_normed_mean": 0.0034107083811046324, "reward_normed_std": 0.07818047857284546, "critic_slow": 6.677489192199707, "critic_target": 6.674417659759522, "actor_ent": 1.0062183653831482, "actor_ent_scale": 0.0010000000474974513, "critic": 6.674222322082519, "fps": 110.173342806302}
{"step": 8522808, "train_return": 15.0, "train_length": 2148.0, "train_total_steps": 2130702.0, "train_total_episodes": 1036.0, "train_loaded_steps": 1999825.0, "train_loaded_episodes": 888.0}
{"step": 8529656, "train_return": 20.0, "train_length": 1712.0, "train_total_steps": 2132414.0, "train_total_episodes": 1037.0, "train_loaded_steps": 1999255.0, "train_loaded_episodes": 886.0}
{"step": 8538440, "train_return": 15.0, "train_length": 2196.0, "train_total_steps": 2134610.0, "train_total_episodes": 1038.0, "train_loaded_steps": 1999932.0, "train_loaded_episodes": 885.0}
{"step": 8545784, "train_return": 19.0, "train_length": 1836.0, "train_total_steps": 2136446.0, "train_total_episodes": 1039.0, "train_loaded_steps": 1999488.0, "train_loaded_episodes": 883.0}
{"step": 8555484, "train_return": 12.0, "train_length": 2425.0, "train_total_steps": 2138871.0, "train_total_episodes": 1040.0, "train_loaded_steps": 1999629.0, "train_loaded_episodes": 881.0}
{"step": 8561356, "kl_loss": 1.424639467048645, "image_loss": 3772.0, "reward_loss": 0.9192501285552979, "discount_loss": 0.007746096514165401, "model_kl": 1.4246394329071046, "prior_ent": 28.125666577148436, "post_ent": 26.711957116699217, "model_loss": 3773.100482421875, "model_loss_scale": 8192.0, "model_grad_norm": 5.955240411376953, "actor_loss": 0.0015206174135222682, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.05650411283969879, "critic_loss": 0.9333145776748657, "critic_loss_scale": 114923.9296, "critic_grad_norm": 0.4722375547647476, "reward_mean": 0.003852934310764249, "reward_std": 0.07788396400809287, "reward_normed_mean": 0.003852934310764249, "reward_normed_std": 0.07788396400809287, "critic_slow": 6.721684815979004, "critic_target": 6.718207511901856, "actor_ent": 0.9897606207847596, "actor_ent_scale": 0.0010000000474974513, "critic": 6.718133791351319, "fps": 111.01539131793001}
{"step": 8563640, "train_return": 18.0, "train_length": 2039.0, "train_total_steps": 2140910.0, "train_total_episodes": 1041.0, "train_loaded_steps": 1999382.0, "train_loaded_episodes": 879.0}
{"step": 8570952, "train_return": 19.0, "train_length": 1828.0, "train_total_steps": 2142738.0, "train_total_episodes": 1042.0, "train_loaded_steps": 1999692.0, "train_loaded_episodes": 878.0}
{"step": 8578364, "train_return": 18.0, "train_length": 1853.0, "train_total_steps": 2144591.0, "train_total_episodes": 1043.0, "train_loaded_steps": 1999964.0, "train_loaded_episodes": 877.0}
{"step": 8586236, "train_return": 16.0, "train_length": 1968.0, "train_total_steps": 2146559.0, "train_total_episodes": 1044.0, "train_loaded_steps": 1999601.0, "train_loaded_episodes": 875.0}
{"step": 8595532, "train_return": 12.0, "train_length": 2324.0, "train_total_steps": 2148883.0, "train_total_episodes": 1045.0, "train_loaded_steps": 1999402.0, "train_loaded_episodes": 873.0}
{"step": 8601356, "kl_loss": 1.4651829608917237, "image_loss": 3772.0, "reward_loss": 0.919240353679657, "discount_loss": 0.0077426331207156186, "model_kl": 1.4651829208374023, "prior_ent": 28.161566375732423, "post_ent": 26.71174385986328, "model_loss": 3773.104503125, "model_loss_scale": 13906.7392, "model_grad_norm": 6.1235328392028805, "actor_loss": -0.0005205345866037532, "actor_loss_scale": 8643621.6832, "actor_grad_norm": Infinity, "critic_loss": 0.9350091832160949, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.5221456690907479, "reward_mean": 0.004191936549049569, "reward_std": 0.07778346043229104, "reward_normed_mean": 0.004191936549049569, "reward_normed_std": 0.07778346043229104, "critic_slow": 6.629700923919677, "critic_target": 6.62664729385376, "actor_ent": 0.9645498929023743, "actor_ent_scale": 0.0010000000474974513, "critic": 6.626298796081543, "fps": 110.7904641869641}
{"step": 8602384, "train_return": 20.0, "train_length": 1713.0, "train_total_steps": 2150596.0, "train_total_episodes": 1046.0, "train_loaded_steps": 1999490.0, "train_loaded_episodes": 872.0}
{"step": 8610648, "train_return": 15.0, "train_length": 2066.0, "train_total_steps": 2152662.0, "train_total_episodes": 1047.0, "train_loaded_steps": 1999777.0, "train_loaded_episodes": 871.0}
{"step": 8618124, "train_return": 18.0, "train_length": 1869.0, "train_total_steps": 2154531.0, "train_total_episodes": 1048.0, "train_loaded_steps": 1999506.0, "train_loaded_episodes": 870.0}
{"step": 8627332, "train_return": 12.0, "train_length": 2302.0, "train_total_steps": 2156833.0, "train_total_episodes": 1049.0, "train_loaded_steps": 1999029.0, "train_loaded_episodes": 869.0}
{"step": 8636020, "train_return": 15.0, "train_length": 2172.0, "train_total_steps": 2159005.0, "train_total_episodes": 1050.0, "train_loaded_steps": 1999401.0, "train_loaded_episodes": 869.0}
{"step": 8641356, "kl_loss": 1.4581397409439087, "image_loss": 3772.0, "reward_loss": 0.9192413084983826, "discount_loss": 0.007742088770866394, "model_kl": 1.458139706993103, "prior_ent": 28.027644952392578, "post_ent": 26.58750403137207, "model_loss": 3773.103797265625, "model_loss_scale": 12766.4128, "model_grad_norm": Infinity, "actor_loss": -0.0034559126418200322, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.058450204214453697, "critic_loss": 0.9338688028335571, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.46880493007898333, "reward_mean": 0.004192257960158168, "reward_std": 0.07723395446538925, "reward_normed_mean": 0.004192257960158168, "reward_normed_std": 0.07723395446538925, "critic_slow": 6.692256568145752, "critic_target": 6.686032372283935, "actor_ent": 0.9538578023910522, "actor_ent_scale": 0.0010000000474974513, "critic": 6.685907903289795, "fps": 110.68177064966943}
{"step": 8642656, "train_return": 21.0, "train_length": 1659.0, "train_total_steps": 2160664.0, "train_total_episodes": 1051.0, "train_loaded_steps": 1999690.0, "train_loaded_episodes": 869.0}
{"step": 8653312, "train_return": 6.0, "train_length": 2664.0, "train_total_steps": 2163328.0, "train_total_episodes": 1052.0, "train_loaded_steps": 1998861.0, "train_loaded_episodes": 868.0}
{"step": 8661836, "train_return": 17.0, "train_length": 2131.0, "train_total_steps": 2165459.0, "train_total_episodes": 1053.0, "train_loaded_steps": 1999244.0, "train_loaded_episodes": 868.0}
{"step": 8669836, "train_return": 16.0, "train_length": 2000.0, "train_total_steps": 2167459.0, "train_total_episodes": 1054.0, "train_loaded_steps": 1999375.0, "train_loaded_episodes": 868.0}
{"step": 8677596, "train_return": 18.0, "train_length": 1940.0, "train_total_steps": 2169399.0, "train_total_episodes": 1055.0, "train_loaded_steps": 1999838.0, "train_loaded_episodes": 868.0}
{"step": 8681356, "kl_loss": 1.4449384769439697, "image_loss": 3772.0, "reward_loss": 0.9192367681503296, "discount_loss": 0.007742164915800095, "model_kl": 1.4449384441375732, "prior_ent": 27.903402899169922, "post_ent": 26.471176190185545, "model_loss": 3773.10247265625, "model_loss_scale": 8192.0, "model_grad_norm": 6.067842306900024, "actor_loss": -0.010672651379347371, "actor_loss_scale": 6516270.6944, "actor_grad_norm": Infinity, "critic_loss": 0.9375124167442321, "critic_loss_scale": 135056.5888, "critic_grad_norm": Infinity, "reward_mean": 0.00439476126456866, "reward_std": 0.07762386044859886, "reward_normed_mean": 0.00439476126456866, "reward_normed_std": 0.07762386044859886, "critic_slow": 6.582460807800293, "critic_target": 6.574230485534668, "actor_ent": 0.9823753543853759, "actor_ent_scale": 0.0010000000474974513, "critic": 6.574121467590332, "fps": 111.87116428317552}
{"step": 8685348, "train_return": 16.0, "train_length": 1938.0, "train_total_steps": 2171337.0, "train_total_episodes": 1056.0, "train_loaded_steps": 1999468.0, "train_loaded_episodes": 868.0}
{"step": 8693316, "train_return": 18.0, "train_length": 1992.0, "train_total_steps": 2173329.0, "train_total_episodes": 1057.0, "train_loaded_steps": 1999481.0, "train_loaded_episodes": 868.0}
{"step": 8700992, "train_return": 17.0, "train_length": 1919.0, "train_total_steps": 2175248.0, "train_total_episodes": 1058.0, "train_loaded_steps": 1999656.0, "train_loaded_episodes": 868.0}
{"step": 8708064, "train_return": 19.0, "train_length": 1768.0, "train_total_steps": 2177016.0, "train_total_episodes": 1059.0, "train_loaded_steps": 1999467.0, "train_loaded_episodes": 868.0}
{"step": 8715556, "train_return": 18.0, "train_length": 1873.0, "train_total_steps": 2178889.0, "train_total_episodes": 1060.0, "train_loaded_steps": 1999467.0, "train_loaded_episodes": 868.0}
{"step": 8721356, "kl_loss": 1.4592692684173585, "image_loss": 3772.0, "reward_loss": 0.9192296573638916, "discount_loss": 0.007742137013375759, "model_kl": 1.459269233894348, "prior_ent": 27.994207135009766, "post_ent": 26.55231178894043, "model_loss": 3773.10390234375, "model_loss_scale": 8192.0, "model_grad_norm": 5.88142409210205, "actor_loss": -0.0065309167628875, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.06243067296743393, "critic_loss": 0.9376165376663208, "critic_loss_scale": 116811.3664, "critic_grad_norm": Infinity, "reward_mean": 0.004394578815186105, "reward_std": 0.07739912329912185, "reward_normed_mean": 0.004394578815186105, "reward_normed_std": 0.07739912329912185, "critic_slow": 6.605969184875488, "critic_target": 6.5991367347717285, "actor_ent": 0.9837456622123718, "actor_ent_scale": 0.0010000000474974513, "critic": 6.599086074829102, "fps": 109.83577044217292}
{"step": 8722588, "train_return": 20.0, "train_length": 1758.0, "train_total_steps": 2180647.0, "train_total_episodes": 1061.0, "train_loaded_steps": 1997955.0, "train_loaded_episodes": 868.0}
{"step": 8730732, "train_return": 17.0, "train_length": 2036.0, "train_total_steps": 2182683.0, "train_total_episodes": 1062.0, "train_loaded_steps": 1999991.0, "train_loaded_episodes": 869.0}
{"step": 8738828, "train_return": 16.0, "train_length": 2024.0, "train_total_steps": 2184707.0, "train_total_episodes": 1063.0, "train_loaded_steps": 1999943.0, "train_loaded_episodes": 869.0}
{"step": 8746632, "train_return": 17.0, "train_length": 1951.0, "train_total_steps": 2186658.0, "train_total_episodes": 1064.0, "train_loaded_steps": 1997792.0, "train_loaded_episodes": 868.0}
{"step": 8755060, "train_return": 17.0, "train_length": 2107.0, "train_total_steps": 2188765.0, "train_total_episodes": 1065.0, "train_loaded_steps": 1999899.0, "train_loaded_episodes": 869.0}
{"step": 8761356, "kl_loss": 1.4297605052947997, "image_loss": 3772.00039609375, "reward_loss": 0.9192123155593872, "discount_loss": 0.007758768539875746, "model_kl": 1.4297604690551757, "prior_ent": 27.901465032958985, "post_ent": 26.48136583862305, "model_loss": 3773.1014125, "model_loss_scale": 10171.1872, "model_grad_norm": 5.981345547103881, "actor_loss": -0.007248366658980376, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.05736800544857979, "critic_loss": 0.934713328075409, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.45506209322214125, "reward_mean": 0.004589059218551847, "reward_std": 0.07769182841181756, "reward_normed_mean": 0.004589059218551847, "reward_normed_std": 0.07769182841181756, "critic_slow": 6.661681829071045, "critic_target": 6.653988681030273, "actor_ent": 0.9663707957267761, "actor_ent_scale": 0.0010000000474974513, "critic": 6.653968891906739, "fps": 112.41586215409292}
{"step": 8763332, "train_return": 15.0, "train_length": 2068.0, "train_total_steps": 2190833.0, "train_total_episodes": 1066.0, "train_loaded_steps": 1999884.0, "train_loaded_episodes": 869.0}
{"step": 8771412, "train_return": 16.0, "train_length": 2020.0, "train_total_steps": 2192853.0, "train_total_episodes": 1067.0, "train_loaded_steps": 1999893.0, "train_loaded_episodes": 869.0}
{"step": 8778704, "train_return": 19.0, "train_length": 1823.0, "train_total_steps": 2194676.0, "train_total_episodes": 1068.0, "train_loaded_steps": 1999090.0, "train_loaded_episodes": 869.0}
{"step": 8786132, "train_return": 18.0, "train_length": 1857.0, "train_total_steps": 2196533.0, "train_total_episodes": 1069.0, "train_loaded_steps": 1998671.0, "train_loaded_episodes": 869.0}
{"step": 8793584, "train_return": 17.0, "train_length": 1863.0, "train_total_steps": 2198396.0, "train_total_episodes": 1070.0, "train_loaded_steps": 1997671.0, "train_loaded_episodes": 869.0}
{"step": 8801356, "kl_loss": 1.4245767107009888, "image_loss": 3772.0, "reward_loss": 0.9192201244354248, "discount_loss": 0.0077593123830854895, "model_kl": 1.4245766733169556, "prior_ent": 27.900423318481444, "post_ent": 26.484902005004884, "model_loss": 3773.100504296875, "model_loss_scale": 16384.0, "model_grad_norm": 5.908636496734619, "actor_loss": -0.005194171352917328, "actor_loss_scale": 5227780.5056, "actor_grad_norm": 0.057236773025989535, "critic_loss": 0.9343919973373414, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.5311812772989273, "reward_mean": 0.004637411162786884, "reward_std": 0.07748254684209824, "reward_normed_mean": 0.004637411162786884, "reward_normed_std": 0.07748254684209824, "critic_slow": 6.577108027648926, "critic_target": 6.57158708190918, "actor_ent": 0.9242899991989135, "actor_ent_scale": 0.0010000000474974513, "critic": 6.571388650512695, "fps": 112.26137754429814}
{"step": 8801832, "train_return": 16.0, "train_length": 2062.0, "train_total_steps": 2200458.0, "train_total_episodes": 1071.0, "train_loaded_steps": 1999733.0, "train_loaded_episodes": 870.0}
{"step": 8809068, "train_return": 18.0, "train_length": 1809.0, "train_total_steps": 2202267.0, "train_total_episodes": 1072.0, "train_loaded_steps": 1999433.0, "train_loaded_episodes": 870.0}
{"step": 8817096, "train_return": 17.0, "train_length": 2007.0, "train_total_steps": 2204274.0, "train_total_episodes": 1073.0, "train_loaded_steps": 1998869.0, "train_loaded_episodes": 870.0}
{"step": 8824380, "train_return": 19.0, "train_length": 1821.0, "train_total_steps": 2206095.0, "train_total_episodes": 1074.0, "train_loaded_steps": 1998862.0, "train_loaded_episodes": 870.0}
{"step": 8832296, "train_return": 18.0, "train_length": 1979.0, "train_total_steps": 2208074.0, "train_total_episodes": 1075.0, "train_loaded_steps": 1998630.0, "train_loaded_episodes": 870.0}
{"step": 8839552, "train_return": 19.0, "train_length": 1814.0, "train_total_steps": 2209888.0, "train_total_episodes": 1076.0, "train_loaded_steps": 1998415.0, "train_loaded_episodes": 870.0}
{"step": 8841356, "kl_loss": 1.4272849800109864, "image_loss": 3772.000187890625, "reward_loss": 0.9192279723167419, "discount_loss": 0.007742699307203293, "model_kl": 1.4272849451065064, "prior_ent": 27.968996688842772, "post_ent": 26.555564193725587, "model_loss": 3773.100891796875, "model_loss_scale": 16384.0, "model_grad_norm": 6.018960210418701, "actor_loss": -0.008629216234839986, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.05497650561630726, "critic_loss": 0.9321799440383911, "critic_loss_scale": 66689.4336, "critic_grad_norm": 0.45579829260110855, "reward_mean": 0.004619431688650365, "reward_std": 0.07670348830223084, "reward_normed_mean": 0.004619431688650365, "reward_normed_std": 0.07670348830223084, "critic_slow": 6.4770617630004885, "critic_target": 6.469602201080322, "actor_ent": 0.9986834342956543, "actor_ent_scale": 0.0010000000474974513, "critic": 6.469695529937744, "fps": 111.29992670267433}
{"step": 8846856, "train_return": 19.0, "train_length": 1826.0, "train_total_steps": 2211714.0, "train_total_episodes": 1077.0, "train_loaded_steps": 1998526.0, "train_loaded_episodes": 870.0}
{"step": 8856076, "train_return": 13.0, "train_length": 2305.0, "train_total_steps": 2214019.0, "train_total_episodes": 1078.0, "train_loaded_steps": 1998735.0, "train_loaded_episodes": 870.0}
{"step": 8864144, "train_return": 15.0, "train_length": 2017.0, "train_total_steps": 2216036.0, "train_total_episodes": 1079.0, "train_loaded_steps": 1998693.0, "train_loaded_episodes": 870.0}
{"step": 8871324, "train_return": 20.0, "train_length": 1795.0, "train_total_steps": 2217831.0, "train_total_episodes": 1080.0, "train_loaded_steps": 1997964.0, "train_loaded_episodes": 870.0}
{"step": 8879100, "train_return": 17.0, "train_length": 1944.0, "train_total_steps": 2219775.0, "train_total_episodes": 1081.0, "train_loaded_steps": 1999908.0, "train_loaded_episodes": 871.0}
{"step": 8881356, "kl_loss": 1.4221253702163696, "image_loss": 3772.0, "reward_loss": 0.9192110342025757, "discount_loss": 0.007742627044022083, "model_kl": 1.4221253356933594, "prior_ent": 27.89215400390625, "post_ent": 26.482067904663086, "model_loss": 3773.100175, "model_loss_scale": 16803.4304, "model_grad_norm": Infinity, "actor_loss": -0.003931825595622649, "actor_loss_scale": 8321499.136, "actor_grad_norm": Infinity, "critic_loss": 0.9325001679420472, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4164606293797493, "reward_mean": 0.004722920545232773, "reward_std": 0.07793904605507851, "reward_normed_mean": 0.004722920545232773, "reward_normed_std": 0.07793904605507851, "critic_slow": 6.369270700073242, "critic_target": 6.362740715026855, "actor_ent": 1.003049528503418, "actor_ent_scale": 0.0010000000474974513, "critic": 6.3626028991699215, "fps": 112.11877596729259}
{"step": 8887880, "train_return": 12.0, "train_length": 2195.0, "train_total_steps": 2221970.0, "train_total_episodes": 1082.0, "train_loaded_steps": 1999626.0, "train_loaded_episodes": 871.0}
{"step": 8896784, "train_return": 15.0, "train_length": 2226.0, "train_total_steps": 2224196.0, "train_total_episodes": 1083.0, "train_loaded_steps": 1999554.0, "train_loaded_episodes": 871.0}
{"step": 8904180, "train_return": 19.0, "train_length": 1849.0, "train_total_steps": 2226045.0, "train_total_episodes": 1084.0, "train_loaded_steps": 1998642.0, "train_loaded_episodes": 871.0}
{"step": 8911568, "train_return": 18.0, "train_length": 1847.0, "train_total_steps": 2227892.0, "train_total_episodes": 1085.0, "train_loaded_steps": 1998796.0, "train_loaded_episodes": 871.0}
{"step": 8907444, "eval_return": 19.0, "eval_length": 1831.0, "eval_total_steps": 21905.0, "eval_total_episodes": 11.0, "eval_loaded_steps": 21916.0, "eval_loaded_episodes": 11.0}
{"step": 8907448, "kl_loss": 1.3794653415679932, "image_loss": 3772.0, "reward_loss": 0.9193621277809143, "discount_loss": 0.007745233830064535, "model_kl": 1.3794653415679932, "prior_ent": 28.144062042236328, "post_ent": 26.772886276245117, "model_loss": 3773.09619140625, "model_loss_scale": 16384.0, "model_grad_norm": 6.292145252227783, "actor_loss": -0.021390095353126526, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.04553373530507088, "critic_loss": 0.9344408512115479, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.8777458667755127, "reward_mean": 0.0027005576994270086, "reward_std": 0.07355973869562149, "reward_normed_mean": 0.0027005576994270086, "reward_normed_std": 0.07355973869562149, "critic_slow": 6.304636001586914, "critic_target": 6.2741289138793945, "actor_ent": 0.838355541229248, "actor_ent_scale": 0.0010000000474974513, "critic": 6.336402416229248, "fps": 0.0}
{"step": 8915084, "train_return": 17.0, "train_length": 1910.0, "train_total_steps": 2228771.0, "train_total_episodes": 1086.0, "train_loaded_steps": 1998788.0, "train_loaded_episodes": 871.0}
{"step": 8922768, "train_return": 17.0, "train_length": 1921.0, "train_total_steps": 2230692.0, "train_total_episodes": 1087.0, "train_loaded_steps": 1997965.0, "train_loaded_episodes": 871.0}
{"step": 8930436, "train_return": 17.0, "train_length": 1917.0, "train_total_steps": 2232609.0, "train_total_episodes": 1088.0, "train_loaded_steps": 1999882.0, "train_loaded_episodes": 872.0}
{"step": 8939128, "train_return": 16.0, "train_length": 2173.0, "train_total_steps": 2234782.0, "train_total_episodes": 1089.0, "train_loaded_steps": 1997361.0, "train_loaded_episodes": 871.0}
{"step": 8947448, "kl_loss": 1.4375784187316893, "image_loss": 3772.0, "reward_loss": 0.9192492214202881, "discount_loss": 0.0077617953076958655, "model_kl": 1.4375783861160278, "prior_ent": 28.095475689697267, "post_ent": 26.666336877441406, "model_loss": 3773.10185703125, "model_loss_scale": 2084.0448, "model_grad_norm": Infinity, "actor_loss": 0.0019848287027562036, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.05729257111251354, "critic_loss": 0.9340593203544617, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.5006706463813781, "reward_mean": 0.004916630280322898, "reward_std": 0.0776902341902256, "reward_normed_mean": 0.004916630280322898, "reward_normed_std": 0.0776902341902256, "critic_slow": 6.610902239227295, "critic_target": 6.608897515869141, "actor_ent": 0.8784725679397583, "actor_ent_scale": 0.0010000000474974513, "critic": 6.608677018737793, "fps": 112.38313196497374}
{"step": 8949084, "train_return": 13.0, "train_length": 2489.0, "train_total_steps": 2237271.0, "train_total_episodes": 1090.0, "train_loaded_steps": 1999850.0, "train_loaded_episodes": 872.0}
{"step": 8956744, "train_return": 17.0, "train_length": 1915.0, "train_total_steps": 2239186.0, "train_total_episodes": 1091.0, "train_loaded_steps": 1999278.0, "train_loaded_episodes": 872.0}
{"step": 8965560, "train_return": 14.0, "train_length": 2204.0, "train_total_steps": 2241390.0, "train_total_episodes": 1092.0, "train_loaded_steps": 1999353.0, "train_loaded_episodes": 872.0}
{"step": 8972732, "train_return": 20.0, "train_length": 1793.0, "train_total_steps": 2243183.0, "train_total_episodes": 1093.0, "train_loaded_steps": 1998690.0, "train_loaded_episodes": 872.0}
{"step": 8981216, "train_return": 15.0, "train_length": 2121.0, "train_total_steps": 2245304.0, "train_total_episodes": 1094.0, "train_loaded_steps": 1998464.0, "train_loaded_episodes": 872.0}
{"step": 8987448, "kl_loss": 1.513153230857849, "image_loss": 3772.000187890625, "reward_loss": 0.9192794854164124, "discount_loss": 0.007830366136878729, "model_kl": 1.5131531955718993, "prior_ent": 28.25938757019043, "post_ent": 26.77027788391113, "model_loss": 3773.10998203125, "model_loss_scale": 2048.0, "model_grad_norm": 5.776510427665711, "actor_loss": 0.0007756491604930489, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.05945113524198532, "critic_loss": 0.9370452816009521, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.4852414075493813, "reward_mean": 0.004862650461276644, "reward_std": 0.07708055568337441, "reward_normed_mean": 0.004862650461276644, "reward_normed_std": 0.07708055568337441, "critic_slow": 6.689481234741211, "critic_target": 6.687213563537598, "actor_ent": 0.880700152873993, "actor_ent_scale": 0.0010000000474974513, "critic": 6.686976593017578, "fps": 112.15766556220721}
{"step": 8988088, "train_return": 20.0, "train_length": 1718.0, "train_total_steps": 2247022.0, "train_total_episodes": 1095.0, "train_loaded_steps": 1997840.0, "train_loaded_episodes": 872.0}
{"step": 8996056, "train_return": 19.0, "train_length": 1992.0, "train_total_steps": 2249014.0, "train_total_episodes": 1096.0, "train_loaded_steps": 1999832.0, "train_loaded_episodes": 873.0}
{"step": 9003284, "train_return": 19.0, "train_length": 1807.0, "train_total_steps": 2250821.0, "train_total_episodes": 1097.0, "train_loaded_steps": 1999082.0, "train_loaded_episodes": 873.0}
{"step": 9010732, "train_return": 17.0, "train_length": 1862.0, "train_total_steps": 2252683.0, "train_total_episodes": 1098.0, "train_loaded_steps": 1998997.0, "train_loaded_episodes": 873.0}
{"step": 9018768, "train_return": 18.0, "train_length": 2009.0, "train_total_steps": 2254692.0, "train_total_episodes": 1099.0, "train_loaded_steps": 1999140.0, "train_loaded_episodes": 873.0}
{"step": 9026556, "train_return": 19.0, "train_length": 1947.0, "train_total_steps": 2256639.0, "train_total_episodes": 1100.0, "train_loaded_steps": 1999120.0, "train_loaded_episodes": 873.0}
{"step": 9027448, "kl_loss": 1.4323749069213867, "image_loss": 3772.0, "reward_loss": 0.9192606797218322, "discount_loss": 0.007763489435613155, "model_kl": 1.4323748733520507, "prior_ent": 28.280685137939454, "post_ent": 26.85763313598633, "model_loss": 3773.101349609375, "model_loss_scale": 2048.0, "model_grad_norm": 5.856919817352295, "actor_loss": 0.004337174077876261, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.05549308733046055, "critic_loss": 0.9337558647155761, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.5254842661976814, "reward_mean": 0.004977099492594425, "reward_std": 0.07795559891462327, "reward_normed_mean": 0.004977099492594425, "reward_normed_std": 0.07795559891462327, "critic_slow": 6.659014093780518, "critic_target": 6.658587885284424, "actor_ent": 0.848556674861908, "actor_ent_scale": 0.0010000000474974513, "critic": 6.658307734680176, "fps": 110.46768196583278}
{"step": 9033468, "train_return": 20.0, "train_length": 1728.0, "train_total_steps": 2258367.0, "train_total_episodes": 1101.0, "train_loaded_steps": 1998625.0, "train_loaded_episodes": 873.0}
{"step": 9040096, "train_return": 21.0, "train_length": 1657.0, "train_total_steps": 2260024.0, "train_total_episodes": 1102.0, "train_loaded_steps": 1998091.0, "train_loaded_episodes": 873.0}
{"step": 9048920, "train_return": 14.0, "train_length": 2206.0, "train_total_steps": 2262230.0, "train_total_episodes": 1103.0, "train_loaded_steps": 1997843.0, "train_loaded_episodes": 873.0}
{"step": 9056764, "train_return": 16.0, "train_length": 1961.0, "train_total_steps": 2264191.0, "train_total_episodes": 1104.0, "train_loaded_steps": 1999804.0, "train_loaded_episodes": 874.0}
{"step": 9065040, "train_return": 16.0, "train_length": 2069.0, "train_total_steps": 2266260.0, "train_total_episodes": 1105.0, "train_loaded_steps": 1999259.0, "train_loaded_episodes": 874.0}
{"step": 9067448, "kl_loss": 1.4386402345657348, "image_loss": 3772.0002, "reward_loss": 0.9192446024894715, "discount_loss": 0.00774314104616642, "model_kl": 1.4386401977539063, "prior_ent": 28.21533890991211, "post_ent": 26.789447564697266, "model_loss": 3773.102065234375, "model_loss_scale": 3676.5696, "model_grad_norm": 6.02692469329834, "actor_loss": -0.0030428099402517545, "actor_loss_scale": 59087.2576, "actor_grad_norm": 0.05411798329651356, "critic_loss": 0.9334520358085633, "critic_loss_scale": 59087.2576, "critic_grad_norm": 0.4508200366735458, "reward_mean": 0.005104535119968932, "reward_std": 0.0776686221063137, "reward_normed_mean": 0.005104535119968932, "reward_normed_std": 0.0776686221063137, "critic_slow": 6.624470561981201, "critic_target": 6.618583497619629, "actor_ent": 0.877078113079071, "actor_ent_scale": 0.0010000000474974513, "critic": 6.618731986236572, "fps": 111.30716593559836}
{"step": 9072716, "train_return": 18.0, "train_length": 1919.0, "train_total_steps": 2268179.0, "train_total_episodes": 1106.0, "train_loaded_steps": 1998222.0, "train_loaded_episodes": 874.0}
{"step": 9079740, "train_return": 20.0, "train_length": 1756.0, "train_total_steps": 2269935.0, "train_total_episodes": 1107.0, "train_loaded_steps": 1999978.0, "train_loaded_episodes": 875.0}
{"step": 9087088, "train_return": 18.0, "train_length": 1837.0, "train_total_steps": 2271772.0, "train_total_episodes": 1108.0, "train_loaded_steps": 1999960.0, "train_loaded_episodes": 875.0}
{"step": 9095840, "train_return": 15.0, "train_length": 2188.0, "train_total_steps": 2273960.0, "train_total_episodes": 1109.0, "train_loaded_steps": 1997861.0, "train_loaded_episodes": 874.0}
{"step": 9104788, "train_return": 16.0, "train_length": 2237.0, "train_total_steps": 2276197.0, "train_total_episodes": 1110.0, "train_loaded_steps": 1998146.0, "train_loaded_episodes": 874.0}
{"step": 9107448, "kl_loss": 1.4614069118499755, "image_loss": 3772.0, "reward_loss": 0.9192700681686401, "discount_loss": 0.007775915638357401, "model_kl": 1.4614068780899048, "prior_ent": 28.1629389251709, "post_ent": 26.71954157104492, "model_loss": 3773.10433125, "model_loss_scale": 4096.0, "model_grad_norm": 6.0457259445190425, "actor_loss": -0.0023232813867303777, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.05751098827123642, "critic_loss": 0.9363684376716613, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.5208967322945595, "reward_mean": 0.0049408154530925456, "reward_std": 0.07677047278881073, "reward_normed_mean": 0.0049408154530925456, "reward_normed_std": 0.07677047278881073, "critic_slow": 6.569790660095215, "critic_target": 6.565477656555176, "actor_ent": 0.8974525032997132, "actor_ent_scale": 0.0010000000474974513, "critic": 6.565309929656983, "fps": 111.27251958969039}
{"step": 9112152, "train_return": 18.0, "train_length": 1841.0, "train_total_steps": 2278038.0, "train_total_episodes": 1111.0, "train_loaded_steps": 1999987.0, "train_loaded_episodes": 875.0}
{"step": 9121052, "train_return": 17.0, "train_length": 2225.0, "train_total_steps": 2280263.0, "train_total_episodes": 1112.0, "train_loaded_steps": 1999747.0, "train_loaded_episodes": 875.0}
{"step": 9128760, "train_return": 17.0, "train_length": 1927.0, "train_total_steps": 2282190.0, "train_total_episodes": 1113.0, "train_loaded_steps": 1998766.0, "train_loaded_episodes": 875.0}
{"step": 9136548, "train_return": 16.0, "train_length": 1947.0, "train_total_steps": 2284137.0, "train_total_episodes": 1114.0, "train_loaded_steps": 1997871.0, "train_loaded_episodes": 875.0}
{"step": 9143836, "train_return": 19.0, "train_length": 1822.0, "train_total_steps": 2285959.0, "train_total_episodes": 1115.0, "train_loaded_steps": 1999693.0, "train_loaded_episodes": 876.0}
{"step": 9147448, "kl_loss": 1.4410601499557496, "image_loss": 3772.000187890625, "reward_loss": 0.9192510522842408, "discount_loss": 0.007767800502479077, "model_kl": 1.441060113143921, "prior_ent": 28.16204222717285, "post_ent": 26.735513275146484, "model_loss": 3773.10242265625, "model_loss_scale": 4096.0, "model_grad_norm": 6.311884945487976, "actor_loss": 0.0026807162304758095, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.057990999323129656, "critic_loss": 0.9375680141448974, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.5319581052541733, "reward_mean": 0.005118954888021107, "reward_std": 0.07743014437556267, "reward_normed_mean": 0.005118954888021107, "reward_normed_std": 0.07743014437556267, "critic_slow": 6.542621788787842, "critic_target": 6.5418294845581055, "actor_ent": 0.891939357471466, "actor_ent_scale": 0.0010000000474974513, "critic": 6.541664808654785, "fps": 112.50187395654297}
{"step": 9152440, "train_return": 14.0, "train_length": 2151.0, "train_total_steps": 2288110.0, "train_total_episodes": 1116.0, "train_loaded_steps": 1998887.0, "train_loaded_episodes": 876.0}
{"step": 9160172, "train_return": 17.0, "train_length": 1933.0, "train_total_steps": 2290043.0, "train_total_episodes": 1117.0, "train_loaded_steps": 1997401.0, "train_loaded_episodes": 876.0}
{"step": 9167700, "train_return": 17.0, "train_length": 1882.0, "train_total_steps": 2291925.0, "train_total_episodes": 1118.0, "train_loaded_steps": 1999283.0, "train_loaded_episodes": 877.0}
{"step": 9177480, "train_return": 13.0, "train_length": 2445.0, "train_total_steps": 2294370.0, "train_total_episodes": 1119.0, "train_loaded_steps": 1998356.0, "train_loaded_episodes": 877.0}
{"step": 9186324, "train_return": 15.0, "train_length": 2211.0, "train_total_steps": 2296581.0, "train_total_episodes": 1120.0, "train_loaded_steps": 1997362.0, "train_loaded_episodes": 877.0}
{"step": 9187448, "kl_loss": 1.4948081409454346, "image_loss": 3772.00019609375, "reward_loss": 0.9192415091514587, "discount_loss": 0.007765789721906185, "model_kl": 1.4948081077575683, "prior_ent": 28.046704296875, "post_ent": 26.576531997680664, "model_loss": 3773.107785546875, "model_loss_scale": 6533.9392, "model_grad_norm": 5.905921095657349, "actor_loss": -0.0003331721242690037, "actor_loss_scale": 105067.3152, "actor_grad_norm": 0.054636130794882776, "critic_loss": 0.9351401762008666, "critic_loss_scale": 105067.3152, "critic_grad_norm": 0.45550714373588563, "reward_mean": 0.005018762245276594, "reward_std": 0.0781697052538395, "reward_normed_mean": 0.005018762245276594, "reward_normed_std": 0.0781697052538395, "critic_slow": 6.527886269378662, "critic_target": 6.524823249816895, "actor_ent": 0.908645639514923, "actor_ent_scale": 0.0010000000474974513, "critic": 6.524690912628174, "fps": 112.86788273524965}
{"step": 9196068, "train_return": 12.0, "train_length": 2436.0, "train_total_steps": 2299017.0, "train_total_episodes": 1121.0, "train_loaded_steps": 1999798.0, "train_loaded_episodes": 878.0}
{"step": 9204052, "train_return": 18.0, "train_length": 1996.0, "train_total_steps": 2301013.0, "train_total_episodes": 1122.0, "train_loaded_steps": 1999277.0, "train_loaded_episodes": 878.0}
{"step": 9211940, "train_return": 17.0, "train_length": 1972.0, "train_total_steps": 2302985.0, "train_total_episodes": 1123.0, "train_loaded_steps": 1998801.0, "train_loaded_episodes": 878.0}
{"step": 9219872, "train_return": 17.0, "train_length": 1983.0, "train_total_steps": 2304968.0, "train_total_episodes": 1124.0, "train_loaded_steps": 1998137.0, "train_loaded_episodes": 878.0}
{"step": 9227448, "kl_loss": 1.4402727392196655, "image_loss": 3772.0, "reward_loss": 0.9192359954833984, "discount_loss": 0.007744416564702988, "model_kl": 1.4402727016448975, "prior_ent": 28.107660830688477, "post_ent": 26.67812400817871, "model_loss": 3773.102020703125, "model_loss_scale": 8192.0, "model_grad_norm": 6.165400846481323, "actor_loss": -0.0009335080593300517, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.052044129094481466, "critic_loss": 0.9342089728355407, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.49942589184045794, "reward_mean": 0.004918115590795059, "reward_std": 0.07855340200066567, "reward_normed_mean": 0.004918115590795059, "reward_normed_std": 0.07855340200066567, "critic_slow": 6.544249934387207, "critic_target": 6.540393551635742, "actor_ent": 0.9276384574890136, "actor_ent_scale": 0.0010000000474974513, "critic": 6.540171558380127, "fps": 114.16738575020683}
{"step": 9228372, "train_return": 14.0, "train_length": 2125.0, "train_total_steps": 2307093.0, "train_total_episodes": 1125.0, "train_loaded_steps": 1997921.0, "train_loaded_episodes": 878.0}
{"step": 9237100, "train_return": 15.0, "train_length": 2182.0, "train_total_steps": 2309275.0, "train_total_episodes": 1126.0, "train_loaded_steps": 1997964.0, "train_loaded_episodes": 878.0}
{"step": 9246160, "train_return": 14.0, "train_length": 2265.0, "train_total_steps": 2311540.0, "train_total_episodes": 1127.0, "train_loaded_steps": 1997561.0, "train_loaded_episodes": 878.0}
{"step": 9253556, "train_return": 18.0, "train_length": 1849.0, "train_total_steps": 2313389.0, "train_total_episodes": 1128.0, "train_loaded_steps": 1999410.0, "train_loaded_episodes": 879.0}
{"step": 9261956, "train_return": 14.0, "train_length": 2100.0, "train_total_steps": 2315489.0, "train_total_episodes": 1129.0, "train_loaded_steps": 1998893.0, "train_loaded_episodes": 879.0}
{"step": 9267448, "kl_loss": 1.4362142469406127, "image_loss": 3772.0, "reward_loss": 0.919229243850708, "discount_loss": 0.007764021740853787, "model_kl": 1.436214211845398, "prior_ent": 28.074264456176756, "post_ent": 26.650691818237306, "model_loss": 3773.10170078125, "model_loss_scale": 8192.0, "model_grad_norm": 5.8132104349136355, "actor_loss": -0.003035832015622873, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.05082303567230701, "critic_loss": 0.9326912405967712, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.47664155008792874, "reward_mean": 0.0051053704913705585, "reward_std": 0.07889833930134774, "reward_normed_mean": 0.0051053704913705585, "reward_normed_std": 0.07889833930134774, "critic_slow": 6.536386735534668, "critic_target": 6.532753869628906, "actor_ent": 0.9541281339645385, "actor_ent_scale": 0.0010000000474974513, "critic": 6.532401987457275, "fps": 114.33724331753095}
{"step": 9271156, "train_return": 15.0, "train_length": 2300.0, "train_total_steps": 2317789.0, "train_total_episodes": 1130.0, "train_loaded_steps": 1998319.0, "train_loaded_episodes": 879.0}
{"step": 9278780, "train_return": 18.0, "train_length": 1906.0, "train_total_steps": 2319695.0, "train_total_episodes": 1131.0, "train_loaded_steps": 1997547.0, "train_loaded_episodes": 879.0}
{"step": 9285924, "train_return": 19.0, "train_length": 1786.0, "train_total_steps": 2321481.0, "train_total_episodes": 1132.0, "train_loaded_steps": 1999333.0, "train_loaded_episodes": 880.0}
{"step": 9295096, "train_return": 14.0, "train_length": 2293.0, "train_total_steps": 2323774.0, "train_total_episodes": 1133.0, "train_loaded_steps": 1999372.0, "train_loaded_episodes": 880.0}
{"step": 9302576, "train_return": 18.0, "train_length": 1870.0, "train_total_steps": 2325644.0, "train_total_episodes": 1134.0, "train_loaded_steps": 1998420.0, "train_loaded_episodes": 880.0}
{"step": 9307448, "kl_loss": 1.4473842554092406, "image_loss": 3772.0, "reward_loss": 0.9192575362205505, "discount_loss": 0.007771521626412869, "model_kl": 1.4473842237472534, "prior_ent": 28.017695153808592, "post_ent": 26.587007019042968, "model_loss": 3773.10288828125, "model_loss_scale": 11429.4784, "model_grad_norm": 6.093058628082275, "actor_loss": -0.0024281634296028642, "actor_loss_scale": 183920.2304, "actor_grad_norm": 0.05196517798006534, "critic_loss": 0.9330627161979675, "critic_loss_scale": 152672.6656, "critic_grad_norm": Infinity, "reward_mean": 0.005179252960037411, "reward_std": 0.07809327526688575, "reward_normed_mean": 0.005179252960037411, "reward_normed_std": 0.07809327526688575, "critic_slow": 6.451837892150879, "critic_target": 6.445666648864746, "actor_ent": 1.0046530778884888, "actor_ent_scale": 0.0010000000474974513, "critic": 6.445725305938721, "fps": 112.5429594279577}
{"step": 9310720, "train_return": 17.0, "train_length": 2036.0, "train_total_steps": 2327680.0, "train_total_episodes": 1135.0, "train_loaded_steps": 1997084.0, "train_loaded_episodes": 880.0}
{"step": 9319016, "train_return": 17.0, "train_length": 2074.0, "train_total_steps": 2329754.0, "train_total_episodes": 1136.0, "train_loaded_steps": 1999158.0, "train_loaded_episodes": 881.0}
{"step": 9327248, "train_return": 15.0, "train_length": 2058.0, "train_total_steps": 2331812.0, "train_total_episodes": 1137.0, "train_loaded_steps": 1998508.0, "train_loaded_episodes": 881.0}
{"step": 9334460, "train_return": 18.0, "train_length": 1803.0, "train_total_steps": 2333615.0, "train_total_episodes": 1138.0, "train_loaded_steps": 1998135.0, "train_loaded_episodes": 881.0}
{"step": 9342932, "train_return": 16.0, "train_length": 2118.0, "train_total_steps": 2335733.0, "train_total_episodes": 1139.0, "train_loaded_steps": 1997244.0, "train_loaded_episodes": 881.0}
{"step": 9347448, "kl_loss": 1.4200092798233033, "image_loss": 3772.0, "reward_loss": 0.9192189146995544, "discount_loss": 0.007741709384322166, "model_kl": 1.4200092416763306, "prior_ent": 27.956297052001954, "post_ent": 26.545898065185547, "model_loss": 3773.099962109375, "model_loss_scale": 16384.0, "model_grad_norm": 6.080831588745117, "actor_loss": -0.004266923792742455, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.05250367619097233, "critic_loss": 0.933842680644989, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.4857923252701759, "reward_mean": 0.00510397654568078, "reward_std": 0.07883962082266807, "reward_normed_mean": 0.00510397654568078, "reward_normed_std": 0.07883962082266807, "critic_slow": 6.380190531158448, "critic_target": 6.376245534515381, "actor_ent": 1.0323675107955932, "actor_ent_scale": 0.0010000000474974513, "critic": 6.376136560058594, "fps": 112.87592223098581}
{"step": 9351176, "train_return": 15.0, "train_length": 2061.0, "train_total_steps": 2337794.0, "train_total_episodes": 1140.0, "train_loaded_steps": 1999305.0, "train_loaded_episodes": 882.0}
{"step": 9359892, "train_return": 14.0, "train_length": 2179.0, "train_total_steps": 2339973.0, "train_total_episodes": 1141.0, "train_loaded_steps": 1998927.0, "train_loaded_episodes": 882.0}
{"step": 9368832, "train_return": 15.0, "train_length": 2235.0, "train_total_steps": 2342208.0, "train_total_episodes": 1142.0, "train_loaded_steps": 1999121.0, "train_loaded_episodes": 882.0}
{"step": 9377508, "train_return": 14.0, "train_length": 2169.0, "train_total_steps": 2344377.0, "train_total_episodes": 1143.0, "train_loaded_steps": 1999181.0, "train_loaded_episodes": 882.0}
{"step": 9386184, "train_return": 17.0, "train_length": 2169.0, "train_total_steps": 2346546.0, "train_total_episodes": 1144.0, "train_loaded_steps": 1998742.0, "train_loaded_episodes": 882.0}
{"step": 9387448, "kl_loss": 1.4096451446533202, "image_loss": 3772.0, "reward_loss": 0.919227272605896, "discount_loss": 0.007741685270518064, "model_kl": 1.4096451122283935, "prior_ent": 27.781971936035156, "post_ent": 26.380752770996093, "model_loss": 3773.0989390625, "model_loss_scale": 16384.0, "model_grad_norm": 6.027907788467407, "actor_loss": -0.0014971003207740977, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.05299028815627098, "critic_loss": 0.9327359301567077, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.49407324471473696, "reward_mean": 0.0051653428565124155, "reward_std": 0.07866940639019013, "reward_normed_mean": 0.0051653428565124155, "reward_normed_std": 0.07866940639019013, "critic_slow": 6.349354918670654, "critic_target": 6.3455198371887205, "actor_ent": 1.0082937470436095, "actor_ent_scale": 0.0010000000474974513, "critic": 6.345525778961182, "fps": 107.4084158165132}
{"step": 9393528, "train_return": 18.0, "train_length": 1836.0, "train_total_steps": 2348382.0, "train_total_episodes": 1145.0, "train_loaded_steps": 1998089.0, "train_loaded_episodes": 882.0}
{"step": 9400484, "train_return": 20.0, "train_length": 1739.0, "train_total_steps": 2350121.0, "train_total_episodes": 1146.0, "train_loaded_steps": 1999828.0, "train_loaded_episodes": 883.0}
{"step": 9408580, "train_return": 15.0, "train_length": 2024.0, "train_total_steps": 2352145.0, "train_total_episodes": 1147.0, "train_loaded_steps": 1999539.0, "train_loaded_episodes": 883.0}
{"step": 9415868, "train_return": 19.0, "train_length": 1822.0, "train_total_steps": 2353967.0, "train_total_episodes": 1148.0, "train_loaded_steps": 1998328.0, "train_loaded_episodes": 883.0}
{"step": 9424452, "train_return": 13.0, "train_length": 2146.0, "train_total_steps": 2356113.0, "train_total_episodes": 1149.0, "train_loaded_steps": 1998114.0, "train_loaded_episodes": 883.0}
{"step": 9427448, "kl_loss": 1.4311044408798217, "image_loss": 3772.0, "reward_loss": 0.9192355792999267, "discount_loss": 0.007743532381206751, "model_kl": 1.431104407310486, "prior_ent": 27.86551975402832, "post_ent": 26.44638439941406, "model_loss": 3773.101093359375, "model_loss_scale": 19451.0848, "model_grad_norm": Infinity, "actor_loss": -0.008118311548465863, "actor_loss_scale": 315411.6608, "actor_grad_norm": 0.05458489812016487, "critic_loss": 0.9357177927970887, "critic_loss_scale": 118698.8032, "critic_grad_norm": Infinity, "reward_mean": 0.005152153937146068, "reward_std": 0.07905715505480766, "reward_normed_mean": 0.005152153937146068, "reward_normed_std": 0.07905715505480766, "critic_slow": 6.173129759216309, "critic_target": 6.167915721130371, "actor_ent": 0.9884480446815491, "actor_ent_scale": 0.0010000000474974513, "critic": 6.168095626831055, "fps": 108.84774378922799}
{"step": 9433204, "train_return": 15.0, "train_length": 2188.0, "train_total_steps": 2358301.0, "train_total_episodes": 1150.0, "train_loaded_steps": 1997483.0, "train_loaded_episodes": 883.0}
{"step": 9440868, "train_return": 17.0, "train_length": 1916.0, "train_total_steps": 2360217.0, "train_total_episodes": 1151.0, "train_loaded_steps": 1999399.0, "train_loaded_episodes": 884.0}
{"step": 9448936, "train_return": 17.0, "train_length": 2017.0, "train_total_steps": 2362234.0, "train_total_episodes": 1152.0, "train_loaded_steps": 1998952.0, "train_loaded_episodes": 884.0}
{"step": 9457044, "train_return": 16.0, "train_length": 2027.0, "train_total_steps": 2364261.0, "train_total_episodes": 1153.0, "train_loaded_steps": 1997862.0, "train_loaded_episodes": 884.0}
{"step": 9464068, "train_return": 20.0, "train_length": 1756.0, "train_total_steps": 2366017.0, "train_total_episodes": 1154.0, "train_loaded_steps": 1999618.0, "train_loaded_episodes": 885.0}
{"step": 9467448, "kl_loss": 1.40113480052948, "image_loss": 3772.0, "reward_loss": 0.9192174798965455, "discount_loss": 0.007767716179043055, "model_kl": 1.401134770011902, "prior_ent": 27.801417568969725, "post_ent": 26.410360818481447, "model_loss": 3773.098203125, "model_loss_scale": 16384.0, "model_grad_norm": 5.984106860351562, "actor_loss": -0.004017241230164654, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.05240808592140674, "critic_loss": 0.9322943946838379, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4038673973917961, "reward_mean": 0.005508101904779323, "reward_std": 0.07908504379987717, "reward_normed_mean": 0.005508101904779323, "reward_normed_std": 0.07908504379987717, "critic_slow": 6.123227043151855, "critic_target": 6.119793684387207, "actor_ent": 1.023698904800415, "actor_ent_scale": 0.0010000000474974513, "critic": 6.119818997955322, "fps": 106.58463209538648}
{"step": 9470976, "train_return": 20.0, "train_length": 1727.0, "train_total_steps": 2367744.0, "train_total_episodes": 1155.0, "train_loaded_steps": 1999184.0, "train_loaded_episodes": 885.0}
{"step": 9478584, "train_return": 19.0, "train_length": 1902.0, "train_total_steps": 2369646.0, "train_total_episodes": 1156.0, "train_loaded_steps": 1998064.0, "train_loaded_episodes": 885.0}
{"step": 9486756, "train_return": 16.0, "train_length": 2043.0, "train_total_steps": 2371689.0, "train_total_episodes": 1157.0, "train_loaded_steps": 1997434.0, "train_loaded_episodes": 885.0}
{"step": 9494016, "train_return": 18.0, "train_length": 1815.0, "train_total_steps": 2373504.0, "train_total_episodes": 1158.0, "train_loaded_steps": 1999249.0, "train_loaded_episodes": 886.0}
{"step": 9501412, "train_return": 19.0, "train_length": 1849.0, "train_total_steps": 2375353.0, "train_total_episodes": 1159.0, "train_loaded_steps": 1998990.0, "train_loaded_episodes": 886.0}
{"step": 9507448, "kl_loss": 1.4029805536270141, "image_loss": 3772.0, "reward_loss": 0.919238124370575, "discount_loss": 0.007771256716549397, "model_kl": 1.4029805181503296, "prior_ent": 27.730505130004882, "post_ent": 26.336171524047852, "model_loss": 3773.098425, "model_loss_scale": 16384.0, "model_grad_norm": 5.87492639503479, "actor_loss": -0.0025653118495065426, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.050811119744181635, "critic_loss": 0.9306432220458984, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4564435757160187, "reward_mean": 0.0053306654814514335, "reward_std": 0.07847055238485336, "reward_normed_mean": 0.0053306654814514335, "reward_normed_std": 0.07847055238485336, "critic_slow": 6.037410864257812, "critic_target": 6.03338557510376, "actor_ent": 1.0497907694816588, "actor_ent_scale": 0.0010000000474974513, "critic": 6.033312033843994, "fps": 106.67953816054943}
{"step": 9510424, "train_return": 14.0, "train_length": 2253.0, "train_total_steps": 2377606.0, "train_total_episodes": 1160.0, "train_loaded_steps": 1998606.0, "train_loaded_episodes": 886.0}
{"step": 9517736, "train_return": 19.0, "train_length": 1828.0, "train_total_steps": 2379434.0, "train_total_episodes": 1161.0, "train_loaded_steps": 1996953.0, "train_loaded_episodes": 886.0}
{"step": 9524816, "train_return": 19.0, "train_length": 1770.0, "train_total_steps": 2381204.0, "train_total_episodes": 1162.0, "train_loaded_steps": 1998723.0, "train_loaded_episodes": 887.0}
{"step": 9533224, "train_return": 15.0, "train_length": 2102.0, "train_total_steps": 2383306.0, "train_total_episodes": 1163.0, "train_loaded_steps": 1998244.0, "train_loaded_episodes": 887.0}
{"step": 9541504, "train_return": 16.0, "train_length": 2070.0, "train_total_steps": 2385376.0, "train_total_episodes": 1164.0, "train_loaded_steps": 1997887.0, "train_loaded_episodes": 887.0}
{"step": 9547448, "kl_loss": 1.457155288505554, "image_loss": 3772.0, "reward_loss": 0.919327035522461, "discount_loss": 0.0078413380458951, "model_kl": 1.4571552507400514, "prior_ent": 27.724496713256837, "post_ent": 26.29142510986328, "model_loss": 3773.104291015625, "model_loss_scale": 16384.0, "model_grad_norm": 6.153015930938721, "actor_loss": 0.0021758557160545026, "actor_loss_scale": 525965.7216, "actor_grad_norm": 0.05074925948381424, "critic_loss": 0.9306322285652161, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.5203865246534347, "reward_mean": 0.005260909753674059, "reward_std": 0.07764325639009476, "reward_normed_mean": 0.005260909753674059, "reward_normed_std": 0.07764325639009476, "critic_slow": 6.028652253723145, "critic_target": 6.027851620483398, "actor_ent": 1.0413840559005738, "actor_ent_scale": 0.0010000000474974513, "critic": 6.027862308502197, "fps": 106.93581543286449}
{"step": 9549576, "train_return": 17.0, "train_length": 2018.0, "train_total_steps": 2387394.0, "train_total_episodes": 1165.0, "train_loaded_steps": 1999905.0, "train_loaded_episodes": 888.0}
{"step": 9557496, "train_return": 17.0, "train_length": 1980.0, "train_total_steps": 2389374.0, "train_total_episodes": 1166.0, "train_loaded_steps": 1999323.0, "train_loaded_episodes": 888.0}
{"step": 9564732, "train_return": 19.0, "train_length": 1809.0, "train_total_steps": 2391183.0, "train_total_episodes": 1167.0, "train_loaded_steps": 1998016.0, "train_loaded_episodes": 888.0}
{"step": 9572372, "train_return": 16.0, "train_length": 1910.0, "train_total_steps": 2393093.0, "train_total_episodes": 1168.0, "train_loaded_steps": 1999926.0, "train_loaded_episodes": 889.0}
{"step": 9579756, "train_return": 18.0, "train_length": 1846.0, "train_total_steps": 2394939.0, "train_total_episodes": 1169.0, "train_loaded_steps": 1999840.0, "train_loaded_episodes": 889.0}
{"step": 9587448, "kl_loss": 1.4271314952850342, "image_loss": 3772.0, "reward_loss": 0.9192605571746826, "discount_loss": 0.007750964213907719, "model_kl": 1.4271314617156983, "prior_ent": 27.762942260742186, "post_ent": 26.349015618896484, "model_loss": 3773.100759765625, "model_loss_scale": 18586.0096, "model_grad_norm": Infinity, "actor_loss": -0.004357819280226249, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.04875386027693748, "critic_loss": 0.9283978590965271, "critic_loss_scale": 130337.9968, "critic_grad_norm": 0.4225207077383995, "reward_mean": 0.005448312901015742, "reward_std": 0.07842075923085212, "reward_normed_mean": 0.005448312901015742, "reward_normed_std": 0.07842075923085212, "critic_slow": 5.931831635665894, "critic_target": 5.928761289215088, "actor_ent": 1.0685094219207765, "actor_ent_scale": 0.0010000000474974513, "critic": 5.928742877197266, "fps": 106.50182009565572}
{"step": 9587732, "train_return": 16.0, "train_length": 1994.0, "train_total_steps": 2396933.0, "train_total_episodes": 1170.0, "train_loaded_steps": 1998951.0, "train_loaded_episodes": 889.0}
{"step": 9596152, "train_return": 13.0, "train_length": 2105.0, "train_total_steps": 2399038.0, "train_total_episodes": 1171.0, "train_loaded_steps": 1998544.0, "train_loaded_episodes": 889.0}
{"step": 9604504, "train_return": 14.0, "train_length": 2088.0, "train_total_steps": 2401126.0, "train_total_episodes": 1172.0, "train_loaded_steps": 1997571.0, "train_loaded_episodes": 889.0}
{"step": 9613012, "train_return": 15.0, "train_length": 2127.0, "train_total_steps": 2403253.0, "train_total_episodes": 1173.0, "train_loaded_steps": 1999698.0, "train_loaded_episodes": 890.0}
{"step": 9619632, "train_return": 21.0, "train_length": 1655.0, "train_total_steps": 2404908.0, "train_total_episodes": 1174.0, "train_loaded_steps": 1999252.0, "train_loaded_episodes": 890.0}
{"step": 9626988, "train_return": 19.0, "train_length": 1839.0, "train_total_steps": 2406747.0, "train_total_episodes": 1175.0, "train_loaded_steps": 1997806.0, "train_loaded_episodes": 890.0}
{"step": 9627448, "kl_loss": 1.4129749378204346, "image_loss": 3772.0, "reward_loss": 0.9192702033996581, "discount_loss": 0.007768569204211235, "model_kl": 1.4129749052047729, "prior_ent": 27.821292404174805, "post_ent": 26.41909680786133, "model_loss": 3773.09945, "model_loss_scale": 8192.0, "model_grad_norm": 5.7561381275177, "actor_loss": -0.0032857513559458314, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.04780776761770249, "critic_loss": 0.9280202081680298, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.40504828000068666, "reward_mean": 0.005437688219855772, "reward_std": 0.07942446355223656, "reward_normed_mean": 0.005437688219855772, "reward_normed_std": 0.07942446355223656, "critic_slow": 5.887441388702393, "critic_target": 5.885183247375489, "actor_ent": 1.1047269060134888, "actor_ent_scale": 0.0010000000474974513, "critic": 5.885240093994141, "fps": 107.64770650707617}
{"step": 9634616, "train_return": 17.0, "train_length": 1907.0, "train_total_steps": 2408654.0, "train_total_episodes": 1176.0, "train_loaded_steps": 1999713.0, "train_loaded_episodes": 891.0}
{"step": 9642696, "train_return": 15.0, "train_length": 2020.0, "train_total_steps": 2410674.0, "train_total_episodes": 1177.0, "train_loaded_steps": 1997917.0, "train_loaded_episodes": 891.0}
{"step": 9651644, "train_return": 13.0, "train_length": 2237.0, "train_total_steps": 2412911.0, "train_total_episodes": 1178.0, "train_loaded_steps": 1997888.0, "train_loaded_episodes": 891.0}
{"step": 9659204, "train_return": 17.0, "train_length": 1890.0, "train_total_steps": 2414801.0, "train_total_episodes": 1179.0, "train_loaded_steps": 1999778.0, "train_loaded_episodes": 892.0}
{"step": 9666308, "train_return": 19.0, "train_length": 1776.0, "train_total_steps": 2416577.0, "train_total_episodes": 1180.0, "train_loaded_steps": 1999643.0, "train_loaded_episodes": 892.0}
{"step": 9667448, "kl_loss": 1.4875999126434327, "image_loss": 3772.0, "reward_loss": 0.9192395007133484, "discount_loss": 0.007788007551431656, "model_kl": 1.4875998792648315, "prior_ent": 28.05586329650879, "post_ent": 26.596805676269533, "model_loss": 3773.1069875, "model_loss_scale": 8192.0, "model_grad_norm": 5.932468206977844, "actor_loss": -0.00013060892094508744, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.05550612779557705, "critic_loss": 0.9372100895881653, "critic_loss_scale": 78852.9152, "critic_grad_norm": Infinity, "reward_mean": 0.005649910763303342, "reward_std": 0.07921537758111953, "reward_normed_mean": 0.005649910763303342, "reward_normed_std": 0.07921537758111953, "critic_slow": 5.894000354003906, "critic_target": 5.892152359008789, "actor_ent": 1.031797738456726, "actor_ent_scale": 0.0010000000474974513, "critic": 5.892226482391357, "fps": 106.53232855398814}
{"step": 9674380, "train_return": 17.0, "train_length": 2018.0, "train_total_steps": 2418595.0, "train_total_episodes": 1181.0, "train_loaded_steps": 1999373.0, "train_loaded_episodes": 892.0}
{"step": 9681380, "train_return": 19.0, "train_length": 1750.0, "train_total_steps": 2420345.0, "train_total_episodes": 1182.0, "train_loaded_steps": 1998155.0, "train_loaded_episodes": 892.0}
{"step": 9689248, "train_return": 16.0, "train_length": 1967.0, "train_total_steps": 2422312.0, "train_total_episodes": 1183.0, "train_loaded_steps": 1996134.0, "train_loaded_episodes": 892.0}
{"step": 9696240, "train_return": 19.0, "train_length": 1748.0, "train_total_steps": 2424060.0, "train_total_episodes": 1184.0, "train_loaded_steps": 1997882.0, "train_loaded_episodes": 893.0}
{"step": 9703520, "train_return": 19.0, "train_length": 1820.0, "train_total_steps": 2425880.0, "train_total_episodes": 1185.0, "train_loaded_steps": 1999702.0, "train_loaded_episodes": 894.0}
{"step": 9707448, "kl_loss": 1.4179263164520264, "image_loss": 3772.0002, "reward_loss": 0.9192155344963073, "discount_loss": 0.007793252348899841, "model_kl": 1.4179262800216674, "prior_ent": 27.836188439941406, "post_ent": 26.429297985839845, "model_loss": 3773.10021640625, "model_loss_scale": 9594.4704, "model_grad_norm": 5.993931636047363, "actor_loss": -0.004346277253585504, "actor_loss_scale": 1890792.2432, "actor_grad_norm": 0.05014290714561939, "critic_loss": 0.9297487792015076, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.38705155975818634, "reward_mean": 0.005469425314059481, "reward_std": 0.07966695851683617, "reward_normed_mean": 0.005469425314059481, "reward_normed_std": 0.07966695851683617, "critic_slow": 5.8085590148925785, "critic_target": 5.805521337890625, "actor_ent": 1.062537636566162, "actor_ent_scale": 0.0010000000474974513, "critic": 5.805662359619141, "fps": 106.46644864122261}
{"step": 9711388, "train_return": 18.0, "train_length": 1967.0, "train_total_steps": 2427847.0, "train_total_episodes": 1186.0, "train_loaded_steps": 1996507.0, "train_loaded_episodes": 893.0}
{"step": 9718856, "train_return": 18.0, "train_length": 1867.0, "train_total_steps": 2429714.0, "train_total_episodes": 1187.0, "train_loaded_steps": 1998374.0, "train_loaded_episodes": 894.0}
{"step": 9726656, "train_return": 17.0, "train_length": 1950.0, "train_total_steps": 2431664.0, "train_total_episodes": 1188.0, "train_loaded_steps": 1996085.0, "train_loaded_episodes": 894.0}
{"step": 9734640, "train_return": 19.0, "train_length": 1996.0, "train_total_steps": 2433660.0, "train_total_episodes": 1189.0, "train_loaded_steps": 1998081.0, "train_loaded_episodes": 895.0}
{"step": 9743356, "train_return": 15.0, "train_length": 2179.0, "train_total_steps": 2435839.0, "train_total_episodes": 1190.0, "train_loaded_steps": 1997174.0, "train_loaded_episodes": 895.0}
{"step": 9747448, "kl_loss": 1.45602097530365, "image_loss": 3772.0, "reward_loss": 0.9192327470779419, "discount_loss": 0.007784710585325956, "model_kl": 1.4560209426879882, "prior_ent": 27.76842822265625, "post_ent": 26.332241424560547, "model_loss": 3773.103807421875, "model_loss_scale": 16384.0, "model_grad_norm": 6.101898019599915, "actor_loss": -0.004499260441651859, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.04877317879796028, "critic_loss": 0.929644822883606, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4177990624308586, "reward_mean": 0.0056601526992919385, "reward_std": 0.0790143406033516, "reward_normed_mean": 0.0056601526992919385, "reward_normed_std": 0.0790143406033516, "critic_slow": 5.764402885055542, "critic_target": 5.759002753829956, "actor_ent": 1.0463317540168762, "actor_ent_scale": 0.0010000000474974513, "critic": 5.758866811752319, "fps": 107.31637228936171}
{"step": 9752116, "train_return": 15.0, "train_length": 2190.0, "train_total_steps": 2438029.0, "train_total_episodes": 1191.0, "train_loaded_steps": 1999364.0, "train_loaded_episodes": 896.0}
{"step": 9759576, "train_return": 18.0, "train_length": 1865.0, "train_total_steps": 2439894.0, "train_total_episodes": 1192.0, "train_loaded_steps": 1998973.0, "train_loaded_episodes": 896.0}
{"step": 9768180, "train_return": 15.0, "train_length": 2151.0, "train_total_steps": 2442045.0, "train_total_episodes": 1193.0, "train_loaded_steps": 1999493.0, "train_loaded_episodes": 896.0}
{"step": 9775572, "train_return": 19.0, "train_length": 1848.0, "train_total_steps": 2443893.0, "train_total_episodes": 1194.0, "train_loaded_steps": 1997516.0, "train_loaded_episodes": 896.0}
{"step": 9782840, "train_return": 18.0, "train_length": 1817.0, "train_total_steps": 2445710.0, "train_total_episodes": 1195.0, "train_loaded_steps": 1999333.0, "train_loaded_episodes": 897.0}
{"step": 9787448, "kl_loss": 1.3999714748382568, "image_loss": 3772.0, "reward_loss": 0.9191894359588623, "discount_loss": 0.0077439178116619585, "model_kl": 1.3999714406967163, "prior_ent": 27.678650161743164, "post_ent": 26.28728837890625, "model_loss": 3773.097956640625, "model_loss_scale": 16384.0, "model_grad_norm": 5.773193730545044, "actor_loss": -0.0036814326615130996, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.045784426856040956, "critic_loss": 0.9246570034980774, "critic_loss_scale": 104647.8848, "critic_grad_norm": 0.37897067017555236, "reward_mean": 0.005885044617846142, "reward_std": 0.07845173735618591, "reward_normed_mean": 0.005885044617846142, "reward_normed_std": 0.07845173735618591, "critic_slow": 5.707553081512451, "critic_target": 5.703660523223877, "actor_ent": 1.0533922562599183, "actor_ent_scale": 0.0010000000474974513, "critic": 5.703639973449707, "fps": 106.64986572451315}
{"step": 9791624, "train_return": 13.0, "train_length": 2196.0, "train_total_steps": 2447906.0, "train_total_episodes": 1196.0, "train_loaded_steps": 1997108.0, "train_loaded_episodes": 897.0}
{"step": 9801576, "train_return": 11.0, "train_length": 2488.0, "train_total_steps": 2450394.0, "train_total_episodes": 1197.0, "train_loaded_steps": 1999596.0, "train_loaded_episodes": 898.0}
{"step": 9809464, "train_return": 18.0, "train_length": 1972.0, "train_total_steps": 2452366.0, "train_total_episodes": 1198.0, "train_loaded_steps": 1997527.0, "train_loaded_episodes": 898.0}
{"step": 9816992, "train_return": 18.0, "train_length": 1882.0, "train_total_steps": 2454248.0, "train_total_episodes": 1199.0, "train_loaded_steps": 1999409.0, "train_loaded_episodes": 899.0}
{"step": 9824364, "train_return": 19.0, "train_length": 1843.0, "train_total_steps": 2456091.0, "train_total_episodes": 1200.0, "train_loaded_steps": 1998384.0, "train_loaded_episodes": 899.0}
{"step": 9827448, "kl_loss": 1.4017379995346069, "image_loss": 3772.0002, "reward_loss": 0.9191956231117249, "discount_loss": 0.007741931137442589, "model_kl": 1.4017379690170289, "prior_ent": 27.632228424072267, "post_ent": 26.24114242553711, "model_loss": 3773.098309765625, "model_loss_scale": 12478.0544, "model_grad_norm": Infinity, "actor_loss": -0.003301506266387878, "actor_loss_scale": 3362154.0864, "actor_grad_norm": 0.0459020888864994, "critic_loss": 0.9254019231796264, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3936363627910614, "reward_mean": 0.005742922144988552, "reward_std": 0.07877249819040298, "reward_normed_mean": 0.005742922144988552, "reward_normed_std": 0.07877249819040298, "critic_slow": 5.65035823135376, "critic_target": 5.648238521575927, "actor_ent": 1.0539280318260194, "actor_ent_scale": 0.0010000000474974513, "critic": 5.648173783111572, "fps": 105.44999977680865}
{"step": 9832864, "train_return": 16.0, "train_length": 2125.0, "train_total_steps": 2458216.0, "train_total_episodes": 1201.0, "train_loaded_steps": 1996923.0, "train_loaded_episodes": 899.0}
{"step": 9840576, "train_return": 16.0, "train_length": 1928.0, "train_total_steps": 2460144.0, "train_total_episodes": 1202.0, "train_loaded_steps": 1998851.0, "train_loaded_episodes": 900.0}
{"step": 9848808, "train_return": 16.0, "train_length": 2058.0, "train_total_steps": 2462202.0, "train_total_episodes": 1203.0, "train_loaded_steps": 1997738.0, "train_loaded_episodes": 900.0}
{"step": 9857484, "train_return": 15.0, "train_length": 2169.0, "train_total_steps": 2464371.0, "train_total_episodes": 1204.0, "train_loaded_steps": 1999907.0, "train_loaded_episodes": 901.0}
{"step": 9865876, "train_return": 13.0, "train_length": 2098.0, "train_total_steps": 2466469.0, "train_total_episodes": 1205.0, "train_loaded_steps": 1997464.0, "train_loaded_episodes": 901.0}
{"step": 9867448, "kl_loss": 1.4108668104171753, "image_loss": 3772.0001921875, "reward_loss": 0.9192188203811645, "discount_loss": 0.0077438854567706585, "model_kl": 1.4108667812347413, "prior_ent": 27.581480615234376, "post_ent": 26.183333670043947, "model_loss": 3773.09925234375, "model_loss_scale": 8192.0, "model_grad_norm": 5.839321226501465, "actor_loss": -0.0034313103292282904, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.044681158849596975, "critic_loss": 0.9239133133888244, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3970378544926643, "reward_mean": 0.0057821356329892295, "reward_std": 0.07869756554365158, "reward_normed_mean": 0.0057821356329892295, "reward_normed_std": 0.07869756554365158, "critic_slow": 5.647033477020264, "critic_target": 5.643955830383301, "actor_ent": 1.0675153977394105, "actor_ent_scale": 0.0010000000474974513, "critic": 5.643753035354615, "fps": 106.85532909883626}
{"step": 9875068, "train_return": 14.0, "train_length": 2298.0, "train_total_steps": 2468767.0, "train_total_episodes": 1206.0, "train_loaded_steps": 1999762.0, "train_loaded_episodes": 902.0}
{"step": 9882844, "train_return": 17.0, "train_length": 1944.0, "train_total_steps": 2470711.0, "train_total_episodes": 1207.0, "train_loaded_steps": 1998692.0, "train_loaded_episodes": 902.0}
{"step": 9891348, "train_return": 16.0, "train_length": 2126.0, "train_total_steps": 2472837.0, "train_total_episodes": 1208.0, "train_loaded_steps": 1999480.0, "train_loaded_episodes": 902.0}
{"step": 9899300, "train_return": 17.0, "train_length": 1988.0, "train_total_steps": 2474825.0, "train_total_episodes": 1209.0, "train_loaded_steps": 1999727.0, "train_loaded_episodes": 902.0}
{"step": 9907444, "eval_return": 17.0, "eval_length": 2032.0, "eval_total_steps": 23736.0, "eval_total_episodes": 12.0, "eval_loaded_steps": 23747.0, "eval_loaded_episodes": 12.0}
{"step": 9907448, "kl_loss": 1.3994045328140259, "image_loss": 3772.0, "reward_loss": 0.9192282283782959, "discount_loss": 0.007786513933539391, "model_kl": 1.3994045003890991, "prior_ent": 27.701389599609374, "post_ent": 26.313817855834962, "model_loss": 3773.0981359375, "model_loss_scale": 8192.0, "model_grad_norm": 5.896245003509521, "actor_loss": -0.0028848765281494705, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.046791444033384325, "critic_loss": 0.925238365650177, "critic_loss_scale": 143654.912, "critic_grad_norm": Infinity, "reward_mean": 0.00577148023591144, "reward_std": 0.07892322393655778, "reward_normed_mean": 0.00577148023591144, "reward_normed_std": 0.07892322393655778, "critic_slow": 5.69622029876709, "critic_target": 5.694467156219482, "actor_ent": 1.0421936195373536, "actor_ent_scale": 0.0010000000474974513, "critic": 5.694302904510498, "fps": 102.33202964685113}
{"step": 9907596, "train_return": 14.0, "train_length": 2074.0, "train_total_steps": 2476899.0, "train_total_episodes": 1210.0, "train_loaded_steps": 1997907.0, "train_loaded_episodes": 902.0}
{"step": 9915316, "train_return": 19.0, "train_length": 1930.0, "train_total_steps": 2478829.0, "train_total_episodes": 1211.0, "train_loaded_steps": 1999837.0, "train_loaded_episodes": 903.0}
{"step": 9922360, "train_return": 19.0, "train_length": 1761.0, "train_total_steps": 2480590.0, "train_total_episodes": 1212.0, "train_loaded_steps": 1997149.0, "train_loaded_episodes": 903.0}
{"step": 9929744, "train_return": 17.0, "train_length": 1846.0, "train_total_steps": 2482436.0, "train_total_episodes": 1213.0, "train_loaded_steps": 1998995.0, "train_loaded_episodes": 904.0}
{"step": 9936592, "train_return": 20.0, "train_length": 1712.0, "train_total_steps": 2484148.0, "train_total_episodes": 1214.0, "train_loaded_steps": 1996166.0, "train_loaded_episodes": 904.0}
{"step": 9943788, "train_return": 18.0, "train_length": 1799.0, "train_total_steps": 2485947.0, "train_total_episodes": 1215.0, "train_loaded_steps": 1997965.0, "train_loaded_episodes": 905.0}
{"step": 9947448, "kl_loss": 1.3996354780197144, "image_loss": 3772.0, "reward_loss": 0.9192073902130127, "discount_loss": 0.007767471402138472, "model_kl": 1.3996354433059692, "prior_ent": 27.597866244506836, "post_ent": 26.209008685302734, "model_loss": 3773.098045703125, "model_loss_scale": 10459.5456, "model_grad_norm": 5.704157490539551, "actor_loss": -0.00035370976683334445, "actor_loss_scale": 5885447.3728, "actor_grad_norm": 0.04539420104920864, "critic_loss": 0.9244101999282837, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.35634658571481703, "reward_mean": 0.005928067628957797, "reward_std": 0.07988230274319649, "reward_normed_mean": 0.005928067628957797, "reward_normed_std": 0.07988230274319649, "critic_slow": 5.676596304321289, "critic_target": 5.674021726608276, "actor_ent": 1.1176723271369935, "actor_ent_scale": 0.0010000000474974513, "critic": 5.673961913681031, "fps": 106.89941715093666}
{"step": 9951356, "train_return": 16.0, "train_length": 1892.0, "train_total_steps": 2487839.0, "train_total_episodes": 1216.0, "train_loaded_steps": 1999857.0, "train_loaded_episodes": 906.0}
{"step": 9960136, "train_return": 12.0, "train_length": 2195.0, "train_total_steps": 2490034.0, "train_total_episodes": 1217.0, "train_loaded_steps": 1999682.0, "train_loaded_episodes": 906.0}
{"step": 9966796, "train_return": 21.0, "train_length": 1665.0, "train_total_steps": 2491699.0, "train_total_episodes": 1218.0, "train_loaded_steps": 1999363.0, "train_loaded_episodes": 906.0}
{"step": 9974884, "train_return": 15.0, "train_length": 2022.0, "train_total_steps": 2493721.0, "train_total_episodes": 1219.0, "train_loaded_steps": 1999224.0, "train_loaded_episodes": 906.0}
{"step": 9982580, "train_return": 17.0, "train_length": 1924.0, "train_total_steps": 2495645.0, "train_total_episodes": 1220.0, "train_loaded_steps": 1996845.0, "train_loaded_episodes": 906.0}
{"step": 9987448, "kl_loss": 1.410007592010498, "image_loss": 3772.0, "reward_loss": 0.9192312218666077, "discount_loss": 0.007743605595827103, "model_kl": 1.4100075565338135, "prior_ent": 27.545686389160156, "post_ent": 26.15107950439453, "model_loss": 3773.098976953125, "model_loss_scale": 16384.0, "model_grad_norm": 5.791057791900635, "actor_loss": -0.005745599347422831, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.04582845914959908, "critic_loss": 0.9249556681632995, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.40420802083015445, "reward_mean": 0.005722252498805756, "reward_std": 0.0791807754456997, "reward_normed_mean": 0.005722252498805756, "reward_normed_std": 0.0791807754456997, "critic_slow": 5.661539929580688, "critic_target": 5.659598350143432, "actor_ent": 1.1156621607780457, "actor_ent_scale": 0.0010000000474974513, "critic": 5.659593243026733, "fps": 105.78278496437821}
{"step": 9990520, "train_return": 17.0, "train_length": 1985.0, "train_total_steps": 2497630.0, "train_total_episodes": 1221.0, "train_loaded_steps": 1998830.0, "train_loaded_episodes": 907.0}
{"step": 9998048, "train_return": 19.0, "train_length": 1882.0, "train_total_steps": 2499512.0, "train_total_episodes": 1222.0, "train_loaded_steps": 1997097.0, "train_loaded_episodes": 907.0}
{"step": 10005592, "train_return": 18.0, "train_length": 1886.0, "train_total_steps": 2501398.0, "train_total_episodes": 1223.0, "train_loaded_steps": 1998983.0, "train_loaded_episodes": 908.0}
{"step": 10012884, "train_return": 18.0, "train_length": 1823.0, "train_total_steps": 2503221.0, "train_total_episodes": 1224.0, "train_loaded_steps": 1998091.0, "train_loaded_episodes": 908.0}
{"step": 10020936, "train_return": 15.0, "train_length": 2013.0, "train_total_steps": 2505234.0, "train_total_episodes": 1225.0, "train_loaded_steps": 1995949.0, "train_loaded_episodes": 908.0}
{"step": 10027448, "kl_loss": 1.4078805110931396, "image_loss": 3772.000187890625, "reward_loss": 0.9192138869285583, "discount_loss": 0.007742251145839691, "model_kl": 1.4078804777145386, "prior_ent": 27.684204663085936, "post_ent": 26.29086936340332, "model_loss": 3773.09892734375, "model_loss_scale": 11259.0848, "model_grad_norm": Infinity, "actor_loss": 0.0014836448610592926, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.04515396744906902, "critic_loss": 0.924700519657135, "critic_loss_scale": 144284.0576, "critic_grad_norm": 0.39538546725511553, "reward_mean": 0.006088434540911112, "reward_std": 0.07971342198252677, "reward_normed_mean": 0.006088434540911112, "reward_normed_std": 0.07971342198252677, "critic_slow": 5.693610927581787, "critic_target": 5.691140510940552, "actor_ent": 1.1856387845993042, "actor_ent_scale": 0.0010000000474974513, "critic": 5.690983403778076, "fps": 106.6504292435076}
{"step": 10028848, "train_return": 16.0, "train_length": 1978.0, "train_total_steps": 2507212.0, "train_total_episodes": 1226.0, "train_loaded_steps": 1997927.0, "train_loaded_episodes": 909.0}
{"step": 10036752, "train_return": 17.0, "train_length": 1976.0, "train_total_steps": 2509188.0, "train_total_episodes": 1227.0, "train_loaded_steps": 1999903.0, "train_loaded_episodes": 910.0}
{"step": 10043852, "train_return": 19.0, "train_length": 1775.0, "train_total_steps": 2510963.0, "train_total_episodes": 1228.0, "train_loaded_steps": 1998454.0, "train_loaded_episodes": 910.0}
{"step": 10051340, "train_return": 18.0, "train_length": 1872.0, "train_total_steps": 2512835.0, "train_total_episodes": 1229.0, "train_loaded_steps": 1997732.0, "train_loaded_episodes": 910.0}
{"step": 10058872, "train_return": 18.0, "train_length": 1883.0, "train_total_steps": 2514718.0, "train_total_episodes": 1230.0, "train_loaded_steps": 1999615.0, "train_loaded_episodes": 911.0}
{"step": 10067108, "train_return": 16.0, "train_length": 2059.0, "train_total_steps": 2516777.0, "train_total_episodes": 1231.0, "train_loaded_steps": 1998927.0, "train_loaded_episodes": 911.0}
{"step": 10067448, "kl_loss": 1.4684547468185425, "image_loss": 3772.0, "reward_loss": 0.9192267402648926, "discount_loss": 0.007774995449185371, "model_kl": 1.4684547132492065, "prior_ent": 27.72459866027832, "post_ent": 26.282283486938475, "model_loss": 3773.104987890625, "model_loss_scale": 8192.0, "model_grad_norm": 5.849344686126709, "actor_loss": -0.008410482632892673, "actor_loss_scale": 8147016.0896, "actor_grad_norm": Infinity, "critic_loss": 0.9269525468826294, "critic_loss_scale": 69625.4464, "critic_grad_norm": Infinity, "reward_mean": 0.005895641025254736, "reward_std": 0.07989405305981637, "reward_normed_mean": 0.005895641025254736, "reward_normed_std": 0.07989405305981637, "critic_slow": 5.747802944946289, "critic_target": 5.742689113616944, "actor_ent": 1.122915566921234, "actor_ent_scale": 0.0010000000474974513, "critic": 5.74266964263916, "fps": 106.56691533886848}
{"step": 10074936, "train_return": 17.0, "train_length": 1957.0, "train_total_steps": 2518734.0, "train_total_episodes": 1232.0, "train_loaded_steps": 1998279.0, "train_loaded_episodes": 911.0}
{"step": 10084536, "train_return": 12.0, "train_length": 2400.0, "train_total_steps": 2521134.0, "train_total_episodes": 1233.0, "train_loaded_steps": 1997376.0, "train_loaded_episodes": 911.0}
{"step": 10092444, "train_return": 18.0, "train_length": 1977.0, "train_total_steps": 2523111.0, "train_total_episodes": 1234.0, "train_loaded_steps": 1999353.0, "train_loaded_episodes": 912.0}
{"step": 10101800, "train_return": 13.0, "train_length": 2339.0, "train_total_steps": 2525450.0, "train_total_episodes": 1235.0, "train_loaded_steps": 1998901.0, "train_loaded_episodes": 912.0}
{"step": 10107448, "kl_loss": 1.4111102657318115, "image_loss": 3772.0, "reward_loss": 0.9192130690574646, "discount_loss": 0.0077521323367953305, "model_kl": 1.4111102319717408, "prior_ent": 27.781304876708983, "post_ent": 26.374707723999023, "model_loss": 3773.099125390625, "model_loss_scale": 8192.0, "model_grad_norm": 5.707094720840454, "actor_loss": -0.00027859218193334527, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.042541015672683716, "critic_loss": 0.9233991754531861, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.3401051300227642, "reward_mean": 0.005930445248726756, "reward_std": 0.0796318182170391, "reward_normed_mean": 0.005930445248726756, "reward_normed_std": 0.0796318182170391, "critic_slow": 5.6756807155609135, "critic_target": 5.674348031616211, "actor_ent": 1.1796841716766358, "actor_ent_scale": 0.0010000000474974513, "critic": 5.674213673019409, "fps": 106.29336372234803}
{"step": 10109572, "train_return": 16.0, "train_length": 1943.0, "train_total_steps": 2527393.0, "train_total_episodes": 1236.0, "train_loaded_steps": 1998187.0, "train_loaded_episodes": 912.0}
{"step": 10117092, "train_return": 19.0, "train_length": 1880.0, "train_total_steps": 2529273.0, "train_total_episodes": 1237.0, "train_loaded_steps": 1995623.0, "train_loaded_episodes": 912.0}
{"step": 10124448, "train_return": 18.0, "train_length": 1839.0, "train_total_steps": 2531112.0, "train_total_episodes": 1238.0, "train_loaded_steps": 1997462.0, "train_loaded_episodes": 913.0}
{"step": 10131288, "train_return": 20.0, "train_length": 1710.0, "train_total_steps": 2532822.0, "train_total_episodes": 1239.0, "train_loaded_steps": 1999172.0, "train_loaded_episodes": 914.0}
{"step": 10139172, "train_return": 18.0, "train_length": 1971.0, "train_total_steps": 2534793.0, "train_total_episodes": 1240.0, "train_loaded_steps": 1997122.0, "train_loaded_episodes": 914.0}
{"step": 10146712, "train_return": 18.0, "train_length": 1885.0, "train_total_steps": 2536678.0, "train_total_episodes": 1241.0, "train_loaded_steps": 1999007.0, "train_loaded_episodes": 915.0}
{"step": 10147448, "kl_loss": 1.391306612586975, "image_loss": 3772.000387890625, "reward_loss": 0.9192111392021179, "discount_loss": 0.007780186554789543, "model_kl": 1.3913065780639648, "prior_ent": 27.615139443969728, "post_ent": 26.23135909729004, "model_loss": 3773.09766640625, "model_loss_scale": 11678.5152, "model_grad_norm": 5.796749488830566, "actor_loss": -0.00039004430835775565, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.04371049598455429, "critic_loss": 0.9233176571846008, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.3489802352309227, "reward_mean": 0.005958023509662598, "reward_std": 0.08019617697000503, "reward_normed_mean": 0.005958023509662598, "reward_normed_std": 0.08019617697000503, "critic_slow": 5.6729250946044925, "critic_target": 5.671980648803711, "actor_ent": 1.1475285194396974, "actor_ent_scale": 0.0010000000474974513, "critic": 5.67197534866333, "fps": 106.75407391306845}
{"step": 10154280, "train_return": 19.0, "train_length": 1892.0, "train_total_steps": 2538570.0, "train_total_episodes": 1242.0, "train_loaded_steps": 1997976.0, "train_loaded_episodes": 915.0}
{"step": 10153652, "eval_return": 19.0, "eval_length": 1848.0, "eval_total_steps": 25766.0, "eval_total_episodes": 13.0, "eval_loaded_steps": 25779.0, "eval_loaded_episodes": 13.0}
{"step": 10153656, "kl_loss": 1.5802507400512695, "image_loss": 3772.0, "reward_loss": 0.9190965294837952, "discount_loss": 0.00773828336969018, "model_kl": 1.5802507400512695, "prior_ent": 27.785810470581055, "post_ent": 26.289352416992188, "model_loss": 3773.11572265625, "model_loss_scale": 16384.0, "model_grad_norm": 4.465564250946045, "actor_loss": 0.009878440760076046, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.05081824213266373, "critic_loss": 0.9271988868713379, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.21282199025154114, "reward_mean": 0.005315965041518211, "reward_std": 0.07419278472661972, "reward_normed_mean": 0.005315965041518211, "reward_normed_std": 0.07419278472661972, "critic_slow": 5.181195259094238, "critic_target": 5.178107261657715, "actor_ent": 1.0444421768188477, "actor_ent_scale": 0.0010000000474974513, "critic": 5.180325984954834, "fps": 0.0}
{"step": 10163280, "train_return": 12.0, "train_length": 2407.0, "train_total_steps": 2540820.0, "train_total_episodes": 1243.0, "train_loaded_steps": 1995814.0, "train_loaded_episodes": 915.0}
{"step": 10170112, "train_return": 20.0, "train_length": 1708.0, "train_total_steps": 2542528.0, "train_total_episodes": 1244.0, "train_loaded_steps": 1997522.0, "train_loaded_episodes": 916.0}
{"step": 10177272, "train_return": 20.0, "train_length": 1790.0, "train_total_steps": 2544318.0, "train_total_episodes": 1245.0, "train_loaded_steps": 1999312.0, "train_loaded_episodes": 917.0}
{"step": 10185316, "train_return": 17.0, "train_length": 2011.0, "train_total_steps": 2546329.0, "train_total_episodes": 1246.0, "train_loaded_steps": 1997364.0, "train_loaded_episodes": 917.0}
{"step": 10193124, "train_return": 17.0, "train_length": 1952.0, "train_total_steps": 2548281.0, "train_total_episodes": 1247.0, "train_loaded_steps": 1999316.0, "train_loaded_episodes": 918.0}
{"step": 10193656, "kl_loss": 1.4221952619552611, "image_loss": 3772.0, "reward_loss": 0.9191982484817505, "discount_loss": 0.007816900119185448, "model_kl": 1.4221952268600464, "prior_ent": 27.605312789916994, "post_ent": 26.196768768310548, "model_loss": 3773.1005328125, "model_loss_scale": 2084.0448, "model_grad_norm": Infinity, "actor_loss": 0.0009420222581509734, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.04918672677874565, "critic_loss": 0.9283135759353638, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.4377429439544678, "reward_mean": 0.006101661345234606, "reward_std": 0.07941626932621003, "reward_normed_mean": 0.006101661345234606, "reward_normed_std": 0.07941626932621003, "critic_slow": 5.651224936676026, "critic_target": 5.649423746490479, "actor_ent": 1.0693744526863098, "actor_ent_scale": 0.0010000000474974513, "critic": 5.649420355987549, "fps": 107.39942129837293}
{"step": 10200700, "train_return": 19.0, "train_length": 1894.0, "train_total_steps": 2550175.0, "train_total_episodes": 1248.0, "train_loaded_steps": 1995787.0, "train_loaded_episodes": 918.0}
{"step": 10209304, "train_return": 17.0, "train_length": 2151.0, "train_total_steps": 2552326.0, "train_total_episodes": 1249.0, "train_loaded_steps": 1997938.0, "train_loaded_episodes": 919.0}
{"step": 10216472, "train_return": 18.0, "train_length": 1792.0, "train_total_steps": 2554118.0, "train_total_episodes": 1250.0, "train_loaded_steps": 1999730.0, "train_loaded_episodes": 920.0}
{"step": 10224224, "train_return": 18.0, "train_length": 1938.0, "train_total_steps": 2556056.0, "train_total_episodes": 1251.0, "train_loaded_steps": 1997959.0, "train_loaded_episodes": 920.0}
{"step": 10231392, "train_return": 19.0, "train_length": 1792.0, "train_total_steps": 2557848.0, "train_total_episodes": 1252.0, "train_loaded_steps": 1999751.0, "train_loaded_episodes": 921.0}
{"step": 10233656, "kl_loss": 1.3952171144485475, "image_loss": 3772.0, "reward_loss": 0.9192031601905822, "discount_loss": 0.007753408340364695, "model_kl": 1.3952170835494995, "prior_ent": 27.61161256713867, "post_ent": 26.220192514038086, "model_loss": 3773.097526953125, "model_loss_scale": 2048.0, "model_grad_norm": 5.493981837654114, "actor_loss": -0.005833187006917433, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.04622873798012733, "critic_loss": 0.9244015727043152, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.36723831512928007, "reward_mean": 0.006056547509459779, "reward_std": 0.08007687756419182, "reward_normed_mean": 0.006056547509459779, "reward_normed_std": 0.08007687756419182, "critic_slow": 5.605121126174927, "critic_target": 5.602664572143555, "actor_ent": 1.0720615110397338, "actor_ent_scale": 0.0010000000474974513, "critic": 5.602644589614868, "fps": 107.3304376734124}
{"step": 10239812, "train_return": 16.0, "train_length": 2105.0, "train_total_steps": 2559953.0, "train_total_episodes": 1253.0, "train_loaded_steps": 1999010.0, "train_loaded_episodes": 921.0}
{"step": 10248296, "train_return": 14.0, "train_length": 2121.0, "train_total_steps": 2562074.0, "train_total_episodes": 1254.0, "train_loaded_steps": 1998577.0, "train_loaded_episodes": 921.0}
{"step": 10255008, "train_return": 21.0, "train_length": 1678.0, "train_total_steps": 2563752.0, "train_total_episodes": 1255.0, "train_loaded_steps": 1997146.0, "train_loaded_episodes": 921.0}
{"step": 10261956, "train_return": 20.0, "train_length": 1737.0, "train_total_steps": 2565489.0, "train_total_episodes": 1256.0, "train_loaded_steps": 1998883.0, "train_loaded_episodes": 922.0}
{"step": 10270176, "train_return": 16.0, "train_length": 2055.0, "train_total_steps": 2567544.0, "train_total_episodes": 1257.0, "train_loaded_steps": 1997927.0, "train_loaded_episodes": 922.0}
{"step": 10273656, "kl_loss": 1.4004307739257813, "image_loss": 3772.0, "reward_loss": 0.9191860518455506, "discount_loss": 0.0077422381825745104, "model_kl": 1.4004307382583618, "prior_ent": 27.52589963684082, "post_ent": 26.140183654785154, "model_loss": 3773.097972265625, "model_loss_scale": 2048.0, "model_grad_norm": 5.883854897117614, "actor_loss": -0.0006401330144522945, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.04337570753991604, "critic_loss": 0.9233194363594055, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.39147069519758226, "reward_mean": 0.0062386668423772785, "reward_std": 0.08111775498390197, "reward_normed_mean": 0.0062386668423772785, "reward_normed_std": 0.08111775498390197, "critic_slow": 5.624649856948852, "critic_target": 5.622755753707886, "actor_ent": 1.0942185926437378, "actor_ent_scale": 0.0010000000474974513, "critic": 5.622671699142456, "fps": 107.58581605964788}
{"step": 10278572, "train_return": 14.0, "train_length": 2099.0, "train_total_steps": 2569643.0, "train_total_episodes": 1258.0, "train_loaded_steps": 1995451.0, "train_loaded_episodes": 922.0}
{"step": 10285748, "train_return": 19.0, "train_length": 1794.0, "train_total_steps": 2571437.0, "train_total_episodes": 1259.0, "train_loaded_steps": 1997245.0, "train_loaded_episodes": 923.0}
{"step": 10293312, "train_return": 19.0, "train_length": 1891.0, "train_total_steps": 2573328.0, "train_total_episodes": 1260.0, "train_loaded_steps": 1999136.0, "train_loaded_episodes": 924.0}
{"step": 10300772, "train_return": 19.0, "train_length": 1865.0, "train_total_steps": 2575193.0, "train_total_episodes": 1261.0, "train_loaded_steps": 1998244.0, "train_loaded_episodes": 924.0}
{"step": 10309076, "train_return": 16.0, "train_length": 2076.0, "train_total_steps": 2577269.0, "train_total_episodes": 1262.0, "train_loaded_steps": 1996646.0, "train_loaded_episodes": 924.0}
{"step": 10313656, "kl_loss": 1.3818528539657593, "image_loss": 3772.0, "reward_loss": 0.9191992011070251, "discount_loss": 0.007763105281442403, "model_kl": 1.3818528217315673, "prior_ent": 27.449354190063477, "post_ent": 26.078772604370116, "model_loss": 3773.096227734375, "model_loss_scale": 3676.5696, "model_grad_norm": 5.6930825853347775, "actor_loss": -0.0014366894606151618, "actor_loss_scale": 59087.2576, "actor_grad_norm": 0.042409376057982444, "critic_loss": 0.9239512097358704, "critic_loss_scale": 59087.2576, "critic_grad_norm": 0.38222217779159545, "reward_mean": 0.006105962236062624, "reward_std": 0.08000835474133491, "reward_normed_mean": 0.006105962236062624, "reward_normed_std": 0.08000835474133491, "critic_slow": 5.6750267578125, "critic_target": 5.672738297271729, "actor_ent": 1.1114508639335632, "actor_ent_scale": 0.0010000000474974513, "critic": 5.67273955154419, "fps": 108.91219808139088}
{"step": 10316424, "train_return": 19.0, "train_length": 1837.0, "train_total_steps": 2579106.0, "train_total_episodes": 1263.0, "train_loaded_steps": 1998483.0, "train_loaded_episodes": 925.0}
{"step": 10324252, "train_return": 16.0, "train_length": 1957.0, "train_total_steps": 2581063.0, "train_total_episodes": 1264.0, "train_loaded_steps": 1996458.0, "train_loaded_episodes": 925.0}
{"step": 10330884, "train_return": 21.0, "train_length": 1658.0, "train_total_steps": 2582721.0, "train_total_episodes": 1265.0, "train_loaded_steps": 1998116.0, "train_loaded_episodes": 926.0}
{"step": 10337876, "train_return": 19.0, "train_length": 1748.0, "train_total_steps": 2584469.0, "train_total_episodes": 1266.0, "train_loaded_steps": 1999864.0, "train_loaded_episodes": 927.0}
{"step": 10345648, "train_return": 17.0, "train_length": 1943.0, "train_total_steps": 2586412.0, "train_total_episodes": 1267.0, "train_loaded_steps": 1997633.0, "train_loaded_episodes": 927.0}
{"step": 10353396, "train_return": 17.0, "train_length": 1937.0, "train_total_steps": 2588349.0, "train_total_episodes": 1268.0, "train_loaded_steps": 1999570.0, "train_loaded_episodes": 928.0}
{"step": 10353656, "kl_loss": 1.3990765272140504, "image_loss": 3772.0, "reward_loss": 0.919183880519867, "discount_loss": 0.007741450937092304, "model_kl": 1.3990764959335327, "prior_ent": 27.366034756469727, "post_ent": 25.983389178466798, "model_loss": 3773.097830078125, "model_loss_scale": 4096.0, "model_grad_norm": 5.732298439025879, "actor_loss": -0.0034734726350405254, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.042342790737748146, "critic_loss": 0.9239332488059998, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.37650388134717944, "reward_mean": 0.0062581629696302115, "reward_std": 0.08044168784618377, "reward_normed_mean": 0.0062581629696302115, "reward_normed_std": 0.08044168784618377, "critic_slow": 5.65699917678833, "critic_target": 5.653713506698608, "actor_ent": 1.153054016685486, "actor_ent_scale": 0.0010000000474974513, "critic": 5.653691929626465, "fps": 107.31909648652363}
{"step": 10361380, "train_return": 16.0, "train_length": 1996.0, "train_total_steps": 2590345.0, "train_total_episodes": 1269.0, "train_loaded_steps": 1998982.0, "train_loaded_episodes": 928.0}
{"step": 10369888, "train_return": 15.0, "train_length": 2127.0, "train_total_steps": 2592472.0, "train_total_episodes": 1270.0, "train_loaded_steps": 1997707.0, "train_loaded_episodes": 928.0}
{"step": 10378024, "train_return": 16.0, "train_length": 2034.0, "train_total_steps": 2594506.0, "train_total_episodes": 1271.0, "train_loaded_steps": 1999741.0, "train_loaded_episodes": 929.0}
{"step": 10386380, "train_return": 18.0, "train_length": 2089.0, "train_total_steps": 2596595.0, "train_total_episodes": 1272.0, "train_loaded_steps": 1998201.0, "train_loaded_episodes": 929.0}
{"step": 10393656, "kl_loss": 1.395289861869812, "image_loss": 3772.0, "reward_loss": 0.9192118447303772, "discount_loss": 0.007756437347084284, "model_kl": 1.3952898286819457, "prior_ent": 27.569166134643556, "post_ent": 26.18631506652832, "model_loss": 3773.09755390625, "model_loss_scale": 4096.0, "model_grad_norm": 5.810404348182678, "actor_loss": -0.0056554869784944456, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.04378668367564678, "critic_loss": 0.9248941621780395, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.3820620721578598, "reward_mean": 0.006291348372137872, "reward_std": 0.08065754821300507, "reward_normed_mean": 0.006291348372137872, "reward_normed_std": 0.08065754821300507, "critic_slow": 5.624666111755371, "critic_target": 5.622428498458862, "actor_ent": 1.1486711804389953, "actor_ent_scale": 0.0010000000474974513, "critic": 5.622380278778076, "fps": 108.3599860729791}
{"step": 10394448, "train_return": 15.0, "train_length": 2017.0, "train_total_steps": 2598612.0, "train_total_episodes": 1273.0, "train_loaded_steps": 1997091.0, "train_loaded_episodes": 929.0}
{"step": 10402304, "train_return": 17.0, "train_length": 1964.0, "train_total_steps": 2600576.0, "train_total_episodes": 1274.0, "train_loaded_steps": 1999055.0, "train_loaded_episodes": 930.0}
{"step": 10410916, "train_return": 17.0, "train_length": 2153.0, "train_total_steps": 2602729.0, "train_total_episodes": 1275.0, "train_loaded_steps": 1998132.0, "train_loaded_episodes": 930.0}
{"step": 10419504, "train_return": 16.0, "train_length": 2147.0, "train_total_steps": 2604876.0, "train_total_episodes": 1276.0, "train_loaded_steps": 1996288.0, "train_loaded_episodes": 930.0}
{"step": 10426756, "train_return": 19.0, "train_length": 1813.0, "train_total_steps": 2606689.0, "train_total_episodes": 1277.0, "train_loaded_steps": 1998101.0, "train_loaded_episodes": 931.0}
{"step": 10433648, "train_return": 19.0, "train_length": 1723.0, "train_total_steps": 2608412.0, "train_total_episodes": 1278.0, "train_loaded_steps": 1999824.0, "train_loaded_episodes": 932.0}
{"step": 10433656, "kl_loss": 1.3746293531417846, "image_loss": 3772.0, "reward_loss": 0.9192143856048584, "discount_loss": 0.007756158778071403, "model_kl": 1.3746293212890626, "prior_ent": 27.507082510375977, "post_ent": 26.140009509277345, "model_loss": 3773.09549140625, "model_loss_scale": 6533.9392, "model_grad_norm": 5.793645121383667, "actor_loss": -0.0030468313934165054, "actor_loss_scale": 105067.3152, "actor_grad_norm": 0.04314150062799454, "critic_loss": 0.9232500916481018, "critic_loss_scale": 105067.3152, "critic_grad_norm": 0.3656378191947937, "reward_mean": 0.00606068218445871, "reward_std": 0.08002272474765777, "reward_normed_mean": 0.00606068218445871, "reward_normed_std": 0.08002272474765777, "critic_slow": 5.617796969223022, "critic_target": 5.6147710208892825, "actor_ent": 1.1499051834106446, "actor_ent_scale": 0.0010000000474974513, "critic": 5.61470796661377, "fps": 107.49308268301512}
{"step": 10442068, "train_return": 17.0, "train_length": 2105.0, "train_total_steps": 2610517.0, "train_total_episodes": 1279.0, "train_loaded_steps": 1998709.0, "train_loaded_episodes": 932.0}
{"step": 10450308, "train_return": 17.0, "train_length": 2060.0, "train_total_steps": 2612577.0, "train_total_episodes": 1280.0, "train_loaded_steps": 1996642.0, "train_loaded_episodes": 932.0}
{"step": 10458260, "train_return": 17.0, "train_length": 1988.0, "train_total_steps": 2614565.0, "train_total_episodes": 1281.0, "train_loaded_steps": 1998630.0, "train_loaded_episodes": 933.0}
{"step": 10465980, "train_return": 17.0, "train_length": 1930.0, "train_total_steps": 2616495.0, "train_total_episodes": 1282.0, "train_loaded_steps": 1996860.0, "train_loaded_episodes": 933.0}
{"step": 10473148, "train_return": 19.0, "train_length": 1792.0, "train_total_steps": 2618287.0, "train_total_episodes": 1283.0, "train_loaded_steps": 1998652.0, "train_loaded_episodes": 934.0}
{"step": 10473656, "kl_loss": 1.4402660831451417, "image_loss": 3772.0, "reward_loss": 0.9192193132400512, "discount_loss": 0.007829290669411421, "model_kl": 1.4402660526275635, "prior_ent": 27.31837501220703, "post_ent": 25.908926446533204, "model_loss": 3773.102429296875, "model_loss_scale": 8192.0, "model_grad_norm": 5.838585623931885, "actor_loss": -0.006193485291340039, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.043078991889953615, "critic_loss": 0.9259499180793762, "critic_loss_scale": 125619.4048, "critic_grad_norm": Infinity, "reward_mean": 0.006144922757183667, "reward_std": 0.08036295893192291, "reward_normed_mean": 0.006144922757183667, "reward_normed_std": 0.08036295893192291, "critic_slow": 5.541474166870117, "critic_target": 5.538758965682983, "actor_ent": 1.1451576261520386, "actor_ent_scale": 0.0010000000474974513, "critic": 5.538769490432739, "fps": 108.08074785549607}
{"step": 10480464, "train_return": 19.0, "train_length": 1829.0, "train_total_steps": 2620116.0, "train_total_episodes": 1284.0, "train_loaded_steps": 1997163.0, "train_loaded_episodes": 934.0}
{"step": 10487688, "train_return": 19.0, "train_length": 1806.0, "train_total_steps": 2621922.0, "train_total_episodes": 1285.0, "train_loaded_steps": 1998969.0, "train_loaded_episodes": 935.0}
{"step": 10495192, "train_return": 18.0, "train_length": 1876.0, "train_total_steps": 2623798.0, "train_total_episodes": 1286.0, "train_loaded_steps": 1998376.0, "train_loaded_episodes": 935.0}
{"step": 10503148, "train_return": 17.0, "train_length": 1989.0, "train_total_steps": 2625787.0, "train_total_episodes": 1287.0, "train_loaded_steps": 1997869.0, "train_loaded_episodes": 935.0}
{"step": 10511956, "train_return": 16.0, "train_length": 2202.0, "train_total_steps": 2627989.0, "train_total_episodes": 1288.0, "train_loaded_steps": 1996434.0, "train_loaded_episodes": 935.0}
{"step": 10513656, "kl_loss": 1.3961537633895873, "image_loss": 3772.0, "reward_loss": 0.9192000769615173, "discount_loss": 0.007770442543178797, "model_kl": 1.3961537284851073, "prior_ent": 27.26376103515625, "post_ent": 25.87880773010254, "model_loss": 3773.097697265625, "model_loss_scale": 8192.0, "model_grad_norm": 5.762157502365112, "actor_loss": -0.00391388400279975, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.04461807659864426, "critic_loss": 0.9239743247032165, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.36628108417987826, "reward_mean": 0.006364538932981668, "reward_std": 0.08052402387857437, "reward_normed_mean": 0.006364538932981668, "reward_normed_std": 0.08052402387857437, "critic_slow": 5.544252294921875, "critic_target": 5.5403091796875, "actor_ent": 1.068609028816223, "actor_ent_scale": 0.0010000000474974513, "critic": 5.540394776916504, "fps": 107.58024818267386}
{"step": 10519136, "train_return": 18.0, "train_length": 1795.0, "train_total_steps": 2629784.0, "train_total_episodes": 1289.0, "train_loaded_steps": 1998229.0, "train_loaded_episodes": 936.0}
{"step": 10526916, "train_return": 18.0, "train_length": 1945.0, "train_total_steps": 2631729.0, "train_total_episodes": 1290.0, "train_loaded_steps": 1996660.0, "train_loaded_episodes": 936.0}
{"step": 10534408, "train_return": 18.0, "train_length": 1873.0, "train_total_steps": 2633602.0, "train_total_episodes": 1291.0, "train_loaded_steps": 1998533.0, "train_loaded_episodes": 937.0}
{"step": 10542736, "train_return": 16.0, "train_length": 2082.0, "train_total_steps": 2635684.0, "train_total_episodes": 1292.0, "train_loaded_steps": 1997868.0, "train_loaded_episodes": 937.0}
{"step": 10549900, "train_return": 19.0, "train_length": 1791.0, "train_total_steps": 2637475.0, "train_total_episodes": 1293.0, "train_loaded_steps": 1999659.0, "train_loaded_episodes": 938.0}
{"step": 10553656, "kl_loss": 1.3576792274475098, "image_loss": 3772.0, "reward_loss": 0.919169636440277, "discount_loss": 0.007746067796647549, "model_kl": 1.3576791923522948, "prior_ent": 27.27265161743164, "post_ent": 25.922129595947265, "model_loss": 3773.09370234375, "model_loss_scale": 10433.3312, "model_grad_norm": Infinity, "actor_loss": -0.007227385308267549, "actor_loss_scale": 183920.2304, "actor_grad_norm": 0.042163575929403306, "critic_loss": 0.9234716137886048, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.32842775408029556, "reward_mean": 0.006349093345587607, "reward_std": 0.08075547764897346, "reward_normed_mean": 0.006349093345587607, "reward_normed_std": 0.08075547764897346, "critic_slow": 5.513059762191772, "critic_target": 5.5090980709075925, "actor_ent": 1.1428986991882324, "actor_ent_scale": 0.0010000000474974513, "critic": 5.509155439376831, "fps": 107.94357553826525}
{"step": 10559016, "train_return": 13.0, "train_length": 2279.0, "train_total_steps": 2639754.0, "train_total_episodes": 1294.0, "train_loaded_steps": 1999590.0, "train_loaded_episodes": 938.0}
{"step": 10566708, "train_return": 16.0, "train_length": 1923.0, "train_total_steps": 2641677.0, "train_total_episodes": 1295.0, "train_loaded_steps": 1997478.0, "train_loaded_episodes": 938.0}
{"step": 10574368, "train_return": 17.0, "train_length": 1915.0, "train_total_steps": 2643592.0, "train_total_episodes": 1296.0, "train_loaded_steps": 1999393.0, "train_loaded_episodes": 939.0}
{"step": 10581092, "train_return": 20.0, "train_length": 1681.0, "train_total_steps": 2645273.0, "train_total_episodes": 1297.0, "train_loaded_steps": 1997522.0, "train_loaded_episodes": 939.0}
{"step": 10589148, "train_return": 15.0, "train_length": 2014.0, "train_total_steps": 2647287.0, "train_total_episodes": 1298.0, "train_loaded_steps": 1999536.0, "train_loaded_episodes": 940.0}
{"step": 10593656, "kl_loss": 1.4129456502914428, "image_loss": 3772.0, "reward_loss": 0.9192162365913391, "discount_loss": 0.007770363722741604, "model_kl": 1.412945620918274, "prior_ent": 27.35511474304199, "post_ent": 25.965608993530275, "model_loss": 3773.099402734375, "model_loss_scale": 8192.0, "model_grad_norm": 5.482645253372192, "actor_loss": -0.005309248152471264, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.0415113726913929, "critic_loss": 0.9236196228981018, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.39287852259874345, "reward_mean": 0.006367897873278707, "reward_std": 0.08068088412880897, "reward_normed_mean": 0.006367897873278707, "reward_normed_std": 0.08068088412880897, "critic_slow": 5.440931203079224, "critic_target": 5.436852646255494, "actor_ent": 1.1556264073371887, "actor_ent_scale": 0.0010000000474974513, "critic": 5.4368575634002685, "fps": 108.36016657000516}
{"step": 10596476, "train_return": 19.0, "train_length": 1832.0, "train_total_steps": 2649119.0, "train_total_episodes": 1299.0, "train_loaded_steps": 1997861.0, "train_loaded_episodes": 940.0}
{"step": 10604768, "train_return": 17.0, "train_length": 2073.0, "train_total_steps": 2651192.0, "train_total_episodes": 1300.0, "train_loaded_steps": 1999934.0, "train_loaded_episodes": 941.0}
{"step": 10613588, "train_return": 15.0, "train_length": 2205.0, "train_total_steps": 2653397.0, "train_total_episodes": 1301.0, "train_loaded_steps": 1999023.0, "train_loaded_episodes": 941.0}
{"step": 10621724, "train_return": 15.0, "train_length": 2034.0, "train_total_steps": 2655431.0, "train_total_episodes": 1302.0, "train_loaded_steps": 1997309.0, "train_loaded_episodes": 941.0}
{"step": 10629848, "train_return": 16.0, "train_length": 2031.0, "train_total_steps": 2657462.0, "train_total_episodes": 1303.0, "train_loaded_steps": 1999340.0, "train_loaded_episodes": 942.0}
{"step": 10633656, "kl_loss": 1.3869091579437256, "image_loss": 3772.0001921875, "reward_loss": 0.9192069905281067, "discount_loss": 0.0077426154747605325, "model_kl": 1.3869091314315796, "prior_ent": 27.271452908325195, "post_ent": 25.894565478515624, "model_loss": 3773.096837109375, "model_loss_scale": 8192.0, "model_grad_norm": 5.589374546813965, "actor_loss": -0.0056660731181327716, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.041073727390170095, "critic_loss": 0.922008244228363, "critic_loss_scale": 123417.3952, "critic_grad_norm": 0.3193029402256012, "reward_mean": 0.00637220407751156, "reward_std": 0.0806035761654377, "reward_normed_mean": 0.00637220407751156, "reward_normed_std": 0.0806035761654377, "critic_slow": 5.459006117248535, "critic_target": 5.457206803512573, "actor_ent": 1.1600372087478639, "actor_ent_scale": 0.0010000000474974513, "critic": 5.457156632614136, "fps": 107.81749460928947}
{"step": 10638004, "train_return": 16.0, "train_length": 2039.0, "train_total_steps": 2659501.0, "train_total_episodes": 1304.0, "train_loaded_steps": 1998139.0, "train_loaded_episodes": 942.0}
{"step": 10646020, "train_return": 16.0, "train_length": 2004.0, "train_total_steps": 2661505.0, "train_total_episodes": 1305.0, "train_loaded_steps": 1996080.0, "train_loaded_episodes": 942.0}
{"step": 10655956, "train_return": 11.0, "train_length": 2484.0, "train_total_steps": 2663989.0, "train_total_episodes": 1306.0, "train_loaded_steps": 1998564.0, "train_loaded_episodes": 943.0}
{"step": 10663428, "train_return": 19.0, "train_length": 1868.0, "train_total_steps": 2665857.0, "train_total_episodes": 1307.0, "train_loaded_steps": 1996555.0, "train_loaded_episodes": 943.0}
{"step": 10672460, "train_return": 15.0, "train_length": 2258.0, "train_total_steps": 2668115.0, "train_total_episodes": 1308.0, "train_loaded_steps": 1998813.0, "train_loaded_episodes": 944.0}
{"step": 10673656, "kl_loss": 1.3952993890762329, "image_loss": 3772.0, "reward_loss": 0.9191839414596558, "discount_loss": 0.007758060385286808, "model_kl": 1.3952993560791016, "prior_ent": 27.189987350463866, "post_ent": 25.815414794921875, "model_loss": 3773.097537109375, "model_loss_scale": 8192.0, "model_grad_norm": 5.684861357498169, "actor_loss": -0.00491050312295265, "actor_loss_scale": 315411.6608, "actor_grad_norm": 0.041429302075505256, "critic_loss": 0.9226764313697815, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.381594020652771, "reward_mean": 0.006426199579238892, "reward_std": 0.08109966391921043, "reward_normed_mean": 0.006426199579238892, "reward_normed_std": 0.08109966391921043, "critic_slow": 5.398374712753296, "critic_target": 5.396149892425537, "actor_ent": 1.1295876759529113, "actor_ent_scale": 0.0010000000474974513, "critic": 5.396139093399048, "fps": 108.8940308496965}
{"step": 10679748, "train_return": 19.0, "train_length": 1822.0, "train_total_steps": 2669937.0, "train_total_episodes": 1309.0, "train_loaded_steps": 1997931.0, "train_loaded_episodes": 944.0}
{"step": 10688048, "train_return": 15.0, "train_length": 2075.0, "train_total_steps": 2672012.0, "train_total_episodes": 1310.0, "train_loaded_steps": 1996745.0, "train_loaded_episodes": 944.0}
{"step": 10695280, "train_return": 19.0, "train_length": 1808.0, "train_total_steps": 2673820.0, "train_total_episodes": 1311.0, "train_loaded_steps": 1998553.0, "train_loaded_episodes": 945.0}
{"step": 10702548, "train_return": 19.0, "train_length": 1817.0, "train_total_steps": 2675637.0, "train_total_episodes": 1312.0, "train_loaded_steps": 1997034.0, "train_loaded_episodes": 945.0}
{"step": 10711124, "train_return": 13.0, "train_length": 2144.0, "train_total_steps": 2677781.0, "train_total_episodes": 1313.0, "train_loaded_steps": 1999178.0, "train_loaded_episodes": 946.0}
{"step": 10713656, "kl_loss": 1.3843242319107056, "image_loss": 3772.0, "reward_loss": 0.919206166267395, "discount_loss": 0.007758152072131634, "model_kl": 1.3843241987228394, "prior_ent": 27.269898336791993, "post_ent": 25.89474924621582, "model_loss": 3773.096464453125, "model_loss_scale": 9070.1824, "model_grad_norm": Infinity, "actor_loss": -0.0041222538383197385, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.04111747702360153, "critic_loss": 0.9229390627861023, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3897013064742088, "reward_mean": 0.00633231950654299, "reward_std": 0.08015170690417289, "reward_normed_mean": 0.00633231950654299, "reward_normed_std": 0.08015170690417289, "critic_slow": 5.326744708633423, "critic_target": 5.324495957183838, "actor_ent": 1.1627314729690552, "actor_ent_scale": 0.0010000000474974513, "critic": 5.3244593097686765, "fps": 108.47408953509485}
{"step": 10718404, "train_return": 19.0, "train_length": 1820.0, "train_total_steps": 2679601.0, "train_total_episodes": 1314.0, "train_loaded_steps": 1997519.0, "train_loaded_episodes": 946.0}
{"step": 10725380, "train_return": 20.0, "train_length": 1744.0, "train_total_steps": 2681345.0, "train_total_episodes": 1315.0, "train_loaded_steps": 1999263.0, "train_loaded_episodes": 947.0}
{"step": 10732100, "train_return": 21.0, "train_length": 1680.0, "train_total_steps": 2683025.0, "train_total_episodes": 1316.0, "train_loaded_steps": 1997714.0, "train_loaded_episodes": 947.0}
{"step": 10739748, "train_return": 17.0, "train_length": 1912.0, "train_total_steps": 2684937.0, "train_total_episodes": 1317.0, "train_loaded_steps": 1999626.0, "train_loaded_episodes": 948.0}
{"step": 10747000, "train_return": 18.0, "train_length": 1813.0, "train_total_steps": 2686750.0, "train_total_episodes": 1318.0, "train_loaded_steps": 1997556.0, "train_loaded_episodes": 948.0}
{"step": 10753656, "kl_loss": 1.367503768157959, "image_loss": 3772.0, "reward_loss": 0.9191810562133789, "discount_loss": 0.007744413627684116, "model_kl": 1.3675037380218507, "prior_ent": 27.186381558227538, "post_ent": 25.831026095581056, "model_loss": 3773.09468828125, "model_loss_scale": 8192.0, "model_grad_norm": 5.624947746276855, "actor_loss": -0.0009365847973371274, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.03986385442018509, "critic_loss": 0.9206772089958191, "critic_loss_scale": 191679.6928, "critic_grad_norm": Infinity, "reward_mean": 0.00637647979297617, "reward_std": 0.08097840616703034, "reward_normed_mean": 0.00637647979297617, "reward_normed_std": 0.08097840616703034, "critic_slow": 5.28763662147522, "critic_target": 5.287081295013428, "actor_ent": 1.1726962938308716, "actor_ent_scale": 0.0010000000474974513, "critic": 5.287040023422241, "fps": 107.56230732661703}
{"step": 10755396, "train_return": 15.0, "train_length": 2099.0, "train_total_steps": 2688849.0, "train_total_episodes": 1319.0, "train_loaded_steps": 1999655.0, "train_loaded_episodes": 949.0}
{"step": 10762604, "train_return": 19.0, "train_length": 1802.0, "train_total_steps": 2690651.0, "train_total_episodes": 1320.0, "train_loaded_steps": 1998316.0, "train_loaded_episodes": 949.0}
{"step": 10770280, "train_return": 16.0, "train_length": 1919.0, "train_total_steps": 2692570.0, "train_total_episodes": 1321.0, "train_loaded_steps": 1997486.0, "train_loaded_episodes": 949.0}
{"step": 10778076, "train_return": 18.0, "train_length": 1949.0, "train_total_steps": 2694519.0, "train_total_episodes": 1322.0, "train_loaded_steps": 1999435.0, "train_loaded_episodes": 950.0}
{"step": 10786024, "train_return": 17.0, "train_length": 1987.0, "train_total_steps": 2696506.0, "train_total_episodes": 1323.0, "train_loaded_steps": 1998017.0, "train_loaded_episodes": 950.0}
{"step": 10793656, "kl_loss": 1.4299547555923462, "image_loss": 3772.0, "reward_loss": 0.9191858137130737, "discount_loss": 0.007741833840310574, "model_kl": 1.4299547220230102, "prior_ent": 27.18089015197754, "post_ent": 25.772736154174805, "model_loss": 3773.10092421875, "model_loss_scale": 8192.0, "model_grad_norm": 5.662331772041321, "actor_loss": -0.003933200550542097, "actor_loss_scale": 525965.7216, "actor_grad_norm": 0.040014304512739185, "critic_loss": 0.921099920463562, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.34206312090158464, "reward_mean": 0.006476150586456061, "reward_std": 0.08112954177856445, "reward_normed_mean": 0.006476150586456061, "reward_normed_std": 0.08112954177856445, "critic_slow": 5.196524238204956, "critic_target": 5.195262014770508, "actor_ent": 1.2246927768707276, "actor_ent_scale": 0.0010000000474974513, "critic": 5.195156162261963, "fps": 107.81365334527598}
{"step": 10793748, "train_return": 18.0, "train_length": 1931.0, "train_total_steps": 2698437.0, "train_total_episodes": 1324.0, "train_loaded_steps": 1999948.0, "train_loaded_episodes": 951.0}
{"step": 10800748, "train_return": 20.0, "train_length": 1750.0, "train_total_steps": 2700187.0, "train_total_episodes": 1325.0, "train_loaded_steps": 1998840.0, "train_loaded_episodes": 951.0}
{"step": 10809228, "train_return": 15.0, "train_length": 2120.0, "train_total_steps": 2702307.0, "train_total_episodes": 1326.0, "train_loaded_steps": 1996432.0, "train_loaded_episodes": 951.0}
{"step": 10816628, "train_return": 19.0, "train_length": 1850.0, "train_total_steps": 2704157.0, "train_total_episodes": 1327.0, "train_loaded_steps": 1998282.0, "train_loaded_episodes": 952.0}
{"step": 10823976, "train_return": 19.0, "train_length": 1837.0, "train_total_steps": 2705994.0, "train_total_episodes": 1328.0, "train_loaded_steps": 1997751.0, "train_loaded_episodes": 952.0}
{"step": 10831180, "train_return": 19.0, "train_length": 1801.0, "train_total_steps": 2707795.0, "train_total_episodes": 1329.0, "train_loaded_steps": 1999552.0, "train_loaded_episodes": 953.0}
{"step": 10833656, "kl_loss": 1.4115578998565674, "image_loss": 3772.0, "reward_loss": 0.919172531414032, "discount_loss": 0.007741308321803808, "model_kl": 1.411557865715027, "prior_ent": 27.23032930908203, "post_ent": 25.83278801574707, "model_loss": 3773.0990640625, "model_loss_scale": 13225.1648, "model_grad_norm": 5.53827351398468, "actor_loss": -0.005010485024820082, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.04150687789022923, "critic_loss": 0.9221267079353332, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3288155089020729, "reward_mean": 0.006473420365829952, "reward_std": 0.08090043452382088, "reward_normed_mean": 0.006473420365829952, "reward_normed_std": 0.08090043452382088, "critic_slow": 5.177337019729614, "critic_target": 5.174547776031494, "actor_ent": 1.194795970916748, "actor_ent_scale": 0.0010000000474974513, "critic": 5.174662788391113, "fps": 108.39491543151728}
{"step": 10838272, "train_return": 18.0, "train_length": 1773.0, "train_total_steps": 2709568.0, "train_total_episodes": 1330.0, "train_loaded_steps": 1997746.0, "train_loaded_episodes": 953.0}
{"step": 10846392, "train_return": 17.0, "train_length": 2030.0, "train_total_steps": 2711598.0, "train_total_episodes": 1331.0, "train_loaded_steps": 1999776.0, "train_loaded_episodes": 954.0}
{"step": 10854400, "train_return": 17.0, "train_length": 2002.0, "train_total_steps": 2713600.0, "train_total_episodes": 1332.0, "train_loaded_steps": 1998673.0, "train_loaded_episodes": 954.0}
{"step": 10862296, "train_return": 16.0, "train_length": 1974.0, "train_total_steps": 2715574.0, "train_total_episodes": 1333.0, "train_loaded_steps": 1997951.0, "train_loaded_episodes": 954.0}
{"step": 10870204, "train_return": 17.0, "train_length": 1977.0, "train_total_steps": 2717551.0, "train_total_episodes": 1334.0, "train_loaded_steps": 1999928.0, "train_loaded_episodes": 955.0}
{"step": 10873656, "kl_loss": 1.3579694690704345, "image_loss": 3772.0, "reward_loss": 0.9191874428749085, "discount_loss": 0.007742641638964415, "model_kl": 1.3579694360733032, "prior_ent": 27.170249844360352, "post_ent": 25.820568682861328, "model_loss": 3773.0937375, "model_loss_scale": 16384.0, "model_grad_norm": 5.42753334274292, "actor_loss": -0.006802365423507581, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.04061600457131863, "critic_loss": 0.9212606639862061, "critic_loss_scale": 133798.2976, "critic_grad_norm": 0.33159565165042876, "reward_mean": 0.006589827744412469, "reward_std": 0.08123722348809242, "reward_normed_mean": 0.006589827744412469, "reward_normed_std": 0.08123722348809242, "critic_slow": 5.237598985290528, "critic_target": 5.236522172164917, "actor_ent": 1.2659405004501343, "actor_ent_scale": 0.0010000000474974513, "critic": 5.236404967880249, "fps": 108.31744194924043}
{"step": 10877772, "train_return": 19.0, "train_length": 1892.0, "train_total_steps": 2719443.0, "train_total_episodes": 1335.0, "train_loaded_steps": 1999178.0, "train_loaded_episodes": 955.0}
{"step": 10885144, "train_return": 19.0, "train_length": 1843.0, "train_total_steps": 2721286.0, "train_total_episodes": 1336.0, "train_loaded_steps": 1998216.0, "train_loaded_episodes": 955.0}
{"step": 10892776, "train_return": 17.0, "train_length": 1908.0, "train_total_steps": 2723194.0, "train_total_episodes": 1337.0, "train_loaded_steps": 1996679.0, "train_loaded_episodes": 955.0}
{"step": 10900208, "train_return": 18.0, "train_length": 1858.0, "train_total_steps": 2725052.0, "train_total_episodes": 1338.0, "train_loaded_steps": 1998537.0, "train_loaded_episodes": 956.0}
{"step": 10907900, "train_return": 16.0, "train_length": 1923.0, "train_total_steps": 2726975.0, "train_total_episodes": 1339.0, "train_loaded_steps": 1997530.0, "train_loaded_episodes": 956.0}
{"step": 10913656, "kl_loss": 1.3707762998580932, "image_loss": 3772.0, "reward_loss": 0.9191732151031494, "discount_loss": 0.007741811541467905, "model_kl": 1.3707762603759766, "prior_ent": 27.349157833862304, "post_ent": 25.993332369995116, "model_loss": 3773.09498984375, "model_loss_scale": 16384.0, "model_grad_norm": 5.538509703636169, "actor_loss": -0.0002851176909171045, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.0397854933142662, "critic_loss": 0.9209764126777649, "critic_loss_scale": 134637.1584, "critic_grad_norm": Infinity, "reward_mean": 0.006502938001300208, "reward_std": 0.08108090596199036, "reward_normed_mean": 0.006502938001300208, "reward_normed_std": 0.08108090596199036, "critic_slow": 5.213293822479248, "critic_target": 5.213800337600708, "actor_ent": 1.2592504991531372, "actor_ent_scale": 0.0010000000474974513, "critic": 5.21369217414856, "fps": 107.28823082854503}
{"step": 10915996, "train_return": 16.0, "train_length": 2024.0, "train_total_steps": 2728999.0, "train_total_episodes": 1340.0, "train_loaded_steps": 1999554.0, "train_loaded_episodes": 957.0}
{"step": 10923528, "train_return": 17.0, "train_length": 1883.0, "train_total_steps": 2730882.0, "train_total_episodes": 1341.0, "train_loaded_steps": 1997733.0, "train_loaded_episodes": 957.0}
{"step": 10930180, "train_return": 21.0, "train_length": 1663.0, "train_total_steps": 2732545.0, "train_total_episodes": 1342.0, "train_loaded_steps": 1999396.0, "train_loaded_episodes": 958.0}
{"step": 10937524, "train_return": 19.0, "train_length": 1836.0, "train_total_steps": 2734381.0, "train_total_episodes": 1343.0, "train_loaded_steps": 1996587.0, "train_loaded_episodes": 958.0}
{"step": 10945984, "train_return": 17.0, "train_length": 2115.0, "train_total_steps": 2736496.0, "train_total_episodes": 1344.0, "train_loaded_steps": 1998702.0, "train_loaded_episodes": 959.0}
{"step": 10953264, "train_return": 19.0, "train_length": 1820.0, "train_total_steps": 2738316.0, "train_total_episodes": 1345.0, "train_loaded_steps": 1997328.0, "train_loaded_episodes": 959.0}
{"step": 10953656, "kl_loss": 1.3845331811904906, "image_loss": 3772.0, "reward_loss": 0.919190075302124, "discount_loss": 0.007742396806925535, "model_kl": 1.3845331495285034, "prior_ent": 27.270043200683595, "post_ent": 25.899147357177736, "model_loss": 3773.09637890625, "model_loss_scale": 18271.4368, "model_grad_norm": Infinity, "actor_loss": 0.0004294307843549177, "actor_loss_scale": 1890792.2432, "actor_grad_norm": 0.038954622209072115, "critic_loss": 0.9209902733802795, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.35120269275307653, "reward_mean": 0.0066337654331786325, "reward_std": 0.08132820685505868, "reward_normed_mean": 0.0066337654331786325, "reward_normed_std": 0.08132820685505868, "critic_slow": 5.193151159667969, "critic_target": 5.19299168510437, "actor_ent": 1.248156353378296, "actor_ent_scale": 0.0010000000474974513, "critic": 5.192941706466675, "fps": 108.50030270172914}
{"step": 10960604, "train_return": 19.0, "train_length": 1835.0, "train_total_steps": 2740151.0, "train_total_episodes": 1346.0, "train_loaded_steps": 1999163.0, "train_loaded_episodes": 960.0}
{"step": 10968872, "train_return": 16.0, "train_length": 2067.0, "train_total_steps": 2742218.0, "train_total_episodes": 1347.0, "train_loaded_steps": 1997982.0, "train_loaded_episodes": 960.0}
{"step": 10975732, "train_return": 20.0, "train_length": 1715.0, "train_total_steps": 2743933.0, "train_total_episodes": 1348.0, "train_loaded_steps": 1999697.0, "train_loaded_episodes": 961.0}
{"step": 10982868, "train_return": 19.0, "train_length": 1784.0, "train_total_steps": 2745717.0, "train_total_episodes": 1349.0, "train_loaded_steps": 1997099.0, "train_loaded_episodes": 961.0}
{"step": 10991120, "train_return": 14.0, "train_length": 2063.0, "train_total_steps": 2747780.0, "train_total_episodes": 1350.0, "train_loaded_steps": 1999162.0, "train_loaded_episodes": 962.0}
{"step": 10993656, "kl_loss": 1.3549770391464233, "image_loss": 3772.00019609375, "reward_loss": 0.9192293740272522, "discount_loss": 0.0077415844403207305, "model_kl": 1.3549770086288453, "prior_ent": 27.301252972412108, "post_ent": 25.95439829711914, "model_loss": 3773.0936640625, "model_loss_scale": 16384.0, "model_grad_norm": 5.454607076072693, "actor_loss": -0.0007412776175391627, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.03818765633702278, "critic_loss": 0.9208635261535645, "critic_loss_scale": 103809.024, "critic_grad_norm": Infinity, "reward_mean": 0.006520259543613065, "reward_std": 0.08091635921001435, "reward_normed_mean": 0.006520259543613065, "reward_normed_std": 0.08091635921001435, "critic_slow": 5.265342832946778, "critic_target": 5.2645026927947995, "actor_ent": 1.2610358251571656, "actor_ent_scale": 0.0010000000474974513, "critic": 5.264723873901367, "fps": 107.92344879461189}
{"step": 10997956, "train_return": 20.0, "train_length": 1709.0, "train_total_steps": 2749489.0, "train_total_episodes": 1351.0, "train_loaded_steps": 1997539.0, "train_loaded_episodes": 962.0}
{"step": 11005308, "train_return": 18.0, "train_length": 1838.0, "train_total_steps": 2751327.0, "train_total_episodes": 1352.0, "train_loaded_steps": 1999377.0, "train_loaded_episodes": 963.0}
{"step": 11013588, "train_return": 15.0, "train_length": 2070.0, "train_total_steps": 2753397.0, "train_total_episodes": 1353.0, "train_loaded_steps": 1998188.0, "train_loaded_episodes": 963.0}
{"step": 11020436, "train_return": 20.0, "train_length": 1712.0, "train_total_steps": 2755109.0, "train_total_episodes": 1354.0, "train_loaded_steps": 1999900.0, "train_loaded_episodes": 964.0}
{"step": 11027944, "train_return": 17.0, "train_length": 1877.0, "train_total_steps": 2756986.0, "train_total_episodes": 1355.0, "train_loaded_steps": 1998023.0, "train_loaded_episodes": 964.0}
{"step": 11033656, "kl_loss": 1.3778000011444091, "image_loss": 3772.0, "reward_loss": 0.9191824036598205, "discount_loss": 0.007756188616901636, "model_kl": 1.3777999732971191, "prior_ent": 27.452476974487304, "post_ent": 26.08762116394043, "model_loss": 3773.095772265625, "model_loss_scale": 16384.0, "model_grad_norm": 5.46540937461853, "actor_loss": -0.0019154116361169145, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.03681595215499401, "critic_loss": 0.9201012791633606, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.2758839713037014, "reward_mean": 0.006476039252869668, "reward_std": 0.08130766968131066, "reward_normed_mean": 0.006476039252869668, "reward_normed_std": 0.08130766968131066, "critic_slow": 5.254025894927978, "critic_target": 5.252918804550171, "actor_ent": 1.2499969551086425, "actor_ent_scale": 0.0010000000474974513, "critic": 5.2529841304779055, "fps": 107.61378730399993}
{"step": 11035992, "train_return": 17.0, "train_length": 2012.0, "train_total_steps": 2758998.0, "train_total_episodes": 1356.0, "train_loaded_steps": 1996726.0, "train_loaded_episodes": 964.0}
{"step": 11043048, "train_return": 19.0, "train_length": 1764.0, "train_total_steps": 2760762.0, "train_total_episodes": 1357.0, "train_loaded_steps": 1998490.0, "train_loaded_episodes": 965.0}
{"step": 11050776, "train_return": 17.0, "train_length": 1932.0, "train_total_steps": 2762694.0, "train_total_episodes": 1358.0, "train_loaded_steps": 1997548.0, "train_loaded_episodes": 965.0}
{"step": 11058064, "train_return": 18.0, "train_length": 1822.0, "train_total_steps": 2764516.0, "train_total_episodes": 1359.0, "train_loaded_steps": 1999370.0, "train_loaded_episodes": 966.0}
{"step": 11065352, "train_return": 19.0, "train_length": 1822.0, "train_total_steps": 2766338.0, "train_total_episodes": 1360.0, "train_loaded_steps": 1997563.0, "train_loaded_episodes": 966.0}
{"step": 11073656, "kl_loss": 1.3931312927246093, "image_loss": 3772.0, "reward_loss": 0.9191795112609863, "discount_loss": 0.007749323251843452, "model_kl": 1.39313126373291, "prior_ent": 27.18881608886719, "post_ent": 25.81674096374512, "model_loss": 3773.097273828125, "model_loss_scale": 17091.7888, "model_grad_norm": Infinity, "actor_loss": -0.002256495233619353, "actor_loss_scale": 3362154.0864, "actor_grad_norm": 0.03743462916910648, "critic_loss": 0.920061403465271, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.30915609444379805, "reward_mean": 0.006718734655078151, "reward_std": 0.08097681389451027, "reward_normed_mean": 0.006718734655078151, "reward_normed_std": 0.08097681389451027, "critic_slow": 5.195781430053711, "critic_target": 5.195764685440063, "actor_ent": 1.2713387420654296, "actor_ent_scale": 0.0010000000474974513, "critic": 5.19578480758667, "fps": 108.30714919431463}
{"step": 11073876, "train_return": 13.0, "train_length": 2131.0, "train_total_steps": 2768469.0, "train_total_episodes": 1361.0, "train_loaded_steps": 1999694.0, "train_loaded_episodes": 967.0}
{"step": 11081592, "train_return": 17.0, "train_length": 1929.0, "train_total_steps": 2770398.0, "train_total_episodes": 1362.0, "train_loaded_steps": 1998068.0, "train_loaded_episodes": 967.0}
{"step": 11089732, "train_return": 17.0, "train_length": 2035.0, "train_total_steps": 2772433.0, "train_total_episodes": 1363.0, "train_loaded_steps": 1996900.0, "train_loaded_episodes": 967.0}
{"step": 11096420, "train_return": 20.0, "train_length": 1672.0, "train_total_steps": 2774105.0, "train_total_episodes": 1364.0, "train_loaded_steps": 1998572.0, "train_loaded_episodes": 968.0}
{"step": 11104992, "train_return": 13.0, "train_length": 2143.0, "train_total_steps": 2776248.0, "train_total_episodes": 1365.0, "train_loaded_steps": 1997062.0, "train_loaded_episodes": 968.0}
{"step": 11113148, "train_return": 16.0, "train_length": 2039.0, "train_total_steps": 2778287.0, "train_total_episodes": 1366.0, "train_loaded_steps": 1999101.0, "train_loaded_episodes": 969.0}
{"step": 11113656, "kl_loss": 1.358468200302124, "image_loss": 3772.0, "reward_loss": 0.9191695199966431, "discount_loss": 0.007742799292504788, "model_kl": 1.3584681688308715, "prior_ent": 27.41689070739746, "post_ent": 26.069910028076173, "model_loss": 3773.0937625, "model_loss_scale": 16384.0, "model_grad_norm": 5.540414087677002, "actor_loss": -0.001602194354479434, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.03816294554173946, "critic_loss": 0.9212688656806945, "critic_loss_scale": 79691.776, "critic_grad_norm": 0.31327201429605483, "reward_mean": 0.006497514574578964, "reward_std": 0.08126990912556649, "reward_normed_mean": 0.006497514574578964, "reward_normed_std": 0.08126990912556649, "critic_slow": 5.173735563659668, "critic_target": 5.174002464294434, "actor_ent": 1.2447097434997558, "actor_ent_scale": 0.0010000000474974513, "critic": 5.174044655227661, "fps": 107.66281603972004}
{"step": 11121984, "train_return": 14.0, "train_length": 2209.0, "train_total_steps": 2780496.0, "train_total_episodes": 1367.0, "train_loaded_steps": 1998277.0, "train_loaded_episodes": 969.0}
{"step": 11129664, "train_return": 18.0, "train_length": 1920.0, "train_total_steps": 2782416.0, "train_total_episodes": 1368.0, "train_loaded_steps": 1997018.0, "train_loaded_episodes": 969.0}
{"step": 11138280, "train_return": 14.0, "train_length": 2154.0, "train_total_steps": 2784570.0, "train_total_episodes": 1369.0, "train_loaded_steps": 1999172.0, "train_loaded_episodes": 970.0}
{"step": 11145728, "train_return": 17.0, "train_length": 1862.0, "train_total_steps": 2786432.0, "train_total_episodes": 1370.0, "train_loaded_steps": 1997897.0, "train_loaded_episodes": 970.0}
{"step": 11153652, "eval_return": 18.0, "eval_length": 1941.0, "eval_total_steps": 27614.0, "eval_total_episodes": 14.0, "eval_loaded_steps": 27627.0, "eval_loaded_episodes": 14.0}
{"step": 11153656, "kl_loss": 1.3391505037307738, "image_loss": 3772.0, "reward_loss": 0.919164729309082, "discount_loss": 0.0077545718006789685, "model_kl": 1.3391504747390748, "prior_ent": 27.21906809082031, "post_ent": 25.888804446411132, "model_loss": 3773.091890234375, "model_loss_scale": 16384.0, "model_grad_norm": 5.339650513839722, "actor_loss": -0.0024233203071780734, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.03980490129590034, "critic_loss": 0.9208664631843567, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.30743372463583946, "reward_mean": 0.006697201879473869, "reward_std": 0.08149332078695297, "reward_normed_mean": 0.006697201879473869, "reward_normed_std": 0.08149332078695297, "critic_slow": 5.182597422790527, "critic_target": 5.182909683609009, "actor_ent": 1.2967769123077393, "actor_ent_scale": 0.0010000000474974513, "critic": 5.182876398086548, "fps": 102.96549177237542}
{"step": 11153724, "train_return": 17.0, "train_length": 1999.0, "train_total_steps": 2788431.0, "train_total_episodes": 1371.0, "train_loaded_steps": 1999896.0, "train_loaded_episodes": 971.0}
{"step": 11161164, "train_return": 17.0, "train_length": 1860.0, "train_total_steps": 2790291.0, "train_total_episodes": 1372.0, "train_loaded_steps": 1998633.0, "train_loaded_episodes": 971.0}
{"step": 11167796, "train_return": 21.0, "train_length": 1658.0, "train_total_steps": 2791949.0, "train_total_episodes": 1373.0, "train_loaded_steps": 1996443.0, "train_loaded_episodes": 971.0}
{"step": 11174400, "train_return": 21.0, "train_length": 1651.0, "train_total_steps": 2793600.0, "train_total_episodes": 1374.0, "train_loaded_steps": 1998094.0, "train_loaded_episodes": 972.0}
{"step": 11181784, "train_return": 19.0, "train_length": 1846.0, "train_total_steps": 2795446.0, "train_total_episodes": 1375.0, "train_loaded_steps": 1999940.0, "train_loaded_episodes": 973.0}
{"step": 11188840, "train_return": 19.0, "train_length": 1764.0, "train_total_steps": 2797210.0, "train_total_episodes": 1376.0, "train_loaded_steps": 1998392.0, "train_loaded_episodes": 973.0}
{"step": 11193656, "kl_loss": 1.3594082651138306, "image_loss": 3772.0, "reward_loss": 0.9191557650566101, "discount_loss": 0.0077675390772521495, "model_kl": 1.3594082372665406, "prior_ent": 27.159180667114256, "post_ent": 25.811059524536134, "model_loss": 3773.09396171875, "model_loss_scale": 14771.8144, "model_grad_norm": Infinity, "actor_loss": -0.004395965622966559, "actor_loss_scale": 5885447.3728, "actor_grad_norm": 0.03830717542171478, "critic_loss": 0.920037771320343, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2838607610821724, "reward_mean": 0.006677764996187762, "reward_std": 0.08141944370865822, "reward_normed_mean": 0.006677764996187762, "reward_normed_std": 0.08141944370865822, "critic_slow": 5.178942813110352, "critic_target": 5.177769581604004, "actor_ent": 1.275660943031311, "actor_ent_scale": 0.0010000000474974513, "critic": 5.177906848526001, "fps": 107.42646075662728}
{"step": 11197664, "train_return": 15.0, "train_length": 2206.0, "train_total_steps": 2799416.0, "train_total_episodes": 1377.0, "train_loaded_steps": 1997286.0, "train_loaded_episodes": 973.0}
{"step": 11205016, "train_return": 19.0, "train_length": 1838.0, "train_total_steps": 2801254.0, "train_total_episodes": 1378.0, "train_loaded_steps": 1999124.0, "train_loaded_episodes": 974.0}
{"step": 11211652, "train_return": 21.0, "train_length": 1659.0, "train_total_steps": 2802913.0, "train_total_episodes": 1379.0, "train_loaded_steps": 1997845.0, "train_loaded_episodes": 974.0}
{"step": 11218616, "train_return": 20.0, "train_length": 1741.0, "train_total_steps": 2804654.0, "train_total_episodes": 1380.0, "train_loaded_steps": 1999586.0, "train_loaded_episodes": 975.0}
{"step": 11225836, "train_return": 19.0, "train_length": 1805.0, "train_total_steps": 2806459.0, "train_total_episodes": 1381.0, "train_loaded_steps": 1998152.0, "train_loaded_episodes": 975.0}
{"step": 11233656, "kl_loss": 1.427842628479004, "image_loss": 3772.0, "reward_loss": 0.9191682374954223, "discount_loss": 0.007741290785372257, "model_kl": 1.4278425985336303, "prior_ent": 27.04117908935547, "post_ent": 25.646106286621094, "model_loss": 3773.10068984375, "model_loss_scale": 8192.0, "model_grad_norm": 5.655025784683228, "actor_loss": -0.002478178199985996, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.036861449748277667, "critic_loss": 0.9202848321914673, "critic_loss_scale": 133169.152, "critic_grad_norm": 0.3098303842425346, "reward_mean": 0.006960237963817781, "reward_std": 0.08182344086170197, "reward_normed_mean": 0.006960237963817781, "reward_normed_std": 0.08182344086170197, "critic_slow": 5.159826731872559, "critic_target": 5.159965186691284, "actor_ent": 1.2338951093673707, "actor_ent_scale": 0.0010000000474974513, "critic": 5.160065789031982, "fps": 108.64056440178956}
{"step": 11233788, "train_return": 18.0, "train_length": 1988.0, "train_total_steps": 2808447.0, "train_total_episodes": 1382.0, "train_loaded_steps": 1997071.0, "train_loaded_episodes": 975.0}
{"step": 11240904, "train_return": 19.0, "train_length": 1779.0, "train_total_steps": 2810226.0, "train_total_episodes": 1383.0, "train_loaded_steps": 1998850.0, "train_loaded_episodes": 976.0}
{"step": 11247552, "train_return": 21.0, "train_length": 1662.0, "train_total_steps": 2811888.0, "train_total_episodes": 1384.0, "train_loaded_steps": 1997225.0, "train_loaded_episodes": 976.0}
{"step": 11254724, "train_return": 18.0, "train_length": 1793.0, "train_total_steps": 2813681.0, "train_total_episodes": 1385.0, "train_loaded_steps": 1999018.0, "train_loaded_episodes": 977.0}
{"step": 11262840, "train_return": 15.0, "train_length": 2029.0, "train_total_steps": 2815710.0, "train_total_episodes": 1386.0, "train_loaded_steps": 1998506.0, "train_loaded_episodes": 977.0}
{"step": 11270168, "train_return": 19.0, "train_length": 1832.0, "train_total_steps": 2817542.0, "train_total_episodes": 1387.0, "train_loaded_steps": 1997160.0, "train_loaded_episodes": 977.0}
{"step": 11273656, "kl_loss": 1.3493193756103516, "image_loss": 3772.0, "reward_loss": 0.919166385269165, "discount_loss": 0.0077448063291609285, "model_kl": 1.3493193468093871, "prior_ent": 27.079806356811524, "post_ent": 25.73767297668457, "model_loss": 3773.092851953125, "model_loss_scale": 8192.0, "model_grad_norm": 5.486498815536499, "actor_loss": -0.005135247077763779, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03798761642277241, "critic_loss": 0.9200005547523499, "critic_loss_scale": 250399.9488, "critic_grad_norm": Infinity, "reward_mean": 0.006754129180253949, "reward_std": 0.08121076682806015, "reward_normed_mean": 0.006754129180253949, "reward_normed_std": 0.08121076682806015, "critic_slow": 5.143086386108399, "critic_target": 5.1420819984436035, "actor_ent": 1.2919644758224487, "actor_ent_scale": 0.0010000000474974513, "critic": 5.142206283187866, "fps": 109.00940042810352}
{"step": 11277016, "train_return": 20.0, "train_length": 1712.0, "train_total_steps": 2819254.0, "train_total_episodes": 1388.0, "train_loaded_steps": 1998872.0, "train_loaded_episodes": 978.0}
{"step": 11284672, "train_return": 19.0, "train_length": 1914.0, "train_total_steps": 2821168.0, "train_total_episodes": 1389.0, "train_loaded_steps": 1997951.0, "train_loaded_episodes": 978.0}
{"step": 11292960, "train_return": 13.0, "train_length": 2072.0, "train_total_steps": 2823240.0, "train_total_episodes": 1390.0, "train_loaded_steps": 1996996.0, "train_loaded_episodes": 978.0}
{"step": 11300576, "train_return": 19.0, "train_length": 1904.0, "train_total_steps": 2825144.0, "train_total_episodes": 1391.0, "train_loaded_steps": 1998900.0, "train_loaded_episodes": 979.0}
{"step": 11307912, "train_return": 18.0, "train_length": 1834.0, "train_total_steps": 2826978.0, "train_total_episodes": 1392.0, "train_loaded_steps": 1998452.0, "train_loaded_episodes": 979.0}
{"step": 11313656, "kl_loss": 1.3524473350524902, "image_loss": 3772.0, "reward_loss": 0.9191790320396424, "discount_loss": 0.007760163803398609, "model_kl": 1.3524473064422606, "prior_ent": 27.26831192932129, "post_ent": 25.926040670776366, "model_loss": 3773.093255078125, "model_loss_scale": 8192.0, "model_grad_norm": 5.185899634742737, "actor_loss": -0.004127150708605768, "actor_loss_scale": 8737574.0928, "actor_grad_norm": Infinity, "critic_loss": 0.9203124978065491, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.318865701007843, "reward_mean": 0.006744273255136796, "reward_std": 0.08122409687638282, "reward_normed_mean": 0.006744273255136796, "reward_normed_std": 0.08122409687638282, "critic_slow": 5.16369698638916, "critic_target": 5.162178948974609, "actor_ent": 1.3099667753219604, "actor_ent_scale": 0.0010000000474974513, "critic": 5.162243534851074, "fps": 107.63803543013947}
{"step": 11315432, "train_return": 17.0, "train_length": 1880.0, "train_total_steps": 2828858.0, "train_total_episodes": 1393.0, "train_loaded_steps": 1997390.0, "train_loaded_episodes": 979.0}
{"step": 11322456, "train_return": 19.0, "train_length": 1756.0, "train_total_steps": 2830614.0, "train_total_episodes": 1394.0, "train_loaded_steps": 1999146.0, "train_loaded_episodes": 980.0}
{"step": 11330372, "train_return": 16.0, "train_length": 1979.0, "train_total_steps": 2832593.0, "train_total_episodes": 1395.0, "train_loaded_steps": 1998609.0, "train_loaded_episodes": 980.0}
{"step": 11337512, "train_return": 19.0, "train_length": 1785.0, "train_total_steps": 2834378.0, "train_total_episodes": 1396.0, "train_loaded_steps": 1997819.0, "train_loaded_episodes": 980.0}
{"step": 11346240, "train_return": 15.0, "train_length": 2182.0, "train_total_steps": 2836560.0, "train_total_episodes": 1397.0, "train_loaded_steps": 1996979.0, "train_loaded_episodes": 980.0}
{"step": 11353176, "train_return": 20.0, "train_length": 1734.0, "train_total_steps": 2838294.0, "train_total_episodes": 1398.0, "train_loaded_steps": 1998713.0, "train_loaded_episodes": 981.0}
{"step": 11353656, "kl_loss": 1.3908093341827392, "image_loss": 3772.0, "reward_loss": 0.9192243041038514, "discount_loss": 0.007856669721752405, "model_kl": 1.3908093027114867, "prior_ent": 27.43868265686035, "post_ent": 26.062324533081053, "model_loss": 3773.097623828125, "model_loss_scale": 16357.7856, "model_grad_norm": 5.383663586807251, "actor_loss": -0.0019131602414112422, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03763317907750607, "critic_loss": 0.9208180391311646, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.29992195695638657, "reward_mean": 0.006914522026479244, "reward_std": 0.08086874801516533, "reward_normed_mean": 0.006914522026479244, "reward_normed_std": 0.08086874801516533, "critic_slow": 5.177748551940918, "critic_target": 5.177360095596313, "actor_ent": 1.2913986530303956, "actor_ent_scale": 0.0010000000474974513, "critic": 5.177429923629761, "fps": 107.24398470212796}
{"step": 11361968, "train_return": 12.0, "train_length": 2198.0, "train_total_steps": 2840492.0, "train_total_episodes": 1399.0, "train_loaded_steps": 1998262.0, "train_loaded_episodes": 981.0}
{"step": 11369224, "train_return": 19.0, "train_length": 1814.0, "train_total_steps": 2842306.0, "train_total_episodes": 1400.0, "train_loaded_steps": 1997793.0, "train_loaded_episodes": 981.0}
{"step": 11377068, "train_return": 17.0, "train_length": 1961.0, "train_total_steps": 2844267.0, "train_total_episodes": 1401.0, "train_loaded_steps": 1999754.0, "train_loaded_episodes": 982.0}
{"step": 11384648, "train_return": 19.0, "train_length": 1895.0, "train_total_steps": 2846162.0, "train_total_episodes": 1402.0, "train_loaded_steps": 1999101.0, "train_loaded_episodes": 982.0}
{"step": 11393064, "train_return": 16.0, "train_length": 2104.0, "train_total_steps": 2848266.0, "train_total_episodes": 1403.0, "train_loaded_steps": 1998280.0, "train_loaded_episodes": 982.0}
{"step": 11393656, "kl_loss": 1.3999548305511476, "image_loss": 3772.0, "reward_loss": 0.9191883209228515, "discount_loss": 0.007767828488349914, "model_kl": 1.3999547971725463, "prior_ent": 27.173042691040038, "post_ent": 25.792352005004883, "model_loss": 3773.0980578125, "model_loss_scale": 13867.4176, "model_grad_norm": Infinity, "actor_loss": -0.001565280833444558, "actor_loss_scale": 7328287.9488, "actor_grad_norm": Infinity, "critic_loss": 0.9216688133239747, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3209149753212929, "reward_mean": 0.006886147960304515, "reward_std": 0.08131254737377167, "reward_normed_mean": 0.006886147960304515, "reward_normed_std": 0.08131254737377167, "critic_slow": 5.160635718154907, "critic_target": 5.158961922836304, "actor_ent": 1.301399663734436, "actor_ent_scale": 0.0010000000474974513, "critic": 5.159055781936646, "fps": 106.82732195539093}
{"step": 11400604, "train_return": 17.0, "train_length": 1885.0, "train_total_steps": 2850151.0, "train_total_episodes": 1404.0, "train_loaded_steps": 1997230.0, "train_loaded_episodes": 982.0}
{"step": 11408216, "train_return": 18.0, "train_length": 1903.0, "train_total_steps": 2852054.0, "train_total_episodes": 1405.0, "train_loaded_steps": 1999133.0, "train_loaded_episodes": 983.0}
{"step": 11415408, "train_return": 19.0, "train_length": 1798.0, "train_total_steps": 2853852.0, "train_total_episodes": 1406.0, "train_loaded_steps": 1998478.0, "train_loaded_episodes": 983.0}
{"step": 11422976, "train_return": 19.0, "train_length": 1892.0, "train_total_steps": 2855744.0, "train_total_episodes": 1407.0, "train_loaded_steps": 1997477.0, "train_loaded_episodes": 983.0}
{"step": 11430612, "train_return": 19.0, "train_length": 1909.0, "train_total_steps": 2857653.0, "train_total_episodes": 1408.0, "train_loaded_steps": 1999386.0, "train_loaded_episodes": 984.0}
{"step": 11433656, "kl_loss": 1.3690749156951905, "image_loss": 3772.0, "reward_loss": 0.9191651275634766, "discount_loss": 0.007758036285638809, "model_kl": 1.369074885749817, "prior_ent": 26.984305938720702, "post_ent": 25.629803973388672, "model_loss": 3773.094909375, "model_loss_scale": 8192.0, "model_grad_norm": 5.326858407020569, "actor_loss": -0.00011268549530650489, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.03670863043963909, "critic_loss": 0.9214759585380554, "critic_loss_scale": 180774.5024, "critic_grad_norm": Infinity, "reward_mean": 0.006829423120658612, "reward_std": 0.08141969314813614, "reward_normed_mean": 0.006829423120658612, "reward_normed_std": 0.08141969314813614, "critic_slow": 5.188809082794189, "critic_target": 5.1885806224822995, "actor_ent": 1.239901353263855, "actor_ent_scale": 0.0010000000474974513, "critic": 5.188806596755981, "fps": 106.0915802791036}
{"step": 11438112, "train_return": 18.0, "train_length": 1875.0, "train_total_steps": 2859528.0, "train_total_episodes": 1409.0, "train_loaded_steps": 1998846.0, "train_loaded_episodes": 984.0}
{"step": 11445252, "train_return": 19.0, "train_length": 1785.0, "train_total_steps": 2861313.0, "train_total_episodes": 1410.0, "train_loaded_steps": 1997917.0, "train_loaded_episodes": 984.0}
{"step": 11452516, "train_return": 20.0, "train_length": 1816.0, "train_total_steps": 2863129.0, "train_total_episodes": 1411.0, "train_loaded_steps": 1999733.0, "train_loaded_episodes": 985.0}
{"step": 11459180, "train_return": 21.0, "train_length": 1666.0, "train_total_steps": 2864795.0, "train_total_episodes": 1412.0, "train_loaded_steps": 1999350.0, "train_loaded_episodes": 985.0}
{"step": 11466092, "train_return": 20.0, "train_length": 1728.0, "train_total_steps": 2866523.0, "train_total_episodes": 1413.0, "train_loaded_steps": 1998295.0, "train_loaded_episodes": 985.0}
{"step": 11472944, "train_return": 20.0, "train_length": 1713.0, "train_total_steps": 2868236.0, "train_total_episodes": 1414.0, "train_loaded_steps": 1997485.0, "train_loaded_episodes": 985.0}
{"step": 11473656, "kl_loss": 1.3276610109329223, "image_loss": 3772.0, "reward_loss": 0.919150723361969, "discount_loss": 0.007747342468798161, "model_kl": 1.3276609828948975, "prior_ent": 27.077783819580077, "post_ent": 25.758323431396484, "model_loss": 3773.09068125, "model_loss_scale": 1603.9936, "model_grad_norm": Infinity, "actor_loss": -0.0016177921937778593, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.034871214246749875, "critic_loss": 0.9186636568069458, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3036308605849743, "reward_mean": 0.007037300250452245, "reward_std": 0.08169418905377387, "reward_normed_mean": 0.007037300250452245, "reward_normed_std": 0.08169418905377387, "critic_slow": 5.182846126556396, "critic_target": 5.182431463241577, "actor_ent": 1.2490731985092163, "actor_ent_scale": 0.0010000000474974513, "critic": 5.182504795837402, "fps": 106.01146978405991}
{"step": 11479832, "train_return": 20.0, "train_length": 1722.0, "train_total_steps": 2869958.0, "train_total_episodes": 1415.0, "train_loaded_steps": 1999207.0, "train_loaded_episodes": 986.0}
{"step": 11486848, "train_return": 20.0, "train_length": 1754.0, "train_total_steps": 2871712.0, "train_total_episodes": 1416.0, "train_loaded_steps": 1998566.0, "train_loaded_episodes": 986.0}
{"step": 11494112, "train_return": 19.0, "train_length": 1816.0, "train_total_steps": 2873528.0, "train_total_episodes": 1417.0, "train_loaded_steps": 1998066.0, "train_loaded_episodes": 986.0}
{"step": 11502216, "train_return": 18.0, "train_length": 2026.0, "train_total_steps": 2875554.0, "train_total_episodes": 1418.0, "train_loaded_steps": 1997675.0, "train_loaded_episodes": 986.0}
{"step": 11510388, "train_return": 16.0, "train_length": 2043.0, "train_total_steps": 2877597.0, "train_total_episodes": 1419.0, "train_loaded_steps": 1999718.0, "train_loaded_episodes": 987.0}
{"step": 11513656, "kl_loss": 1.3404191259384155, "image_loss": 3772.0, "reward_loss": 0.9191461771011352, "discount_loss": 0.007775618839263916, "model_kl": 1.3404190961837767, "prior_ent": 27.113898022460937, "post_ent": 25.785328982543945, "model_loss": 3773.092108984375, "model_loss_scale": 1024.0, "model_grad_norm": 2.3814333775520327, "actor_loss": 0.0006394687551190145, "actor_loss_scale": 4415763.2512, "actor_grad_norm": 0.0344311050131917, "critic_loss": 0.9192762551307678, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3036829097211361, "reward_mean": 0.006995379679673351, "reward_std": 0.08187219337821007, "reward_normed_mean": 0.006995379679673351, "reward_normed_std": 0.08187219337821007, "critic_slow": 5.140548936843872, "critic_target": 5.1408082447052, "actor_ent": 1.2824799003601075, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1407937232971195, "fps": 109.54926528904112}
{"step": 11518128, "train_return": 17.0, "train_length": 1935.0, "train_total_steps": 2879532.0, "train_total_episodes": 1420.0, "train_loaded_steps": 1998630.0, "train_loaded_episodes": 987.0}
{"step": 11524760, "train_return": 21.0, "train_length": 1658.0, "train_total_steps": 2881190.0, "train_total_episodes": 1421.0, "train_loaded_steps": 1997867.0, "train_loaded_episodes": 987.0}
{"step": 11531932, "train_return": 19.0, "train_length": 1793.0, "train_total_steps": 2882983.0, "train_total_episodes": 1422.0, "train_loaded_steps": 1999660.0, "train_loaded_episodes": 988.0}
{"step": 11538796, "train_return": 20.0, "train_length": 1716.0, "train_total_steps": 2884699.0, "train_total_episodes": 1423.0, "train_loaded_steps": 1998893.0, "train_loaded_episodes": 988.0}
{"step": 11545636, "train_return": 20.0, "train_length": 1710.0, "train_total_steps": 2886409.0, "train_total_episodes": 1424.0, "train_loaded_steps": 1998217.0, "train_loaded_episodes": 988.0}
{"step": 11552576, "train_return": 20.0, "train_length": 1735.0, "train_total_steps": 2888144.0, "train_total_episodes": 1425.0, "train_loaded_steps": 1999952.0, "train_loaded_episodes": 989.0}
{"step": 11553656, "kl_loss": 1.3395192974090575, "image_loss": 3772.0, "reward_loss": 0.9191339825630188, "discount_loss": 0.007742267990857363, "model_kl": 1.3395192699432372, "prior_ent": 27.069166064453125, "post_ent": 25.73806802368164, "model_loss": 3773.091830078125, "model_loss_scale": 1024.0, "model_grad_norm": 4.41862993221283, "actor_loss": 0.0006270154149506197, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03331588408052921, "critic_loss": 0.918802986907959, "critic_loss_scale": 171756.7488, "critic_grad_norm": 0.25622251148819924, "reward_mean": 0.007001916948775761, "reward_std": 0.08218192116618156, "reward_normed_mean": 0.007001916948775761, "reward_normed_std": 0.08218192116618156, "critic_slow": 5.152852981185913, "critic_target": 5.153139506530762, "actor_ent": 1.2509211421966553, "actor_ent_scale": 0.0010000000474974513, "critic": 5.15317438659668, "fps": 106.29387654170363}
{"step": 11560612, "train_return": 16.0, "train_length": 2009.0, "train_total_steps": 2890153.0, "train_total_episodes": 1426.0, "train_loaded_steps": 1999730.0, "train_loaded_episodes": 989.0}
{"step": 11568140, "train_return": 18.0, "train_length": 1882.0, "train_total_steps": 2892035.0, "train_total_episodes": 1427.0, "train_loaded_steps": 1999212.0, "train_loaded_episodes": 989.0}
{"step": 11575948, "train_return": 18.0, "train_length": 1952.0, "train_total_steps": 2893987.0, "train_total_episodes": 1428.0, "train_loaded_steps": 1998965.0, "train_loaded_episodes": 989.0}
{"step": 11583340, "train_return": 19.0, "train_length": 1848.0, "train_total_steps": 2895835.0, "train_total_episodes": 1429.0, "train_loaded_steps": 1998734.0, "train_loaded_episodes": 989.0}
{"step": 11591184, "train_return": 17.0, "train_length": 1961.0, "train_total_steps": 2897796.0, "train_total_episodes": 1430.0, "train_loaded_steps": 1998736.0, "train_loaded_episodes": 989.0}
{"step": 11593656, "kl_loss": 1.3448763969421387, "image_loss": 3772.0, "reward_loss": 0.9191590321540832, "discount_loss": 0.007741872351616621, "model_kl": 1.3448763677597046, "prior_ent": 27.039951358032226, "post_ent": 25.70633303833008, "model_loss": 3773.092392578125, "model_loss_scale": 1754.7264, "model_grad_norm": 5.041354597663879, "actor_loss": 0.0011977791340905242, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.033151217253506185, "critic_loss": 0.9190254801750183, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.2615169087409973, "reward_mean": 0.00693787823272869, "reward_std": 0.08152029528617859, "reward_normed_mean": 0.00693787823272869, "reward_normed_std": 0.08152029528617859, "critic_slow": 5.138239904022217, "critic_target": 5.138325199508667, "actor_ent": 1.2638603820800782, "actor_ent_scale": 0.0010000000474974513, "critic": 5.138427845001221, "fps": 106.3850880654053}
{"step": 11598616, "train_return": 19.0, "train_length": 1858.0, "train_total_steps": 2899654.0, "train_total_episodes": 1431.0, "train_loaded_steps": 1998067.0, "train_loaded_episodes": 989.0}
{"step": 11605768, "train_return": 19.0, "train_length": 1788.0, "train_total_steps": 2901442.0, "train_total_episodes": 1432.0, "train_loaded_steps": 1999855.0, "train_loaded_episodes": 990.0}
{"step": 11612812, "train_return": 19.0, "train_length": 1761.0, "train_total_steps": 2903203.0, "train_total_episodes": 1433.0, "train_loaded_steps": 1999184.0, "train_loaded_episodes": 990.0}
{"step": 11621276, "train_return": 14.0, "train_length": 2116.0, "train_total_steps": 2905319.0, "train_total_episodes": 1434.0, "train_loaded_steps": 1998971.0, "train_loaded_episodes": 990.0}
{"step": 11629388, "train_return": 16.0, "train_length": 2028.0, "train_total_steps": 2907347.0, "train_total_episodes": 1435.0, "train_loaded_steps": 1998801.0, "train_loaded_episodes": 990.0}
{"step": 11633656, "kl_loss": 1.3643281866073609, "image_loss": 3772.0, "reward_loss": 0.9191473448753357, "discount_loss": 0.007742177668213844, "model_kl": 1.3643281538009644, "prior_ent": 27.056340689086912, "post_ent": 25.706169360351563, "model_loss": 3773.094325, "model_loss_scale": 2048.0, "model_grad_norm": 5.361490906524658, "actor_loss": -0.00018296436096716206, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03199424238502979, "critic_loss": 0.9187189127922059, "critic_loss_scale": 198390.5792, "critic_grad_norm": Infinity, "reward_mean": 0.006861543114599772, "reward_std": 0.08118272435069084, "reward_normed_mean": 0.006861543114599772, "reward_normed_std": 0.08118272435069084, "critic_slow": 5.190634469604492, "critic_target": 5.191004827499389, "actor_ent": 1.2841802577972412, "actor_ent_scale": 0.0010000000474974513, "critic": 5.191001145553589, "fps": 107.36409326731876}
{"step": 11638584, "train_return": 12.0, "train_length": 2299.0, "train_total_steps": 2909646.0, "train_total_episodes": 1436.0, "train_loaded_steps": 1998278.0, "train_loaded_episodes": 990.0}
{"step": 11646780, "train_return": 15.0, "train_length": 2049.0, "train_total_steps": 2911695.0, "train_total_episodes": 1437.0, "train_loaded_steps": 1997936.0, "train_loaded_episodes": 990.0}
{"step": 11654224, "train_return": 19.0, "train_length": 1861.0, "train_total_steps": 2913556.0, "train_total_episodes": 1438.0, "train_loaded_steps": 1999797.0, "train_loaded_episodes": 991.0}
{"step": 11661588, "train_return": 19.0, "train_length": 1841.0, "train_total_steps": 2915397.0, "train_total_episodes": 1439.0, "train_loaded_steps": 1998759.0, "train_loaded_episodes": 991.0}
{"step": 11669680, "train_return": 16.0, "train_length": 2023.0, "train_total_steps": 2917420.0, "train_total_episodes": 1440.0, "train_loaded_steps": 1998336.0, "train_loaded_episodes": 991.0}
{"step": 11673656, "kl_loss": 1.33438939743042, "image_loss": 3772.0, "reward_loss": 0.9191463490486145, "discount_loss": 0.007741110626608133, "model_kl": 1.3343893671035767, "prior_ent": 27.002305477905274, "post_ent": 25.677397830200196, "model_loss": 3773.091321875, "model_loss_scale": 2048.0, "model_grad_norm": 5.387353273200989, "actor_loss": 0.0005633736125339056, "actor_loss_scale": 12643309.9776, "actor_grad_norm": Infinity, "critic_loss": 0.9185848811149597, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.31821694276332857, "reward_mean": 0.006976235446252394, "reward_std": 0.08181135521531105, "reward_normed_mean": 0.006976235446252394, "reward_normed_std": 0.08181135521531105, "critic_slow": 5.130752220916748, "critic_target": 5.13139585609436, "actor_ent": 1.2899952405929564, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1314250732421876, "fps": 106.6362862567564}
{"step": 11676708, "train_return": 20.0, "train_length": 1757.0, "train_total_steps": 2919177.0, "train_total_episodes": 1441.0, "train_loaded_steps": 1997676.0, "train_loaded_episodes": 991.0}
{"step": 11684364, "train_return": 17.0, "train_length": 1914.0, "train_total_steps": 2921091.0, "train_total_episodes": 1442.0, "train_loaded_steps": 1999590.0, "train_loaded_episodes": 992.0}
{"step": 11692224, "train_return": 17.0, "train_length": 1965.0, "train_total_steps": 2923056.0, "train_total_episodes": 1443.0, "train_loaded_steps": 1999377.0, "train_loaded_episodes": 992.0}
{"step": 11699492, "train_return": 19.0, "train_length": 1817.0, "train_total_steps": 2924873.0, "train_total_episodes": 1444.0, "train_loaded_steps": 1999297.0, "train_loaded_episodes": 992.0}
{"step": 11706928, "train_return": 18.0, "train_length": 1859.0, "train_total_steps": 2926732.0, "train_total_episodes": 1445.0, "train_loaded_steps": 1998473.0, "train_loaded_episodes": 992.0}
{"step": 11713656, "kl_loss": 1.3618962800979615, "image_loss": 3772.0, "reward_loss": 0.9191495369911193, "discount_loss": 0.007743642620742321, "model_kl": 1.3618962518692017, "prior_ent": 26.93393723754883, "post_ent": 25.588289205932618, "model_loss": 3773.094087109375, "model_loss_scale": 3099.8528, "model_grad_norm": 5.382730097198486, "actor_loss": -0.0007054208955545618, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.034242261701822284, "critic_loss": 0.9197297366142273, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.28061323499679564, "reward_mean": 0.007046617861877894, "reward_std": 0.08144078427553177, "reward_normed_mean": 0.007046617861877894, "reward_normed_std": 0.08144078427553177, "critic_slow": 5.169109422302246, "critic_target": 5.168001706314087, "actor_ent": 1.286590117263794, "actor_ent_scale": 0.0010000000474974513, "critic": 5.167944900512695, "fps": 106.44614937633308}
{"step": 11713972, "train_return": 19.0, "train_length": 1761.0, "train_total_steps": 2928493.0, "train_total_episodes": 1446.0, "train_loaded_steps": 1998357.0, "train_loaded_episodes": 992.0}
{"step": 11720964, "train_return": 19.0, "train_length": 1748.0, "train_total_steps": 2930241.0, "train_total_episodes": 1447.0, "train_loaded_steps": 1997077.0, "train_loaded_episodes": 992.0}
{"step": 11728600, "train_return": 17.0, "train_length": 1909.0, "train_total_steps": 2932150.0, "train_total_episodes": 1448.0, "train_loaded_steps": 1998986.0, "train_loaded_episodes": 993.0}
{"step": 11735868, "train_return": 20.0, "train_length": 1817.0, "train_total_steps": 2933967.0, "train_total_episodes": 1449.0, "train_loaded_steps": 1998669.0, "train_loaded_episodes": 993.0}
{"step": 11743992, "train_return": 15.0, "train_length": 2031.0, "train_total_steps": 2935998.0, "train_total_episodes": 1450.0, "train_loaded_steps": 1998459.0, "train_loaded_episodes": 993.0}
{"step": 11752100, "train_return": 18.0, "train_length": 2027.0, "train_total_steps": 2938025.0, "train_total_episodes": 1451.0, "train_loaded_steps": 1998043.0, "train_loaded_episodes": 993.0}
{"step": 11753656, "kl_loss": 1.3444235107421876, "image_loss": 3772.0, "reward_loss": 0.9191559941291809, "discount_loss": 0.007748132269829512, "model_kl": 1.3444234815597533, "prior_ent": 27.120115158081056, "post_ent": 25.787153259277343, "model_loss": 3773.092364453125, "model_loss_scale": 4096.0, "model_grad_norm": 5.477398997879028, "actor_loss": 0.000659412170611904, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.032793684700131415, "critic_loss": 0.9180090511322021, "critic_loss_scale": 132959.4368, "critic_grad_norm": Infinity, "reward_mean": 0.007108383324241731, "reward_std": 0.08167573585510254, "reward_normed_mean": 0.007108383324241731, "reward_normed_std": 0.08167573585510254, "critic_slow": 5.157061740875244, "critic_target": 5.15653258934021, "actor_ent": 1.2965450624465942, "actor_ent_scale": 0.0010000000474974513, "critic": 5.156482483673096, "fps": 107.38821455167269}
{"step": 11759584, "train_return": 18.0, "train_length": 1871.0, "train_total_steps": 2939896.0, "train_total_episodes": 1452.0, "train_loaded_steps": 1999914.0, "train_loaded_episodes": 994.0}
{"step": 11768244, "train_return": 16.0, "train_length": 2165.0, "train_total_steps": 2942061.0, "train_total_episodes": 1453.0, "train_loaded_steps": 1998047.0, "train_loaded_episodes": 993.0}
{"step": 11776052, "train_return": 18.0, "train_length": 1952.0, "train_total_steps": 2944013.0, "train_total_episodes": 1454.0, "train_loaded_steps": 1999999.0, "train_loaded_episodes": 994.0}
{"step": 11782676, "train_return": 21.0, "train_length": 1656.0, "train_total_steps": 2945669.0, "train_total_episodes": 1455.0, "train_loaded_steps": 1999147.0, "train_loaded_episodes": 994.0}
{"step": 11790240, "train_return": 19.0, "train_length": 1891.0, "train_total_steps": 2947560.0, "train_total_episodes": 1456.0, "train_loaded_steps": 1999137.0, "train_loaded_episodes": 994.0}
{"step": 11793656, "kl_loss": 1.3737349815368651, "image_loss": 3772.0, "reward_loss": 0.9191441039085388, "discount_loss": 0.007803480337560177, "model_kl": 1.3737349483489991, "prior_ent": 27.057615826416015, "post_ent": 25.70046031188965, "model_loss": 3773.095569921875, "model_loss_scale": 4096.0, "model_grad_norm": 5.357999250221252, "actor_loss": -0.0027915817024040733, "actor_loss_scale": 8683887.0016, "actor_grad_norm": Infinity, "critic_loss": 0.9224522566795349, "critic_loss_scale": 95944.704, "critic_grad_norm": Infinity, "reward_mean": 0.007001103474025149, "reward_std": 0.08150216774940491, "reward_normed_mean": 0.007001103474025149, "reward_normed_std": 0.08150216774940491, "critic_slow": 5.248019534301758, "critic_target": 5.245986017990112, "actor_ent": 1.221765800666809, "actor_ent_scale": 0.0010000000474974513, "critic": 5.245767571258545, "fps": 106.20561523603291}
{"step": 11797972, "train_return": 17.0, "train_length": 1933.0, "train_total_steps": 2949493.0, "train_total_episodes": 1457.0, "train_loaded_steps": 1998513.0, "train_loaded_episodes": 994.0}
{"step": 11805940, "train_return": 17.0, "train_length": 1992.0, "train_total_steps": 2951485.0, "train_total_episodes": 1458.0, "train_loaded_steps": 1998383.0, "train_loaded_episodes": 994.0}
{"step": 11813708, "train_return": 19.0, "train_length": 1942.0, "train_total_steps": 2953427.0, "train_total_episodes": 1459.0, "train_loaded_steps": 1998134.0, "train_loaded_episodes": 994.0}
{"step": 11821196, "train_return": 18.0, "train_length": 1872.0, "train_total_steps": 2955299.0, "train_total_episodes": 1460.0, "train_loaded_steps": 1997902.0, "train_loaded_episodes": 994.0}
{"step": 11828744, "train_return": 18.0, "train_length": 1887.0, "train_total_steps": 2957186.0, "train_total_episodes": 1461.0, "train_loaded_steps": 1999789.0, "train_loaded_episodes": 995.0}
{"step": 11827868, "eval_return": 16.0, "eval_length": 1957.0, "eval_total_steps": 29553.0, "eval_total_episodes": 15.0, "eval_loaded_steps": 29568.0, "eval_loaded_episodes": 15.0}
{"step": 11827872, "kl_loss": 1.3370893001556396, "image_loss": 3772.0, "reward_loss": 0.9190599322319031, "discount_loss": 0.007735481485724449, "model_kl": 1.33708918094635, "prior_ent": 26.8034725189209, "post_ent": 25.49665069580078, "model_loss": 3773.09130859375, "model_loss_scale": 16384.0, "model_grad_norm": 6.940866947174072, "actor_loss": -0.02014203742146492, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.034521374851465225, "critic_loss": 0.9191613793373108, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.24185766279697418, "reward_mean": 0.003081714501604438, "reward_std": 0.07266413420438766, "reward_normed_mean": 0.003081714501604438, "reward_normed_std": 0.07266413420438766, "critic_slow": 5.8749680519104, "critic_target": 5.855144500732422, "actor_ent": 1.2515712976455688, "actor_ent_scale": 0.0010000000474974513, "critic": 5.859751224517822, "fps": 0.0}
{"step": 11837052, "train_return": 14.0, "train_length": 2296.0, "train_total_steps": 2959263.0, "train_total_episodes": 1462.0, "train_loaded_steps": 1999953.0, "train_loaded_episodes": 995.0}
{"step": 11844620, "train_return": 18.0, "train_length": 1892.0, "train_total_steps": 2961155.0, "train_total_episodes": 1463.0, "train_loaded_steps": 1999297.0, "train_loaded_episodes": 995.0}
{"step": 11852340, "train_return": 17.0, "train_length": 1930.0, "train_total_steps": 2963085.0, "train_total_episodes": 1464.0, "train_loaded_steps": 1999202.0, "train_loaded_episodes": 995.0}
{"step": 11860916, "train_return": 15.0, "train_length": 2144.0, "train_total_steps": 2965229.0, "train_total_episodes": 1465.0, "train_loaded_steps": 1999375.0, "train_loaded_episodes": 995.0}
{"step": 11867872, "kl_loss": 1.3554311643600463, "image_loss": 3772.0, "reward_loss": 0.9191553786277771, "discount_loss": 0.007755349082499742, "model_kl": 1.3554311346054078, "prior_ent": 27.138455728149413, "post_ent": 25.790591027832033, "model_loss": 3773.09350390625, "model_loss_scale": 2084.0448, "model_grad_norm": Infinity, "actor_loss": -0.0032394174390610714, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.03699872909486294, "critic_loss": 0.9192445086479187, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.2956307821750641, "reward_mean": 0.00696160684711067, "reward_std": 0.08142254517674447, "reward_normed_mean": 0.00696160684711067, "reward_normed_std": 0.08142254517674447, "critic_slow": 5.206616865921021, "critic_target": 5.205158667755127, "actor_ent": 1.2904002460479735, "actor_ent_scale": 0.0010000000474974513, "critic": 5.205250034713745, "fps": 107.10996942276066}
{"step": 11868528, "train_return": 18.0, "train_length": 1903.0, "train_total_steps": 2967132.0, "train_total_episodes": 1466.0, "train_loaded_steps": 1998826.0, "train_loaded_episodes": 995.0}
{"step": 11875616, "train_return": 20.0, "train_length": 1772.0, "train_total_steps": 2968904.0, "train_total_episodes": 1467.0, "train_loaded_steps": 1998534.0, "train_loaded_episodes": 995.0}
{"step": 11882264, "train_return": 21.0, "train_length": 1662.0, "train_total_steps": 2970566.0, "train_total_episodes": 1468.0, "train_loaded_steps": 1998051.0, "train_loaded_episodes": 995.0}
{"step": 11890116, "train_return": 16.0, "train_length": 1963.0, "train_total_steps": 2972529.0, "train_total_episodes": 1469.0, "train_loaded_steps": 1997407.0, "train_loaded_episodes": 995.0}
{"step": 11897248, "train_return": 20.0, "train_length": 1783.0, "train_total_steps": 2974312.0, "train_total_episodes": 1470.0, "train_loaded_steps": 1999190.0, "train_loaded_episodes": 996.0}
{"step": 11904152, "train_return": 20.0, "train_length": 1726.0, "train_total_steps": 2976038.0, "train_total_episodes": 1471.0, "train_loaded_steps": 1998591.0, "train_loaded_episodes": 996.0}
{"step": 11907872, "kl_loss": 1.362933582305908, "image_loss": 3772.0, "reward_loss": 0.9191609957695007, "discount_loss": 0.007797995437681675, "model_kl": 1.362933553314209, "prior_ent": 27.197684075927736, "post_ent": 25.847258053588867, "model_loss": 3773.094480859375, "model_loss_scale": 2048.0, "model_grad_norm": 5.063518866348266, "actor_loss": -0.008891473696271714, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.037148928767442704, "critic_loss": 0.9196478129386901, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.3319528015732765, "reward_mean": 0.007044693394657225, "reward_std": 0.08151703109741211, "reward_normed_mean": 0.007044693394657225, "reward_normed_std": 0.08151703109741211, "critic_slow": 5.179696928405762, "critic_target": 5.177397282791138, "actor_ent": 1.3228955186843872, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1774351646423336, "fps": 108.23419545427599}
{"step": 11911772, "train_return": 18.0, "train_length": 1905.0, "train_total_steps": 2977943.0, "train_total_episodes": 1472.0, "train_loaded_steps": 1998313.0, "train_loaded_episodes": 996.0}
{"step": 11919204, "train_return": 19.0, "train_length": 1858.0, "train_total_steps": 2979801.0, "train_total_episodes": 1473.0, "train_loaded_steps": 1998027.0, "train_loaded_episodes": 996.0}
{"step": 11927276, "train_return": 17.0, "train_length": 2018.0, "train_total_steps": 2981819.0, "train_total_episodes": 1474.0, "train_loaded_steps": 1998131.0, "train_loaded_episodes": 996.0}
{"step": 11934748, "train_return": 19.0, "train_length": 1868.0, "train_total_steps": 2983687.0, "train_total_episodes": 1475.0, "train_loaded_steps": 1999999.0, "train_loaded_episodes": 997.0}
{"step": 11942620, "train_return": 16.0, "train_length": 1968.0, "train_total_steps": 2985655.0, "train_total_episodes": 1476.0, "train_loaded_steps": 1999865.0, "train_loaded_episodes": 997.0}
{"step": 11947872, "kl_loss": 1.3607819410324096, "image_loss": 3772.0, "reward_loss": 0.9191842736244201, "discount_loss": 0.007741540601104498, "model_kl": 1.3607819124221803, "prior_ent": 27.11883843688965, "post_ent": 25.773654498291016, "model_loss": 3773.09400234375, "model_loss_scale": 2048.0, "model_grad_norm": 5.2856802562713625, "actor_loss": -0.0048789115653758925, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.03808321568071842, "critic_loss": 0.9199925488471985, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.3021785447657108, "reward_mean": 0.007023089108103887, "reward_std": 0.0817947905778885, "reward_normed_mean": 0.007023089108103887, "reward_normed_std": 0.0817947905778885, "critic_slow": 5.164967367172241, "critic_target": 5.163817152023316, "actor_ent": 1.3294866327285766, "actor_ent_scale": 0.0010000000474974513, "critic": 5.163854020309448, "fps": 109.38356863664485}
{"step": 11950660, "train_return": 16.0, "train_length": 2010.0, "train_total_steps": 2987665.0, "train_total_episodes": 1477.0, "train_loaded_steps": 1999850.0, "train_loaded_episodes": 997.0}
{"step": 11958676, "train_return": 16.0, "train_length": 2004.0, "train_total_steps": 2989669.0, "train_total_episodes": 1478.0, "train_loaded_steps": 1999553.0, "train_loaded_episodes": 997.0}
{"step": 11966664, "train_return": 17.0, "train_length": 1997.0, "train_total_steps": 2991666.0, "train_total_episodes": 1479.0, "train_loaded_steps": 1999213.0, "train_loaded_episodes": 997.0}
{"step": 11973632, "train_return": 19.0, "train_length": 1742.0, "train_total_steps": 2993408.0, "train_total_episodes": 1480.0, "train_loaded_steps": 1998534.0, "train_loaded_episodes": 997.0}
{"step": 11980680, "train_return": 19.0, "train_length": 1762.0, "train_total_steps": 2995170.0, "train_total_episodes": 1481.0, "train_loaded_steps": 1997545.0, "train_loaded_episodes": 997.0}
{"step": 11987872, "kl_loss": 1.3422118587493896, "image_loss": 3772.0, "reward_loss": 0.919158837890625, "discount_loss": 0.007742083802074194, "model_kl": 1.3422118288040161, "prior_ent": 27.02097624206543, "post_ent": 25.68771198425293, "model_loss": 3773.092119140625, "model_loss_scale": 3676.5696, "model_grad_norm": 5.427562756729126, "actor_loss": -0.002972023494206951, "actor_loss_scale": 59087.2576, "actor_grad_norm": 0.035533675426244735, "critic_loss": 0.918679020690918, "critic_loss_scale": 59087.2576, "critic_grad_norm": 0.29120070500969886, "reward_mean": 0.006939345148648135, "reward_std": 0.08190083740353585, "reward_normed_mean": 0.006939345148648135, "reward_normed_std": 0.08190083740353585, "critic_slow": 5.106511207580566, "critic_target": 5.106331301498413, "actor_ent": 1.3216721757888794, "actor_ent_scale": 0.0010000000474974513, "critic": 5.106299287033081, "fps": 105.93252306639943}
{"step": 11988168, "train_return": 18.0, "train_length": 1872.0, "train_total_steps": 2997042.0, "train_total_episodes": 1482.0, "train_loaded_steps": 1999417.0, "train_loaded_episodes": 998.0}
{"step": 11994884, "train_return": 20.0, "train_length": 1679.0, "train_total_steps": 2998721.0, "train_total_episodes": 1483.0, "train_loaded_steps": 1998703.0, "train_loaded_episodes": 998.0}
{"step": 12001800, "train_return": 20.0, "train_length": 1729.0, "train_total_steps": 3000450.0, "train_total_episodes": 1484.0, "train_loaded_steps": 1997976.0, "train_loaded_episodes": 998.0}
{"step": 12008764, "train_return": 20.0, "train_length": 1741.0, "train_total_steps": 3002191.0, "train_total_episodes": 1485.0, "train_loaded_steps": 1999717.0, "train_loaded_episodes": 999.0}
{"step": 12015576, "train_return": 21.0, "train_length": 1703.0, "train_total_steps": 3003894.0, "train_total_episodes": 1486.0, "train_loaded_steps": 1999302.0, "train_loaded_episodes": 999.0}
{"step": 12024232, "train_return": 16.0, "train_length": 2164.0, "train_total_steps": 3006058.0, "train_total_episodes": 1487.0, "train_loaded_steps": 1999349.0, "train_loaded_episodes": 999.0}
{"step": 12027872, "kl_loss": 1.3963669628143311, "image_loss": 3772.0001921875, "reward_loss": 0.9191740593910217, "discount_loss": 0.007785841780155897, "model_kl": 1.3963669319152832, "prior_ent": 27.18466059265137, "post_ent": 25.812277774047853, "model_loss": 3773.09796796875, "model_loss_scale": 4096.0, "model_grad_norm": 5.401850039863587, "actor_loss": -0.003959887541154603, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.040297727984189985, "critic_loss": 0.9237055312156677, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.3356025039494038, "reward_mean": 0.007052347045578063, "reward_std": 0.08165979803204536, "reward_normed_mean": 0.007052347045578063, "reward_normed_std": 0.08165979803204536, "critic_slow": 5.065552314376831, "critic_target": 5.065920116424561, "actor_ent": 1.281321817779541, "actor_ent_scale": 0.0010000000474974513, "critic": 5.06594927558899, "fps": 106.59787771015222}
{"step": 12031856, "train_return": 17.0, "train_length": 1906.0, "train_total_steps": 3007964.0, "train_total_episodes": 1488.0, "train_loaded_steps": 1999208.0, "train_loaded_episodes": 999.0}
{"step": 12038512, "train_return": 21.0, "train_length": 1664.0, "train_total_steps": 3009628.0, "train_total_episodes": 1489.0, "train_loaded_steps": 1998602.0, "train_loaded_episodes": 999.0}
{"step": 12046620, "train_return": 17.0, "train_length": 2027.0, "train_total_steps": 3011655.0, "train_total_episodes": 1490.0, "train_loaded_steps": 1998681.0, "train_loaded_episodes": 999.0}
{"step": 12053936, "train_return": 19.0, "train_length": 1829.0, "train_total_steps": 3013484.0, "train_total_episodes": 1491.0, "train_loaded_steps": 1998158.0, "train_loaded_episodes": 999.0}
{"step": 12061340, "train_return": 18.0, "train_length": 1851.0, "train_total_steps": 3015335.0, "train_total_episodes": 1492.0, "train_loaded_steps": 1997973.0, "train_loaded_episodes": 999.0}
{"step": 12067872, "kl_loss": 1.359495823097229, "image_loss": 3772.0, "reward_loss": 0.9191485340118408, "discount_loss": 0.007755870381742716, "model_kl": 1.3594957935333252, "prior_ent": 27.071585079956055, "post_ent": 25.72496616821289, "model_loss": 3773.093925390625, "model_loss_scale": 4096.0, "model_grad_norm": 5.500526371002198, "actor_loss": 2.6985565712675452e-05, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.04043661642670631, "critic_loss": 0.9213770487785339, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.29453564631938933, "reward_mean": 0.007088850848306902, "reward_std": 0.08166228547692299, "reward_normed_mean": 0.007088850848306902, "reward_normed_std": 0.08166228547692299, "critic_slow": 5.130158493423462, "critic_target": 5.133834399032593, "actor_ent": 1.2960787502288817, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1337736686706545, "fps": 106.3687547722236}
{"step": 12069192, "train_return": 17.0, "train_length": 1963.0, "train_total_steps": 3017298.0, "train_total_episodes": 1493.0, "train_loaded_steps": 1999936.0, "train_loaded_episodes": 1000.0}
{"step": 12076332, "train_return": 19.0, "train_length": 1785.0, "train_total_steps": 3019083.0, "train_total_episodes": 1494.0, "train_loaded_steps": 1999461.0, "train_loaded_episodes": 1000.0}
{"step": 12083676, "train_return": 19.0, "train_length": 1836.0, "train_total_steps": 3020919.0, "train_total_episodes": 1495.0, "train_loaded_steps": 1999200.0, "train_loaded_episodes": 1000.0}
{"step": 12092624, "train_return": 15.0, "train_length": 2237.0, "train_total_steps": 3023156.0, "train_total_episodes": 1496.0, "train_loaded_steps": 1998276.0, "train_loaded_episodes": 1000.0}
{"step": 12100048, "train_return": 18.0, "train_length": 1856.0, "train_total_steps": 3025012.0, "train_total_episodes": 1497.0, "train_loaded_steps": 1997844.0, "train_loaded_episodes": 1000.0}
{"step": 12107872, "kl_loss": 1.3605123874664307, "image_loss": 3772.0, "reward_loss": 0.9191542349815368, "discount_loss": 0.007742213563621044, "model_kl": 1.360512357711792, "prior_ent": 26.96921804199219, "post_ent": 25.622682177734376, "model_loss": 3773.09394453125, "model_loss_scale": 6533.9392, "model_grad_norm": 5.377408302879333, "actor_loss": -0.000395692806574516, "actor_loss_scale": 105067.3152, "actor_grad_norm": 0.03641875569820404, "critic_loss": 0.9184567479133606, "critic_loss_scale": 105067.3152, "critic_grad_norm": 0.2677404421031475, "reward_mean": 0.0071293005945160986, "reward_std": 0.08146734136939049, "reward_normed_mean": 0.0071293005945160986, "reward_normed_std": 0.08146734136939049, "critic_slow": 5.113413486480713, "critic_target": 5.115649061965942, "actor_ent": 1.3089694231033324, "actor_ent_scale": 0.0010000000474974513, "critic": 5.115632244491577, "fps": 107.19106753916087}
{"step": 12108152, "train_return": 16.0, "train_length": 2026.0, "train_total_steps": 3027038.0, "train_total_episodes": 1498.0, "train_loaded_steps": 1999870.0, "train_loaded_episodes": 1001.0}
{"step": 12115204, "train_return": 20.0, "train_length": 1763.0, "train_total_steps": 3028801.0, "train_total_episodes": 1499.0, "train_loaded_steps": 1999674.0, "train_loaded_episodes": 1001.0}
{"step": 12123436, "train_return": 16.0, "train_length": 2058.0, "train_total_steps": 3030859.0, "train_total_episodes": 1500.0, "train_loaded_steps": 1999783.0, "train_loaded_episodes": 1001.0}
{"step": 12130620, "train_return": 20.0, "train_length": 1796.0, "train_total_steps": 3032655.0, "train_total_episodes": 1501.0, "train_loaded_steps": 1999652.0, "train_loaded_episodes": 1001.0}
{"step": 12138628, "train_return": 17.0, "train_length": 2002.0, "train_total_steps": 3034657.0, "train_total_episodes": 1502.0, "train_loaded_steps": 1999359.0, "train_loaded_episodes": 1001.0}
{"step": 12146044, "train_return": 19.0, "train_length": 1854.0, "train_total_steps": 3036511.0, "train_total_episodes": 1503.0, "train_loaded_steps": 1998812.0, "train_loaded_episodes": 1001.0}
{"step": 12147872, "kl_loss": 1.3720310512542724, "image_loss": 3772.0, "reward_loss": 0.9191467861175537, "discount_loss": 0.007756513964384794, "model_kl": 1.3720310186386109, "prior_ent": 26.987432470703126, "post_ent": 25.626430645751952, "model_loss": 3773.09516171875, "model_loss_scale": 8192.0, "model_grad_norm": 5.250298722648621, "actor_loss": -0.004490059989731526, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.03779727862477303, "critic_loss": 0.919442092704773, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2753403501152992, "reward_mean": 0.007091362531483174, "reward_std": 0.0815179904282093, "reward_normed_mean": 0.007091362531483174, "reward_normed_std": 0.0815179904282093, "critic_slow": 5.071430626296997, "critic_target": 5.072006062316895, "actor_ent": 1.3078803739547729, "actor_ent_scale": 0.0010000000474974513, "critic": 5.0719659145355225, "fps": 104.8525168155176}
{"step": 12153232, "train_return": 19.0, "train_length": 1797.0, "train_total_steps": 3038308.0, "train_total_episodes": 1504.0, "train_loaded_steps": 1998341.0, "train_loaded_episodes": 1001.0}
{"step": 12161048, "train_return": 18.0, "train_length": 1954.0, "train_total_steps": 3040262.0, "train_total_episodes": 1505.0, "train_loaded_steps": 1998242.0, "train_loaded_episodes": 1001.0}
{"step": 12168168, "train_return": 19.0, "train_length": 1780.0, "train_total_steps": 3042042.0, "train_total_episodes": 1506.0, "train_loaded_steps": 1998038.0, "train_loaded_episodes": 1001.0}
{"step": 12177480, "train_return": 13.0, "train_length": 2328.0, "train_total_steps": 3044370.0, "train_total_episodes": 1507.0, "train_loaded_steps": 1998334.0, "train_loaded_episodes": 1001.0}
{"step": 12185456, "train_return": 16.0, "train_length": 1994.0, "train_total_steps": 3046364.0, "train_total_episodes": 1508.0, "train_loaded_steps": 1998246.0, "train_loaded_episodes": 1001.0}
{"step": 12187872, "kl_loss": 1.3669703781127929, "image_loss": 3772.0, "reward_loss": 0.9191660207748413, "discount_loss": 0.007741168205440044, "model_kl": 1.366970347213745, "prior_ent": 27.187867739868164, "post_ent": 25.833854415893555, "model_loss": 3773.094599609375, "model_loss_scale": 8192.0, "model_grad_norm": 5.513644424438477, "actor_loss": -0.001121721339225769, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.03758186415731907, "critic_loss": 0.9195613311767579, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3168748138785362, "reward_mean": 0.00693358760047704, "reward_std": 0.0814920248568058, "reward_normed_mean": 0.00693358760047704, "reward_normed_std": 0.0814920248568058, "critic_slow": 5.084050762939453, "critic_target": 5.08427486000061, "actor_ent": 1.316687042617798, "actor_ent_scale": 0.0010000000474974513, "critic": 5.084374855422974, "fps": 104.50861698800738}
{"step": 12192764, "train_return": 18.0, "train_length": 1827.0, "train_total_steps": 3048191.0, "train_total_episodes": 1509.0, "train_loaded_steps": 1997954.0, "train_loaded_episodes": 1001.0}
{"step": 12201304, "train_return": 14.0, "train_length": 2135.0, "train_total_steps": 3050326.0, "train_total_episodes": 1510.0, "train_loaded_steps": 1998222.0, "train_loaded_episodes": 1001.0}
{"step": 12209056, "train_return": 18.0, "train_length": 1938.0, "train_total_steps": 3052264.0, "train_total_episodes": 1511.0, "train_loaded_steps": 1997758.0, "train_loaded_episodes": 1001.0}
{"step": 12216452, "train_return": 19.0, "train_length": 1849.0, "train_total_steps": 3054113.0, "train_total_episodes": 1512.0, "train_loaded_steps": 1999607.0, "train_loaded_episodes": 1002.0}
{"step": 12223968, "train_return": 17.0, "train_length": 1879.0, "train_total_steps": 3055992.0, "train_total_episodes": 1513.0, "train_loaded_steps": 1999061.0, "train_loaded_episodes": 1002.0}
{"step": 12227872, "kl_loss": 1.3409347839355468, "image_loss": 3772.0, "reward_loss": 0.9191528026580811, "discount_loss": 0.007765490312129259, "model_kl": 1.3409347490310668, "prior_ent": 26.92737950439453, "post_ent": 25.59366801147461, "model_loss": 3773.092104296875, "model_loss_scale": 11429.4784, "model_grad_norm": 5.265889376831055, "actor_loss": -0.0001659418031500536, "actor_loss_scale": 183920.2304, "actor_grad_norm": 0.03419619173705578, "critic_loss": 0.9179299721717834, "critic_loss_scale": 183920.2304, "critic_grad_norm": 0.2553349673271179, "reward_mean": 0.007134683058364317, "reward_std": 0.08171723035573959, "reward_normed_mean": 0.007134683058364317, "reward_normed_std": 0.08171723035573959, "critic_slow": 5.048376414108277, "critic_target": 5.048968782424927, "actor_ent": 1.3333008443832397, "actor_ent_scale": 0.0010000000474974513, "critic": 5.048955930328369, "fps": 107.0692978291203}
{"step": 12232172, "train_return": 17.0, "train_length": 2051.0, "train_total_steps": 3058043.0, "train_total_episodes": 1514.0, "train_loaded_steps": 1999084.0, "train_loaded_episodes": 1002.0}
{"step": 12239780, "train_return": 18.0, "train_length": 1902.0, "train_total_steps": 3059945.0, "train_total_episodes": 1515.0, "train_loaded_steps": 1998865.0, "train_loaded_episodes": 1002.0}
{"step": 12247440, "train_return": 18.0, "train_length": 1915.0, "train_total_steps": 3061860.0, "train_total_episodes": 1516.0, "train_loaded_steps": 1998834.0, "train_loaded_episodes": 1002.0}
{"step": 12255188, "train_return": 17.0, "train_length": 1937.0, "train_total_steps": 3063797.0, "train_total_episodes": 1517.0, "train_loaded_steps": 1999010.0, "train_loaded_episodes": 1002.0}
{"step": 12262940, "train_return": 18.0, "train_length": 1938.0, "train_total_steps": 3065735.0, "train_total_episodes": 1518.0, "train_loaded_steps": 1999237.0, "train_loaded_episodes": 1002.0}
{"step": 12267872, "kl_loss": 1.3896647352218627, "image_loss": 3772.0, "reward_loss": 0.9191632339477539, "discount_loss": 0.007756651035696268, "model_kl": 1.3896647045135497, "prior_ent": 26.660086199951174, "post_ent": 25.292463580322266, "model_loss": 3773.0969421875, "model_loss_scale": 16384.0, "model_grad_norm": 5.350845640563965, "actor_loss": -0.004167422559976694, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.03523389344960451, "critic_loss": 0.9190461086273194, "critic_loss_scale": 151624.0896, "critic_grad_norm": Infinity, "reward_mean": 0.007138662676559761, "reward_std": 0.08131703116297721, "reward_normed_mean": 0.007138662676559761, "reward_normed_std": 0.08131703116297721, "critic_slow": 5.001033710479736, "critic_target": 5.000488983917236, "actor_ent": 1.3304237756729127, "actor_ent_scale": 0.0010000000474974513, "critic": 5.000617317199707, "fps": 105.96196072059573}
{"step": 12270940, "train_return": 18.0, "train_length": 2000.0, "train_total_steps": 3067735.0, "train_total_episodes": 1519.0, "train_loaded_steps": 1999077.0, "train_loaded_episodes": 1002.0}
{"step": 12278956, "train_return": 17.0, "train_length": 2004.0, "train_total_steps": 3069739.0, "train_total_episodes": 1520.0, "train_loaded_steps": 1998942.0, "train_loaded_episodes": 1002.0}
{"step": 12286388, "train_return": 19.0, "train_length": 1858.0, "train_total_steps": 3071597.0, "train_total_episodes": 1521.0, "train_loaded_steps": 1998209.0, "train_loaded_episodes": 1002.0}
{"step": 12294276, "train_return": 17.0, "train_length": 1972.0, "train_total_steps": 3073569.0, "train_total_episodes": 1522.0, "train_loaded_steps": 1998169.0, "train_loaded_episodes": 1002.0}
{"step": 12300920, "train_return": 21.0, "train_length": 1661.0, "train_total_steps": 3075230.0, "train_total_episodes": 1523.0, "train_loaded_steps": 1999830.0, "train_loaded_episodes": 1003.0}
{"step": 12307872, "kl_loss": 1.340556144142151, "image_loss": 3772.0, "reward_loss": 0.9191614304542541, "discount_loss": 0.0077411572031676765, "model_kl": 1.3405561128616332, "prior_ent": 26.84431872253418, "post_ent": 25.51274296569824, "model_loss": 3773.091952734375, "model_loss_scale": 16384.0, "model_grad_norm": 5.5921749549865725, "actor_loss": -0.0024997144787048454, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.03507263425886631, "critic_loss": 0.9183017201423646, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.28895484930872917, "reward_mean": 0.0071796971035655585, "reward_std": 0.08204712500572205, "reward_normed_mean": 0.0071796971035655585, "reward_normed_std": 0.08204712500572205, "critic_slow": 5.049569094848633, "critic_target": 5.0498816143035885, "actor_ent": 1.3003919054031372, "actor_ent_scale": 0.0010000000474974513, "critic": 5.049842067718506, "fps": 106.93291205278555}
{"step": 12308004, "train_return": 19.0, "train_length": 1771.0, "train_total_steps": 3077001.0, "train_total_episodes": 1524.0, "train_loaded_steps": 1999683.0, "train_loaded_episodes": 1003.0}
{"step": 12316036, "train_return": 16.0, "train_length": 2008.0, "train_total_steps": 3079009.0, "train_total_episodes": 1525.0, "train_loaded_steps": 1999365.0, "train_loaded_episodes": 1003.0}
{"step": 12323516, "train_return": 17.0, "train_length": 1870.0, "train_total_steps": 3080879.0, "train_total_episodes": 1526.0, "train_loaded_steps": 1999024.0, "train_loaded_episodes": 1003.0}
{"step": 12330752, "train_return": 18.0, "train_length": 1809.0, "train_total_steps": 3082688.0, "train_total_episodes": 1527.0, "train_loaded_steps": 1998448.0, "train_loaded_episodes": 1003.0}
{"step": 12338028, "train_return": 19.0, "train_length": 1819.0, "train_total_steps": 3084507.0, "train_total_episodes": 1528.0, "train_loaded_steps": 1998131.0, "train_loaded_episodes": 1003.0}
{"step": 12345416, "train_return": 20.0, "train_length": 1847.0, "train_total_steps": 3086354.0, "train_total_episodes": 1529.0, "train_loaded_steps": 1999978.0, "train_loaded_episodes": 1004.0}
{"step": 12347872, "kl_loss": 1.3613114614486694, "image_loss": 3772.0, "reward_loss": 0.919175545501709, "discount_loss": 0.007748352061957121, "model_kl": 1.3613114355087281, "prior_ent": 26.908498287963866, "post_ent": 25.56008726196289, "model_loss": 3773.094076171875, "model_loss_scale": 16646.144, "model_grad_norm": Infinity, "actor_loss": -0.0014086069196113384, "actor_loss_scale": 315411.6608, "actor_grad_norm": 0.03619661054313183, "critic_loss": 0.918566042137146, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2847560759305954, "reward_mean": 0.007133525301050395, "reward_std": 0.08179732304811478, "reward_normed_mean": 0.007133525301050395, "reward_normed_std": 0.08179732304811478, "critic_slow": 5.020931330871582, "critic_target": 5.0215531410217285, "actor_ent": 1.3093452180862426, "actor_ent_scale": 0.0010000000474974513, "critic": 5.021534392929077, "fps": 107.10380079133898}
{"step": 12353064, "train_return": 16.0, "train_length": 1912.0, "train_total_steps": 3088266.0, "train_total_episodes": 1530.0, "train_loaded_steps": 1999881.0, "train_loaded_episodes": 1004.0}
{"step": 12360804, "train_return": 17.0, "train_length": 1935.0, "train_total_steps": 3090201.0, "train_total_episodes": 1531.0, "train_loaded_steps": 1999524.0, "train_loaded_episodes": 1004.0}
{"step": 12368348, "train_return": 19.0, "train_length": 1886.0, "train_total_steps": 3092087.0, "train_total_episodes": 1532.0, "train_loaded_steps": 1998962.0, "train_loaded_episodes": 1004.0}
{"step": 12376612, "train_return": 16.0, "train_length": 2066.0, "train_total_steps": 3094153.0, "train_total_episodes": 1533.0, "train_loaded_steps": 1998961.0, "train_loaded_episodes": 1004.0}
{"step": 12384472, "train_return": 16.0, "train_length": 1965.0, "train_total_steps": 3096118.0, "train_total_episodes": 1534.0, "train_loaded_steps": 1998969.0, "train_loaded_episodes": 1004.0}
{"step": 12387872, "kl_loss": 1.3666069381713868, "image_loss": 3772.0, "reward_loss": 0.9191685062408447, "discount_loss": 0.00774461704865098, "model_kl": 1.3666069025039673, "prior_ent": 26.981237298583984, "post_ent": 25.624937225341796, "model_loss": 3773.09458828125, "model_loss_scale": 15086.3872, "model_grad_norm": Infinity, "actor_loss": -0.002369260244411271, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.03852492059469223, "critic_loss": 0.9189147333145141, "critic_loss_scale": 161900.1344, "critic_grad_norm": Infinity, "reward_mean": 0.007033445381687488, "reward_std": 0.08155920710563659, "reward_normed_mean": 0.007033445381687488, "reward_normed_std": 0.08155920710563659, "critic_slow": 4.994891505050659, "critic_target": 4.99688381690979, "actor_ent": 1.2500929622650145, "actor_ent_scale": 0.0010000000474974513, "critic": 4.997040568161011, "fps": 106.64256295668199}
{"step": 12391488, "train_return": 20.0, "train_length": 1754.0, "train_total_steps": 3097872.0, "train_total_episodes": 1535.0, "train_loaded_steps": 1998777.0, "train_loaded_episodes": 1004.0}
{"step": 12399640, "train_return": 14.0, "train_length": 2038.0, "train_total_steps": 3099910.0, "train_total_episodes": 1536.0, "train_loaded_steps": 1998383.0, "train_loaded_episodes": 1004.0}
{"step": 12406760, "train_return": 19.0, "train_length": 1780.0, "train_total_steps": 3101690.0, "train_total_episodes": 1537.0, "train_loaded_steps": 1997599.0, "train_loaded_episodes": 1004.0}
{"step": 12414300, "train_return": 18.0, "train_length": 1885.0, "train_total_steps": 3103575.0, "train_total_episodes": 1538.0, "train_loaded_steps": 1999484.0, "train_loaded_episodes": 1005.0}
{"step": 12420940, "train_return": 21.0, "train_length": 1660.0, "train_total_steps": 3105235.0, "train_total_episodes": 1539.0, "train_loaded_steps": 1999116.0, "train_loaded_episodes": 1005.0}
{"step": 12427872, "kl_loss": 1.3540155738830566, "image_loss": 3772.0, "reward_loss": 0.9191647972106933, "discount_loss": 0.007752310693264008, "model_kl": 1.354015545463562, "prior_ent": 27.03515610656738, "post_ent": 25.69028985595703, "model_loss": 3773.093360546875, "model_loss_scale": 8192.0, "model_grad_norm": 5.266590434265137, "actor_loss": 0.003778899870684836, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.03631212774813175, "critic_loss": 0.9182236496925354, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2718708668410778, "reward_mean": 0.007255527188372799, "reward_std": 0.08145697645545005, "reward_normed_mean": 0.007255527188372799, "reward_normed_std": 0.08145697645545005, "critic_slow": 4.919195774459839, "critic_target": 4.921219255065918, "actor_ent": 1.2653309646606445, "actor_ent_scale": 0.0010000000474974513, "critic": 4.921519690322876, "fps": 107.15207504149285}
{"step": 12428376, "train_return": 19.0, "train_length": 1859.0, "train_total_steps": 3107094.0, "train_total_episodes": 1540.0, "train_loaded_steps": 1998828.0, "train_loaded_episodes": 1005.0}
{"step": 12436452, "train_return": 17.0, "train_length": 2019.0, "train_total_steps": 3109113.0, "train_total_episodes": 1541.0, "train_loaded_steps": 1998845.0, "train_loaded_episodes": 1005.0}
{"step": 12443608, "train_return": 19.0, "train_length": 1789.0, "train_total_steps": 3110902.0, "train_total_episodes": 1542.0, "train_loaded_steps": 1998460.0, "train_loaded_episodes": 1005.0}
{"step": 12450744, "train_return": 19.0, "train_length": 1784.0, "train_total_steps": 3112686.0, "train_total_episodes": 1543.0, "train_loaded_steps": 1997947.0, "train_loaded_episodes": 1005.0}
{"step": 12458416, "train_return": 18.0, "train_length": 1918.0, "train_total_steps": 3114604.0, "train_total_episodes": 1544.0, "train_loaded_steps": 1999865.0, "train_loaded_episodes": 1006.0}
{"step": 12466312, "train_return": 17.0, "train_length": 1974.0, "train_total_steps": 3116578.0, "train_total_episodes": 1545.0, "train_loaded_steps": 1997520.0, "train_loaded_episodes": 1005.0}
{"step": 12467872, "kl_loss": 1.3673703256607055, "image_loss": 3772.0, "reward_loss": 0.9191576772689819, "discount_loss": 0.00774645392075181, "model_kl": 1.367370294570923, "prior_ent": 27.013614169311523, "post_ent": 25.658351681518553, "model_loss": 3773.094660546875, "model_loss_scale": 8192.0, "model_grad_norm": 5.323418916130066, "actor_loss": -0.000763041690987302, "actor_loss_scale": 525965.7216, "actor_grad_norm": 0.03660617663860321, "critic_loss": 0.9201865894317627, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2902180356025696, "reward_mean": 0.007129572836589068, "reward_std": 0.08163209509849548, "reward_normed_mean": 0.007129572836589068, "reward_normed_std": 0.08163209509849548, "critic_slow": 4.872786944198609, "critic_target": 4.874487242889404, "actor_ent": 1.3141254796981812, "actor_ent_scale": 0.0010000000474974513, "critic": 4.874480173492431, "fps": 105.5872012252343}
{"step": 12474264, "train_return": 17.0, "train_length": 1988.0, "train_total_steps": 3118566.0, "train_total_episodes": 1546.0, "train_loaded_steps": 1999508.0, "train_loaded_episodes": 1006.0}
{"step": 12482248, "train_return": 18.0, "train_length": 1996.0, "train_total_steps": 3120562.0, "train_total_episodes": 1547.0, "train_loaded_steps": 1999174.0, "train_loaded_episodes": 1006.0}
{"step": 12489072, "train_return": 21.0, "train_length": 1706.0, "train_total_steps": 3122268.0, "train_total_episodes": 1548.0, "train_loaded_steps": 1998568.0, "train_loaded_episodes": 1006.0}
{"step": 12497132, "train_return": 17.0, "train_length": 2015.0, "train_total_steps": 3124283.0, "train_total_episodes": 1549.0, "train_loaded_steps": 1998641.0, "train_loaded_episodes": 1006.0}
{"step": 12506184, "train_return": 14.0, "train_length": 2263.0, "train_total_steps": 3126546.0, "train_total_episodes": 1550.0, "train_loaded_steps": 1998849.0, "train_loaded_episodes": 1006.0}
{"step": 12507872, "kl_loss": 1.3419070459365845, "image_loss": 3772.0, "reward_loss": 0.9191519887924194, "discount_loss": 0.007759513721615076, "model_kl": 1.3419070175170897, "prior_ent": 26.893674130249025, "post_ent": 25.563181134033204, "model_loss": 3773.0921671875, "model_loss_scale": 8192.0, "model_grad_norm": 5.349930961608886, "actor_loss": 0.0007990917948889546, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.034229489839077, "critic_loss": 0.9174985311508179, "critic_loss_scale": 146590.9248, "critic_grad_norm": Infinity, "reward_mean": 0.007319540856638923, "reward_std": 0.08256151664853097, "reward_normed_mean": 0.007319540856638923, "reward_normed_std": 0.08256151664853097, "critic_slow": 4.84508886680603, "critic_target": 4.846361179733276, "actor_ent": 1.3159539712905883, "actor_ent_scale": 0.0010000000474974513, "critic": 4.846420261001587, "fps": 107.0919553793111}
{"step": 12513936, "train_return": 17.0, "train_length": 1938.0, "train_total_steps": 3128484.0, "train_total_episodes": 1551.0, "train_loaded_steps": 1998716.0, "train_loaded_episodes": 1006.0}
{"step": 12521008, "train_return": 19.0, "train_length": 1768.0, "train_total_steps": 3130252.0, "train_total_episodes": 1552.0, "train_loaded_steps": 1998348.0, "train_loaded_episodes": 1006.0}
{"step": 12528976, "train_return": 16.0, "train_length": 1992.0, "train_total_steps": 3132244.0, "train_total_episodes": 1553.0, "train_loaded_steps": 1998229.0, "train_loaded_episodes": 1006.0}
{"step": 12536508, "train_return": 20.0, "train_length": 1883.0, "train_total_steps": 3134127.0, "train_total_episodes": 1554.0, "train_loaded_steps": 1998157.0, "train_loaded_episodes": 1006.0}
{"step": 12544364, "train_return": 17.0, "train_length": 1964.0, "train_total_steps": 3136091.0, "train_total_episodes": 1555.0, "train_loaded_steps": 1997885.0, "train_loaded_episodes": 1006.0}
{"step": 12547872, "kl_loss": 1.3636685791015626, "image_loss": 3772.0, "reward_loss": 0.9191526738166809, "discount_loss": 0.007747625488042831, "model_kl": 1.3636685438156129, "prior_ent": 27.0519652923584, "post_ent": 25.698965451049805, "model_loss": 3773.094284375, "model_loss_scale": 16043.2128, "model_grad_norm": 5.255351463317871, "actor_loss": 0.0019251789390727935, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.03238582449406385, "critic_loss": 0.9174955874443054, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.24946506592035295, "reward_mean": 0.007136625439563068, "reward_std": 0.0821771403491497, "reward_normed_mean": 0.007136625439563068, "reward_normed_std": 0.0821771403491497, "critic_slow": 4.7471831615447995, "critic_target": 4.750047211456299, "actor_ent": 1.3312340019226074, "actor_ent_scale": 0.0010000000474974513, "critic": 4.750023609542847, "fps": 107.28235961722058}
{"step": 12554872, "train_return": 12.0, "train_length": 2627.0, "train_total_steps": 3138718.0, "train_total_episodes": 1556.0, "train_loaded_steps": 1998620.0, "train_loaded_episodes": 1006.0}
{"step": 12562256, "train_return": 19.0, "train_length": 1846.0, "train_total_steps": 3140564.0, "train_total_episodes": 1557.0, "train_loaded_steps": 1998729.0, "train_loaded_episodes": 1006.0}
{"step": 12570412, "train_return": 18.0, "train_length": 2039.0, "train_total_steps": 3142603.0, "train_total_episodes": 1558.0, "train_loaded_steps": 1998625.0, "train_loaded_episodes": 1006.0}
{"step": 12577476, "train_return": 20.0, "train_length": 1766.0, "train_total_steps": 3144369.0, "train_total_episodes": 1559.0, "train_loaded_steps": 1998476.0, "train_loaded_episodes": 1006.0}
{"step": 12584684, "train_return": 19.0, "train_length": 1802.0, "train_total_steps": 3146171.0, "train_total_episodes": 1560.0, "train_loaded_steps": 1998460.0, "train_loaded_episodes": 1006.0}
{"step": 12587872, "kl_loss": 1.3714187185287476, "image_loss": 3772.0, "reward_loss": 0.9191414507865906, "discount_loss": 0.007742879171669484, "model_kl": 1.3714186882019044, "prior_ent": 27.035601290893556, "post_ent": 25.68497554321289, "model_loss": 3773.09503359375, "model_loss_scale": 16384.0, "model_grad_norm": 5.528824765014648, "actor_loss": 0.002930821833164646, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.03365622864663601, "critic_loss": 0.9170243098258972, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2328996334195137, "reward_mean": 0.007279385399911553, "reward_std": 0.08219051585793495, "reward_normed_mean": 0.007279385399911553, "reward_normed_std": 0.08219051585793495, "critic_slow": 4.824123404693603, "critic_target": 4.826995736312866, "actor_ent": 1.3329589500427246, "actor_ent_scale": 0.0010000000474974513, "critic": 4.826974334335327, "fps": 107.85503042860005}
{"step": 12591748, "train_return": 20.0, "train_length": 1766.0, "train_total_steps": 3147937.0, "train_total_episodes": 1561.0, "train_loaded_steps": 1998013.0, "train_loaded_episodes": 1006.0}
{"step": 12600712, "train_return": 14.0, "train_length": 2241.0, "train_total_steps": 3150178.0, "train_total_episodes": 1562.0, "train_loaded_steps": 1997835.0, "train_loaded_episodes": 1006.0}
{"step": 12609268, "train_return": 17.0, "train_length": 2139.0, "train_total_steps": 3152317.0, "train_total_episodes": 1563.0, "train_loaded_steps": 1999974.0, "train_loaded_episodes": 1007.0}
{"step": 12616660, "train_return": 20.0, "train_length": 1848.0, "train_total_steps": 3154165.0, "train_total_episodes": 1564.0, "train_loaded_steps": 1999952.0, "train_loaded_episodes": 1007.0}
{"step": 12623948, "train_return": 20.0, "train_length": 1822.0, "train_total_steps": 3155987.0, "train_total_episodes": 1565.0, "train_loaded_steps": 1999650.0, "train_loaded_episodes": 1007.0}
{"step": 12627872, "kl_loss": 1.3434913900375367, "image_loss": 3772.0, "reward_loss": 0.9191351075172425, "discount_loss": 0.0077416293203830715, "model_kl": 1.3434913608551025, "prior_ent": 26.928721231079102, "post_ent": 25.59181944885254, "model_loss": 3773.092225, "model_loss_scale": 16384.0, "model_grad_norm": 5.113588164520264, "actor_loss": 0.0018796786099934252, "actor_loss_scale": 1890792.2432, "actor_grad_norm": 0.03211499675512314, "critic_loss": 0.9167353156089783, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.23632071409225464, "reward_mean": 0.00701885097536724, "reward_std": 0.08189818093776703, "reward_normed_mean": 0.00701885097536724, "reward_normed_std": 0.08189818093776703, "critic_slow": 4.778358261871338, "critic_target": 4.780249221038819, "actor_ent": 1.3495026393890381, "actor_ent_scale": 0.0010000000474974513, "critic": 4.780246899032592, "fps": 108.6362078710582}
{"step": 12630964, "train_return": 20.0, "train_length": 1754.0, "train_total_steps": 3157741.0, "train_total_episodes": 1566.0, "train_loaded_steps": 1999502.0, "train_loaded_episodes": 1007.0}
{"step": 12638796, "train_return": 17.0, "train_length": 1958.0, "train_total_steps": 3159699.0, "train_total_episodes": 1567.0, "train_loaded_steps": 1999557.0, "train_loaded_episodes": 1007.0}
{"step": 12645416, "train_return": 21.0, "train_length": 1655.0, "train_total_steps": 3161354.0, "train_total_episodes": 1568.0, "train_loaded_steps": 1999112.0, "train_loaded_episodes": 1007.0}
{"step": 12653144, "train_return": 17.0, "train_length": 1932.0, "train_total_steps": 3163286.0, "train_total_episodes": 1569.0, "train_loaded_steps": 1998752.0, "train_loaded_episodes": 1007.0}
{"step": 12661376, "train_return": 17.0, "train_length": 2058.0, "train_total_steps": 3165344.0, "train_total_episodes": 1570.0, "train_loaded_steps": 1998694.0, "train_loaded_episodes": 1007.0}
{"step": 12667872, "kl_loss": 1.408618639755249, "image_loss": 3772.000387890625, "reward_loss": 0.9191500137329102, "discount_loss": 0.007755330533534288, "model_kl": 1.4086186071395874, "prior_ent": 26.896242517089842, "post_ent": 25.507531677246092, "model_loss": 3773.099199609375, "model_loss_scale": 8467.2512, "model_grad_norm": Infinity, "actor_loss": 0.0064242709818237926, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.03474229784011841, "critic_loss": 0.9176080991744995, "critic_loss_scale": 198810.0096, "critic_grad_norm": Infinity, "reward_mean": 0.007205464409431443, "reward_std": 0.0822527879536152, "reward_normed_mean": 0.007205464409431443, "reward_normed_std": 0.0822527879536152, "critic_slow": 4.809001135253906, "critic_target": 4.8142850303649904, "actor_ent": 1.3280201143264772, "actor_ent_scale": 0.0010000000474974513, "critic": 4.814189056777954, "fps": 107.8663045171824}
{"step": 12668812, "train_return": 19.0, "train_length": 1859.0, "train_total_steps": 3167203.0, "train_total_episodes": 1571.0, "train_loaded_steps": 1998786.0, "train_loaded_episodes": 1007.0}
{"step": 12676464, "train_return": 18.0, "train_length": 1913.0, "train_total_steps": 3169116.0, "train_total_episodes": 1572.0, "train_loaded_steps": 1998384.0, "train_loaded_episodes": 1007.0}
{"step": 12683660, "train_return": 19.0, "train_length": 1799.0, "train_total_steps": 3170915.0, "train_total_episodes": 1573.0, "train_loaded_steps": 1998054.0, "train_loaded_episodes": 1007.0}
{"step": 12691076, "train_return": 18.0, "train_length": 1854.0, "train_total_steps": 3172769.0, "train_total_episodes": 1574.0, "train_loaded_steps": 1999908.0, "train_loaded_episodes": 1008.0}
{"step": 12698504, "train_return": 18.0, "train_length": 1857.0, "train_total_steps": 3174626.0, "train_total_episodes": 1575.0, "train_loaded_steps": 1999912.0, "train_loaded_episodes": 1008.0}
{"step": 12706148, "train_return": 17.0, "train_length": 1911.0, "train_total_steps": 3176537.0, "train_total_episodes": 1576.0, "train_loaded_steps": 1999770.0, "train_loaded_episodes": 1008.0}
{"step": 12707872, "kl_loss": 1.3711805130004884, "image_loss": 3772.0, "reward_loss": 0.919145120716095, "discount_loss": 0.007876920037716627, "model_kl": 1.371180480003357, "prior_ent": 26.90560979309082, "post_ent": 25.54715128479004, "model_loss": 3773.095676171875, "model_loss_scale": 8192.0, "model_grad_norm": 5.277982340049744, "actor_loss": 0.006398935312501271, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.03407358202338219, "critic_loss": 0.9198068078041076, "critic_loss_scale": 82627.7888, "critic_grad_norm": Infinity, "reward_mean": 0.007149184420425445, "reward_std": 0.08198708860874176, "reward_normed_mean": 0.007149184420425445, "reward_normed_std": 0.08198708860874176, "critic_slow": 4.807496897888184, "critic_target": 4.81192491607666, "actor_ent": 1.3424501998901368, "actor_ent_scale": 0.0010000000474974513, "critic": 4.811961599731445, "fps": 105.68053485330536}
{"step": 12713220, "train_return": 19.0, "train_length": 1768.0, "train_total_steps": 3178305.0, "train_total_episodes": 1577.0, "train_loaded_steps": 1999388.0, "train_loaded_episodes": 1008.0}
{"step": 12720032, "train_return": 21.0, "train_length": 1703.0, "train_total_steps": 3180008.0, "train_total_episodes": 1578.0, "train_loaded_steps": 1998973.0, "train_loaded_episodes": 1008.0}
{"step": 12727456, "train_return": 18.0, "train_length": 1856.0, "train_total_steps": 3181864.0, "train_total_episodes": 1579.0, "train_loaded_steps": 1998580.0, "train_loaded_episodes": 1008.0}
{"step": 12734288, "train_return": 20.0, "train_length": 1708.0, "train_total_steps": 3183572.0, "train_total_episodes": 1580.0, "train_loaded_steps": 1997781.0, "train_loaded_episodes": 1008.0}
{"step": 12733812, "eval_return": 16.0, "eval_length": 2067.0, "eval_total_steps": 31509.0, "eval_total_episodes": 16.0, "eval_loaded_steps": 31525.0, "eval_loaded_episodes": 16.0}
{"step": 12733816, "kl_loss": 1.3483940362930298, "image_loss": 3772.0, "reward_loss": 0.919640302658081, "discount_loss": 0.007735494989901781, "model_kl": 1.3483939170837402, "prior_ent": 26.966564178466797, "post_ent": 25.640361785888672, "model_loss": 3773.093017578125, "model_loss_scale": 16384.0, "model_grad_norm": 6.907036304473877, "actor_loss": -0.0180517490953207, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.057346127927303314, "critic_loss": 0.9329230189323425, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.31204017996788025, "reward_mean": 0.006965819746255875, "reward_std": 0.07899635285139084, "reward_normed_mean": 0.006965819746255875, "reward_normed_std": 0.07899635285139084, "critic_slow": 5.558169364929199, "critic_target": 5.54505729675293, "actor_ent": 1.251842737197876, "actor_ent_scale": 0.0010000000474974513, "critic": 5.522321701049805, "fps": 0.0}
{"step": 12741732, "train_return": 19.0, "train_length": 1980.0, "train_total_steps": 3185433.0, "train_total_episodes": 1581.0, "train_loaded_steps": 1999761.0, "train_loaded_episodes": 1009.0}
{"step": 12749548, "train_return": 17.0, "train_length": 1954.0, "train_total_steps": 3187387.0, "train_total_episodes": 1582.0, "train_loaded_steps": 1999439.0, "train_loaded_episodes": 1009.0}
{"step": 12757708, "train_return": 14.0, "train_length": 2040.0, "train_total_steps": 3189427.0, "train_total_episodes": 1583.0, "train_loaded_steps": 1998913.0, "train_loaded_episodes": 1009.0}
{"step": 12765900, "train_return": 17.0, "train_length": 2048.0, "train_total_steps": 3191475.0, "train_total_episodes": 1584.0, "train_loaded_steps": 1999037.0, "train_loaded_episodes": 1009.0}
{"step": 12773304, "train_return": 19.0, "train_length": 1851.0, "train_total_steps": 3193326.0, "train_total_episodes": 1585.0, "train_loaded_steps": 1998777.0, "train_loaded_episodes": 1009.0}
{"step": 12773816, "kl_loss": 1.3846047584533692, "image_loss": 3772.0, "reward_loss": 0.9191926941871643, "discount_loss": 0.007755413261055946, "model_kl": 1.3846047262191772, "prior_ent": 27.089803125, "post_ent": 25.716427880859374, "model_loss": 3773.096465234375, "model_loss_scale": 2084.0448, "model_grad_norm": Infinity, "actor_loss": -0.005942582262156065, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.03805185210108757, "critic_loss": 0.9202008721351623, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.3185113612949848, "reward_mean": 0.007054458744474686, "reward_std": 0.08172798824310303, "reward_normed_mean": 0.007054458744474686, "reward_normed_std": 0.08172798824310303, "critic_slow": 5.186376599884033, "critic_target": 5.184938161468506, "actor_ent": 1.326567873764038, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1850202201843265, "fps": 107.72589707780061}
{"step": 12780148, "train_return": 20.0, "train_length": 1711.0, "train_total_steps": 3195037.0, "train_total_episodes": 1586.0, "train_loaded_steps": 1998050.0, "train_loaded_episodes": 1009.0}
{"step": 12787284, "train_return": 19.0, "train_length": 1784.0, "train_total_steps": 3196821.0, "train_total_episodes": 1587.0, "train_loaded_steps": 1999834.0, "train_loaded_episodes": 1010.0}
{"step": 12794768, "train_return": 18.0, "train_length": 1871.0, "train_total_steps": 3198692.0, "train_total_episodes": 1588.0, "train_loaded_steps": 1999597.0, "train_loaded_episodes": 1010.0}
{"step": 12802904, "train_return": 15.0, "train_length": 2034.0, "train_total_steps": 3200726.0, "train_total_episodes": 1589.0, "train_loaded_steps": 1999520.0, "train_loaded_episodes": 1010.0}
{"step": 12811760, "train_return": 13.0, "train_length": 2214.0, "train_total_steps": 3202940.0, "train_total_episodes": 1590.0, "train_loaded_steps": 1999144.0, "train_loaded_episodes": 1010.0}
{"step": 12813816, "kl_loss": 1.3628915702819824, "image_loss": 3772.0, "reward_loss": 0.9191733924865723, "discount_loss": 0.007741381812095642, "model_kl": 1.3628915386199951, "prior_ent": 27.00891801147461, "post_ent": 25.6581873046875, "model_loss": 3773.09419921875, "model_loss_scale": 2048.0, "model_grad_norm": 5.164417694091797, "actor_loss": -0.006540683083416661, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.0367856559574604, "critic_loss": 0.9197193428993226, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.3107561682283878, "reward_mean": 0.007238709264376667, "reward_std": 0.08185293259620667, "reward_normed_mean": 0.007238709264376667, "reward_normed_std": 0.08185293259620667, "critic_slow": 5.238120348739624, "critic_target": 5.2363762939453125, "actor_ent": 1.31609140625, "actor_ent_scale": 0.0010000000474974513, "critic": 5.236496876525879, "fps": 109.30346081606172}
{"step": 12821128, "train_return": 15.0, "train_length": 2342.0, "train_total_steps": 3205282.0, "train_total_episodes": 1591.0, "train_loaded_steps": 1999431.0, "train_loaded_episodes": 1010.0}
{"step": 12830036, "train_return": 14.0, "train_length": 2227.0, "train_total_steps": 3207509.0, "train_total_episodes": 1592.0, "train_loaded_steps": 1999520.0, "train_loaded_episodes": 1010.0}
{"step": 12837316, "train_return": 19.0, "train_length": 1820.0, "train_total_steps": 3209329.0, "train_total_episodes": 1593.0, "train_loaded_steps": 1999013.0, "train_loaded_episodes": 1010.0}
{"step": 12845336, "train_return": 16.0, "train_length": 2005.0, "train_total_steps": 3211334.0, "train_total_episodes": 1594.0, "train_loaded_steps": 1998484.0, "train_loaded_episodes": 1010.0}
{"step": 12853816, "kl_loss": 1.39698228931427, "image_loss": 3772.0, "reward_loss": 0.9191808752059937, "discount_loss": 0.007839644769579173, "model_kl": 1.396982257080078, "prior_ent": 27.13264871826172, "post_ent": 25.75032003173828, "model_loss": 3773.098115234375, "model_loss_scale": 2048.0, "model_grad_norm": 5.268107343292236, "actor_loss": -0.003927461323561147, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.043056217005848885, "critic_loss": 0.9262449403762817, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.36927475045919417, "reward_mean": 0.007061526167392731, "reward_std": 0.08245254551768302, "reward_normed_mean": 0.007061526167392731, "reward_normed_std": 0.08245254551768302, "critic_slow": 5.142275132751465, "critic_target": 5.144243677902222, "actor_ent": 1.285882572364807, "actor_ent_scale": 0.0010000000474974513, "critic": 5.144226226043701, "fps": 110.22744619348715}
{"step": 12855004, "train_return": 12.0, "train_length": 2417.0, "train_total_steps": 3213751.0, "train_total_episodes": 1595.0, "train_loaded_steps": 1998585.0, "train_loaded_episodes": 1010.0}
{"step": 12863176, "train_return": 17.0, "train_length": 2043.0, "train_total_steps": 3215794.0, "train_total_episodes": 1596.0, "train_loaded_steps": 1998188.0, "train_loaded_episodes": 1010.0}
{"step": 12870416, "train_return": 19.0, "train_length": 1810.0, "train_total_steps": 3217604.0, "train_total_episodes": 1597.0, "train_loaded_steps": 1999998.0, "train_loaded_episodes": 1011.0}
{"step": 12879824, "train_return": 14.0, "train_length": 2352.0, "train_total_steps": 3219956.0, "train_total_episodes": 1598.0, "train_loaded_steps": 1999720.0, "train_loaded_episodes": 1011.0}
{"step": 12887916, "train_return": 16.0, "train_length": 2023.0, "train_total_steps": 3221979.0, "train_total_episodes": 1599.0, "train_loaded_steps": 1999703.0, "train_loaded_episodes": 1011.0}
{"step": 12893816, "kl_loss": 1.3630090961456298, "image_loss": 3772.0, "reward_loss": 0.9191640983581543, "discount_loss": 0.007744722364842892, "model_kl": 1.3630090662002563, "prior_ent": 27.06066208190918, "post_ent": 25.706215292358397, "model_loss": 3773.0942125, "model_loss_scale": 3676.5696, "model_grad_norm": 5.375233574676514, "actor_loss": -0.0051387956453952935, "actor_loss_scale": 59087.2576, "actor_grad_norm": 0.038910370245575907, "critic_loss": 0.920386061668396, "critic_loss_scale": 59087.2576, "critic_grad_norm": 0.3136652944087982, "reward_mean": 0.007046713821811136, "reward_std": 0.08173499730825425, "reward_normed_mean": 0.007046713821811136, "reward_normed_std": 0.08173499730825425, "critic_slow": 5.129466444778442, "critic_target": 5.1288320949554445, "actor_ent": 1.3091879878997803, "actor_ent_scale": 0.0010000000474974513, "critic": 5.128955772018433, "fps": 109.21539849591365}
{"step": 12895048, "train_return": 19.0, "train_length": 1783.0, "train_total_steps": 3223762.0, "train_total_episodes": 1600.0, "train_loaded_steps": 1999328.0, "train_loaded_episodes": 1011.0}
{"step": 12902756, "train_return": 17.0, "train_length": 1927.0, "train_total_steps": 3225689.0, "train_total_episodes": 1601.0, "train_loaded_steps": 1999484.0, "train_loaded_episodes": 1011.0}
{"step": 12911036, "train_return": 15.0, "train_length": 2070.0, "train_total_steps": 3227759.0, "train_total_episodes": 1602.0, "train_loaded_steps": 1999323.0, "train_loaded_episodes": 1011.0}
{"step": 12918200, "train_return": 19.0, "train_length": 1791.0, "train_total_steps": 3229550.0, "train_total_episodes": 1603.0, "train_loaded_steps": 1999165.0, "train_loaded_episodes": 1011.0}
{"step": 12925676, "train_return": 18.0, "train_length": 1869.0, "train_total_steps": 3231419.0, "train_total_episodes": 1604.0, "train_loaded_steps": 1999166.0, "train_loaded_episodes": 1011.0}
{"step": 12932624, "train_return": 20.0, "train_length": 1737.0, "train_total_steps": 3233156.0, "train_total_episodes": 1605.0, "train_loaded_steps": 1999194.0, "train_loaded_episodes": 1011.0}
{"step": 12933816, "kl_loss": 1.3626523777008057, "image_loss": 3772.0, "reward_loss": 0.9191902697563171, "discount_loss": 0.00776056013405323, "model_kl": 1.362652345275879, "prior_ent": 27.12913857421875, "post_ent": 25.776860342407225, "model_loss": 3773.094292578125, "model_loss_scale": 4096.0, "model_grad_norm": 5.378815560531616, "actor_loss": -0.004045137397840153, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.036324093088507654, "critic_loss": 0.9195354536056518, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.27702891579866407, "reward_mean": 0.0071040381989441815, "reward_std": 0.0814160586476326, "reward_normed_mean": 0.0071040381989441815, "reward_normed_std": 0.0814160586476326, "critic_slow": 5.170288319015503, "critic_target": 5.170150911331176, "actor_ent": 1.3000824089050294, "actor_ent_scale": 0.0010000000474974513, "critic": 5.170234268951416, "fps": 109.54228745056481}
{"step": 12940908, "train_return": 14.0, "train_length": 2071.0, "train_total_steps": 3235227.0, "train_total_episodes": 1606.0, "train_loaded_steps": 1999188.0, "train_loaded_episodes": 1011.0}
{"step": 12947808, "train_return": 20.0, "train_length": 1725.0, "train_total_steps": 3236952.0, "train_total_episodes": 1607.0, "train_loaded_steps": 1998972.0, "train_loaded_episodes": 1011.0}
{"step": 12954772, "train_return": 20.0, "train_length": 1741.0, "train_total_steps": 3238693.0, "train_total_episodes": 1608.0, "train_loaded_steps": 1998818.0, "train_loaded_episodes": 1011.0}
{"step": 12962040, "train_return": 19.0, "train_length": 1817.0, "train_total_steps": 3240510.0, "train_total_episodes": 1609.0, "train_loaded_steps": 1998718.0, "train_loaded_episodes": 1011.0}
{"step": 12969668, "train_return": 18.0, "train_length": 1907.0, "train_total_steps": 3242417.0, "train_total_episodes": 1610.0, "train_loaded_steps": 1998526.0, "train_loaded_episodes": 1011.0}
{"step": 12973816, "kl_loss": 1.3624808109283448, "image_loss": 3772.0, "reward_loss": 0.9191691048622131, "discount_loss": 0.007754971628636122, "model_kl": 1.3624807836532593, "prior_ent": 27.03216011657715, "post_ent": 25.68076907043457, "model_loss": 3773.094228515625, "model_loss_scale": 4096.0, "model_grad_norm": 5.478437568664551, "actor_loss": -0.0012851402999933725, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.03533936034142971, "critic_loss": 0.9190262655258179, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.26728068519234655, "reward_mean": 0.007163404983843793, "reward_std": 0.08166010721325874, "reward_normed_mean": 0.007163404983843793, "reward_normed_std": 0.08166010721325874, "critic_slow": 5.194608818435669, "critic_target": 5.194684776687622, "actor_ent": 1.3082541324615478, "actor_ent_scale": 0.0010000000474974513, "critic": 5.194729877853393, "fps": 106.69793831023789}
{"step": 12977072, "train_return": 19.0, "train_length": 1851.0, "train_total_steps": 3244268.0, "train_total_episodes": 1611.0, "train_loaded_steps": 1998508.0, "train_loaded_episodes": 1011.0}
{"step": 12985712, "train_return": 16.0, "train_length": 2160.0, "train_total_steps": 3246428.0, "train_total_episodes": 1612.0, "train_loaded_steps": 1998639.0, "train_loaded_episodes": 1011.0}
{"step": 12993624, "train_return": 17.0, "train_length": 1978.0, "train_total_steps": 3248406.0, "train_total_episodes": 1613.0, "train_loaded_steps": 1997572.0, "train_loaded_episodes": 1011.0}
{"step": 13000692, "train_return": 20.0, "train_length": 1767.0, "train_total_steps": 3250173.0, "train_total_episodes": 1614.0, "train_loaded_steps": 1999339.0, "train_loaded_episodes": 1012.0}
{"step": 13008212, "train_return": 19.0, "train_length": 1880.0, "train_total_steps": 3252053.0, "train_total_episodes": 1615.0, "train_loaded_steps": 1999198.0, "train_loaded_episodes": 1012.0}
{"step": 13013816, "kl_loss": 1.3600804077148438, "image_loss": 3772.0002, "reward_loss": 0.9191855932235717, "discount_loss": 0.007742655888944864, "model_kl": 1.3600803749084474, "prior_ent": 26.92772574157715, "post_ent": 25.577285467529297, "model_loss": 3773.09414375, "model_loss_scale": 6533.9392, "model_grad_norm": 5.301539813995361, "actor_loss": -0.002214637580740964, "actor_loss_scale": 105067.3152, "actor_grad_norm": 0.03727656334936619, "critic_loss": 0.9203793361663818, "critic_loss_scale": 105067.3152, "critic_grad_norm": 0.33197544679045676, "reward_mean": 0.007111276286542125, "reward_std": 0.08136532760858536, "reward_normed_mean": 0.007111276286542125, "reward_normed_std": 0.08136532760858536, "critic_slow": 5.193303616333008, "critic_target": 5.193381317520141, "actor_ent": 1.311146557044983, "actor_ent_scale": 0.0010000000474974513, "critic": 5.193404047775268, "fps": 107.65485897704008}
{"step": 13016420, "train_return": 15.0, "train_length": 2052.0, "train_total_steps": 3254105.0, "train_total_episodes": 1616.0, "train_loaded_steps": 1999290.0, "train_loaded_episodes": 1012.0}
{"step": 13024764, "train_return": 15.0, "train_length": 2086.0, "train_total_steps": 3256191.0, "train_total_episodes": 1617.0, "train_loaded_steps": 1998980.0, "train_loaded_episodes": 1012.0}
{"step": 13032516, "train_return": 18.0, "train_length": 1938.0, "train_total_steps": 3258129.0, "train_total_episodes": 1618.0, "train_loaded_steps": 1999130.0, "train_loaded_episodes": 1012.0}
{"step": 13040768, "train_return": 17.0, "train_length": 2063.0, "train_total_steps": 3260192.0, "train_total_episodes": 1619.0, "train_loaded_steps": 1998575.0, "train_loaded_episodes": 1012.0}
{"step": 13048356, "train_return": 18.0, "train_length": 1897.0, "train_total_steps": 3262089.0, "train_total_episodes": 1620.0, "train_loaded_steps": 1998735.0, "train_loaded_episodes": 1012.0}
{"step": 13053816, "kl_loss": 1.4032601781845093, "image_loss": 3772.0, "reward_loss": 0.9191630520820617, "discount_loss": 0.007741788850724697, "model_kl": 1.4032601467132568, "prior_ent": 26.9662391998291, "post_ent": 25.58059965209961, "model_loss": 3773.098224609375, "model_loss_scale": 8192.0, "model_grad_norm": 5.298263329696655, "actor_loss": -0.00043531718293088486, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.03693154511451721, "critic_loss": 0.9204107063293457, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.29433482370376585, "reward_mean": 0.007074630350351799, "reward_std": 0.08175004976391792, "reward_normed_mean": 0.007074630350351799, "reward_normed_std": 0.08175004976391792, "critic_slow": 5.131748830413819, "critic_target": 5.132245326995849, "actor_ent": 1.3113149826049804, "actor_ent_scale": 0.0010000000474974513, "critic": 5.132403932952881, "fps": 107.21289954787086}
{"step": 13055208, "train_return": 20.0, "train_length": 1713.0, "train_total_steps": 3263802.0, "train_total_episodes": 1621.0, "train_loaded_steps": 1998134.0, "train_loaded_episodes": 1012.0}
{"step": 13063704, "train_return": 15.0, "train_length": 2124.0, "train_total_steps": 3265926.0, "train_total_episodes": 1622.0, "train_loaded_steps": 1998142.0, "train_loaded_episodes": 1012.0}
{"step": 13071800, "train_return": 18.0, "train_length": 2024.0, "train_total_steps": 3267950.0, "train_total_episodes": 1623.0, "train_loaded_steps": 1998035.0, "train_loaded_episodes": 1012.0}
{"step": 13079732, "train_return": 16.0, "train_length": 1983.0, "train_total_steps": 3269933.0, "train_total_episodes": 1624.0, "train_loaded_steps": 1997970.0, "train_loaded_episodes": 1012.0}
{"step": 13087764, "train_return": 18.0, "train_length": 2008.0, "train_total_steps": 3271941.0, "train_total_episodes": 1625.0, "train_loaded_steps": 1999978.0, "train_loaded_episodes": 1013.0}
{"step": 13093816, "kl_loss": 1.3650674394607545, "image_loss": 3772.0, "reward_loss": 0.919194480419159, "discount_loss": 0.0077703247971832754, "model_kl": 1.3650674039840698, "prior_ent": 26.99854811706543, "post_ent": 25.645695745849608, "model_loss": 3773.0945875, "model_loss_scale": 8192.0, "model_grad_norm": 5.373280461120605, "actor_loss": -0.004038717328140046, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.0363494219481945, "critic_loss": 0.9197704922676087, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3193875453054905, "reward_mean": 0.007256327881116886, "reward_std": 0.08135367542505265, "reward_normed_mean": 0.007256327881116886, "reward_normed_std": 0.08135367542505265, "critic_slow": 5.13347526550293, "critic_target": 5.132937234497071, "actor_ent": 1.2915922552108765, "actor_ent_scale": 0.0010000000474974513, "critic": 5.133005919647217, "fps": 109.02106103695783}
{"step": 13095696, "train_return": 19.0, "train_length": 1983.0, "train_total_steps": 3273924.0, "train_total_episodes": 1626.0, "train_loaded_steps": 1997990.0, "train_loaded_episodes": 1012.0}
{"step": 13103700, "train_return": 15.0, "train_length": 2001.0, "train_total_steps": 3275925.0, "train_total_episodes": 1627.0, "train_loaded_steps": 1999991.0, "train_loaded_episodes": 1013.0}
{"step": 13111512, "train_return": 17.0, "train_length": 1953.0, "train_total_steps": 3277878.0, "train_total_episodes": 1628.0, "train_loaded_steps": 1999723.0, "train_loaded_episodes": 1013.0}
{"step": 13118764, "train_return": 19.0, "train_length": 1813.0, "train_total_steps": 3279691.0, "train_total_episodes": 1629.0, "train_loaded_steps": 1999183.0, "train_loaded_episodes": 1013.0}
{"step": 13126288, "train_return": 18.0, "train_length": 1881.0, "train_total_steps": 3281572.0, "train_total_episodes": 1630.0, "train_loaded_steps": 1998977.0, "train_loaded_episodes": 1013.0}
{"step": 13133816, "kl_loss": 1.3733995775222778, "image_loss": 3772.0, "reward_loss": 0.9191761912345886, "discount_loss": 0.007759941812604666, "model_kl": 1.3733995458602906, "prior_ent": 26.95126226501465, "post_ent": 25.591556024169922, "model_loss": 3773.09534921875, "model_loss_scale": 11429.4784, "model_grad_norm": 5.442398959350586, "actor_loss": -0.003415030018730249, "actor_loss_scale": 183920.2304, "actor_grad_norm": 0.03545424875617027, "critic_loss": 0.9190808527946472, "critic_loss_scale": 156028.1088, "critic_grad_norm": Infinity, "reward_mean": 0.007094791027871542, "reward_std": 0.08151229118108749, "reward_normed_mean": 0.007094791027871542, "reward_normed_std": 0.08151229118108749, "critic_slow": 5.1123043838500974, "critic_target": 5.112799172210694, "actor_ent": 1.3349667776107788, "actor_ent_scale": 0.0010000000474974513, "critic": 5.112915168380737, "fps": 106.86797591689921}
{"step": 13133984, "train_return": 18.0, "train_length": 1924.0, "train_total_steps": 3283496.0, "train_total_episodes": 1631.0, "train_loaded_steps": 1999164.0, "train_loaded_episodes": 1013.0}
{"step": 13143304, "train_return": 14.0, "train_length": 2330.0, "train_total_steps": 3285826.0, "train_total_episodes": 1632.0, "train_loaded_steps": 1999384.0, "train_loaded_episodes": 1013.0}
{"step": 13150916, "train_return": 18.0, "train_length": 1903.0, "train_total_steps": 3287729.0, "train_total_episodes": 1633.0, "train_loaded_steps": 1998999.0, "train_loaded_episodes": 1013.0}
{"step": 13160172, "train_return": 14.0, "train_length": 2314.0, "train_total_steps": 3290043.0, "train_total_episodes": 1634.0, "train_loaded_steps": 1999441.0, "train_loaded_episodes": 1013.0}
{"step": 13167796, "train_return": 17.0, "train_length": 1906.0, "train_total_steps": 3291949.0, "train_total_episodes": 1635.0, "train_loaded_steps": 1999373.0, "train_loaded_episodes": 1013.0}
{"step": 13173816, "kl_loss": 1.4069491083145143, "image_loss": 3772.0, "reward_loss": 0.9191583839416504, "discount_loss": 0.00781078749448061, "model_kl": 1.4069490802764892, "prior_ent": 27.029552420043945, "post_ent": 25.640855880737305, "model_loss": 3773.098954296875, "model_loss_scale": 16384.0, "model_grad_norm": 5.17398794593811, "actor_loss": -0.0036829613574489487, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.039676645705103875, "critic_loss": 0.921741743183136, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.33403961394429205, "reward_mean": 0.007131857868027874, "reward_std": 0.08234431371092796, "reward_normed_mean": 0.007131857868027874, "reward_normed_std": 0.08234431371092796, "critic_slow": 5.057828440475464, "critic_target": 5.058602556228638, "actor_ent": 1.3112596397399903, "actor_ent_scale": 0.0010000000474974513, "critic": 5.058574390029907, "fps": 110.59218013889343}
{"step": 13175552, "train_return": 17.0, "train_length": 1939.0, "train_total_steps": 3293888.0, "train_total_episodes": 1636.0, "train_loaded_steps": 1999423.0, "train_loaded_episodes": 1013.0}
{"step": 13183528, "train_return": 15.0, "train_length": 1994.0, "train_total_steps": 3295882.0, "train_total_episodes": 1637.0, "train_loaded_steps": 1999354.0, "train_loaded_episodes": 1013.0}
{"step": 13191120, "train_return": 17.0, "train_length": 1898.0, "train_total_steps": 3297780.0, "train_total_episodes": 1638.0, "train_loaded_steps": 1998839.0, "train_loaded_episodes": 1013.0}
{"step": 13198264, "train_return": 19.0, "train_length": 1786.0, "train_total_steps": 3299566.0, "train_total_episodes": 1639.0, "train_loaded_steps": 1998330.0, "train_loaded_episodes": 1013.0}
{"step": 13205808, "train_return": 17.0, "train_length": 1886.0, "train_total_steps": 3301452.0, "train_total_episodes": 1640.0, "train_loaded_steps": 1998093.0, "train_loaded_episodes": 1013.0}
{"step": 13213544, "train_return": 17.0, "train_length": 1934.0, "train_total_steps": 3303386.0, "train_total_episodes": 1641.0, "train_loaded_steps": 1997910.0, "train_loaded_episodes": 1013.0}
{"step": 13213816, "kl_loss": 1.3697400793075563, "image_loss": 3772.0, "reward_loss": 0.919152795791626, "discount_loss": 0.0077679811634123325, "model_kl": 1.3697400466918945, "prior_ent": 27.00610094909668, "post_ent": 25.64456649169922, "model_loss": 3773.095007421875, "model_loss_scale": 16384.0, "model_grad_norm": 5.537993162536621, "actor_loss": -0.0017417427543652594, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.03620490330159664, "critic_loss": 0.9192837465286254, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2513927429616451, "reward_mean": 0.007015567244845443, "reward_std": 0.0818188767671585, "reward_normed_mean": 0.007015567244845443, "reward_normed_std": 0.0818188767671585, "critic_slow": 5.133015107727051, "critic_target": 5.1356593681335445, "actor_ent": 1.3479973596572876, "actor_ent_scale": 0.0010000000474974513, "critic": 5.135701971054077, "fps": 110.93015262809287}
{"step": 13221104, "train_return": 19.0, "train_length": 1890.0, "train_total_steps": 3305276.0, "train_total_episodes": 1642.0, "train_loaded_steps": 1999800.0, "train_loaded_episodes": 1014.0}
{"step": 13228600, "train_return": 19.0, "train_length": 1874.0, "train_total_steps": 3307150.0, "train_total_episodes": 1643.0, "train_loaded_steps": 1999562.0, "train_loaded_episodes": 1014.0}
{"step": 13236224, "train_return": 18.0, "train_length": 1906.0, "train_total_steps": 3309056.0, "train_total_episodes": 1644.0, "train_loaded_steps": 1998976.0, "train_loaded_episodes": 1014.0}
{"step": 13244788, "train_return": 15.0, "train_length": 2141.0, "train_total_steps": 3311197.0, "train_total_episodes": 1645.0, "train_loaded_steps": 1999244.0, "train_loaded_episodes": 1014.0}
{"step": 13252012, "train_return": 18.0, "train_length": 1806.0, "train_total_steps": 3313003.0, "train_total_episodes": 1646.0, "train_loaded_steps": 1998916.0, "train_loaded_episodes": 1014.0}
{"step": 13253816, "kl_loss": 1.3647293073654174, "image_loss": 3772.0, "reward_loss": 0.9191557662010192, "discount_loss": 0.007742820429801941, "model_kl": 1.3647292764663697, "prior_ent": 26.913866735839843, "post_ent": 25.558904467773438, "model_loss": 3773.0943625, "model_loss_scale": 17956.864, "model_grad_norm": Infinity, "actor_loss": -0.0011776922748424113, "actor_loss_scale": 315411.6608, "actor_grad_norm": 0.0341917019456625, "critic_loss": 0.918079157447815, "critic_loss_scale": 132749.7216, "critic_grad_norm": 0.251676728284359, "reward_mean": 0.007084185749955941, "reward_std": 0.08167108932733536, "reward_normed_mean": 0.007084185749955941, "reward_normed_std": 0.08167108932733536, "critic_slow": 5.140879828643799, "critic_target": 5.142597312164306, "actor_ent": 1.3201212259292603, "actor_ent_scale": 0.0010000000474974513, "critic": 5.142666289138794, "fps": 109.05989746884305}
{"step": 13259152, "train_return": 20.0, "train_length": 1785.0, "train_total_steps": 3314788.0, "train_total_episodes": 1647.0, "train_loaded_steps": 1998845.0, "train_loaded_episodes": 1014.0}
{"step": 13266732, "train_return": 18.0, "train_length": 1895.0, "train_total_steps": 3316683.0, "train_total_episodes": 1648.0, "train_loaded_steps": 1998772.0, "train_loaded_episodes": 1014.0}
{"step": 13273928, "train_return": 18.0, "train_length": 1799.0, "train_total_steps": 3318482.0, "train_total_episodes": 1649.0, "train_loaded_steps": 1998599.0, "train_loaded_episodes": 1014.0}
{"step": 13281144, "train_return": 20.0, "train_length": 1804.0, "train_total_steps": 3320286.0, "train_total_episodes": 1650.0, "train_loaded_steps": 1998111.0, "train_loaded_episodes": 1014.0}
{"step": 13290104, "train_return": 14.0, "train_length": 2240.0, "train_total_steps": 3322526.0, "train_total_episodes": 1651.0, "train_loaded_steps": 1998539.0, "train_loaded_episodes": 1014.0}
{"step": 13293816, "kl_loss": 1.3957231067657472, "image_loss": 3772.0001921875, "reward_loss": 0.9191466692924499, "discount_loss": 0.007742057364434004, "model_kl": 1.3957230754852294, "prior_ent": 26.80424737854004, "post_ent": 25.426027886962892, "model_loss": 3773.09765703125, "model_loss_scale": 16384.0, "model_grad_norm": 5.325851094436645, "actor_loss": -0.002949733040187857, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.036071425804495814, "critic_loss": 0.9194216163635254, "critic_loss_scale": 236139.3152, "critic_grad_norm": Infinity, "reward_mean": 0.007090159369143657, "reward_std": 0.08235593419671058, "reward_normed_mean": 0.007090159369143657, "reward_normed_std": 0.08235593419671058, "critic_slow": 5.110304559326172, "critic_target": 5.111316709136963, "actor_ent": 1.332836404800415, "actor_ent_scale": 0.0010000000474974513, "critic": 5.111599919509888, "fps": 108.28589376732543}
{"step": 13297964, "train_return": 17.0, "train_length": 1965.0, "train_total_steps": 3324491.0, "train_total_episodes": 1652.0, "train_loaded_steps": 1998488.0, "train_loaded_episodes": 1014.0}
{"step": 13306400, "train_return": 13.0, "train_length": 2109.0, "train_total_steps": 3326600.0, "train_total_episodes": 1653.0, "train_loaded_steps": 1998335.0, "train_loaded_episodes": 1014.0}
{"step": 13313880, "train_return": 18.0, "train_length": 1870.0, "train_total_steps": 3328470.0, "train_total_episodes": 1654.0, "train_loaded_steps": 1998280.0, "train_loaded_episodes": 1014.0}
{"step": 13321380, "train_return": 17.0, "train_length": 1875.0, "train_total_steps": 3330345.0, "train_total_episodes": 1655.0, "train_loaded_steps": 1998103.0, "train_loaded_episodes": 1014.0}
{"step": 13329168, "train_return": 16.0, "train_length": 1947.0, "train_total_steps": 3332292.0, "train_total_episodes": 1656.0, "train_loaded_steps": 1997853.0, "train_loaded_episodes": 1014.0}
{"step": 13333816, "kl_loss": 1.4116397636413573, "image_loss": 3772.0, "reward_loss": 0.9191706032752991, "discount_loss": 0.007749434020370245, "model_kl": 1.4116397287368774, "prior_ent": 26.85840901489258, "post_ent": 25.46738314819336, "model_loss": 3773.0991109375, "model_loss_scale": 16384.0, "model_grad_norm": 5.470484301185608, "actor_loss": -0.0028913943704857955, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.03748485768437385, "critic_loss": 0.9206200937271118, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3151971113026142, "reward_mean": 0.007181102731682404, "reward_std": 0.08204307206869126, "reward_normed_mean": 0.007181102731682404, "reward_normed_std": 0.08204307206869126, "critic_slow": 5.041934321975708, "critic_target": 5.043902621459961, "actor_ent": 1.3361251428604126, "actor_ent_scale": 0.0010000000474974513, "critic": 5.0439711196899415, "fps": 110.74824590193033}
{"step": 13336684, "train_return": 18.0, "train_length": 1879.0, "train_total_steps": 3334171.0, "train_total_episodes": 1657.0, "train_loaded_steps": 1999732.0, "train_loaded_episodes": 1015.0}
{"step": 13345320, "train_return": 14.0, "train_length": 2159.0, "train_total_steps": 3336330.0, "train_total_episodes": 1658.0, "train_loaded_steps": 1997836.0, "train_loaded_episodes": 1014.0}
{"step": 13352336, "train_return": 20.0, "train_length": 1754.0, "train_total_steps": 3338084.0, "train_total_episodes": 1659.0, "train_loaded_steps": 1999590.0, "train_loaded_episodes": 1015.0}
{"step": 13361904, "train_return": 11.0, "train_length": 2392.0, "train_total_steps": 3340476.0, "train_total_episodes": 1660.0, "train_loaded_steps": 2000000.0, "train_loaded_episodes": 1015.0}
{"step": 13368932, "train_return": 20.0, "train_length": 1757.0, "train_total_steps": 3342233.0, "train_total_episodes": 1661.0, "train_loaded_steps": 1999764.0, "train_loaded_episodes": 1015.0}
{"step": 13373816, "kl_loss": 1.3960155338287354, "image_loss": 3772.0, "reward_loss": 0.9191638214111328, "discount_loss": 0.007741364243626594, "model_kl": 1.396015502166748, "prior_ent": 27.254248217773437, "post_ent": 25.873067236328126, "model_loss": 3773.097512890625, "model_loss_scale": 16384.0, "model_grad_norm": 5.248529013061524, "actor_loss": -0.006999305632372853, "actor_loss_scale": 525965.7216, "actor_grad_norm": 0.03656122470200062, "critic_loss": 0.918877099609375, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2748297643125057, "reward_mean": 0.007333407839533174, "reward_std": 0.08221902084946632, "reward_normed_mean": 0.007333407839533174, "reward_normed_std": 0.08221902084946632, "critic_slow": 5.075255323028564, "critic_target": 5.074031229782104, "actor_ent": 1.3148657093048095, "actor_ent_scale": 0.0010000000474974513, "critic": 5.074167975616455, "fps": 109.88256125477021}
{"step": 13377288, "train_return": 18.0, "train_length": 2089.0, "train_total_steps": 3344322.0, "train_total_episodes": 1662.0, "train_loaded_steps": 1999609.0, "train_loaded_episodes": 1015.0}
{"step": 13383960, "train_return": 20.0, "train_length": 1668.0, "train_total_steps": 3345990.0, "train_total_episodes": 1663.0, "train_loaded_steps": 1999319.0, "train_loaded_episodes": 1015.0}
{"step": 13390884, "train_return": 20.0, "train_length": 1731.0, "train_total_steps": 3347721.0, "train_total_episodes": 1664.0, "train_loaded_steps": 1998973.0, "train_loaded_episodes": 1015.0}
{"step": 13398164, "train_return": 18.0, "train_length": 1820.0, "train_total_steps": 3349541.0, "train_total_episodes": 1665.0, "train_loaded_steps": 1998710.0, "train_loaded_episodes": 1015.0}
{"step": 13406476, "train_return": 16.0, "train_length": 2078.0, "train_total_steps": 3351619.0, "train_total_episodes": 1666.0, "train_loaded_steps": 1998393.0, "train_loaded_episodes": 1015.0}
{"step": 13413628, "train_return": 19.0, "train_length": 1788.0, "train_total_steps": 3353407.0, "train_total_episodes": 1667.0, "train_loaded_steps": 1997856.0, "train_loaded_episodes": 1015.0}
{"step": 13413816, "kl_loss": 1.37019692363739, "image_loss": 3772.0, "reward_loss": 0.9191729815483093, "discount_loss": 0.007742739205807448, "model_kl": 1.3701968936920166, "prior_ent": 27.055717434692383, "post_ent": 25.69512706604004, "model_loss": 3773.09493203125, "model_loss_scale": 16724.7872, "model_grad_norm": Infinity, "actor_loss": -0.005546471235669742, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.0331214443385601, "critic_loss": 0.9170633856773377, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2347334266245365, "reward_mean": 0.007173455629590899, "reward_std": 0.08215370668172836, "reward_normed_mean": 0.007173455629590899, "reward_normed_std": 0.08215370668172836, "critic_slow": 5.000379606628418, "critic_target": 5.000435858535766, "actor_ent": 1.3524701267242432, "actor_ent_scale": 0.0010000000474974513, "critic": 5.000520658874512, "fps": 111.52917226918709}
{"step": 13422172, "train_return": 17.0, "train_length": 2136.0, "train_total_steps": 3355543.0, "train_total_episodes": 1668.0, "train_loaded_steps": 1999992.0, "train_loaded_episodes": 1016.0}
{"step": 13430680, "train_return": 15.0, "train_length": 2127.0, "train_total_steps": 3357670.0, "train_total_episodes": 1669.0, "train_loaded_steps": 1999941.0, "train_loaded_episodes": 1016.0}
{"step": 13437624, "train_return": 21.0, "train_length": 1736.0, "train_total_steps": 3359406.0, "train_total_episodes": 1670.0, "train_loaded_steps": 1999567.0, "train_loaded_episodes": 1016.0}
{"step": 13445084, "train_return": 18.0, "train_length": 1865.0, "train_total_steps": 3361271.0, "train_total_episodes": 1671.0, "train_loaded_steps": 1999105.0, "train_loaded_episodes": 1016.0}
{"step": 13452008, "train_return": 20.0, "train_length": 1731.0, "train_total_steps": 3363002.0, "train_total_episodes": 1672.0, "train_loaded_steps": 1998541.0, "train_loaded_episodes": 1016.0}
{"step": 13453816, "kl_loss": 1.3544597007751464, "image_loss": 3772.0, "reward_loss": 0.9191494782447815, "discount_loss": 0.007749488241225481, "model_kl": 1.3544596700668334, "prior_ent": 26.986774728393556, "post_ent": 25.64221455078125, "model_loss": 3773.093377734375, "model_loss_scale": 16384.0, "model_grad_norm": 5.281984317779541, "actor_loss": -0.005400030178157613, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.03296579794585705, "critic_loss": 0.9179202869415283, "critic_loss_scale": 261934.2848, "critic_grad_norm": 0.24595230500102044, "reward_mean": 0.007227321717329324, "reward_std": 0.08204857146143914, "reward_normed_mean": 0.007227321717329324, "reward_normed_std": 0.08204857146143914, "critic_slow": 5.056626657104492, "critic_target": 5.05807772064209, "actor_ent": 1.3758921075820922, "actor_ent_scale": 0.0010000000474974513, "critic": 5.058028443527221, "fps": 110.72467601875002}
{"step": 13460184, "train_return": 18.0, "train_length": 2044.0, "train_total_steps": 3365046.0, "train_total_episodes": 1673.0, "train_loaded_steps": 1998173.0, "train_loaded_episodes": 1016.0}
{"step": 13468368, "train_return": 16.0, "train_length": 2046.0, "train_total_steps": 3367092.0, "train_total_episodes": 1674.0, "train_loaded_steps": 1998151.0, "train_loaded_episodes": 1016.0}
{"step": 13476764, "train_return": 16.0, "train_length": 2099.0, "train_total_steps": 3369191.0, "train_total_episodes": 1675.0, "train_loaded_steps": 1998000.0, "train_loaded_episodes": 1016.0}
{"step": 13484252, "train_return": 19.0, "train_length": 1872.0, "train_total_steps": 3371063.0, "train_total_episodes": 1676.0, "train_loaded_steps": 1999872.0, "train_loaded_episodes": 1017.0}
{"step": 13490896, "train_return": 21.0, "train_length": 1661.0, "train_total_steps": 3372724.0, "train_total_episodes": 1677.0, "train_loaded_steps": 1999540.0, "train_loaded_episodes": 1017.0}
{"step": 13493816, "kl_loss": 1.3528438478469849, "image_loss": 3772.0, "reward_loss": 0.9191714560508728, "discount_loss": 0.007750764732062817, "model_kl": 1.3528438156127929, "prior_ent": 26.865952798461915, "post_ent": 25.521160626220702, "model_loss": 3773.09323125, "model_loss_scale": 16384.0, "model_grad_norm": 5.579433617210388, "actor_loss": -0.008576877856755163, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.03482352994978428, "critic_loss": 0.9192267848014831, "critic_loss_scale": 93323.264, "critic_grad_norm": Infinity, "reward_mean": 0.00719740352826193, "reward_std": 0.08205997955799103, "reward_normed_mean": 0.00719740352826193, "reward_normed_std": 0.08205997955799103, "critic_slow": 5.143172310256958, "critic_target": 5.141880264282227, "actor_ent": 1.4027677604675293, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1421412742614745, "fps": 108.50058099059282}
{"step": 13499016, "train_return": 16.0, "train_length": 2030.0, "train_total_steps": 3374754.0, "train_total_episodes": 1678.0, "train_loaded_steps": 1999605.0, "train_loaded_episodes": 1017.0}
{"step": 13506000, "train_return": 19.0, "train_length": 1746.0, "train_total_steps": 3376500.0, "train_total_episodes": 1679.0, "train_loaded_steps": 1998927.0, "train_loaded_episodes": 1017.0}
{"step": 13512948, "train_return": 20.0, "train_length": 1737.0, "train_total_steps": 3378237.0, "train_total_episodes": 1680.0, "train_loaded_steps": 1998606.0, "train_loaded_episodes": 1017.0}
{"step": 13520092, "train_return": 19.0, "train_length": 1786.0, "train_total_steps": 3380023.0, "train_total_episodes": 1681.0, "train_loaded_steps": 1998139.0, "train_loaded_episodes": 1017.0}
{"step": 13526908, "train_return": 20.0, "train_length": 1704.0, "train_total_steps": 3381727.0, "train_total_episodes": 1682.0, "train_loaded_steps": 1999843.0, "train_loaded_episodes": 1018.0}
{"step": 13533816, "kl_loss": 1.427024401664734, "image_loss": 3772.0002, "reward_loss": 0.9191513672828674, "discount_loss": 0.007741909286379814, "model_kl": 1.4270243696212768, "prior_ent": 26.91849957885742, "post_ent": 25.52045679321289, "model_loss": 3773.1007859375, "model_loss_scale": 16410.2144, "model_grad_norm": Infinity, "actor_loss": -0.008135164222004823, "actor_loss_scale": 1890792.2432, "actor_grad_norm": 0.03807769151926041, "critic_loss": 0.9222924136161804, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.32179818389415743, "reward_mean": 0.007136818636057433, "reward_std": 0.08158091864585877, "reward_normed_mean": 0.007136818636057433, "reward_normed_std": 0.08158091864585877, "critic_slow": 5.149337107086182, "critic_target": 5.148473125839233, "actor_ent": 1.360878872680664, "actor_ent_scale": 0.0010000000474974513, "critic": 5.14850590057373, "fps": 107.40230056286852}
{"step": 13535088, "train_return": 17.0, "train_length": 2045.0, "train_total_steps": 3383772.0, "train_total_episodes": 1683.0, "train_loaded_steps": 1999669.0, "train_loaded_episodes": 1018.0}
{"step": 13542380, "train_return": 19.0, "train_length": 1823.0, "train_total_steps": 3385595.0, "train_total_episodes": 1684.0, "train_loaded_steps": 1999267.0, "train_loaded_episodes": 1018.0}
{"step": 13549588, "train_return": 19.0, "train_length": 1802.0, "train_total_steps": 3387397.0, "train_total_episodes": 1685.0, "train_loaded_steps": 1999153.0, "train_loaded_episodes": 1018.0}
{"step": 13556988, "train_return": 19.0, "train_length": 1850.0, "train_total_steps": 3389247.0, "train_total_episodes": 1686.0, "train_loaded_steps": 1999096.0, "train_loaded_episodes": 1018.0}
{"step": 13564344, "train_return": 19.0, "train_length": 1839.0, "train_total_steps": 3391086.0, "train_total_episodes": 1687.0, "train_loaded_steps": 1999138.0, "train_loaded_episodes": 1018.0}
{"step": 13572184, "train_return": 17.0, "train_length": 1960.0, "train_total_steps": 3393046.0, "train_total_episodes": 1688.0, "train_loaded_steps": 1999014.0, "train_loaded_episodes": 1018.0}
{"step": 13573816, "kl_loss": 1.3798485288619995, "image_loss": 3772.0, "reward_loss": 0.9191399648666382, "discount_loss": 0.007755876294523478, "model_kl": 1.3798484983444215, "prior_ent": 27.003431326293946, "post_ent": 25.635776275634765, "model_loss": 3773.095931640625, "model_loss_scale": 16384.0, "model_grad_norm": 5.256382719612121, "actor_loss": -0.006340817887545563, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.03349174778461456, "critic_loss": 0.9193722098350525, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.2808650123655796, "reward_mean": 0.007264991372451186, "reward_std": 0.08185980168581009, "reward_normed_mean": 0.007264991372451186, "reward_normed_std": 0.08185980168581009, "critic_slow": 5.1883651103973385, "critic_target": 5.18713373298645, "actor_ent": 1.3704950105667115, "actor_ent_scale": 0.0010000000474974513, "critic": 5.187097991943359, "fps": 107.68015143260676}
{"step": 13580728, "train_return": 13.0, "train_length": 2136.0, "train_total_steps": 3395182.0, "train_total_episodes": 1689.0, "train_loaded_steps": 1999024.0, "train_loaded_episodes": 1018.0}
{"step": 13588936, "train_return": 15.0, "train_length": 2052.0, "train_total_steps": 3397234.0, "train_total_episodes": 1690.0, "train_loaded_steps": 1999098.0, "train_loaded_episodes": 1018.0}
{"step": 13596660, "train_return": 18.0, "train_length": 1931.0, "train_total_steps": 3399165.0, "train_total_episodes": 1691.0, "train_loaded_steps": 1999075.0, "train_loaded_episodes": 1018.0}
{"step": 13605944, "train_return": 11.0, "train_length": 2321.0, "train_total_steps": 3401486.0, "train_total_episodes": 1692.0, "train_loaded_steps": 1999276.0, "train_loaded_episodes": 1018.0}
{"step": 13613640, "train_return": 17.0, "train_length": 1924.0, "train_total_steps": 3403410.0, "train_total_episodes": 1693.0, "train_loaded_steps": 1999380.0, "train_loaded_episodes": 1018.0}
{"step": 13613816, "kl_loss": 1.3421711458206176, "image_loss": 3772.0, "reward_loss": 0.9191593991279602, "discount_loss": 0.00774783097282052, "model_kl": 1.3421711114883423, "prior_ent": 26.974276211547853, "post_ent": 25.6385600189209, "model_loss": 3773.092146484375, "model_loss_scale": 16384.0, "model_grad_norm": 5.199680774879456, "actor_loss": -0.0036712262330089286, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.03450245758891106, "critic_loss": 0.9193272872924805, "critic_loss_scale": 108632.4736, "critic_grad_norm": 0.26473495621681215, "reward_mean": 0.00733892784813047, "reward_std": 0.08210838988423347, "reward_normed_mean": 0.00733892784813047, "reward_normed_std": 0.08210838988423347, "critic_slow": 5.180441123962402, "critic_target": 5.17933260269165, "actor_ent": 1.3332641304016113, "actor_ent_scale": 0.0010000000474974513, "critic": 5.179421508407593, "fps": 107.32330977742714}
{"step": 13620940, "train_return": 18.0, "train_length": 1825.0, "train_total_steps": 3405235.0, "train_total_episodes": 1694.0, "train_loaded_steps": 1998543.0, "train_loaded_episodes": 1018.0}
{"step": 13628916, "train_return": 15.0, "train_length": 1994.0, "train_total_steps": 3407229.0, "train_total_episodes": 1695.0, "train_loaded_steps": 1998042.0, "train_loaded_episodes": 1018.0}
{"step": 13635968, "train_return": 20.0, "train_length": 1763.0, "train_total_steps": 3408992.0, "train_total_episodes": 1696.0, "train_loaded_steps": 1999805.0, "train_loaded_episodes": 1019.0}
{"step": 13643584, "train_return": 18.0, "train_length": 1904.0, "train_total_steps": 3410896.0, "train_total_episodes": 1697.0, "train_loaded_steps": 1999398.0, "train_loaded_episodes": 1019.0}
{"step": 13650624, "train_return": 20.0, "train_length": 1760.0, "train_total_steps": 3412656.0, "train_total_episodes": 1698.0, "train_loaded_steps": 1998971.0, "train_loaded_episodes": 1019.0}
{"step": 13653816, "kl_loss": 1.3529478826522827, "image_loss": 3772.0, "reward_loss": 0.9191506559371948, "discount_loss": 0.0077430556401610375, "model_kl": 1.3529478506088257, "prior_ent": 26.870989028930666, "post_ent": 25.52677153015137, "model_loss": 3773.093194921875, "model_loss_scale": 11324.6208, "model_grad_norm": Infinity, "actor_loss": -0.0018190356995102775, "actor_loss_scale": 3362154.0864, "actor_grad_norm": 0.03300687952786684, "critic_loss": 0.9184122019767761, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2483419382572174, "reward_mean": 0.0073692108345145245, "reward_std": 0.0822486472427845, "reward_normed_mean": 0.0073692108345145245, "reward_normed_std": 0.0822486472427845, "critic_slow": 5.199603297805786, "critic_target": 5.199973247146606, "actor_ent": 1.3453222061157226, "actor_ent_scale": 0.0010000000474974513, "critic": 5.200076526641846, "fps": 105.42708528892942}
{"step": 13658232, "train_return": 18.0, "train_length": 1902.0, "train_total_steps": 3414558.0, "train_total_episodes": 1699.0, "train_loaded_steps": 1998723.0, "train_loaded_episodes": 1019.0}
{"step": 13665376, "train_return": 19.0, "train_length": 1786.0, "train_total_steps": 3416344.0, "train_total_episodes": 1700.0, "train_loaded_steps": 1998034.0, "train_loaded_episodes": 1019.0}
{"step": 13673196, "train_return": 19.0, "train_length": 1955.0, "train_total_steps": 3418299.0, "train_total_episodes": 1701.0, "train_loaded_steps": 1999989.0, "train_loaded_episodes": 1020.0}
{"step": 13679844, "train_return": 21.0, "train_length": 1662.0, "train_total_steps": 3419961.0, "train_total_episodes": 1702.0, "train_loaded_steps": 1999479.0, "train_loaded_episodes": 1020.0}
{"step": 13687648, "train_return": 16.0, "train_length": 1951.0, "train_total_steps": 3421912.0, "train_total_episodes": 1703.0, "train_loaded_steps": 1999588.0, "train_loaded_episodes": 1020.0}
{"step": 13693816, "kl_loss": 1.3583604858398437, "image_loss": 3772.0, "reward_loss": 0.9191438834190369, "discount_loss": 0.007741551911830902, "model_kl": 1.3583604528427125, "prior_ent": 26.824935635375976, "post_ent": 25.477612933349608, "model_loss": 3773.09372890625, "model_loss_scale": 8192.0, "model_grad_norm": 5.2180600803375246, "actor_loss": -0.003214725798548898, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.03502173462808132, "critic_loss": 0.9195935195922852, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2885650271177292, "reward_mean": 0.007265447724446858, "reward_std": 0.0820190228164196, "reward_normed_mean": 0.007265447724446858, "reward_normed_std": 0.0820190228164196, "critic_slow": 5.157208483505249, "critic_target": 5.156741342163086, "actor_ent": 1.3507622873306275, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1568090530395505, "fps": 105.83366780240242}
{"step": 13695096, "train_return": 17.0, "train_length": 1862.0, "train_total_steps": 3423774.0, "train_total_episodes": 1704.0, "train_loaded_steps": 1999431.0, "train_loaded_episodes": 1020.0}
{"step": 13703028, "train_return": 18.0, "train_length": 1983.0, "train_total_steps": 3425757.0, "train_total_episodes": 1705.0, "train_loaded_steps": 1999434.0, "train_loaded_episodes": 1020.0}
{"step": 13710556, "train_return": 19.0, "train_length": 1882.0, "train_total_steps": 3427639.0, "train_total_episodes": 1706.0, "train_loaded_steps": 1999327.0, "train_loaded_episodes": 1020.0}
{"step": 13717740, "train_return": 20.0, "train_length": 1796.0, "train_total_steps": 3429435.0, "train_total_episodes": 1707.0, "train_loaded_steps": 1999213.0, "train_loaded_episodes": 1020.0}
{"step": 13724980, "train_return": 19.0, "train_length": 1810.0, "train_total_steps": 3431245.0, "train_total_episodes": 1708.0, "train_loaded_steps": 1998983.0, "train_loaded_episodes": 1020.0}
{"step": 13732784, "train_return": 17.0, "train_length": 1951.0, "train_total_steps": 3433196.0, "train_total_episodes": 1709.0, "train_loaded_steps": 1998485.0, "train_loaded_episodes": 1020.0}
{"step": 13733812, "eval_return": 18.0, "eval_length": 1904.0, "eval_total_steps": 33576.0, "eval_total_episodes": 17.0, "eval_loaded_steps": 33592.0, "eval_loaded_episodes": 17.0}
{"step": 13733816, "kl_loss": 1.3551410829544068, "image_loss": 3772.0, "reward_loss": 0.9191214039802551, "discount_loss": 0.00774184907451272, "model_kl": 1.3551410511016846, "prior_ent": 26.916538912963865, "post_ent": 25.572429794311525, "model_loss": 3773.09338046875, "model_loss_scale": 8192.0, "model_grad_norm": 5.288464696502685, "actor_loss": -0.0054163197005982515, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.035323489066958424, "critic_loss": 0.9188520773887634, "critic_loss_scale": 189163.1104, "critic_grad_norm": Infinity, "reward_mean": 0.007290656644618139, "reward_std": 0.08183708282709122, "reward_normed_mean": 0.007290656644618139, "reward_normed_std": 0.08183708282709122, "critic_slow": 5.212724080276489, "critic_target": 5.21094253578186, "actor_ent": 1.3476706760406494, "actor_ent_scale": 0.0010000000474974513, "critic": 5.2109533843994145, "fps": 100.96256501498219}
{"step": 13740792, "train_return": 17.0, "train_length": 2002.0, "train_total_steps": 3435198.0, "train_total_episodes": 1710.0, "train_loaded_steps": 1998664.0, "train_loaded_episodes": 1020.0}
{"step": 13748924, "train_return": 17.0, "train_length": 2033.0, "train_total_steps": 3437231.0, "train_total_episodes": 1711.0, "train_loaded_steps": 1998594.0, "train_loaded_episodes": 1020.0}
{"step": 13755564, "train_return": 21.0, "train_length": 1660.0, "train_total_steps": 3438891.0, "train_total_episodes": 1712.0, "train_loaded_steps": 1998465.0, "train_loaded_episodes": 1020.0}
{"step": 13764088, "train_return": 14.0, "train_length": 2131.0, "train_total_steps": 3441022.0, "train_total_episodes": 1713.0, "train_loaded_steps": 1998813.0, "train_loaded_episodes": 1020.0}
{"step": 13771508, "train_return": 19.0, "train_length": 1855.0, "train_total_steps": 3442877.0, "train_total_episodes": 1714.0, "train_loaded_steps": 1998598.0, "train_loaded_episodes": 1020.0}
{"step": 13773816, "kl_loss": 1.3679816562652587, "image_loss": 3772.0, "reward_loss": 0.9191654929161072, "discount_loss": 0.007801512794196606, "model_kl": 1.3679816228866577, "prior_ent": 27.078729336547852, "post_ent": 25.723613507080078, "model_loss": 3773.095000390625, "model_loss_scale": 11612.9792, "model_grad_norm": 5.307404458999634, "actor_loss": -0.002861333679725067, "actor_loss_scale": 5885447.3728, "actor_grad_norm": 0.03607094710767269, "critic_loss": 0.9201762762069702, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.31967788628339766, "reward_mean": 0.007304112918674946, "reward_std": 0.0825175953745842, "reward_normed_mean": 0.007304112918674946, "reward_normed_std": 0.0825175953745842, "critic_slow": 5.182504940032959, "critic_target": 5.1827431224823, "actor_ent": 1.3485286287307738, "actor_ent_scale": 0.0010000000474974513, "critic": 5.182877952575684, "fps": 103.82163315876035}
{"step": 13779216, "train_return": 17.0, "train_length": 1927.0, "train_total_steps": 3444804.0, "train_total_episodes": 1715.0, "train_loaded_steps": 1998531.0, "train_loaded_episodes": 1020.0}
{"step": 13786456, "train_return": 19.0, "train_length": 1810.0, "train_total_steps": 3446614.0, "train_total_episodes": 1716.0, "train_loaded_steps": 1998276.0, "train_loaded_episodes": 1020.0}
{"step": 13793764, "train_return": 18.0, "train_length": 1827.0, "train_total_steps": 3448441.0, "train_total_episodes": 1717.0, "train_loaded_steps": 1998159.0, "train_loaded_episodes": 1020.0}
{"step": 13800936, "train_return": 19.0, "train_length": 1793.0, "train_total_steps": 3450234.0, "train_total_episodes": 1718.0, "train_loaded_steps": 1999952.0, "train_loaded_episodes": 1021.0}
{"step": 13808960, "train_return": 18.0, "train_length": 2006.0, "train_total_steps": 3452240.0, "train_total_episodes": 1719.0, "train_loaded_steps": 1999840.0, "train_loaded_episodes": 1021.0}
{"step": 13813816, "kl_loss": 1.339207082748413, "image_loss": 3772.0, "reward_loss": 0.919163638305664, "discount_loss": 0.00774125179797411, "model_kl": 1.3392070508956908, "prior_ent": 26.92216340637207, "post_ent": 25.594505764770506, "model_loss": 3773.091816796875, "model_loss_scale": 16384.0, "model_grad_norm": 5.228484549331665, "actor_loss": -0.0035485133874666643, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03304161025583744, "critic_loss": 0.9177427910804749, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.24296448100805282, "reward_mean": 0.007168640172318556, "reward_std": 0.08160117847919464, "reward_normed_mean": 0.007168640172318556, "reward_normed_std": 0.08160117847919464, "critic_slow": 5.14329673576355, "critic_target": 5.1428228355407715, "actor_ent": 1.3846063371658326, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1427144458770755, "fps": 105.51376033382486}
{"step": 13816184, "train_return": 19.0, "train_length": 1806.0, "train_total_steps": 3454046.0, "train_total_episodes": 1720.0, "train_loaded_steps": 1999648.0, "train_loaded_episodes": 1021.0}
{"step": 13823264, "train_return": 20.0, "train_length": 1770.0, "train_total_steps": 3455816.0, "train_total_episodes": 1721.0, "train_loaded_steps": 1999519.0, "train_loaded_episodes": 1021.0}
{"step": 13830408, "train_return": 19.0, "train_length": 1786.0, "train_total_steps": 3457602.0, "train_total_episodes": 1722.0, "train_loaded_steps": 1999323.0, "train_loaded_episodes": 1021.0}
{"step": 13837688, "train_return": 19.0, "train_length": 1820.0, "train_total_steps": 3459422.0, "train_total_episodes": 1723.0, "train_loaded_steps": 1998888.0, "train_loaded_episodes": 1021.0}
{"step": 13845548, "train_return": 17.0, "train_length": 1965.0, "train_total_steps": 3461387.0, "train_total_episodes": 1724.0, "train_loaded_steps": 1998843.0, "train_loaded_episodes": 1021.0}
{"step": 13852712, "train_return": 18.0, "train_length": 1791.0, "train_total_steps": 3463178.0, "train_total_episodes": 1725.0, "train_loaded_steps": 1998597.0, "train_loaded_episodes": 1021.0}
{"step": 13853816, "kl_loss": 1.4118293523788452, "image_loss": 3772.0, "reward_loss": 0.9191236225128174, "discount_loss": 0.007748594078421593, "model_kl": 1.4118293176651, "prior_ent": 27.03029975280762, "post_ent": 25.643195965576172, "model_loss": 3773.099083203125, "model_loss_scale": 14444.1344, "model_grad_norm": Infinity, "actor_loss": -0.004839173609824502, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03703657696396113, "critic_loss": 0.9223178299903869, "critic_loss_scale": 121425.1008, "critic_grad_norm": Infinity, "reward_mean": 0.007136802303721197, "reward_std": 0.0812130165874958, "reward_normed_mean": 0.007136802303721197, "reward_normed_std": 0.0812130165874958, "critic_slow": 5.184071486663818, "critic_target": 5.182188805389404, "actor_ent": 1.3883117967605592, "actor_ent_scale": 0.0010000000474974513, "critic": 5.182265841674805, "fps": 105.31551217605245}
{"step": 13861296, "train_return": 16.0, "train_length": 2146.0, "train_total_steps": 3465324.0, "train_total_episodes": 1726.0, "train_loaded_steps": 1998808.0, "train_loaded_episodes": 1021.0}
{"step": 13869040, "train_return": 17.0, "train_length": 1936.0, "train_total_steps": 3467260.0, "train_total_episodes": 1727.0, "train_loaded_steps": 1998692.0, "train_loaded_episodes": 1021.0}
{"step": 13876208, "train_return": 20.0, "train_length": 1792.0, "train_total_steps": 3469052.0, "train_total_episodes": 1728.0, "train_loaded_steps": 1998373.0, "train_loaded_episodes": 1021.0}
{"step": 13884048, "train_return": 17.0, "train_length": 1960.0, "train_total_steps": 3471012.0, "train_total_episodes": 1729.0, "train_loaded_steps": 1998489.0, "train_loaded_episodes": 1021.0}
{"step": 13891520, "train_return": 18.0, "train_length": 1868.0, "train_total_steps": 3472880.0, "train_total_episodes": 1730.0, "train_loaded_steps": 1998438.0, "train_loaded_episodes": 1021.0}
{"step": 13893816, "kl_loss": 1.3627988035202026, "image_loss": 3772.0, "reward_loss": 0.9191367182731628, "discount_loss": 0.0077608413413167, "model_kl": 1.3627987743377685, "prior_ent": 27.105235443115234, "post_ent": 25.748767770385744, "model_loss": 3773.09424453125, "model_loss_scale": 1024.0, "model_grad_norm": 1.8308260725975036, "actor_loss": -0.002354087249166332, "actor_loss_scale": 10093173.1456, "actor_grad_norm": 0.03794162404537201, "critic_loss": 0.9213530070304871, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.2619927274942398, "reward_mean": 0.007308537976839579, "reward_std": 0.0821315052986145, "reward_normed_mean": 0.007308537976839579, "reward_normed_std": 0.0821315052986145, "critic_slow": 5.158334576797485, "critic_target": 5.1577598693847655, "actor_ent": 1.3199177391052246, "actor_ent_scale": 0.0010000000474974513, "critic": 5.157880473327637, "fps": 105.61183311085638}
{"step": 13898996, "train_return": 18.0, "train_length": 1869.0, "train_total_steps": 3474749.0, "train_total_episodes": 1731.0, "train_loaded_steps": 1998538.0, "train_loaded_episodes": 1021.0}
{"step": 13905864, "train_return": 20.0, "train_length": 1717.0, "train_total_steps": 3476466.0, "train_total_episodes": 1732.0, "train_loaded_steps": 1998287.0, "train_loaded_episodes": 1021.0}
{"step": 13913612, "train_return": 17.0, "train_length": 1937.0, "train_total_steps": 3478403.0, "train_total_episodes": 1733.0, "train_loaded_steps": 1998176.0, "train_loaded_episodes": 1021.0}
{"step": 13921832, "train_return": 18.0, "train_length": 2055.0, "train_total_steps": 3480458.0, "train_total_episodes": 1734.0, "train_loaded_steps": 1998044.0, "train_loaded_episodes": 1021.0}
{"step": 13929800, "train_return": 17.0, "train_length": 1992.0, "train_total_steps": 3482450.0, "train_total_episodes": 1735.0, "train_loaded_steps": 1998139.0, "train_loaded_episodes": 1021.0}
{"step": 13933816, "kl_loss": 1.3808556003570556, "image_loss": 3772.0, "reward_loss": 0.9191590919494629, "discount_loss": 0.007756891316175461, "model_kl": 1.380855570411682, "prior_ent": 26.878217272949218, "post_ent": 25.515516116333007, "model_loss": 3773.096062890625, "model_loss_scale": 1024.0, "model_grad_norm": 3.235932230949402, "actor_loss": -0.004272695146186743, "actor_loss_scale": 14495514.624, "actor_grad_norm": Infinity, "critic_loss": 0.918695508480072, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.25636397554278373, "reward_mean": 0.0073538058603182434, "reward_std": 0.08185722141265869, "reward_normed_mean": 0.0073538058603182434, "reward_normed_std": 0.08185722141265869, "critic_slow": 5.184051895141602, "critic_target": 5.182971698760986, "actor_ent": 1.341294330215454, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1830266586303715, "fps": 108.78324124585578}
{"step": 13937240, "train_return": 18.0, "train_length": 1860.0, "train_total_steps": 3484310.0, "train_total_episodes": 1736.0, "train_loaded_steps": 1999999.0, "train_loaded_episodes": 1022.0}
{"step": 13944776, "train_return": 19.0, "train_length": 1884.0, "train_total_steps": 3486194.0, "train_total_episodes": 1737.0, "train_loaded_steps": 1999885.0, "train_loaded_episodes": 1022.0}
{"step": 13953400, "train_return": 15.0, "train_length": 2156.0, "train_total_steps": 3488350.0, "train_total_episodes": 1738.0, "train_loaded_steps": 1998036.0, "train_loaded_episodes": 1021.0}
{"step": 13962408, "train_return": 15.0, "train_length": 2252.0, "train_total_steps": 3490602.0, "train_total_episodes": 1739.0, "train_loaded_steps": 1998336.0, "train_loaded_episodes": 1021.0}
{"step": 13969664, "train_return": 19.0, "train_length": 1814.0, "train_total_steps": 3492416.0, "train_total_episodes": 1740.0, "train_loaded_steps": 1998229.0, "train_loaded_episodes": 1021.0}
{"step": 13973816, "kl_loss": 1.3636421709060669, "image_loss": 3772.0, "reward_loss": 0.9191617137908935, "discount_loss": 0.0077722100228071215, "model_kl": 1.363642138671875, "prior_ent": 26.81750458984375, "post_ent": 25.463468728637697, "model_loss": 3773.094416796875, "model_loss_scale": 1024.0, "model_grad_norm": 4.017925354385376, "actor_loss": -0.0019443881708953996, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.033972653964161874, "critic_loss": 0.9179167924880981, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.25452273252606394, "reward_mean": 0.007331120928446762, "reward_std": 0.08152613817453384, "reward_normed_mean": 0.007331120928446762, "reward_normed_std": 0.08152613817453384, "critic_slow": 5.186288270568848, "critic_target": 5.18515955696106, "actor_ent": 1.3184582376480103, "actor_ent_scale": 0.0010000000474974513, "critic": 5.185265390777588, "fps": 105.55122459486392}
{"step": 13977160, "train_return": 18.0, "train_length": 1874.0, "train_total_steps": 3494290.0, "train_total_episodes": 1741.0, "train_loaded_steps": 1998263.0, "train_loaded_episodes": 1021.0}
{"step": 13984400, "train_return": 19.0, "train_length": 1810.0, "train_total_steps": 3496100.0, "train_total_episodes": 1742.0, "train_loaded_steps": 1998204.0, "train_loaded_episodes": 1021.0}
{"step": 13991832, "train_return": 19.0, "train_length": 1858.0, "train_total_steps": 3497958.0, "train_total_episodes": 1743.0, "train_loaded_steps": 1998156.0, "train_loaded_episodes": 1021.0}
{"step": 13999840, "train_return": 17.0, "train_length": 2002.0, "train_total_steps": 3499960.0, "train_total_episodes": 1744.0, "train_loaded_steps": 1997865.0, "train_loaded_episodes": 1021.0}
{"step": 14007552, "train_return": 19.0, "train_length": 1928.0, "train_total_steps": 3501888.0, "train_total_episodes": 1745.0, "train_loaded_steps": 1999793.0, "train_loaded_episodes": 1022.0}
{"step": 14013816, "kl_loss": 1.4169764017105102, "image_loss": 3772.0, "reward_loss": 0.9191289164543152, "discount_loss": 0.007743460267037153, "model_kl": 1.416976371574402, "prior_ent": 26.860043948364257, "post_ent": 25.466981341552735, "model_loss": 3773.09956953125, "model_loss_scale": 1961.1648, "model_grad_norm": 4.667529884147644, "actor_loss": -0.0075421981191961095, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03306538328528404, "critic_loss": 0.917502173423767, "critic_loss_scale": 127611.6992, "critic_grad_norm": 0.2501445035457611, "reward_mean": 0.007364183469954878, "reward_std": 0.08197383305430413, "reward_normed_mean": 0.007364183469954878, "reward_normed_std": 0.08197383305430413, "critic_slow": 5.162349515151978, "critic_target": 5.160790537643432, "actor_ent": 1.370720397567749, "actor_ent_scale": 0.0010000000474974513, "critic": 5.160799030303955, "fps": 106.98254453521986}
{"step": 14015252, "train_return": 18.0, "train_length": 1925.0, "train_total_steps": 3503813.0, "train_total_episodes": 1746.0, "train_loaded_steps": 1999655.0, "train_loaded_episodes": 1022.0}
{"step": 14022184, "train_return": 20.0, "train_length": 1733.0, "train_total_steps": 3505546.0, "train_total_episodes": 1747.0, "train_loaded_steps": 1999363.0, "train_loaded_episodes": 1022.0}
{"step": 14030268, "train_return": 17.0, "train_length": 2021.0, "train_total_steps": 3507567.0, "train_total_episodes": 1748.0, "train_loaded_steps": 1999202.0, "train_loaded_episodes": 1022.0}
{"step": 14038192, "train_return": 15.0, "train_length": 1981.0, "train_total_steps": 3509548.0, "train_total_episodes": 1749.0, "train_loaded_steps": 1998917.0, "train_loaded_episodes": 1022.0}
{"step": 14045480, "train_return": 19.0, "train_length": 1822.0, "train_total_steps": 3511370.0, "train_total_episodes": 1750.0, "train_loaded_steps": 1998920.0, "train_loaded_episodes": 1022.0}
{"step": 14053296, "train_return": 18.0, "train_length": 1954.0, "train_total_steps": 3513324.0, "train_total_episodes": 1751.0, "train_loaded_steps": 1998825.0, "train_loaded_episodes": 1022.0}
{"step": 14053816, "kl_loss": 1.3845577550888062, "image_loss": 3772.0, "reward_loss": 0.9191466650009156, "discount_loss": 0.00774184079170227, "model_kl": 1.3845577249526977, "prior_ent": 26.94654697265625, "post_ent": 25.56988063964844, "model_loss": 3773.09634140625, "model_loss_scale": 2048.0, "model_grad_norm": 5.197269330787659, "actor_loss": -0.0030135031327357866, "actor_loss_scale": 8992587.776, "actor_grad_norm": 0.03264938125610352, "critic_loss": 0.9180052380561828, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2559604577660561, "reward_mean": 0.007215035676397383, "reward_std": 0.08178999380469322, "reward_normed_mean": 0.007215035676397383, "reward_normed_std": 0.08178999380469322, "critic_slow": 5.111309878540039, "critic_target": 5.111014369964599, "actor_ent": 1.3462419826507568, "actor_ent_scale": 0.0010000000474974513, "critic": 5.111056586456299, "fps": 106.4507341694976}
{"step": 14059936, "train_return": 21.0, "train_length": 1660.0, "train_total_steps": 3514984.0, "train_total_episodes": 1752.0, "train_loaded_steps": 1998619.0, "train_loaded_episodes": 1022.0}
{"step": 14059248, "eval_return": 14.0, "eval_length": 2251.0, "eval_total_steps": 35478.0, "eval_total_episodes": 18.0, "eval_loaded_steps": 35496.0, "eval_loaded_episodes": 18.0}
{"step": 14059252, "kl_loss": 1.2402812242507935, "image_loss": 3772.0, "reward_loss": 0.9189478158950806, "discount_loss": 0.007745161186903715, "model_kl": 1.2402812242507935, "prior_ent": 27.030860900878906, "post_ent": 25.775489807128906, "model_loss": 3773.081787109375, "model_loss_scale": 16384.0, "model_grad_norm": 6.767140865325928, "actor_loss": -0.05046737566590309, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02886168099939823, "critic_loss": 0.9168782830238342, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.3916528820991516, "reward_mean": 0.004995354916900396, "reward_std": 0.0861709713935852, "reward_normed_mean": 0.004995354916900396, "reward_normed_std": 0.0861709713935852, "critic_slow": 5.421372890472412, "critic_target": 5.387612342834473, "actor_ent": 1.411895751953125, "actor_ent_scale": 0.0010000000474974513, "critic": 5.4139509201049805, "fps": 0.0}
{"step": 14066788, "train_return": 18.0, "train_length": 1885.0, "train_total_steps": 3516697.0, "train_total_episodes": 1753.0, "train_loaded_steps": 1998586.0, "train_loaded_episodes": 1022.0}
{"step": 14074520, "train_return": 18.0, "train_length": 1933.0, "train_total_steps": 3518630.0, "train_total_episodes": 1754.0, "train_loaded_steps": 1998547.0, "train_loaded_episodes": 1022.0}
{"step": 14082496, "train_return": 16.0, "train_length": 1994.0, "train_total_steps": 3520624.0, "train_total_episodes": 1755.0, "train_loaded_steps": 1998602.0, "train_loaded_episodes": 1022.0}
{"step": 14090440, "train_return": 18.0, "train_length": 1986.0, "train_total_steps": 3522610.0, "train_total_episodes": 1756.0, "train_loaded_steps": 1998655.0, "train_loaded_episodes": 1022.0}
{"step": 14097764, "train_return": 19.0, "train_length": 1831.0, "train_total_steps": 3524441.0, "train_total_episodes": 1757.0, "train_loaded_steps": 1998392.0, "train_loaded_episodes": 1022.0}
{"step": 14099252, "kl_loss": 1.3446934209823609, "image_loss": 3772.0002, "reward_loss": 0.9191187523841858, "discount_loss": 0.007741341529041529, "model_kl": 1.3446933885574341, "prior_ent": 26.770265252685547, "post_ent": 25.433724990844727, "model_loss": 3773.092522265625, "model_loss_scale": 4122.2144, "model_grad_norm": Infinity, "actor_loss": -0.003883564391249092, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.03421484357714653, "critic_loss": 0.9189477686882019, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.24566709684729576, "reward_mean": 0.007198572530411184, "reward_std": 0.08197527908086777, "reward_normed_mean": 0.007198572530411184, "reward_normed_std": 0.08197527908086777, "critic_slow": 5.160920274734497, "critic_target": 5.159891115951538, "actor_ent": 1.3965494693756104, "actor_ent_scale": 0.0010000000474974513, "critic": 5.159884437179565, "fps": 111.54679824000952}
{"step": 14104748, "train_return": 19.0, "train_length": 1746.0, "train_total_steps": 3526187.0, "train_total_episodes": 1758.0, "train_loaded_steps": 1998251.0, "train_loaded_episodes": 1022.0}
{"step": 14111684, "train_return": 20.0, "train_length": 1734.0, "train_total_steps": 3527921.0, "train_total_episodes": 1759.0, "train_loaded_steps": 1999985.0, "train_loaded_episodes": 1023.0}
{"step": 14119940, "train_return": 18.0, "train_length": 2064.0, "train_total_steps": 3529985.0, "train_total_episodes": 1760.0, "train_loaded_steps": 1999834.0, "train_loaded_episodes": 1023.0}
{"step": 14128040, "train_return": 16.0, "train_length": 2025.0, "train_total_steps": 3532010.0, "train_total_episodes": 1761.0, "train_loaded_steps": 1998002.0, "train_loaded_episodes": 1022.0}
{"step": 14135852, "train_return": 17.0, "train_length": 1953.0, "train_total_steps": 3533963.0, "train_total_episodes": 1762.0, "train_loaded_steps": 1999955.0, "train_loaded_episodes": 1023.0}
{"step": 14139252, "kl_loss": 1.3674652004241943, "image_loss": 3772.0, "reward_loss": 0.9191277294158936, "discount_loss": 0.0077412666954100135, "model_kl": 1.3674651704788208, "prior_ent": 26.675381005859375, "post_ent": 25.320774206542968, "model_loss": 3773.09461015625, "model_loss_scale": 4096.0, "model_grad_norm": 4.885394840049743, "actor_loss": -0.0067633106431312625, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.033512394914031025, "critic_loss": 0.917892962551117, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.2604874751985073, "reward_mean": 0.007249007105547935, "reward_std": 0.0822693900346756, "reward_normed_mean": 0.007249007105547935, "reward_normed_std": 0.0822693900346756, "critic_slow": 5.126236380386352, "critic_target": 5.123928702545166, "actor_ent": 1.4210874870300294, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1239728790283205, "fps": 114.26225155310449}
{"step": 14144352, "train_return": 15.0, "train_length": 2125.0, "train_total_steps": 3536088.0, "train_total_episodes": 1763.0, "train_loaded_steps": 1998228.0, "train_loaded_episodes": 1022.0}
{"step": 14151940, "train_return": 18.0, "train_length": 1897.0, "train_total_steps": 3537985.0, "train_total_episodes": 1764.0, "train_loaded_steps": 1997678.0, "train_loaded_episodes": 1022.0}
{"step": 14160144, "train_return": 18.0, "train_length": 2051.0, "train_total_steps": 3540036.0, "train_total_episodes": 1765.0, "train_loaded_steps": 1999729.0, "train_loaded_episodes": 1023.0}
{"step": 14169132, "train_return": 15.0, "train_length": 2247.0, "train_total_steps": 3542283.0, "train_total_episodes": 1766.0, "train_loaded_steps": 1998081.0, "train_loaded_episodes": 1022.0}
{"step": 14177124, "train_return": 17.0, "train_length": 1998.0, "train_total_steps": 3544281.0, "train_total_episodes": 1767.0, "train_loaded_steps": 1998123.0, "train_loaded_episodes": 1022.0}
{"step": 14179252, "kl_loss": 1.3417643001556396, "image_loss": 3772.0, "reward_loss": 0.9191361065864563, "discount_loss": 0.007768343925476074, "model_kl": 1.3417642713546754, "prior_ent": 26.70655579223633, "post_ent": 25.373698922729492, "model_loss": 3773.09218359375, "model_loss_scale": 4096.0, "model_grad_norm": 5.101259406661987, "actor_loss": -0.0058418980954995274, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.031451437817513944, "critic_loss": 0.9169267665863037, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.2668469978153706, "reward_mean": 0.007393753454321995, "reward_std": 0.0822767171561718, "reward_normed_mean": 0.007393753454321995, "reward_normed_std": 0.0822767171561718, "critic_slow": 5.099367504882813, "critic_target": 5.098159051895141, "actor_ent": 1.4162955728530884, "actor_ent_scale": 0.0010000000474974513, "critic": 5.098187451934814, "fps": 111.68299898828235}
{"step": 14184672, "train_return": 18.0, "train_length": 1887.0, "train_total_steps": 3546168.0, "train_total_episodes": 1768.0, "train_loaded_steps": 1998121.0, "train_loaded_episodes": 1022.0}
{"step": 14191956, "train_return": 19.0, "train_length": 1821.0, "train_total_steps": 3547989.0, "train_total_episodes": 1769.0, "train_loaded_steps": 1999942.0, "train_loaded_episodes": 1023.0}
{"step": 14199372, "train_return": 20.0, "train_length": 1854.0, "train_total_steps": 3549843.0, "train_total_episodes": 1770.0, "train_loaded_steps": 1999651.0, "train_loaded_episodes": 1023.0}
{"step": 14207572, "train_return": 16.0, "train_length": 2050.0, "train_total_steps": 3551893.0, "train_total_episodes": 1771.0, "train_loaded_steps": 1999832.0, "train_loaded_episodes": 1023.0}
{"step": 14215056, "train_return": 17.0, "train_length": 1871.0, "train_total_steps": 3553764.0, "train_total_episodes": 1772.0, "train_loaded_steps": 1999664.0, "train_loaded_episodes": 1023.0}
{"step": 14219252, "kl_loss": 1.3591452011108398, "image_loss": 3772.0, "reward_loss": 0.919162420463562, "discount_loss": 0.007761068880558014, "model_kl": 1.359145167160034, "prior_ent": 26.723132388305665, "post_ent": 25.377728573608398, "model_loss": 3773.093919921875, "model_loss_scale": 7359.6928, "model_grad_norm": 5.194003916168213, "actor_loss": -0.002752604148100363, "actor_loss_scale": 59087.2576, "actor_grad_norm": 0.032861632370948794, "critic_loss": 0.9180468427658081, "critic_loss_scale": 59087.2576, "critic_grad_norm": 0.28130509572029117, "reward_mean": 0.007395985353691503, "reward_std": 0.08170736113786697, "reward_normed_mean": 0.007395985353691503, "reward_normed_std": 0.08170736113786697, "critic_slow": 5.1082582183837895, "critic_target": 5.108135906600952, "actor_ent": 1.3893916759490967, "actor_ent_scale": 0.0010000000474974513, "critic": 5.108129580307007, "fps": 110.50094121918404}
{"step": 14222456, "train_return": 19.0, "train_length": 1850.0, "train_total_steps": 3555614.0, "train_total_episodes": 1773.0, "train_loaded_steps": 1999777.0, "train_loaded_episodes": 1023.0}
{"step": 14230108, "train_return": 18.0, "train_length": 1913.0, "train_total_steps": 3557527.0, "train_total_episodes": 1774.0, "train_loaded_steps": 1999669.0, "train_loaded_episodes": 1023.0}
{"step": 14237888, "train_return": 17.0, "train_length": 1945.0, "train_total_steps": 3559472.0, "train_total_episodes": 1775.0, "train_loaded_steps": 1999306.0, "train_loaded_episodes": 1023.0}
{"step": 14244700, "train_return": 20.0, "train_length": 1703.0, "train_total_steps": 3561175.0, "train_total_episodes": 1776.0, "train_loaded_steps": 1999003.0, "train_loaded_episodes": 1023.0}
{"step": 14251740, "train_return": 19.0, "train_length": 1760.0, "train_total_steps": 3562935.0, "train_total_episodes": 1777.0, "train_loaded_steps": 1998877.0, "train_loaded_episodes": 1023.0}
{"step": 14259252, "kl_loss": 1.357958828163147, "image_loss": 3772.0002, "reward_loss": 0.9191389856338501, "discount_loss": 0.007798900879919529, "model_kl": 1.357958798980713, "prior_ent": 26.756449151611328, "post_ent": 25.40933091430664, "model_loss": 3773.09416171875, "model_loss_scale": 8192.0, "model_grad_norm": 5.1818334655761715, "actor_loss": -0.005487964173825458, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.031760158956050874, "critic_loss": 0.9171768116950989, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.2571633674681187, "reward_mean": 0.00721167316599749, "reward_std": 0.08173140230178833, "reward_normed_mean": 0.00721167316599749, "reward_normed_std": 0.08173140230178833, "critic_slow": 5.079596532821656, "critic_target": 5.07965814781189, "actor_ent": 1.4024676635742188, "actor_ent_scale": 0.0010000000474974513, "critic": 5.079691607284546, "fps": 109.8804291809206}
{"step": 14259440, "train_return": 18.0, "train_length": 1925.0, "train_total_steps": 3564860.0, "train_total_episodes": 1778.0, "train_loaded_steps": 1998793.0, "train_loaded_episodes": 1023.0}
{"step": 14266884, "train_return": 20.0, "train_length": 1861.0, "train_total_steps": 3566721.0, "train_total_episodes": 1779.0, "train_loaded_steps": 1998782.0, "train_loaded_episodes": 1023.0}
{"step": 14274512, "train_return": 18.0, "train_length": 1907.0, "train_total_steps": 3568628.0, "train_total_episodes": 1780.0, "train_loaded_steps": 1998763.0, "train_loaded_episodes": 1023.0}
{"step": 14282868, "train_return": 17.0, "train_length": 2089.0, "train_total_steps": 3570717.0, "train_total_episodes": 1781.0, "train_loaded_steps": 1998891.0, "train_loaded_episodes": 1023.0}
{"step": 14290336, "train_return": 18.0, "train_length": 1867.0, "train_total_steps": 3572584.0, "train_total_episodes": 1782.0, "train_loaded_steps": 1998874.0, "train_loaded_episodes": 1023.0}
{"step": 14297384, "train_return": 19.0, "train_length": 1762.0, "train_total_steps": 3574346.0, "train_total_episodes": 1783.0, "train_loaded_steps": 1998815.0, "train_loaded_episodes": 1023.0}
{"step": 14299252, "kl_loss": 1.3521117092132569, "image_loss": 3772.0, "reward_loss": 0.9191499772071838, "discount_loss": 0.007744266727566719, "model_kl": 1.3521116744995116, "prior_ent": 26.710786227416992, "post_ent": 25.368548193359373, "model_loss": 3773.093108203125, "model_loss_scale": 8192.0, "model_grad_norm": 5.284497785568237, "actor_loss": -0.005486735921143918, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.031027814501523972, "critic_loss": 0.9163427134513855, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.22318967289328576, "reward_mean": 0.007344372644834221, "reward_std": 0.08241187291145324, "reward_normed_mean": 0.007344372644834221, "reward_normed_std": 0.08241187291145324, "critic_slow": 5.082160052871704, "critic_target": 5.0815053569793704, "actor_ent": 1.4138977800369263, "actor_ent_scale": 0.0010000000474974513, "critic": 5.08159463005066, "fps": 112.44239674205068}
{"step": 14304652, "train_return": 19.0, "train_length": 1817.0, "train_total_steps": 3576163.0, "train_total_episodes": 1784.0, "train_loaded_steps": 1998481.0, "train_loaded_episodes": 1023.0}
{"step": 14312556, "train_return": 16.0, "train_length": 1976.0, "train_total_steps": 3578139.0, "train_total_episodes": 1785.0, "train_loaded_steps": 1998175.0, "train_loaded_episodes": 1023.0}
{"step": 14319396, "train_return": 20.0, "train_length": 1710.0, "train_total_steps": 3579849.0, "train_total_episodes": 1786.0, "train_loaded_steps": 1999885.0, "train_loaded_episodes": 1024.0}
{"step": 14326180, "train_return": 21.0, "train_length": 1696.0, "train_total_steps": 3581545.0, "train_total_episodes": 1787.0, "train_loaded_steps": 1999661.0, "train_loaded_episodes": 1024.0}
{"step": 14333544, "train_return": 19.0, "train_length": 1841.0, "train_total_steps": 3583386.0, "train_total_episodes": 1788.0, "train_loaded_steps": 1999376.0, "train_loaded_episodes": 1024.0}
{"step": 14339252, "kl_loss": 1.3530375411987305, "image_loss": 3772.0, "reward_loss": 0.9191312430381775, "discount_loss": 0.007742074683308601, "model_kl": 1.353037512397766, "prior_ent": 26.61094797363281, "post_ent": 25.26995354309082, "model_loss": 3773.093181640625, "model_loss_scale": 13080.9856, "model_grad_norm": 5.412063380432129, "actor_loss": -0.0062420940703537785, "actor_loss_scale": 105067.3152, "actor_grad_norm": 0.02837135860174894, "critic_loss": 0.9165761717796326, "critic_loss_scale": 105067.3152, "critic_grad_norm": 0.23863462042808534, "reward_mean": 0.0072962310494855045, "reward_std": 0.0818705062031746, "reward_normed_mean": 0.0072962310494855045, "reward_normed_std": 0.0818705062031746, "critic_slow": 5.08945471534729, "critic_target": 5.088506967926025, "actor_ent": 1.4022494560241698, "actor_ent_scale": 0.0010000000474974513, "critic": 5.088548921966553, "fps": 109.93900910394346}
{"step": 14340812, "train_return": 20.0, "train_length": 1817.0, "train_total_steps": 3585203.0, "train_total_episodes": 1789.0, "train_loaded_steps": 1999195.0, "train_loaded_episodes": 1024.0}
{"step": 14348040, "train_return": 18.0, "train_length": 1807.0, "train_total_steps": 3587010.0, "train_total_episodes": 1790.0, "train_loaded_steps": 1998887.0, "train_loaded_episodes": 1024.0}
{"step": 14355792, "train_return": 18.0, "train_length": 1938.0, "train_total_steps": 3588948.0, "train_total_episodes": 1791.0, "train_loaded_steps": 1998613.0, "train_loaded_episodes": 1024.0}
{"step": 14362928, "train_return": 18.0, "train_length": 1784.0, "train_total_steps": 3590732.0, "train_total_episodes": 1792.0, "train_loaded_steps": 1998340.0, "train_loaded_episodes": 1024.0}
{"step": 14370800, "train_return": 17.0, "train_length": 1968.0, "train_total_steps": 3592700.0, "train_total_episodes": 1793.0, "train_loaded_steps": 1998369.0, "train_loaded_episodes": 1024.0}
{"step": 14378428, "train_return": 19.0, "train_length": 1907.0, "train_total_steps": 3594607.0, "train_total_episodes": 1794.0, "train_loaded_steps": 1998428.0, "train_loaded_episodes": 1024.0}
{"step": 14379252, "kl_loss": 1.3772709739685058, "image_loss": 3772.0, "reward_loss": 0.9191267978668213, "discount_loss": 0.007769838041067123, "model_kl": 1.3772709447860718, "prior_ent": 26.859744967651366, "post_ent": 25.503357876586914, "model_loss": 3773.095727734375, "model_loss_scale": 16384.0, "model_grad_norm": 5.078491842269897, "actor_loss": -0.0035112849701894448, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.033457364690303804, "critic_loss": 0.9200023483276367, "critic_loss_scale": 75707.1872, "critic_grad_norm": Infinity, "reward_mean": 0.007447513408493251, "reward_std": 0.08272844775915146, "reward_normed_mean": 0.007447513408493251, "reward_normed_std": 0.08272844775915146, "critic_slow": 5.1124231773376465, "critic_target": 5.113072898864746, "actor_ent": 1.3526886993408203, "actor_ent_scale": 0.0010000000474974513, "critic": 5.113266540145874, "fps": 112.7601900914327}
{"step": 14387640, "train_return": 14.0, "train_length": 2303.0, "train_total_steps": 3596910.0, "train_total_episodes": 1795.0, "train_loaded_steps": 1998378.0, "train_loaded_episodes": 1024.0}
{"step": 14395316, "train_return": 15.0, "train_length": 1919.0, "train_total_steps": 3598829.0, "train_total_episodes": 1796.0, "train_loaded_steps": 1998352.0, "train_loaded_episodes": 1024.0}
{"step": 14404080, "train_return": 13.0, "train_length": 2191.0, "train_total_steps": 3601020.0, "train_total_episodes": 1797.0, "train_loaded_steps": 1998589.0, "train_loaded_episodes": 1024.0}
{"step": 14411096, "train_return": 20.0, "train_length": 1754.0, "train_total_steps": 3602774.0, "train_total_episodes": 1798.0, "train_loaded_steps": 1998283.0, "train_loaded_episodes": 1024.0}
{"step": 14417972, "train_return": 20.0, "train_length": 1719.0, "train_total_steps": 3604493.0, "train_total_episodes": 1799.0, "train_loaded_steps": 1998209.0, "train_loaded_episodes": 1024.0}
{"step": 14419252, "kl_loss": 1.37664609375, "image_loss": 3772.0, "reward_loss": 0.9191532198905945, "discount_loss": 0.0077414508454501626, "model_kl": 1.3766460618972778, "prior_ent": 26.860111569213867, "post_ent": 25.493855532836914, "model_loss": 3773.095553125, "model_loss_scale": 16384.0, "model_grad_norm": 5.039607406044007, "actor_loss": -0.0029518714953621385, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.032081523628532886, "critic_loss": 0.91800306930542, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.2690206802368164, "reward_mean": 0.007376480439375155, "reward_std": 0.08234018345475197, "reward_normed_mean": 0.007376480439375155, "reward_normed_std": 0.08234018345475197, "critic_slow": 5.110563752365112, "critic_target": 5.111431966781616, "actor_ent": 1.3393442674636842, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1114550354003905, "fps": 110.64377623321207}
{"step": 14425476, "train_return": 19.0, "train_length": 1876.0, "train_total_steps": 3606369.0, "train_total_episodes": 1800.0, "train_loaded_steps": 1998125.0, "train_loaded_episodes": 1024.0}
{"step": 14434584, "train_return": 14.0, "train_length": 2277.0, "train_total_steps": 3608646.0, "train_total_episodes": 1801.0, "train_loaded_steps": 1998462.0, "train_loaded_episodes": 1024.0}
{"step": 14442208, "train_return": 17.0, "train_length": 1906.0, "train_total_steps": 3610552.0, "train_total_episodes": 1802.0, "train_loaded_steps": 1998045.0, "train_loaded_episodes": 1024.0}
{"step": 14449952, "train_return": 17.0, "train_length": 1936.0, "train_total_steps": 3612488.0, "train_total_episodes": 1803.0, "train_loaded_steps": 1999981.0, "train_loaded_episodes": 1025.0}
{"step": 14458640, "train_return": 13.0, "train_length": 2172.0, "train_total_steps": 3614660.0, "train_total_episodes": 1804.0, "train_loaded_steps": 1998266.0, "train_loaded_episodes": 1024.0}
{"step": 14459252, "kl_loss": 1.355711467552185, "image_loss": 3772.0, "reward_loss": 0.9191408546447754, "discount_loss": 0.007742411733418703, "model_kl": 1.355711438179016, "prior_ent": 26.734173062133788, "post_ent": 25.387223831176758, "model_loss": 3773.093455859375, "model_loss_scale": 21889.024, "model_grad_norm": Infinity, "actor_loss": -0.00276495144382352, "actor_loss_scale": 183920.2304, "actor_grad_norm": 0.03024794392436743, "critic_loss": 0.9168295548439026, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.2226798004090786, "reward_mean": 0.007350502689462155, "reward_std": 0.08192851812243461, "reward_normed_mean": 0.007350502689462155, "reward_normed_std": 0.08192851812243461, "critic_slow": 5.0620730735778805, "critic_target": 5.063041910552979, "actor_ent": 1.3900229347229003, "actor_ent_scale": 0.0010000000474974513, "critic": 5.063046754074096, "fps": 109.80400583522272}
{"step": 14467452, "train_return": 14.0, "train_length": 2203.0, "train_total_steps": 3616863.0, "train_total_episodes": 1805.0, "train_loaded_steps": 1998761.0, "train_loaded_episodes": 1024.0}
{"step": 14476708, "train_return": 15.0, "train_length": 2314.0, "train_total_steps": 3619177.0, "train_total_episodes": 1806.0, "train_loaded_steps": 1999146.0, "train_loaded_episodes": 1024.0}
{"step": 14484116, "train_return": 19.0, "train_length": 1852.0, "train_total_steps": 3621029.0, "train_total_episodes": 1807.0, "train_loaded_steps": 1998845.0, "train_loaded_episodes": 1024.0}
{"step": 14491880, "train_return": 17.0, "train_length": 1941.0, "train_total_steps": 3622970.0, "train_total_episodes": 1808.0, "train_loaded_steps": 1998733.0, "train_loaded_episodes": 1024.0}
{"step": 14499252, "kl_loss": 1.3886829692840577, "image_loss": 3772.0, "reward_loss": 0.9191508918762207, "discount_loss": 0.007744419424235821, "model_kl": 1.3886829399108886, "prior_ent": 26.58671421508789, "post_ent": 25.216373840332032, "model_loss": 3773.096773828125, "model_loss_scale": 16384.0, "model_grad_norm": 5.36526757926941, "actor_loss": -0.004236156745010522, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.030126742321252824, "critic_loss": 0.9170390790939331, "critic_loss_scale": 107793.6128, "critic_grad_norm": 0.25530204393863676, "reward_mean": 0.007359246826102026, "reward_std": 0.08190636550784111, "reward_normed_mean": 0.007359246826102026, "reward_normed_std": 0.08190636550784111, "critic_slow": 5.070194940567017, "critic_target": 5.070522248077393, "actor_ent": 1.3943073778152466, "actor_ent_scale": 0.0010000000474974513, "critic": 5.070538282394409, "fps": 112.1432213474839}
{"step": 14500820, "train_return": 14.0, "train_length": 2235.0, "train_total_steps": 3625205.0, "train_total_episodes": 1809.0, "train_loaded_steps": 1998846.0, "train_loaded_episodes": 1024.0}
{"step": 14508728, "train_return": 18.0, "train_length": 1977.0, "train_total_steps": 3627182.0, "train_total_episodes": 1810.0, "train_loaded_steps": 1998361.0, "train_loaded_episodes": 1024.0}
{"step": 14517768, "train_return": 15.0, "train_length": 2260.0, "train_total_steps": 3629442.0, "train_total_episodes": 1811.0, "train_loaded_steps": 1998811.0, "train_loaded_episodes": 1024.0}
{"step": 14525076, "train_return": 18.0, "train_length": 1827.0, "train_total_steps": 3631269.0, "train_total_episodes": 1812.0, "train_loaded_steps": 1998176.0, "train_loaded_episodes": 1024.0}
{"step": 14532148, "train_return": 20.0, "train_length": 1768.0, "train_total_steps": 3633037.0, "train_total_episodes": 1813.0, "train_loaded_steps": 1999944.0, "train_loaded_episodes": 1025.0}
{"step": 14539252, "kl_loss": 1.3535971675872802, "image_loss": 3772.0, "reward_loss": 0.9191424689292907, "discount_loss": 0.007741169993579388, "model_kl": 1.3535971361160277, "prior_ent": 26.740644564819338, "post_ent": 25.39598427734375, "model_loss": 3773.093244921875, "model_loss_scale": 16384.0, "model_grad_norm": 5.0557629608154295, "actor_loss": -0.0033000740982388377, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.03002626949548721, "critic_loss": 0.9175560872077941, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.25322344630360605, "reward_mean": 0.007231282518617809, "reward_std": 0.0810816583454609, "reward_normed_mean": 0.007231282518617809, "reward_normed_std": 0.0810816583454609, "critic_slow": 5.027875646591187, "critic_target": 5.029186527633667, "actor_ent": 1.3987925853729248, "actor_ent_scale": 0.0010000000474974513, "critic": 5.0290635986328125, "fps": 110.40936589993679}
{"step": 14541040, "train_return": 13.0, "train_length": 2223.0, "train_total_steps": 3635260.0, "train_total_episodes": 1814.0, "train_loaded_steps": 1998295.0, "train_loaded_episodes": 1024.0}
{"step": 14548596, "train_return": 18.0, "train_length": 1889.0, "train_total_steps": 3637149.0, "train_total_episodes": 1815.0, "train_loaded_steps": 1997997.0, "train_loaded_episodes": 1024.0}
{"step": 14557156, "train_return": 14.0, "train_length": 2140.0, "train_total_steps": 3639289.0, "train_total_episodes": 1816.0, "train_loaded_steps": 1998145.0, "train_loaded_episodes": 1024.0}
{"step": 14564352, "train_return": 20.0, "train_length": 1799.0, "train_total_steps": 3641088.0, "train_total_episodes": 1817.0, "train_loaded_steps": 1999944.0, "train_loaded_episodes": 1025.0}
{"step": 14571772, "train_return": 20.0, "train_length": 1855.0, "train_total_steps": 3642943.0, "train_total_episodes": 1818.0, "train_loaded_steps": 1998315.0, "train_loaded_episodes": 1024.0}
{"step": 14579252, "kl_loss": 1.3442449174880982, "image_loss": 3772.0, "reward_loss": 0.9191190069198608, "discount_loss": 0.007786413099616766, "model_kl": 1.3442448896408081, "prior_ent": 26.867472811889648, "post_ent": 25.533712069702148, "model_loss": 3773.092508984375, "model_loss_scale": 16384.0, "model_grad_norm": 5.165873351097107, "actor_loss": -0.0038857916339184156, "actor_loss_scale": 315411.6608, "actor_grad_norm": 0.029873947158455847, "critic_loss": 0.9166430446624756, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2400816740632057, "reward_mean": 0.007516508850979153, "reward_std": 0.08225199934244155, "reward_normed_mean": 0.007516508850979153, "reward_normed_std": 0.08225199934244155, "critic_slow": 5.000946341323853, "critic_target": 5.002249913406372, "actor_ent": 1.417710754585266, "actor_ent_scale": 0.0010000000474974513, "critic": 5.002281642913818, "fps": 112.73996888512342}
{"step": 14579792, "train_return": 16.0, "train_length": 2005.0, "train_total_steps": 3644948.0, "train_total_episodes": 1819.0, "train_loaded_steps": 1998510.0, "train_loaded_episodes": 1024.0}
{"step": 14586900, "train_return": 19.0, "train_length": 1777.0, "train_total_steps": 3646725.0, "train_total_episodes": 1820.0, "train_loaded_steps": 1998320.0, "train_loaded_episodes": 1024.0}
{"step": 14594192, "train_return": 19.0, "train_length": 1823.0, "train_total_steps": 3648548.0, "train_total_episodes": 1821.0, "train_loaded_steps": 1998165.0, "train_loaded_episodes": 1024.0}
{"step": 14601652, "train_return": 17.0, "train_length": 1865.0, "train_total_steps": 3650413.0, "train_total_episodes": 1822.0, "train_loaded_steps": 1998133.0, "train_loaded_episodes": 1024.0}
{"step": 14608728, "train_return": 19.0, "train_length": 1769.0, "train_total_steps": 3652182.0, "train_total_episodes": 1823.0, "train_loaded_steps": 1999902.0, "train_loaded_episodes": 1025.0}
{"step": 14616124, "train_return": 18.0, "train_length": 1849.0, "train_total_steps": 3654031.0, "train_total_episodes": 1824.0, "train_loaded_steps": 1999770.0, "train_loaded_episodes": 1025.0}
{"step": 14619252, "kl_loss": 1.3415686923980712, "image_loss": 3772.0, "reward_loss": 0.9191182106018067, "discount_loss": 0.007742049350589514, "model_kl": 1.3415686628341674, "prior_ent": 26.685473110961915, "post_ent": 25.35226723327637, "model_loss": 3773.092015625, "model_loss_scale": 16960.7168, "model_grad_norm": Infinity, "actor_loss": -0.0055468582640693055, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.030155049669742584, "critic_loss": 0.916633570766449, "critic_loss_scale": 168191.5904, "critic_grad_norm": Infinity, "reward_mean": 0.007312137690698728, "reward_std": 0.08209869972467422, "reward_normed_mean": 0.007312137690698728, "reward_normed_std": 0.08209869972467422, "critic_slow": 5.069103395843506, "critic_target": 5.069886242294311, "actor_ent": 1.4101179668426513, "actor_ent_scale": 0.0010000000474974513, "critic": 5.069873709487915, "fps": 111.87322496521091}
{"step": 14625408, "train_return": 16.0, "train_length": 2321.0, "train_total_steps": 3656352.0, "train_total_episodes": 1825.0, "train_loaded_steps": 1997904.0, "train_loaded_episodes": 1024.0}
{"step": 14633992, "train_return": 12.0, "train_length": 2146.0, "train_total_steps": 3658498.0, "train_total_episodes": 1826.0, "train_loaded_steps": 1998198.0, "train_loaded_episodes": 1024.0}
{"step": 14641828, "train_return": 15.0, "train_length": 1959.0, "train_total_steps": 3660457.0, "train_total_episodes": 1827.0, "train_loaded_steps": 1997683.0, "train_loaded_episodes": 1024.0}
{"step": 14649580, "train_return": 18.0, "train_length": 1938.0, "train_total_steps": 3662395.0, "train_total_episodes": 1828.0, "train_loaded_steps": 1999621.0, "train_loaded_episodes": 1025.0}
{"step": 14656864, "train_return": 19.0, "train_length": 1821.0, "train_total_steps": 3664216.0, "train_total_episodes": 1829.0, "train_loaded_steps": 1999419.0, "train_loaded_episodes": 1025.0}
{"step": 14659252, "kl_loss": 1.3619449359893798, "image_loss": 3772.0, "reward_loss": 0.9191498378753662, "discount_loss": 0.007743686225265264, "model_kl": 1.361944902229309, "prior_ent": 26.71235347290039, "post_ent": 25.364298959350585, "model_loss": 3773.09408828125, "model_loss_scale": 16384.0, "model_grad_norm": 4.818096592712402, "actor_loss": -0.004667418682202697, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.031821623568236826, "critic_loss": 0.9164727431297303, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2406630597770214, "reward_mean": 0.007372581695951522, "reward_std": 0.08187749708294868, "reward_normed_mean": 0.007372581695951522, "reward_normed_std": 0.08187749708294868, "critic_slow": 5.002787192153931, "critic_target": 5.003932002639771, "actor_ent": 1.39551726436615, "actor_ent_scale": 0.0010000000474974513, "critic": 5.003947314834595, "fps": 112.35784251323764}
{"step": 14665608, "train_return": 15.0, "train_length": 2186.0, "train_total_steps": 3666402.0, "train_total_episodes": 1830.0, "train_loaded_steps": 1999353.0, "train_loaded_episodes": 1025.0}
{"step": 14673468, "train_return": 17.0, "train_length": 1965.0, "train_total_steps": 3668367.0, "train_total_episodes": 1831.0, "train_loaded_steps": 1998965.0, "train_loaded_episodes": 1025.0}
{"step": 14680096, "train_return": 21.0, "train_length": 1657.0, "train_total_steps": 3670024.0, "train_total_episodes": 1832.0, "train_loaded_steps": 1998760.0, "train_loaded_episodes": 1025.0}
{"step": 14687532, "train_return": 18.0, "train_length": 1859.0, "train_total_steps": 3671883.0, "train_total_episodes": 1833.0, "train_loaded_steps": 1998780.0, "train_loaded_episodes": 1025.0}
{"step": 14695976, "train_return": 16.0, "train_length": 2111.0, "train_total_steps": 3673994.0, "train_total_episodes": 1834.0, "train_loaded_steps": 1998722.0, "train_loaded_episodes": 1025.0}
{"step": 14699252, "kl_loss": 1.3487050731658936, "image_loss": 3772.0, "reward_loss": 0.9191400740623474, "discount_loss": 0.007755981296300888, "model_kl": 1.3487050430297851, "prior_ent": 26.570980926513673, "post_ent": 25.23045320739746, "model_loss": 3773.09281953125, "model_loss_scale": 16384.0, "model_grad_norm": 5.187158727264404, "actor_loss": -0.0026493253325024853, "actor_loss_scale": 525965.7216, "actor_grad_norm": 0.03350634267181158, "critic_loss": 0.9171410131454468, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2714821225106716, "reward_mean": 0.007314116112748161, "reward_std": 0.08243550271391868, "reward_normed_mean": 0.007314116112748161, "reward_normed_std": 0.08243550271391868, "critic_slow": 5.011941254806518, "critic_target": 5.014527202987671, "actor_ent": 1.3821255323410033, "actor_ent_scale": 0.0010000000474974513, "critic": 5.01447966041565, "fps": 113.11858226215493}
{"step": 14703040, "train_return": 20.0, "train_length": 1766.0, "train_total_steps": 3675760.0, "train_total_episodes": 1835.0, "train_loaded_steps": 1998586.0, "train_loaded_episodes": 1025.0}
{"step": 14709672, "train_return": 21.0, "train_length": 1658.0, "train_total_steps": 3677418.0, "train_total_episodes": 1836.0, "train_loaded_steps": 1998418.0, "train_loaded_episodes": 1025.0}
{"step": 14716984, "train_return": 18.0, "train_length": 1828.0, "train_total_steps": 3679246.0, "train_total_episodes": 1837.0, "train_loaded_steps": 1998305.0, "train_loaded_episodes": 1025.0}
{"step": 14724472, "train_return": 18.0, "train_length": 1872.0, "train_total_steps": 3681118.0, "train_total_episodes": 1838.0, "train_loaded_steps": 1998152.0, "train_loaded_episodes": 1025.0}
{"step": 14732280, "train_return": 17.0, "train_length": 1952.0, "train_total_steps": 3683070.0, "train_total_episodes": 1839.0, "train_loaded_steps": 1998139.0, "train_loaded_episodes": 1025.0}
{"step": 14739160, "train_return": 19.0, "train_length": 1720.0, "train_total_steps": 3684790.0, "train_total_episodes": 1840.0, "train_loaded_steps": 1999859.0, "train_loaded_episodes": 1026.0}
{"step": 14739252, "kl_loss": 1.3429484930038451, "image_loss": 3772.0, "reward_loss": 0.9191381197929382, "discount_loss": 0.007752089215070009, "model_kl": 1.3429484628677368, "prior_ent": 26.503720950317383, "post_ent": 25.17202707824707, "model_loss": 3773.092223828125, "model_loss_scale": 17065.5744, "model_grad_norm": Infinity, "actor_loss": -0.004102298538433388, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.03368201814889908, "critic_loss": 0.9175367937088013, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.24828052789568902, "reward_mean": 0.007322858659084886, "reward_std": 0.08257496414780617, "reward_normed_mean": 0.007322858659084886, "reward_normed_std": 0.08257496414780617, "critic_slow": 5.052882806396484, "critic_target": 5.053783457183838, "actor_ent": 1.405357405281067, "actor_ent_scale": 0.0010000000474974513, "critic": 5.053802682495117, "fps": 111.96465298789794}
{"step": 14745784, "train_return": 21.0, "train_length": 1656.0, "train_total_steps": 3686446.0, "train_total_episodes": 1841.0, "train_loaded_steps": 1999506.0, "train_loaded_episodes": 1026.0}
{"step": 14753524, "train_return": 17.0, "train_length": 1935.0, "train_total_steps": 3688381.0, "train_total_episodes": 1842.0, "train_loaded_steps": 1999280.0, "train_loaded_episodes": 1026.0}
{"step": 14761356, "train_return": 17.0, "train_length": 1958.0, "train_total_steps": 3690339.0, "train_total_episodes": 1843.0, "train_loaded_steps": 1999437.0, "train_loaded_episodes": 1026.0}
{"step": 14769596, "train_return": 15.0, "train_length": 2060.0, "train_total_steps": 3692399.0, "train_total_episodes": 1844.0, "train_loaded_steps": 1999281.0, "train_loaded_episodes": 1026.0}
{"step": 14776944, "train_return": 19.0, "train_length": 1837.0, "train_total_steps": 3694236.0, "train_total_episodes": 1845.0, "train_loaded_steps": 1999185.0, "train_loaded_episodes": 1026.0}
{"step": 14779252, "kl_loss": 1.4609437004089356, "image_loss": 3772.0002, "reward_loss": 0.9191272682189942, "discount_loss": 0.008252605871856212, "model_kl": 1.4609436670303344, "prior_ent": 26.644128448486327, "post_ent": 25.2132971862793, "model_loss": 3773.106714453125, "model_loss_scale": 16384.0, "model_grad_norm": 5.209812232971191, "actor_loss": 0.003928133587905904, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.05291354054808617, "critic_loss": 0.9360390683174133, "critic_loss_scale": 93637.8368, "critic_grad_norm": Infinity, "reward_mean": 0.007355506142601371, "reward_std": 0.08257298129796982, "reward_normed_mean": 0.007355506142601371, "reward_normed_std": 0.08257298129796982, "critic_slow": 5.168153536605835, "critic_target": 5.170861519241333, "actor_ent": 1.2613456552505493, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1706891574859615, "fps": 114.44886104957342}
{"step": 14784608, "train_return": 18.0, "train_length": 1916.0, "train_total_steps": 3696152.0, "train_total_episodes": 1846.0, "train_loaded_steps": 1998917.0, "train_loaded_episodes": 1026.0}
{"step": 14792756, "train_return": 15.0, "train_length": 2037.0, "train_total_steps": 3698189.0, "train_total_episodes": 1847.0, "train_loaded_steps": 1998727.0, "train_loaded_episodes": 1026.0}
{"step": 14801556, "train_return": 14.0, "train_length": 2200.0, "train_total_steps": 3700389.0, "train_total_episodes": 1848.0, "train_loaded_steps": 1999144.0, "train_loaded_episodes": 1026.0}
{"step": 14809028, "train_return": 19.0, "train_length": 1868.0, "train_total_steps": 3702257.0, "train_total_episodes": 1849.0, "train_loaded_steps": 1999057.0, "train_loaded_episodes": 1026.0}
{"step": 14816912, "train_return": 15.0, "train_length": 1971.0, "train_total_steps": 3704228.0, "train_total_episodes": 1850.0, "train_loaded_steps": 1999072.0, "train_loaded_episodes": 1026.0}
{"step": 14819252, "kl_loss": 1.3561214141845703, "image_loss": 3772.0, "reward_loss": 0.919130978012085, "discount_loss": 0.007774331294745207, "model_kl": 1.3561213817596436, "prior_ent": 26.756580325317383, "post_ent": 25.407783111572265, "model_loss": 3773.09364765625, "model_loss_scale": 16384.0, "model_grad_norm": 4.895631909942627, "actor_loss": -0.002373767713344023, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.06243129711449146, "critic_loss": 0.937673028087616, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.644364908850193, "reward_mean": 0.0075115837274584915, "reward_std": 0.08337038659453393, "reward_normed_mean": 0.0075115837274584915, "reward_normed_std": 0.08337038659453393, "critic_slow": 5.115669793701172, "critic_target": 5.113955535507202, "actor_ent": 1.1901251838684082, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1137449821472165, "fps": 115.67530502915284}
{"step": 14825496, "train_return": 11.0, "train_length": 2146.0, "train_total_steps": 3706374.0, "train_total_episodes": 1851.0, "train_loaded_steps": 1999539.0, "train_loaded_episodes": 1026.0}
{"step": 14835588, "train_return": -1.0, "train_length": 2523.0, "train_total_steps": 3708897.0, "train_total_episodes": 1852.0, "train_loaded_steps": 1999963.0, "train_loaded_episodes": 1026.0}
{"step": 14844148, "train_return": 9.0, "train_length": 2140.0, "train_total_steps": 3711037.0, "train_total_episodes": 1853.0, "train_loaded_steps": 1999898.0, "train_loaded_episodes": 1026.0}
{"step": 14853328, "train_return": 7.0, "train_length": 2295.0, "train_total_steps": 3713332.0, "train_total_episodes": 1854.0, "train_loaded_steps": 1999877.0, "train_loaded_episodes": 1026.0}
{"step": 14859252, "kl_loss": 1.3720838264465332, "image_loss": 3772.0002, "reward_loss": 0.919134739780426, "discount_loss": 0.007742936962097883, "model_kl": 1.3720837980270386, "prior_ent": 26.648289889526367, "post_ent": 25.28742598876953, "model_loss": 3773.09528046875, "model_loss_scale": 12307.6608, "model_grad_norm": Infinity, "actor_loss": 0.017835959197068586, "actor_loss_scale": 1890792.2432, "actor_grad_norm": 0.058895769208669665, "critic_loss": 0.9300078802108764, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.4767989357471466, "reward_mean": 0.006979416024824605, "reward_std": 0.08487701959609985, "reward_normed_mean": 0.006979416024824605, "reward_normed_std": 0.08487701959609985, "critic_slow": 5.104346520996094, "critic_target": 5.112580199813843, "actor_ent": 1.2480982582092286, "actor_ent_scale": 0.0010000000474974513, "critic": 5.111989418792724, "fps": 113.09337106525956}
{"step": 14862744, "train_return": -1.0, "train_length": 2354.0, "train_total_steps": 3715686.0, "train_total_episodes": 1855.0, "train_loaded_steps": 1998316.0, "train_loaded_episodes": 1025.0}
{"step": 14872636, "train_return": -1.0, "train_length": 2473.0, "train_total_steps": 3718159.0, "train_total_episodes": 1856.0, "train_loaded_steps": 1998705.0, "train_loaded_episodes": 1025.0}
{"step": 14882516, "train_return": 3.0, "train_length": 2470.0, "train_total_steps": 3720629.0, "train_total_episodes": 1857.0, "train_loaded_steps": 1999418.0, "train_loaded_episodes": 1025.0}
{"step": 14890580, "train_return": 14.0, "train_length": 2016.0, "train_total_steps": 3722645.0, "train_total_episodes": 1858.0, "train_loaded_steps": 1999496.0, "train_loaded_episodes": 1025.0}
{"step": 14899252, "kl_loss": 1.3784618078231812, "image_loss": 3772.0, "reward_loss": 0.9191635049819946, "discount_loss": 0.007852111599594355, "model_kl": 1.3784617794036864, "prior_ent": 26.785494564819334, "post_ent": 25.418283187866212, "model_loss": 3773.09631796875, "model_loss_scale": 8192.0, "model_grad_norm": 4.990033206748962, "actor_loss": -0.0001849885653355159, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.046121103566884994, "critic_loss": 0.9237634554862976, "critic_loss_scale": 36909.8752, "critic_grad_norm": 0.41577598308324815, "reward_mean": 0.0071785599655937405, "reward_std": 0.08295990244746208, "reward_normed_mean": 0.0071785599655937405, "reward_normed_std": 0.08295990244746208, "critic_slow": 5.115781184768677, "critic_target": 5.11430357170105, "actor_ent": 1.2930829273223876, "actor_ent_scale": 0.0010000000474974513, "critic": 5.113836853790283, "fps": 114.12013462157972}
{"step": 14900100, "train_return": 7.0, "train_length": 2380.0, "train_total_steps": 3725025.0, "train_total_episodes": 1859.0, "train_loaded_steps": 1999881.0, "train_loaded_episodes": 1025.0}
{"step": 14907796, "train_return": 17.0, "train_length": 1924.0, "train_total_steps": 3726949.0, "train_total_episodes": 1860.0, "train_loaded_steps": 1999548.0, "train_loaded_episodes": 1025.0}
{"step": 14916432, "train_return": 12.0, "train_length": 2159.0, "train_total_steps": 3729108.0, "train_total_episodes": 1861.0, "train_loaded_steps": 1999624.0, "train_loaded_episodes": 1025.0}
{"step": 14923988, "train_return": 17.0, "train_length": 1889.0, "train_total_steps": 3730997.0, "train_total_episodes": 1862.0, "train_loaded_steps": 1999406.0, "train_loaded_episodes": 1025.0}
{"step": 14932504, "train_return": 15.0, "train_length": 2129.0, "train_total_steps": 3733126.0, "train_total_episodes": 1863.0, "train_loaded_steps": 1999639.0, "train_loaded_episodes": 1025.0}
{"step": 14939228, "train_return": 21.0, "train_length": 1681.0, "train_total_steps": 3734807.0, "train_total_episodes": 1864.0, "train_loaded_steps": 1999339.0, "train_loaded_episodes": 1025.0}
{"step": 14939252, "kl_loss": 1.36135096282959, "image_loss": 3772.0, "reward_loss": 0.9191311628341675, "discount_loss": 0.007742982792854309, "model_kl": 1.3613509317398071, "prior_ent": 26.621538388061524, "post_ent": 25.269003723144532, "model_loss": 3773.09401484375, "model_loss_scale": 8192.0, "model_grad_norm": 5.095113779449463, "actor_loss": -0.0014294001672233209, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.04295606542825699, "critic_loss": 0.9213392431259155, "critic_loss_scale": 47815.0656, "critic_grad_norm": Infinity, "reward_mean": 0.006991121761035174, "reward_std": 0.08354939271807671, "reward_normed_mean": 0.006991121761035174, "reward_normed_std": 0.08354939271807671, "critic_slow": 5.15667163772583, "critic_target": 5.155138017272949, "actor_ent": 1.34803624458313, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1549430828094485, "fps": 115.29884664633703}
{"step": 14945852, "train_return": 21.0, "train_length": 1656.0, "train_total_steps": 3736463.0, "train_total_episodes": 1865.0, "train_loaded_steps": 1999179.0, "train_loaded_episodes": 1025.0}
{"step": 14953480, "train_return": 16.0, "train_length": 1907.0, "train_total_steps": 3738370.0, "train_total_episodes": 1866.0, "train_loaded_steps": 1998859.0, "train_loaded_episodes": 1025.0}
{"step": 14960608, "train_return": 19.0, "train_length": 1782.0, "train_total_steps": 3740152.0, "train_total_episodes": 1867.0, "train_loaded_steps": 1998585.0, "train_loaded_episodes": 1025.0}
{"step": 14968416, "train_return": 16.0, "train_length": 1952.0, "train_total_steps": 3742104.0, "train_total_episodes": 1868.0, "train_loaded_steps": 1998501.0, "train_loaded_episodes": 1025.0}
{"step": 14975464, "train_return": 19.0, "train_length": 1762.0, "train_total_steps": 3743866.0, "train_total_episodes": 1869.0, "train_loaded_steps": 1998263.0, "train_loaded_episodes": 1025.0}
{"step": 14979252, "kl_loss": 1.4660218275070191, "image_loss": 3772.0, "reward_loss": 0.9191316650390625, "discount_loss": 0.007746858204901218, "model_kl": 1.4660217987060546, "prior_ent": 26.4475349609375, "post_ent": 25.019612490844725, "model_loss": 3773.104496484375, "model_loss_scale": 10629.9392, "model_grad_norm": 5.351416120529175, "actor_loss": 0.0005867297272197903, "actor_loss_scale": 3362154.0864, "actor_grad_norm": 0.04540212649703026, "critic_loss": 0.9238998627662659, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.42778686957359313, "reward_mean": 0.007237147098965943, "reward_std": 0.083638485455513, "reward_normed_mean": 0.007237147098965943, "reward_normed_std": 0.083638485455513, "critic_slow": 5.150073976898193, "critic_target": 5.150518754577637, "actor_ent": 1.347557497024536, "actor_ent_scale": 0.0010000000474974513, "critic": 5.149936734390259, "fps": 115.49332079375314}
{"step": 14984444, "train_return": 13.0, "train_length": 2245.0, "train_total_steps": 3746111.0, "train_total_episodes": 1870.0, "train_loaded_steps": 1998583.0, "train_loaded_episodes": 1025.0}
{"step": 14994356, "train_return": 10.0, "train_length": 2478.0, "train_total_steps": 3748589.0, "train_total_episodes": 1871.0, "train_loaded_steps": 1998906.0, "train_loaded_episodes": 1025.0}
{"step": 15002100, "train_return": 17.0, "train_length": 1936.0, "train_total_steps": 3750525.0, "train_total_episodes": 1872.0, "train_loaded_steps": 1998725.0, "train_loaded_episodes": 1025.0}
{"step": 15010516, "train_return": 14.0, "train_length": 2104.0, "train_total_steps": 3752629.0, "train_total_episodes": 1873.0, "train_loaded_steps": 1998924.0, "train_loaded_episodes": 1025.0}
{"step": 15017976, "train_return": 18.0, "train_length": 1865.0, "train_total_steps": 3754494.0, "train_total_episodes": 1874.0, "train_loaded_steps": 1998440.0, "train_loaded_episodes": 1025.0}
{"step": 15019252, "kl_loss": 1.3846970781326293, "image_loss": 3772.0, "reward_loss": 0.9191292673110962, "discount_loss": 0.007767040599882603, "model_kl": 1.3846970453262328, "prior_ent": 26.616763055419923, "post_ent": 25.2407826171875, "model_loss": 3773.096458984375, "model_loss_scale": 16384.0, "model_grad_norm": 4.813231083869934, "actor_loss": -0.0026792484225035876, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.039979647183418274, "critic_loss": 0.9218443503379822, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.36444005403518676, "reward_mean": 0.007035027125896886, "reward_std": 0.08285594025850296, "reward_normed_mean": 0.007035027125896886, "reward_normed_std": 0.08285594025850296, "critic_slow": 5.101237811279297, "critic_target": 5.099204140853882, "actor_ent": 1.3817655555725097, "actor_ent_scale": 0.0010000000474974513, "critic": 5.099393203735351, "fps": 116.01741756324708}
{"step": 15026448, "train_return": 13.0, "train_length": 2118.0, "train_total_steps": 3756612.0, "train_total_episodes": 1875.0, "train_loaded_steps": 1998272.0, "train_loaded_episodes": 1025.0}
{"step": 15035008, "train_return": 15.0, "train_length": 2140.0, "train_total_steps": 3758752.0, "train_total_episodes": 1876.0, "train_loaded_steps": 1998562.0, "train_loaded_episodes": 1025.0}
{"step": 15043008, "train_return": 16.0, "train_length": 2000.0, "train_total_steps": 3760752.0, "train_total_episodes": 1877.0, "train_loaded_steps": 1998433.0, "train_loaded_episodes": 1025.0}
{"step": 15049636, "train_return": 21.0, "train_length": 1657.0, "train_total_steps": 3762409.0, "train_total_episodes": 1878.0, "train_loaded_steps": 1998319.0, "train_loaded_episodes": 1025.0}
{"step": 15057896, "train_return": 17.0, "train_length": 2065.0, "train_total_steps": 3764474.0, "train_total_episodes": 1879.0, "train_loaded_steps": 1998542.0, "train_loaded_episodes": 1025.0}
{"step": 15059248, "eval_return": 16.0, "eval_length": 2067.0, "eval_total_steps": 37729.0, "eval_total_episodes": 19.0, "eval_loaded_steps": 37747.0, "eval_loaded_episodes": 19.0}
{"step": 15059252, "kl_loss": 1.3821809867858887, "image_loss": 3772.0, "reward_loss": 0.9191476370811462, "discount_loss": 0.007766093540936709, "model_kl": 1.3821809511184693, "prior_ent": 26.80466209716797, "post_ent": 25.431426342773438, "model_loss": 3773.0962375, "model_loss_scale": 16384.0, "model_grad_norm": 5.0364866508483885, "actor_loss": -0.0037465299336763565, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.03723139652013779, "critic_loss": 0.9215510614395142, "critic_loss_scale": 43935.3344, "critic_grad_norm": 0.3716629239439964, "reward_mean": 0.007204626102850307, "reward_std": 0.08261764186024666, "reward_normed_mean": 0.007204626102850307, "reward_normed_std": 0.08261764186024666, "critic_slow": 5.11858881187439, "critic_target": 5.117086009979248, "actor_ent": 1.3469475770950317, "actor_ent_scale": 0.0010000000474974513, "critic": 5.117359320831299, "fps": 109.37716380491676}
{"step": 15065500, "train_return": 18.0, "train_length": 1901.0, "train_total_steps": 3766375.0, "train_total_episodes": 1880.0, "train_loaded_steps": 1998403.0, "train_loaded_episodes": 1025.0}
{"step": 15072252, "train_return": 21.0, "train_length": 1688.0, "train_total_steps": 3768063.0, "train_total_episodes": 1881.0, "train_loaded_steps": 1998276.0, "train_loaded_episodes": 1025.0}
{"step": 15080316, "train_return": 16.0, "train_length": 2016.0, "train_total_steps": 3770079.0, "train_total_episodes": 1882.0, "train_loaded_steps": 1998513.0, "train_loaded_episodes": 1025.0}
{"step": 15087164, "train_return": 20.0, "train_length": 1712.0, "train_total_steps": 3771791.0, "train_total_episodes": 1883.0, "train_loaded_steps": 1998212.0, "train_loaded_episodes": 1025.0}
{"step": 15094256, "train_return": 20.0, "train_length": 1773.0, "train_total_steps": 3773564.0, "train_total_episodes": 1884.0, "train_loaded_steps": 1999985.0, "train_loaded_episodes": 1026.0}
{"step": 15099252, "kl_loss": 1.366628893661499, "image_loss": 3772.0, "reward_loss": 0.9191278021812439, "discount_loss": 0.007744935396313667, "model_kl": 1.366628864479065, "prior_ent": 26.827069250488282, "post_ent": 25.473242803955078, "model_loss": 3773.094543359375, "model_loss_scale": 17983.0784, "model_grad_norm": 5.115715719795227, "actor_loss": -0.004512916974083055, "actor_loss_scale": 5885447.3728, "actor_grad_norm": 0.03835234624445438, "critic_loss": 0.9210193078041077, "critic_loss_scale": 64067.9936, "critic_grad_norm": Infinity, "reward_mean": 0.007362955534795765, "reward_std": 0.08267549454569817, "reward_normed_mean": 0.007362955534795765, "reward_normed_std": 0.08267549454569817, "critic_slow": 5.069533525466919, "critic_target": 5.06776074295044, "actor_ent": 1.3765592449188233, "actor_ent_scale": 0.0010000000474974513, "critic": 5.068160905075073, "fps": 110.98708873593785}
{"step": 15101392, "train_return": 19.0, "train_length": 1784.0, "train_total_steps": 3775348.0, "train_total_episodes": 1885.0, "train_loaded_steps": 1999984.0, "train_loaded_episodes": 1026.0}
{"step": 15108228, "train_return": 20.0, "train_length": 1709.0, "train_total_steps": 3777057.0, "train_total_episodes": 1886.0, "train_loaded_steps": 1999786.0, "train_loaded_episodes": 1026.0}
{"step": 15116300, "train_return": 17.0, "train_length": 2018.0, "train_total_steps": 3779075.0, "train_total_episodes": 1887.0, "train_loaded_steps": 1999771.0, "train_loaded_episodes": 1026.0}
{"step": 15123460, "train_return": 19.0, "train_length": 1790.0, "train_total_steps": 3780865.0, "train_total_episodes": 1888.0, "train_loaded_steps": 1999269.0, "train_loaded_episodes": 1026.0}
{"step": 15130480, "train_return": 20.0, "train_length": 1755.0, "train_total_steps": 3782620.0, "train_total_episodes": 1889.0, "train_loaded_steps": 1999207.0, "train_loaded_episodes": 1026.0}
{"step": 15138412, "train_return": 17.0, "train_length": 1983.0, "train_total_steps": 3784603.0, "train_total_episodes": 1890.0, "train_loaded_steps": 1999368.0, "train_loaded_episodes": 1026.0}
{"step": 15139252, "kl_loss": 1.3473806440353393, "image_loss": 3772.0, "reward_loss": 0.9191374855041504, "discount_loss": 0.007741229914873839, "model_kl": 1.3473806093215943, "prior_ent": 26.67643942565918, "post_ent": 25.339626498413086, "model_loss": 3773.09261328125, "model_loss_scale": 18087.936, "model_grad_norm": Infinity, "actor_loss": -0.003967817187780747, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03928017536699772, "critic_loss": 0.9204857083320618, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.33750755581855774, "reward_mean": 0.007318647604016587, "reward_std": 0.08274646109342575, "reward_normed_mean": 0.007318647604016587, "reward_normed_std": 0.08274646109342575, "critic_slow": 5.011650689315796, "critic_target": 5.010619121932983, "actor_ent": 1.3699908443450928, "actor_ent_scale": 0.0010000000474974513, "critic": 5.0105009944915775, "fps": 112.05107216905725}
{"step": 15146100, "train_return": 20.0, "train_length": 1922.0, "train_total_steps": 3786525.0, "train_total_episodes": 1891.0, "train_loaded_steps": 1999041.0, "train_loaded_episodes": 1026.0}
{"step": 15153120, "train_return": 20.0, "train_length": 1755.0, "train_total_steps": 3788280.0, "train_total_episodes": 1892.0, "train_loaded_steps": 1998810.0, "train_loaded_episodes": 1026.0}
{"step": 15162132, "train_return": 13.0, "train_length": 2253.0, "train_total_steps": 3790533.0, "train_total_episodes": 1893.0, "train_loaded_steps": 1998943.0, "train_loaded_episodes": 1026.0}
{"step": 15170104, "train_return": 17.0, "train_length": 1993.0, "train_total_steps": 3792526.0, "train_total_episodes": 1894.0, "train_loaded_steps": 1999033.0, "train_loaded_episodes": 1026.0}
{"step": 15177144, "train_return": 20.0, "train_length": 1760.0, "train_total_steps": 3794286.0, "train_total_episodes": 1895.0, "train_loaded_steps": 1998520.0, "train_loaded_episodes": 1026.0}
{"step": 15179252, "kl_loss": 1.3571256511688232, "image_loss": 3772.0, "reward_loss": 0.919124675655365, "discount_loss": 0.007743133945763111, "model_kl": 1.3571256204605102, "prior_ent": 26.689033197021484, "post_ent": 25.34364536743164, "model_loss": 3773.09358046875, "model_loss_scale": 16384.0, "model_grad_norm": 5.115525919532776, "actor_loss": -0.0037699403075035663, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03798582071065903, "critic_loss": 0.9202796913146972, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.3155956397891045, "reward_mean": 0.007398951653018594, "reward_std": 0.08310979109406472, "reward_normed_mean": 0.007398951653018594, "reward_normed_std": 0.08310979109406472, "critic_slow": 4.958885404205322, "critic_target": 4.9573015701293945, "actor_ent": 1.3806443885803223, "actor_ent_scale": 0.0010000000474974513, "critic": 4.957233019638061, "fps": 112.2349946853096}
{"step": 15184528, "train_return": 19.0, "train_length": 1846.0, "train_total_steps": 3796132.0, "train_total_episodes": 1896.0, "train_loaded_steps": 1998268.0, "train_loaded_episodes": 1026.0}
{"step": 15191988, "train_return": 18.0, "train_length": 1865.0, "train_total_steps": 3797997.0, "train_total_episodes": 1897.0, "train_loaded_steps": 1998049.0, "train_loaded_episodes": 1026.0}
{"step": 15199516, "train_return": 19.0, "train_length": 1882.0, "train_total_steps": 3799879.0, "train_total_episodes": 1898.0, "train_loaded_steps": 1999931.0, "train_loaded_episodes": 1027.0}
{"step": 15209356, "train_return": 11.0, "train_length": 2460.0, "train_total_steps": 3802339.0, "train_total_episodes": 1899.0, "train_loaded_steps": 1997699.0, "train_loaded_episodes": 1026.0}
{"step": 15216204, "train_return": 20.0, "train_length": 1712.0, "train_total_steps": 3804051.0, "train_total_episodes": 1900.0, "train_loaded_steps": 1999411.0, "train_loaded_episodes": 1027.0}
{"step": 15219252, "kl_loss": 1.3530511131286622, "image_loss": 3772.0, "reward_loss": 0.9191174865722657, "discount_loss": 0.007742224257439375, "model_kl": 1.3530510820388795, "prior_ent": 26.638194677734376, "post_ent": 25.292868643188477, "model_loss": 3773.09316171875, "model_loss_scale": 16384.0, "model_grad_norm": 4.97096716594696, "actor_loss": -0.0035521980867713864, "actor_loss_scale": 8912057.1392, "actor_grad_norm": Infinity, "critic_loss": 0.9207824832916259, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.35760623968839644, "reward_mean": 0.00728195837480016, "reward_std": 0.08227464200258255, "reward_normed_mean": 0.00728195837480016, "reward_normed_std": 0.08227464200258255, "critic_slow": 4.9983003662109375, "critic_target": 4.997365100479126, "actor_ent": 1.365486524963379, "actor_ent_scale": 0.0010000000474974513, "critic": 4.9973233150482175, "fps": 112.93637064439663}
{"step": 15225060, "train_return": 15.0, "train_length": 2214.0, "train_total_steps": 3806265.0, "train_total_episodes": 1901.0, "train_loaded_steps": 1999723.0, "train_loaded_episodes": 1027.0}
{"step": 15233152, "train_return": 18.0, "train_length": 2023.0, "train_total_steps": 3808288.0, "train_total_episodes": 1902.0, "train_loaded_steps": 1999769.0, "train_loaded_episodes": 1027.0}
{"step": 15240248, "train_return": 19.0, "train_length": 1774.0, "train_total_steps": 3810062.0, "train_total_episodes": 1903.0, "train_loaded_steps": 1999776.0, "train_loaded_episodes": 1027.0}
{"step": 15247532, "train_return": 19.0, "train_length": 1821.0, "train_total_steps": 3811883.0, "train_total_episodes": 1904.0, "train_loaded_steps": 1999747.0, "train_loaded_episodes": 1027.0}
{"step": 15254736, "train_return": 20.0, "train_length": 1801.0, "train_total_steps": 3813684.0, "train_total_episodes": 1905.0, "train_loaded_steps": 1999198.0, "train_loaded_episodes": 1027.0}
{"step": 15259252, "kl_loss": 1.3590862577438354, "image_loss": 3772.0, "reward_loss": 0.9191320551872253, "discount_loss": 0.007769179429113865, "model_kl": 1.3590862270355224, "prior_ent": 26.540978829956053, "post_ent": 25.19641957702637, "model_loss": 3773.093923828125, "model_loss_scale": 17825.792, "model_grad_norm": Infinity, "actor_loss": -0.0025215290589869254, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03752350971996784, "critic_loss": 0.920675283241272, "critic_loss_scale": 60450.4064, "critic_grad_norm": 0.3560953385829925, "reward_mean": 0.007444223977089859, "reward_std": 0.08306271136403084, "reward_normed_mean": 0.007444223977089859, "reward_normed_std": 0.08306271136403084, "critic_slow": 5.03037279586792, "critic_target": 5.031353482055664, "actor_ent": 1.3840321355819702, "actor_ent_scale": 0.0010000000474974513, "critic": 5.031264112472535, "fps": 110.69429369942658}
{"step": 15262856, "train_return": 17.0, "train_length": 2030.0, "train_total_steps": 3815714.0, "train_total_episodes": 1906.0, "train_loaded_steps": 1999315.0, "train_loaded_episodes": 1027.0}
{"step": 15270128, "train_return": 19.0, "train_length": 1818.0, "train_total_steps": 3817532.0, "train_total_episodes": 1907.0, "train_loaded_steps": 1999214.0, "train_loaded_episodes": 1027.0}
{"step": 15278288, "train_return": 17.0, "train_length": 2040.0, "train_total_steps": 3819572.0, "train_total_episodes": 1908.0, "train_loaded_steps": 1999333.0, "train_loaded_episodes": 1027.0}
{"step": 15285284, "train_return": 20.0, "train_length": 1749.0, "train_total_steps": 3821321.0, "train_total_episodes": 1909.0, "train_loaded_steps": 1998744.0, "train_loaded_episodes": 1027.0}
{"step": 15294376, "train_return": 14.0, "train_length": 2273.0, "train_total_steps": 3823594.0, "train_total_episodes": 1910.0, "train_loaded_steps": 1998832.0, "train_loaded_episodes": 1027.0}
{"step": 15299252, "kl_loss": 1.4398398345947265, "image_loss": 3772.0, "reward_loss": 0.9191582075119018, "discount_loss": 0.007744492623209954, "model_kl": 1.4398398008346558, "prior_ent": 27.03455883483887, "post_ent": 25.62327594604492, "model_loss": 3773.10189453125, "model_loss_scale": 16384.0, "model_grad_norm": 4.962829212188721, "actor_loss": -0.0034206383876502515, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03998209290504456, "critic_loss": 0.9227919928550721, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.39543437622785566, "reward_mean": 0.007495393895357847, "reward_std": 0.0824949126958847, "reward_normed_mean": 0.007495393895357847, "reward_normed_std": 0.0824949126958847, "critic_slow": 5.070619730377198, "critic_target": 5.070250368499756, "actor_ent": 1.372896999168396, "actor_ent_scale": 0.0010000000474974513, "critic": 5.0699555252075195, "fps": 112.59673057598839}
{"step": 15301680, "train_return": 19.0, "train_length": 1826.0, "train_total_steps": 3825420.0, "train_total_episodes": 1911.0, "train_loaded_steps": 1998863.0, "train_loaded_episodes": 1027.0}
{"step": 15308392, "train_return": 20.0, "train_length": 1678.0, "train_total_steps": 3827098.0, "train_total_episodes": 1912.0, "train_loaded_steps": 1998566.0, "train_loaded_episodes": 1027.0}
{"step": 15315920, "train_return": 18.0, "train_length": 1882.0, "train_total_steps": 3828980.0, "train_total_episodes": 1913.0, "train_loaded_steps": 1998710.0, "train_loaded_episodes": 1027.0}
{"step": 15323232, "train_return": 19.0, "train_length": 1828.0, "train_total_steps": 3830808.0, "train_total_episodes": 1914.0, "train_loaded_steps": 1998617.0, "train_loaded_episodes": 1027.0}
{"step": 15330600, "train_return": 18.0, "train_length": 1842.0, "train_total_steps": 3832650.0, "train_total_episodes": 1915.0, "train_loaded_steps": 1998615.0, "train_loaded_episodes": 1027.0}
{"step": 15337520, "train_return": 21.0, "train_length": 1730.0, "train_total_steps": 3834380.0, "train_total_episodes": 1916.0, "train_loaded_steps": 1998194.0, "train_loaded_episodes": 1027.0}
{"step": 15339252, "kl_loss": 1.350072484779358, "image_loss": 3772.0, "reward_loss": 0.9191289161682129, "discount_loss": 0.007741806871443987, "model_kl": 1.3500724504470825, "prior_ent": 26.76635266418457, "post_ent": 25.422856100463868, "model_loss": 3773.0928765625, "model_loss_scale": 16384.0, "model_grad_norm": 5.058818116950989, "actor_loss": -0.005933558426355011, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.0384008352547884, "critic_loss": 0.9207069573402404, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.33946148792505265, "reward_mean": 0.0072943499767687174, "reward_std": 0.08265232347249984, "reward_normed_mean": 0.0072943499767687174, "reward_normed_std": 0.08265232347249984, "critic_slow": 5.174073607254028, "critic_target": 5.1734503044128415, "actor_ent": 1.357701003074646, "actor_ent_scale": 0.0010000000474974513, "critic": 5.173302393341064, "fps": 113.72263198792446}
{"step": 15345200, "train_return": 20.0, "train_length": 1920.0, "train_total_steps": 3836300.0, "train_total_episodes": 1917.0, "train_loaded_steps": 1998165.0, "train_loaded_episodes": 1027.0}
{"step": 15352328, "train_return": 19.0, "train_length": 1782.0, "train_total_steps": 3838082.0, "train_total_episodes": 1918.0, "train_loaded_steps": 1999947.0, "train_loaded_episodes": 1028.0}
{"step": 15359868, "train_return": 18.0, "train_length": 1885.0, "train_total_steps": 3839967.0, "train_total_episodes": 1919.0, "train_loaded_steps": 1999273.0, "train_loaded_episodes": 1028.0}
{"step": 15367896, "train_return": 16.0, "train_length": 2007.0, "train_total_steps": 3841974.0, "train_total_episodes": 1920.0, "train_loaded_steps": 1999265.0, "train_loaded_episodes": 1028.0}
{"step": 15375960, "train_return": 17.0, "train_length": 2016.0, "train_total_steps": 3843990.0, "train_total_episodes": 1921.0, "train_loaded_steps": 1999299.0, "train_loaded_episodes": 1028.0}
{"step": 15379252, "kl_loss": 1.3359649311065673, "image_loss": 3772.0, "reward_loss": 0.9191071429252624, "discount_loss": 0.007742068968713284, "model_kl": 1.335964902305603, "prior_ent": 26.65695446777344, "post_ent": 25.32955051574707, "model_loss": 3773.091432421875, "model_loss_scale": 17091.7888, "model_grad_norm": Infinity, "actor_loss": -0.005498293337926589, "actor_loss_scale": 8616778.1376, "actor_grad_norm": Infinity, "critic_loss": 0.9211034938812256, "critic_loss_scale": 83099.648, "critic_grad_norm": Infinity, "reward_mean": 0.007259415806364268, "reward_std": 0.08286278528571128, "reward_normed_mean": 0.007259415806364268, "reward_normed_std": 0.08286278528571128, "critic_slow": 5.140245123672486, "critic_target": 5.138268144607544, "actor_ent": 1.3824336805343629, "actor_ent_scale": 0.0010000000474974513, "critic": 5.137288702774048, "fps": 114.04159308384008}
{"step": 15383472, "train_return": 19.0, "train_length": 1878.0, "train_total_steps": 3845868.0, "train_total_episodes": 1922.0, "train_loaded_steps": 1999132.0, "train_loaded_episodes": 1028.0}
{"step": 15390760, "train_return": 19.0, "train_length": 1822.0, "train_total_steps": 3847690.0, "train_total_episodes": 1923.0, "train_loaded_steps": 1998992.0, "train_loaded_episodes": 1028.0}
{"step": 15397820, "train_return": 19.0, "train_length": 1765.0, "train_total_steps": 3849455.0, "train_total_episodes": 1924.0, "train_loaded_steps": 1998810.0, "train_loaded_episodes": 1028.0}
{"step": 15404768, "train_return": 20.0, "train_length": 1737.0, "train_total_steps": 3851192.0, "train_total_episodes": 1925.0, "train_loaded_steps": 1998480.0, "train_loaded_episodes": 1028.0}
{"step": 15412796, "train_return": 17.0, "train_length": 2007.0, "train_total_steps": 3853199.0, "train_total_episodes": 1926.0, "train_loaded_steps": 1998481.0, "train_loaded_episodes": 1028.0}
{"step": 15419252, "kl_loss": 1.3777968980789184, "image_loss": 3772.0, "reward_loss": 0.9191404596328735, "discount_loss": 0.007765354941785336, "model_kl": 1.3777968645095826, "prior_ent": 26.594763180541992, "post_ent": 25.232762155151367, "model_loss": 3773.095780078125, "model_loss_scale": 16384.0, "model_grad_norm": 4.905384139823914, "actor_loss": -0.004780821202945663, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03990517045855522, "critic_loss": 0.9222644135475159, "critic_loss_scale": 16384.0, "critic_grad_norm": 0.38417423387765887, "reward_mean": 0.007250035705254413, "reward_std": 0.08333132882118226, "reward_normed_mean": 0.007250035705254413, "reward_normed_std": 0.08333132882118226, "critic_slow": 5.077844596481323, "critic_target": 5.076306465148925, "actor_ent": 1.379482749557495, "actor_ent_scale": 0.0010000000474974513, "critic": 5.075841223526001, "fps": 113.66474119276447}
{"step": 15420520, "train_return": 17.0, "train_length": 1931.0, "train_total_steps": 3855130.0, "train_total_episodes": 1927.0, "train_loaded_steps": 1998131.0, "train_loaded_episodes": 1028.0}
{"step": 15427356, "train_return": 20.0, "train_length": 1709.0, "train_total_steps": 3856839.0, "train_total_episodes": 1928.0, "train_loaded_steps": 1999840.0, "train_loaded_episodes": 1029.0}
{"step": 15435656, "train_return": 16.0, "train_length": 2075.0, "train_total_steps": 3858914.0, "train_total_episodes": 1929.0, "train_loaded_steps": 1999937.0, "train_loaded_episodes": 1029.0}
{"step": 15444620, "train_return": 14.0, "train_length": 2241.0, "train_total_steps": 3861155.0, "train_total_episodes": 1930.0, "train_loaded_steps": 1998537.0, "train_loaded_episodes": 1028.0}
{"step": 15451896, "train_return": 19.0, "train_length": 1819.0, "train_total_steps": 3862974.0, "train_total_episodes": 1931.0, "train_loaded_steps": 1998337.0, "train_loaded_episodes": 1028.0}
{"step": 15459252, "kl_loss": 1.3692720420837403, "image_loss": 3772.0, "reward_loss": 0.9191250056266784, "discount_loss": 0.007757556715607643, "model_kl": 1.3692720085144043, "prior_ent": 26.586218838500976, "post_ent": 25.229241903686525, "model_loss": 3773.094865625, "model_loss_scale": 16384.0, "model_grad_norm": 4.847387813949585, "actor_loss": -0.007254676260797706, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.037955819568037986, "critic_loss": 0.9207929595947265, "critic_loss_scale": 16384.0, "critic_grad_norm": 0.33084944573640823, "reward_mean": 0.007440957208285545, "reward_std": 0.08312988097071648, "reward_normed_mean": 0.007440957208285545, "reward_normed_std": 0.08312988097071648, "critic_slow": 5.0930637256622315, "critic_target": 5.091309534072876, "actor_ent": 1.4067112394332886, "actor_ent_scale": 0.0010000000474974513, "critic": 5.090968505859375, "fps": 111.90192798776837}
{"step": 15459728, "train_return": 19.0, "train_length": 1958.0, "train_total_steps": 3864932.0, "train_total_episodes": 1932.0, "train_loaded_steps": 1998136.0, "train_loaded_episodes": 1028.0}
{"step": 15467804, "train_return": 16.0, "train_length": 2019.0, "train_total_steps": 3866951.0, "train_total_episodes": 1933.0, "train_loaded_steps": 1997755.0, "train_loaded_episodes": 1028.0}
{"step": 15477344, "train_return": 10.0, "train_length": 2385.0, "train_total_steps": 3869336.0, "train_total_episodes": 1934.0, "train_loaded_steps": 1998016.0, "train_loaded_episodes": 1028.0}
{"step": 15484856, "train_return": 18.0, "train_length": 1878.0, "train_total_steps": 3871214.0, "train_total_episodes": 1935.0, "train_loaded_steps": 1999894.0, "train_loaded_episodes": 1029.0}
{"step": 15491816, "train_return": 20.0, "train_length": 1740.0, "train_total_steps": 3872954.0, "train_total_episodes": 1936.0, "train_loaded_steps": 1999232.0, "train_loaded_episodes": 1029.0}
{"step": 15499252, "kl_loss": 1.3898525945663451, "image_loss": 3772.025967578125, "reward_loss": 0.9191605533599854, "discount_loss": 0.007765980176627636, "model_kl": 1.3898525648117066, "prior_ent": 26.56703441772461, "post_ent": 25.20076469116211, "model_loss": 3773.12297421875, "model_loss_scale": 10074.112, "model_grad_norm": Infinity, "actor_loss": -0.002303967931335501, "actor_loss_scale": 7992665.7024, "actor_grad_norm": Infinity, "critic_loss": 0.921851676273346, "critic_loss_scale": 16384.0, "critic_grad_norm": 0.34448339161872865, "reward_mean": 0.007351496804179624, "reward_std": 0.08233525968194008, "reward_normed_mean": 0.007351496804179624, "reward_normed_std": 0.08233525968194008, "critic_slow": 5.155458031082153, "critic_target": 5.155238689422608, "actor_ent": 1.4093062755584718, "actor_ent_scale": 0.0010000000474974513, "critic": 5.154807406997681, "fps": 112.94152884517379}
{"step": 15499720, "train_return": 16.0, "train_length": 1976.0, "train_total_steps": 3874930.0, "train_total_episodes": 1937.0, "train_loaded_steps": 1999336.0, "train_loaded_episodes": 1029.0}
{"step": 15507776, "train_return": 16.0, "train_length": 2014.0, "train_total_steps": 3876944.0, "train_total_episodes": 1938.0, "train_loaded_steps": 1999345.0, "train_loaded_episodes": 1029.0}
{"step": 15515784, "train_return": 16.0, "train_length": 2002.0, "train_total_steps": 3878946.0, "train_total_episodes": 1939.0, "train_loaded_steps": 1999392.0, "train_loaded_episodes": 1029.0}
{"step": 15524060, "train_return": 16.0, "train_length": 2069.0, "train_total_steps": 3881015.0, "train_total_episodes": 1940.0, "train_loaded_steps": 1998959.0, "train_loaded_episodes": 1029.0}
{"step": 15532108, "train_return": 17.0, "train_length": 2012.0, "train_total_steps": 3883027.0, "train_total_episodes": 1941.0, "train_loaded_steps": 1998908.0, "train_loaded_episodes": 1029.0}
{"step": 15538812, "train_return": 20.0, "train_length": 1676.0, "train_total_steps": 3884703.0, "train_total_episodes": 1942.0, "train_loaded_steps": 1998480.0, "train_loaded_episodes": 1029.0}
{"step": 15539252, "kl_loss": 1.4031090591430664, "image_loss": 3772.0, "reward_loss": 0.9191458458900452, "discount_loss": 0.007769578769803047, "model_kl": 1.4031090223312377, "prior_ent": 26.720624212646484, "post_ent": 25.331724142456054, "model_loss": 3773.098335546875, "model_loss_scale": 256.0, "model_grad_norm": 3.0064089834213257, "actor_loss": 0.006960771512344945, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.04611996245682239, "critic_loss": 0.9264478226661682, "critic_loss_scale": 32532.0704, "critic_grad_norm": 0.40331541873812676, "reward_mean": 0.007296190021093935, "reward_std": 0.08229875474572182, "reward_normed_mean": 0.007296190021093935, "reward_normed_std": 0.08229875474572182, "critic_slow": 5.208761359024048, "critic_target": 5.215054912948609, "actor_ent": 1.3067508499145508, "actor_ent_scale": 0.0010000000474974513, "critic": 5.21481474647522, "fps": 114.88276610485015}
{"step": 15547100, "train_return": 15.0, "train_length": 2072.0, "train_total_steps": 3886775.0, "train_total_episodes": 1943.0, "train_loaded_steps": 1998401.0, "train_loaded_episodes": 1029.0}
{"step": 15553828, "train_return": 21.0, "train_length": 1682.0, "train_total_steps": 3888457.0, "train_total_episodes": 1944.0, "train_loaded_steps": 1998163.0, "train_loaded_episodes": 1029.0}
{"step": 15560656, "train_return": 20.0, "train_length": 1707.0, "train_total_steps": 3890164.0, "train_total_episodes": 1945.0, "train_loaded_steps": 1999870.0, "train_loaded_episodes": 1030.0}
{"step": 15568832, "train_return": 13.0, "train_length": 2044.0, "train_total_steps": 3892208.0, "train_total_episodes": 1946.0, "train_loaded_steps": 1998018.0, "train_loaded_episodes": 1029.0}
{"step": 15575480, "train_return": 21.0, "train_length": 1662.0, "train_total_steps": 3893870.0, "train_total_episodes": 1947.0, "train_loaded_steps": 1999680.0, "train_loaded_episodes": 1030.0}
{"step": 15579252, "kl_loss": 1.3579543487548829, "image_loss": 3772.0001921875, "reward_loss": 0.919112609577179, "discount_loss": 0.007755869883298874, "model_kl": 1.3579543155670166, "prior_ent": 26.537368426513673, "post_ent": 25.188081616210937, "model_loss": 3773.093896484375, "model_loss_scale": 256.0, "model_grad_norm": 4.125109346961975, "actor_loss": -0.0012118508093291894, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.03770416264533997, "critic_loss": 0.9205907120704651, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.3543480653345585, "reward_mean": 0.007361598235089332, "reward_std": 0.0829599006652832, "reward_normed_mean": 0.007361598235089332, "reward_normed_std": 0.0829599006652832, "critic_slow": 5.209341433334351, "critic_target": 5.208398224639892, "actor_ent": 1.337517579650879, "actor_ent_scale": 0.0010000000474974513, "critic": 5.207916855239868, "fps": 111.64443224033819}
{"step": 15582408, "train_return": 20.0, "train_length": 1732.0, "train_total_steps": 3895602.0, "train_total_episodes": 1948.0, "train_loaded_steps": 1999424.0, "train_loaded_episodes": 1030.0}
{"step": 15589512, "train_return": 20.0, "train_length": 1776.0, "train_total_steps": 3897378.0, "train_total_episodes": 1949.0, "train_loaded_steps": 1999145.0, "train_loaded_episodes": 1030.0}
{"step": 15597208, "train_return": 16.0, "train_length": 1924.0, "train_total_steps": 3899302.0, "train_total_episodes": 1950.0, "train_loaded_steps": 1999016.0, "train_loaded_episodes": 1030.0}
{"step": 15605148, "train_return": 18.0, "train_length": 1985.0, "train_total_steps": 3901287.0, "train_total_episodes": 1951.0, "train_loaded_steps": 1999182.0, "train_loaded_episodes": 1030.0}
{"step": 15612568, "train_return": 18.0, "train_length": 1855.0, "train_total_steps": 3903142.0, "train_total_episodes": 1952.0, "train_loaded_steps": 1999010.0, "train_loaded_episodes": 1030.0}
{"step": 15619252, "kl_loss": 1.361147567176819, "image_loss": 3772.0, "reward_loss": 0.9191388205528259, "discount_loss": 0.007767491007596254, "model_kl": 1.3611475381851197, "prior_ent": 26.553110583496093, "post_ent": 25.206738232421873, "model_loss": 3773.09412890625, "model_loss_scale": 300.2368, "model_grad_norm": 4.866645185089111, "actor_loss": -0.007179413856402971, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.03738447501957416, "critic_loss": 0.9198728119850159, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.3042615613758564, "reward_mean": 0.0072892872249241914, "reward_std": 0.08240155537724494, "reward_normed_mean": 0.0072892872249241914, "reward_normed_std": 0.08240155537724494, "critic_slow": 5.20424768409729, "critic_target": 5.2028559394836424, "actor_ent": 1.3650737426757813, "actor_ent_scale": 0.0010000000474974513, "critic": 5.202611410522461, "fps": 112.60302141930829}
{"step": 15620136, "train_return": 18.0, "train_length": 1892.0, "train_total_steps": 3905034.0, "train_total_episodes": 1953.0, "train_loaded_steps": 1999189.0, "train_loaded_episodes": 1030.0}
{"step": 15627024, "train_return": 20.0, "train_length": 1722.0, "train_total_steps": 3906756.0, "train_total_episodes": 1954.0, "train_loaded_steps": 1999097.0, "train_loaded_episodes": 1030.0}
{"step": 15635128, "train_return": 16.0, "train_length": 2026.0, "train_total_steps": 3908782.0, "train_total_episodes": 1955.0, "train_loaded_steps": 1999315.0, "train_loaded_episodes": 1030.0}
{"step": 15642784, "train_return": 18.0, "train_length": 1914.0, "train_total_steps": 3910696.0, "train_total_episodes": 1956.0, "train_loaded_steps": 1999464.0, "train_loaded_episodes": 1030.0}
{"step": 15649988, "train_return": 20.0, "train_length": 1801.0, "train_total_steps": 3912497.0, "train_total_episodes": 1957.0, "train_loaded_steps": 1999377.0, "train_loaded_episodes": 1030.0}
{"step": 15656880, "train_return": 19.0, "train_length": 1723.0, "train_total_steps": 3914220.0, "train_total_episodes": 1958.0, "train_loaded_steps": 1999147.0, "train_loaded_episodes": 1030.0}
{"step": 15659252, "kl_loss": 1.364651238822937, "image_loss": 3772.0, "reward_loss": 0.9191154733657837, "discount_loss": 0.007743044040352106, "model_kl": 1.3646512048721313, "prior_ent": 26.555335220336914, "post_ent": 25.199406216430663, "model_loss": 3773.094331640625, "model_loss_scale": 512.0, "model_grad_norm": 5.0910625673294065, "actor_loss": -0.0018979802898480558, "actor_loss_scale": 8173859.6352, "actor_grad_norm": 0.0366721312969923, "critic_loss": 0.919051060295105, "critic_loss_scale": 58510.5408, "critic_grad_norm": 0.3414280054926872, "reward_mean": 0.0072701846587704495, "reward_std": 0.08226471716165543, "reward_normed_mean": 0.0072701846587704495, "reward_normed_std": 0.08226471716165543, "critic_slow": 5.230266475677491, "critic_target": 5.230259604263305, "actor_ent": 1.3635397228240966, "actor_ent_scale": 0.0010000000474974513, "critic": 5.229658364105225, "fps": 114.81210924403247}
{"step": 15664776, "train_return": 18.0, "train_length": 1974.0, "train_total_steps": 3916194.0, "train_total_episodes": 1959.0, "train_loaded_steps": 1999129.0, "train_loaded_episodes": 1030.0}
{"step": 15672872, "train_return": 17.0, "train_length": 2024.0, "train_total_steps": 3918218.0, "train_total_episodes": 1960.0, "train_loaded_steps": 1998919.0, "train_loaded_episodes": 1030.0}
{"step": 15680784, "train_return": 18.0, "train_length": 1978.0, "train_total_steps": 3920196.0, "train_total_episodes": 1961.0, "train_loaded_steps": 1999045.0, "train_loaded_episodes": 1030.0}
{"step": 15690764, "train_return": 11.0, "train_length": 2495.0, "train_total_steps": 3922691.0, "train_total_episodes": 1962.0, "train_loaded_steps": 1999014.0, "train_loaded_episodes": 1030.0}
{"step": 15698728, "train_return": 16.0, "train_length": 1991.0, "train_total_steps": 3924682.0, "train_total_episodes": 1963.0, "train_loaded_steps": 1998957.0, "train_loaded_episodes": 1030.0}
{"step": 15699252, "kl_loss": 1.415450281715393, "image_loss": 3772.0, "reward_loss": 0.9191439893722534, "discount_loss": 0.007742049986869097, "model_kl": 1.4154502517700196, "prior_ent": 26.68982952270508, "post_ent": 25.299441400146485, "model_loss": 3773.099424609375, "model_loss_scale": 512.0, "model_grad_norm": 5.2055672260284425, "actor_loss": -0.006923957080184482, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.036836739587783815, "critic_loss": 0.9197957751274108, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.31068835661411287, "reward_mean": 0.00720608126083389, "reward_std": 0.0820186465203762, "reward_normed_mean": 0.00720608126083389, "reward_normed_std": 0.0820186465203762, "critic_slow": 5.244978488540649, "critic_target": 5.244104605102539, "actor_ent": 1.2813375423431397, "actor_ent_scale": 0.0010000000474974513, "critic": 5.243646557998657, "fps": 116.16675807661802}
{"step": 15706344, "train_return": 17.0, "train_length": 1904.0, "train_total_steps": 3926586.0, "train_total_episodes": 1964.0, "train_loaded_steps": 1999064.0, "train_loaded_episodes": 1030.0}
{"step": 15714040, "train_return": 17.0, "train_length": 1924.0, "train_total_steps": 3928510.0, "train_total_episodes": 1965.0, "train_loaded_steps": 1999255.0, "train_loaded_episodes": 1030.0}
{"step": 15721440, "train_return": 18.0, "train_length": 1850.0, "train_total_steps": 3930360.0, "train_total_episodes": 1966.0, "train_loaded_steps": 1999148.0, "train_loaded_episodes": 1030.0}
{"step": 15730084, "train_return": 14.0, "train_length": 2161.0, "train_total_steps": 3932521.0, "train_total_episodes": 1967.0, "train_loaded_steps": 1999610.0, "train_loaded_episodes": 1030.0}
{"step": 15738152, "train_return": 18.0, "train_length": 2017.0, "train_total_steps": 3934538.0, "train_total_episodes": 1968.0, "train_loaded_steps": 1999553.0, "train_loaded_episodes": 1030.0}
{"step": 15739252, "kl_loss": 1.357569965171814, "image_loss": 3772.0, "reward_loss": 0.9191345046043397, "discount_loss": 0.0077430655673146245, "model_kl": 1.3575699321746826, "prior_ent": 26.50702796020508, "post_ent": 25.159714123535156, "model_loss": 3773.09363125, "model_loss_scale": 512.0, "model_grad_norm": 5.20654171333313, "actor_loss": -0.004336244466286007, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03441114660203457, "critic_loss": 0.9185250639915467, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.315821026301384, "reward_mean": 0.007283852133713663, "reward_std": 0.08244370511174202, "reward_normed_mean": 0.007283852133713663, "reward_normed_std": 0.08244370511174202, "critic_slow": 5.296045027160645, "critic_target": 5.295231716918945, "actor_ent": 1.3776186080932618, "actor_ent_scale": 0.0010000000474974513, "critic": 5.294873566818238, "fps": 113.39286630215882}
{"step": 15745812, "train_return": 18.0, "train_length": 1915.0, "train_total_steps": 3936453.0, "train_total_episodes": 1969.0, "train_loaded_steps": 1999574.0, "train_loaded_episodes": 1030.0}
{"step": 15754520, "train_return": 15.0, "train_length": 2177.0, "train_total_steps": 3938630.0, "train_total_episodes": 1970.0, "train_loaded_steps": 1999947.0, "train_loaded_episodes": 1030.0}
{"step": 15761696, "train_return": 19.0, "train_length": 1794.0, "train_total_steps": 3940424.0, "train_total_episodes": 1971.0, "train_loaded_steps": 1998001.0, "train_loaded_episodes": 1029.0}
{"step": 15768524, "train_return": 20.0, "train_length": 1707.0, "train_total_steps": 3942131.0, "train_total_episodes": 1972.0, "train_loaded_steps": 1999708.0, "train_loaded_episodes": 1030.0}
{"step": 15776336, "train_return": 18.0, "train_length": 1953.0, "train_total_steps": 3944084.0, "train_total_episodes": 1973.0, "train_loaded_steps": 1999573.0, "train_loaded_episodes": 1030.0}
{"step": 15779252, "kl_loss": 1.3899209642410277, "image_loss": 3772.0, "reward_loss": 0.9191474915504455, "discount_loss": 0.0077660789012908935, "model_kl": 1.3899209331512452, "prior_ent": 26.5267385925293, "post_ent": 25.152428518676757, "model_loss": 3773.097002734375, "model_loss_scale": 1010.0736, "model_grad_norm": 5.277320154953003, "actor_loss": -0.00676681020531978, "actor_loss_scale": 7348420.608, "actor_grad_norm": Infinity, "critic_loss": 0.9213090299606324, "critic_loss_scale": 71303.168, "critic_grad_norm": Infinity, "reward_mean": 0.00736743688996512, "reward_std": 0.08242877050638199, "reward_normed_mean": 0.00736743688996512, "reward_normed_std": 0.08242877050638199, "critic_slow": 5.256489025115966, "critic_target": 5.255912365341186, "actor_ent": 1.3278097007751466, "actor_ent_scale": 0.0010000000474974513, "critic": 5.255405857849121, "fps": 114.39835409228404}
{"step": 15784480, "train_return": 17.0, "train_length": 2036.0, "train_total_steps": 3946120.0, "train_total_episodes": 1974.0, "train_loaded_steps": 1999258.0, "train_loaded_episodes": 1030.0}
{"step": 15791104, "train_return": 21.0, "train_length": 1656.0, "train_total_steps": 3947776.0, "train_total_episodes": 1975.0, "train_loaded_steps": 1999140.0, "train_loaded_episodes": 1030.0}
{"step": 15798652, "train_return": 17.0, "train_length": 1887.0, "train_total_steps": 3949663.0, "train_total_episodes": 1976.0, "train_loaded_steps": 1999068.0, "train_loaded_episodes": 1030.0}
{"step": 15806832, "train_return": 18.0, "train_length": 2045.0, "train_total_steps": 3951708.0, "train_total_episodes": 1977.0, "train_loaded_steps": 1999105.0, "train_loaded_episodes": 1030.0}
{"step": 15814556, "train_return": 17.0, "train_length": 1931.0, "train_total_steps": 3953639.0, "train_total_episodes": 1978.0, "train_loaded_steps": 1999066.0, "train_loaded_episodes": 1030.0}
{"step": 15819252, "kl_loss": 1.3644889719009399, "image_loss": 3772.0, "reward_loss": 0.9191322256088257, "discount_loss": 0.007792562033236027, "model_kl": 1.3644889394760131, "prior_ent": 26.595499032592773, "post_ent": 25.24311910095215, "model_loss": 3773.094583203125, "model_loss_scale": 1024.0, "model_grad_norm": 5.184681358337403, "actor_loss": -0.004434804106797674, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.03663329834938049, "critic_loss": 0.9193948369979859, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.32920626114606855, "reward_mean": 0.007227813922427595, "reward_std": 0.08200332927703857, "reward_normed_mean": 0.007227813922427595, "reward_normed_std": 0.08200332927703857, "critic_slow": 5.263302107620239, "critic_target": 5.261613214111328, "actor_ent": 1.3507176765441895, "actor_ent_scale": 0.0010000000474974513, "critic": 5.261252014541626, "fps": 112.56628761135563}
{"step": 15822844, "train_return": 17.0, "train_length": 2072.0, "train_total_steps": 3955711.0, "train_total_episodes": 1979.0, "train_loaded_steps": 1999131.0, "train_loaded_episodes": 1030.0}
{"step": 15830308, "train_return": 20.0, "train_length": 1866.0, "train_total_steps": 3957577.0, "train_total_episodes": 1980.0, "train_loaded_steps": 1999120.0, "train_loaded_episodes": 1030.0}
{"step": 15837468, "train_return": 20.0, "train_length": 1790.0, "train_total_steps": 3959367.0, "train_total_episodes": 1981.0, "train_loaded_steps": 1999067.0, "train_loaded_episodes": 1030.0}
{"step": 15846064, "train_return": 16.0, "train_length": 2149.0, "train_total_steps": 3961516.0, "train_total_episodes": 1982.0, "train_loaded_steps": 1999265.0, "train_loaded_episodes": 1030.0}
{"step": 15854060, "train_return": 16.0, "train_length": 1999.0, "train_total_steps": 3963515.0, "train_total_episodes": 1983.0, "train_loaded_steps": 1999418.0, "train_loaded_episodes": 1030.0}
{"step": 15859252, "kl_loss": 1.370945520401001, "image_loss": 3772.0, "reward_loss": 0.9190944567680359, "discount_loss": 0.007760160405188799, "model_kl": 1.3709454908370973, "prior_ent": 26.528046075439452, "post_ent": 25.1697662109375, "model_loss": 3773.095017578125, "model_loss_scale": 1024.0, "model_grad_norm": 5.184450406837463, "actor_loss": -0.0059559525626806135, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.03524465634971857, "critic_loss": 0.9196280155181885, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.3366472820818424, "reward_mean": 0.007278093415312469, "reward_std": 0.08278650524616242, "reward_normed_mean": 0.007278093415312469, "reward_normed_std": 0.08278650524616242, "critic_slow": 5.261993916320801, "critic_target": 5.260772729110718, "actor_ent": 1.3725902774810792, "actor_ent_scale": 0.0010000000474974513, "critic": 5.260499979782105, "fps": 111.84778514156697}
{"step": 15861712, "train_return": 17.0, "train_length": 1913.0, "train_total_steps": 3965428.0, "train_total_episodes": 1984.0, "train_loaded_steps": 1999359.0, "train_loaded_episodes": 1030.0}
{"step": 15869428, "train_return": 18.0, "train_length": 1929.0, "train_total_steps": 3967357.0, "train_total_episodes": 1985.0, "train_loaded_steps": 1999140.0, "train_loaded_episodes": 1030.0}
{"step": 15876132, "train_return": 21.0, "train_length": 1676.0, "train_total_steps": 3969033.0, "train_total_episodes": 1986.0, "train_loaded_steps": 1998712.0, "train_loaded_episodes": 1030.0}
{"step": 15885140, "train_return": 15.0, "train_length": 2252.0, "train_total_steps": 3971285.0, "train_total_episodes": 1987.0, "train_loaded_steps": 1999191.0, "train_loaded_episodes": 1030.0}
{"step": 15893356, "train_return": 17.0, "train_length": 2054.0, "train_total_steps": 3973339.0, "train_total_episodes": 1988.0, "train_loaded_steps": 1999165.0, "train_loaded_episodes": 1030.0}
{"step": 15899252, "kl_loss": 1.3383804624557496, "image_loss": 3772.0, "reward_loss": 0.9191145698547363, "discount_loss": 0.007743143279105425, "model_kl": 1.3383804315567016, "prior_ent": 26.400124697875977, "post_ent": 25.068651837158203, "model_loss": 3773.09169375, "model_loss_scale": 1815.3472, "model_grad_norm": 5.1299840259552, "actor_loss": -0.0016347296974883647, "actor_loss_scale": 5509637.7344, "actor_grad_norm": 0.03610734446048736, "critic_loss": 0.9186988949775696, "critic_loss_scale": 85039.5136, "critic_grad_norm": 0.2833637606561184, "reward_mean": 0.007402803193824366, "reward_std": 0.08242351685166359, "reward_normed_mean": 0.007402803193824366, "reward_normed_std": 0.08242351685166359, "critic_slow": 5.319736833190918, "critic_target": 5.320817484283447, "actor_ent": 1.3962877298355103, "actor_ent_scale": 0.0010000000474974513, "critic": 5.320447792434693, "fps": 113.80337635991835}
{"step": 15902164, "train_return": 17.0, "train_length": 2202.0, "train_total_steps": 3975541.0, "train_total_episodes": 1989.0, "train_loaded_steps": 1999382.0, "train_loaded_episodes": 1030.0}
{"step": 15909664, "train_return": 18.0, "train_length": 1875.0, "train_total_steps": 3977416.0, "train_total_episodes": 1990.0, "train_loaded_steps": 1999330.0, "train_loaded_episodes": 1030.0}
{"step": 15917356, "train_return": 20.0, "train_length": 1923.0, "train_total_steps": 3979339.0, "train_total_episodes": 1991.0, "train_loaded_steps": 1999464.0, "train_loaded_episodes": 1030.0}
{"step": 15924732, "train_return": 19.0, "train_length": 1844.0, "train_total_steps": 3981183.0, "train_total_episodes": 1992.0, "train_loaded_steps": 1999049.0, "train_loaded_episodes": 1030.0}
{"step": 15932304, "train_return": 19.0, "train_length": 1893.0, "train_total_steps": 3983076.0, "train_total_episodes": 1993.0, "train_loaded_steps": 1999032.0, "train_loaded_episodes": 1030.0}
{"step": 15939252, "kl_loss": 1.3662322954177857, "image_loss": 3772.0, "reward_loss": 0.9191651627540588, "discount_loss": 0.007808259432017803, "model_kl": 1.3662322645187377, "prior_ent": 26.583716983032225, "post_ent": 25.231065881347657, "model_loss": 3773.094869921875, "model_loss_scale": 2048.0, "model_grad_norm": 5.102411476135254, "actor_loss": -0.0017286916069453582, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03895310870409012, "critic_loss": 0.9223992755889893, "critic_loss_scale": 82732.6464, "critic_grad_norm": Infinity, "reward_mean": 0.007356248251514626, "reward_std": 0.08224267485141754, "reward_normed_mean": 0.007356248251514626, "reward_normed_std": 0.08224267485141754, "critic_slow": 5.323925096511841, "critic_target": 5.325339093399048, "actor_ent": 1.3180698862075806, "actor_ent_scale": 0.0010000000474974513, "critic": 5.325111165237427, "fps": 112.08245561397662}
{"step": 15939880, "train_return": 18.0, "train_length": 1894.0, "train_total_steps": 3984970.0, "train_total_episodes": 1994.0, "train_loaded_steps": 1998947.0, "train_loaded_episodes": 1030.0}
{"step": 15948896, "train_return": 15.0, "train_length": 2254.0, "train_total_steps": 3987224.0, "train_total_episodes": 1995.0, "train_loaded_steps": 1999437.0, "train_loaded_episodes": 1030.0}
{"step": 15955540, "train_return": 21.0, "train_length": 1661.0, "train_total_steps": 3988885.0, "train_total_episodes": 1996.0, "train_loaded_steps": 1999256.0, "train_loaded_episodes": 1030.0}
{"step": 15963124, "train_return": 18.0, "train_length": 1896.0, "train_total_steps": 3990781.0, "train_total_episodes": 1997.0, "train_loaded_steps": 1999109.0, "train_loaded_episodes": 1030.0}
{"step": 15971508, "train_return": 17.0, "train_length": 2096.0, "train_total_steps": 3992877.0, "train_total_episodes": 1998.0, "train_loaded_steps": 1999237.0, "train_loaded_episodes": 1030.0}
{"step": 15978936, "train_return": 19.0, "train_length": 1857.0, "train_total_steps": 3994734.0, "train_total_episodes": 1999.0, "train_loaded_steps": 1999156.0, "train_loaded_episodes": 1030.0}
{"step": 15979252, "kl_loss": 1.3536324985504151, "image_loss": 3772.0, "reward_loss": 0.9191256175994873, "discount_loss": 0.007764068978279829, "model_kl": 1.3536324668884276, "prior_ent": 26.669730435180664, "post_ent": 25.32540061035156, "model_loss": 3773.0933546875, "model_loss_scale": 2048.0, "model_grad_norm": 4.951910710906982, "actor_loss": -0.002006266583071556, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03626511351764202, "critic_loss": 0.9198996940612792, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.278240301156044, "reward_mean": 0.0072946098526241255, "reward_std": 0.08243605315685272, "reward_normed_mean": 0.0072946098526241255, "reward_normed_std": 0.08243605315685272, "critic_slow": 5.29103408164978, "critic_target": 5.290919798660278, "actor_ent": 1.3756366449356079, "actor_ent_scale": 0.0010000000474974513, "critic": 5.290459257507324, "fps": 114.26289519769941}
{"step": 15987240, "train_return": 14.0, "train_length": 2076.0, "train_total_steps": 3996810.0, "train_total_episodes": 2000.0, "train_loaded_steps": 1999302.0, "train_loaded_episodes": 1030.0}
{"step": 15995900, "train_return": 17.0, "train_length": 2165.0, "train_total_steps": 3998975.0, "train_total_episodes": 2001.0, "train_loaded_steps": 1999803.0, "train_loaded_episodes": 1030.0}
{"step": 16004440, "train_return": 16.0, "train_length": 2135.0, "train_total_steps": 4001110.0, "train_total_episodes": 2002.0, "train_loaded_steps": 1998286.0, "train_loaded_episodes": 1029.0}
{"step": 16012632, "train_return": 16.0, "train_length": 2048.0, "train_total_steps": 4003158.0, "train_total_episodes": 2003.0, "train_loaded_steps": 1998178.0, "train_loaded_episodes": 1029.0}
{"step": 16019252, "kl_loss": 1.6445373798370362, "image_loss": 3772.0, "reward_loss": 0.9191366878509521, "discount_loss": 0.007777301160991192, "model_kl": 1.6445373445510865, "prior_ent": 25.786142529296875, "post_ent": 24.18556416015625, "model_loss": 3773.122512109375, "model_loss_scale": 3221.0944, "model_grad_norm": 5.080168246459961, "actor_loss": 0.019366345829726198, "actor_loss_scale": 4731174.912, "actor_grad_norm": Infinity, "critic_loss": 0.9387431933403015, "critic_loss_scale": 36962.304, "critic_grad_norm": Infinity, "reward_mean": 0.007168555938440841, "reward_std": 0.08144613866209983, "reward_normed_mean": 0.007168555938440841, "reward_normed_std": 0.08144613866209983, "critic_slow": 5.244886308670044, "critic_target": 5.26168359336853, "actor_ent": 1.2456833169937134, "actor_ent_scale": 0.0010000000474974513, "critic": 5.261345471191406, "fps": 111.75877794995712}
{"step": 16020148, "train_return": 19.0, "train_length": 1879.0, "train_total_steps": 4005037.0, "train_total_episodes": 2004.0, "train_loaded_steps": 1998217.0, "train_loaded_episodes": 1029.0}
{"step": 16027916, "train_return": 17.0, "train_length": 1942.0, "train_total_steps": 4006979.0, "train_total_episodes": 2005.0, "train_loaded_steps": 1997754.0, "train_loaded_episodes": 1029.0}
{"step": 16036232, "train_return": 15.0, "train_length": 2079.0, "train_total_steps": 4009058.0, "train_total_episodes": 2006.0, "train_loaded_steps": 1999833.0, "train_loaded_episodes": 1030.0}
{"step": 16044312, "train_return": 15.0, "train_length": 2020.0, "train_total_steps": 4011078.0, "train_total_episodes": 2007.0, "train_loaded_steps": 1999814.0, "train_loaded_episodes": 1030.0}
{"step": 16051352, "train_return": 19.0, "train_length": 1760.0, "train_total_steps": 4012838.0, "train_total_episodes": 2008.0, "train_loaded_steps": 1999382.0, "train_loaded_episodes": 1030.0}
{"step": 16058248, "train_return": 20.0, "train_length": 1724.0, "train_total_steps": 4014562.0, "train_total_episodes": 2009.0, "train_loaded_steps": 1998900.0, "train_loaded_episodes": 1030.0}
{"step": 16059248, "eval_return": 20.0, "eval_length": 1715.0, "eval_total_steps": 39796.0, "eval_total_episodes": 20.0, "eval_loaded_steps": 39814.0, "eval_loaded_episodes": 20.0}
{"step": 16059252, "kl_loss": 1.3970971391677856, "image_loss": 3772.0002, "reward_loss": 0.9191289134979248, "discount_loss": 0.007745351435989142, "model_kl": 1.3970971057891846, "prior_ent": 26.424590698242188, "post_ent": 25.033463766479493, "model_loss": 3773.097803125, "model_loss_scale": 4096.0, "model_grad_norm": 5.161567590713501, "actor_loss": 0.014337534769062767, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.04749769463837147, "critic_loss": 0.9289500247001647, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.3765622115731239, "reward_mean": 0.007469706619996577, "reward_std": 0.08263147597908974, "reward_normed_mean": 0.007469706619996577, "reward_normed_std": 0.08263147597908974, "critic_slow": 5.3449025730133055, "critic_target": 5.3523367965698245, "actor_ent": 1.1794818462371826, "actor_ent_scale": 0.0010000000474974513, "critic": 5.352168383789063, "fps": 110.12465956217352}
{"step": 16064992, "train_return": 21.0, "train_length": 1686.0, "train_total_steps": 4016248.0, "train_total_episodes": 2010.0, "train_loaded_steps": 1998662.0, "train_loaded_episodes": 1030.0}
{"step": 16072264, "train_return": 19.0, "train_length": 1818.0, "train_total_steps": 4018066.0, "train_total_episodes": 2011.0, "train_loaded_steps": 1998398.0, "train_loaded_episodes": 1030.0}
{"step": 16080496, "train_return": 13.0, "train_length": 2058.0, "train_total_steps": 4020124.0, "train_total_episodes": 2012.0, "train_loaded_steps": 1998284.0, "train_loaded_episodes": 1030.0}
{"step": 16090340, "train_return": 12.0, "train_length": 2461.0, "train_total_steps": 4022585.0, "train_total_episodes": 2013.0, "train_loaded_steps": 1998800.0, "train_loaded_episodes": 1030.0}
{"step": 16097816, "train_return": 18.0, "train_length": 1869.0, "train_total_steps": 4024454.0, "train_total_episodes": 2014.0, "train_loaded_steps": 1998634.0, "train_loaded_episodes": 1030.0}
{"step": 16099252, "kl_loss": 1.4059916505813599, "image_loss": 3772.0, "reward_loss": 0.9191080198287964, "discount_loss": 0.007743004049360752, "model_kl": 1.4059916175842284, "prior_ent": 26.38815475769043, "post_ent": 24.99071334838867, "model_loss": 3773.098452734375, "model_loss_scale": 4096.0, "model_grad_norm": 5.108097170257568, "actor_loss": 0.00490030203606002, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.041034619024395945, "critic_loss": 0.9247131939888, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.39530322101116183, "reward_mean": 0.007219957100739703, "reward_std": 0.08244557052254677, "reward_normed_mean": 0.007219957100739703, "reward_normed_std": 0.08244557052254677, "critic_slow": 5.318707218551635, "critic_target": 5.32262497253418, "actor_ent": 1.269500583267212, "actor_ent_scale": 0.0010000000474974513, "critic": 5.322415193557739, "fps": 112.4064760194611}
{"step": 16104844, "train_return": 19.0, "train_length": 1757.0, "train_total_steps": 4026211.0, "train_total_episodes": 2015.0, "train_loaded_steps": 1998155.0, "train_loaded_episodes": 1030.0}
{"step": 16111724, "train_return": 20.0, "train_length": 1720.0, "train_total_steps": 4027931.0, "train_total_episodes": 2016.0, "train_loaded_steps": 1999875.0, "train_loaded_episodes": 1031.0}
{"step": 16119596, "train_return": 15.0, "train_length": 1968.0, "train_total_steps": 4029899.0, "train_total_episodes": 2017.0, "train_loaded_steps": 1998232.0, "train_loaded_episodes": 1030.0}
{"step": 16126548, "train_return": 20.0, "train_length": 1738.0, "train_total_steps": 4031637.0, "train_total_episodes": 2018.0, "train_loaded_steps": 1999970.0, "train_loaded_episodes": 1031.0}
{"step": 16133184, "train_return": 21.0, "train_length": 1659.0, "train_total_steps": 4033296.0, "train_total_episodes": 2019.0, "train_loaded_steps": 1999680.0, "train_loaded_episodes": 1031.0}
{"step": 16139252, "kl_loss": 1.3753774650573731, "image_loss": 3772.0, "reward_loss": 0.9191202832221985, "discount_loss": 0.007741440738737583, "model_kl": 1.3753774339675904, "prior_ent": 26.40218519592285, "post_ent": 25.03565124206543, "model_loss": 3773.095392578125, "model_loss_scale": 5622.9888, "model_grad_norm": 4.919933365440369, "actor_loss": 0.0056460616669035514, "actor_loss_scale": 7012876.288, "actor_grad_norm": 0.038334973961114883, "critic_loss": 0.9225960614204407, "critic_loss_scale": 54788.096, "critic_grad_norm": 0.3829440482020378, "reward_mean": 0.0073665449862834066, "reward_std": 0.0830284128665924, "reward_normed_mean": 0.0073665449862834066, "reward_normed_std": 0.0830284128665924, "critic_slow": 5.412247726440429, "critic_target": 5.415547616195679, "actor_ent": 1.3703546297073363, "actor_ent_scale": 0.0010000000474974513, "critic": 5.415294256591797, "fps": 113.80280967264461}
{"step": 16140468, "train_return": 19.0, "train_length": 1821.0, "train_total_steps": 4035117.0, "train_total_episodes": 2020.0, "train_loaded_steps": 1999653.0, "train_loaded_episodes": 1031.0}
{"step": 16147288, "train_return": 21.0, "train_length": 1705.0, "train_total_steps": 4036822.0, "train_total_episodes": 2021.0, "train_loaded_steps": 1999425.0, "train_loaded_episodes": 1031.0}
{"step": 16154448, "train_return": 19.0, "train_length": 1790.0, "train_total_steps": 4038612.0, "train_total_episodes": 2022.0, "train_loaded_steps": 1999068.0, "train_loaded_episodes": 1031.0}
{"step": 16161672, "train_return": 19.0, "train_length": 1806.0, "train_total_steps": 4040418.0, "train_total_episodes": 2023.0, "train_loaded_steps": 1998825.0, "train_loaded_episodes": 1031.0}
{"step": 16169540, "train_return": 16.0, "train_length": 1967.0, "train_total_steps": 4042385.0, "train_total_episodes": 2024.0, "train_loaded_steps": 1998486.0, "train_loaded_episodes": 1031.0}
{"step": 16177216, "train_return": 17.0, "train_length": 1919.0, "train_total_steps": 4044304.0, "train_total_episodes": 2025.0, "train_loaded_steps": 1998552.0, "train_loaded_episodes": 1031.0}
{"step": 16179252, "kl_loss": 1.4013499423980713, "image_loss": 3772.0001921875, "reward_loss": 0.9191283703804016, "discount_loss": 0.007741184955835342, "model_kl": 1.4013499095916748, "prior_ent": 26.274130850219727, "post_ent": 24.894645742797852, "model_loss": 3773.098187109375, "model_loss_scale": 8192.0, "model_grad_norm": 5.0072770580291746, "actor_loss": 0.001753104768882622, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.036569574368000034, "critic_loss": 0.921539448928833, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.4451904096841812, "reward_mean": 0.007404163231409621, "reward_std": 0.08222747136950492, "reward_normed_mean": 0.007404163231409621, "reward_normed_std": 0.08222747136950492, "critic_slow": 5.391029055786133, "critic_target": 5.394025751495361, "actor_ent": 1.4171190076828002, "actor_ent_scale": 0.0010000000474974513, "critic": 5.393812152099609, "fps": 115.88691539404378}
{"step": 16185120, "train_return": 18.0, "train_length": 1976.0, "train_total_steps": 4046280.0, "train_total_episodes": 2026.0, "train_loaded_steps": 1998414.0, "train_loaded_episodes": 1031.0}
{"step": 16193280, "train_return": 16.0, "train_length": 2040.0, "train_total_steps": 4048320.0, "train_total_episodes": 2027.0, "train_loaded_steps": 1998483.0, "train_loaded_episodes": 1031.0}
{"step": 16199916, "train_return": 21.0, "train_length": 1659.0, "train_total_steps": 4049979.0, "train_total_episodes": 2028.0, "train_loaded_steps": 1998488.0, "train_loaded_episodes": 1031.0}
{"step": 16208000, "train_return": 15.0, "train_length": 2021.0, "train_total_steps": 4052000.0, "train_total_episodes": 2029.0, "train_loaded_steps": 1998367.0, "train_loaded_episodes": 1031.0}
{"step": 16214868, "train_return": 20.0, "train_length": 1717.0, "train_total_steps": 4053717.0, "train_total_episodes": 2030.0, "train_loaded_steps": 1997828.0, "train_loaded_episodes": 1031.0}
{"step": 16219252, "kl_loss": 1.3559590240478516, "image_loss": 3772.0, "reward_loss": 0.9191140369415283, "discount_loss": 0.007741469424217939, "model_kl": 1.3559589918136596, "prior_ent": 26.40095048828125, "post_ent": 25.05432066040039, "model_loss": 3773.09344453125, "model_loss_scale": 8192.0, "model_grad_norm": 5.022088172721863, "actor_loss": 0.003322448628494749, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03620245934426784, "critic_loss": 0.9214769916534424, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.3758688126206398, "reward_mean": 0.00748506492979941, "reward_std": 0.08279454632997513, "reward_normed_mean": 0.00748506492979941, "reward_normed_std": 0.08279454632997513, "critic_slow": 5.482528165054322, "critic_target": 5.486514392089844, "actor_ent": 1.3855462408065795, "actor_ent_scale": 0.0010000000474974513, "critic": 5.486051985549927, "fps": 116.87731753740248}
{"step": 16223028, "train_return": 17.0, "train_length": 2040.0, "train_total_steps": 4055757.0, "train_total_episodes": 2031.0, "train_loaded_steps": 1999868.0, "train_loaded_episodes": 1032.0}
{"step": 16230892, "train_return": 17.0, "train_length": 1966.0, "train_total_steps": 4057723.0, "train_total_episodes": 2032.0, "train_loaded_steps": 1999826.0, "train_loaded_episodes": 1032.0}
{"step": 16238680, "train_return": 18.0, "train_length": 1947.0, "train_total_steps": 4059670.0, "train_total_episodes": 2033.0, "train_loaded_steps": 1999645.0, "train_loaded_episodes": 1032.0}
{"step": 16246720, "train_return": 18.0, "train_length": 2010.0, "train_total_steps": 4061680.0, "train_total_episodes": 2034.0, "train_loaded_steps": 1999902.0, "train_loaded_episodes": 1032.0}
{"step": 16254876, "train_return": 18.0, "train_length": 2039.0, "train_total_steps": 4063719.0, "train_total_episodes": 2035.0, "train_loaded_steps": 1997840.0, "train_loaded_episodes": 1031.0}
{"step": 16259252, "kl_loss": 1.4176267784118652, "image_loss": 3772.0, "reward_loss": 0.9191103702545166, "discount_loss": 0.007744861348718404, "model_kl": 1.4176267461776733, "prior_ent": 26.602286428833008, "post_ent": 25.202737606811525, "model_loss": 3773.09962265625, "model_loss_scale": 5010.2272, "model_grad_norm": Infinity, "actor_loss": 0.0030745586566627028, "actor_loss_scale": 9744207.0528, "actor_grad_norm": Infinity, "critic_loss": 0.920082528591156, "critic_loss_scale": 96468.992, "critic_grad_norm": 0.3892774688959122, "reward_mean": 0.007395379664283246, "reward_std": 0.08246666520237923, "reward_normed_mean": 0.007395379664283246, "reward_normed_std": 0.08246666520237923, "critic_slow": 5.478313896942138, "critic_target": 5.481156074523926, "actor_ent": 1.4213454769134521, "actor_ent_scale": 0.0010000000474974513, "critic": 5.480757641601563, "fps": 113.67253932828666}
{"step": 16262880, "train_return": 20.0, "train_length": 2001.0, "train_total_steps": 4065720.0, "train_total_episodes": 2036.0, "train_loaded_steps": 1999841.0, "train_loaded_episodes": 1032.0}
{"step": 16271392, "train_return": 16.0, "train_length": 2128.0, "train_total_steps": 4067848.0, "train_total_episodes": 2037.0, "train_loaded_steps": 1998139.0, "train_loaded_episodes": 1031.0}
{"step": 16279556, "train_return": 15.0, "train_length": 2041.0, "train_total_steps": 4069889.0, "train_total_episodes": 2038.0, "train_loaded_steps": 1997960.0, "train_loaded_episodes": 1031.0}
{"step": 16287576, "train_return": 17.0, "train_length": 2005.0, "train_total_steps": 4071894.0, "train_total_episodes": 2039.0, "train_loaded_steps": 1999965.0, "train_loaded_episodes": 1032.0}
{"step": 16295652, "train_return": 16.0, "train_length": 2019.0, "train_total_steps": 4073913.0, "train_total_episodes": 2040.0, "train_loaded_steps": 1999953.0, "train_loaded_episodes": 1032.0}
{"step": 16299252, "kl_loss": 1.3654744874954223, "image_loss": 3772.0, "reward_loss": 0.9191198451042175, "discount_loss": 0.007784088020026684, "model_kl": 1.3654744537353516, "prior_ent": 26.572916885375978, "post_ent": 25.217193267822264, "model_loss": 3773.0946171875, "model_loss_scale": 1024.0, "model_grad_norm": 2.218488663673401, "actor_loss": -0.000469024722854374, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03437633244097233, "critic_loss": 0.9189026585578919, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3947867609858513, "reward_mean": 0.007324361832463182, "reward_std": 0.0825616046011448, "reward_normed_mean": 0.007324361832463182, "reward_normed_std": 0.0825616046011448, "critic_slow": 5.498585336303711, "critic_target": 5.500818811035156, "actor_ent": 1.4100756578445435, "actor_ent_scale": 0.0010000000474974513, "critic": 5.500169909667969, "fps": 112.86264933683233}
{"step": 16302532, "train_return": 20.0, "train_length": 1720.0, "train_total_steps": 4075633.0, "train_total_episodes": 2041.0, "train_loaded_steps": 1999660.0, "train_loaded_episodes": 1032.0}
{"step": 16310172, "train_return": 17.0, "train_length": 1910.0, "train_total_steps": 4077543.0, "train_total_episodes": 2042.0, "train_loaded_steps": 1999685.0, "train_loaded_episodes": 1032.0}
{"step": 16317400, "train_return": 19.0, "train_length": 1807.0, "train_total_steps": 4079350.0, "train_total_episodes": 2043.0, "train_loaded_steps": 1999137.0, "train_loaded_episodes": 1032.0}
{"step": 16325764, "train_return": 16.0, "train_length": 2091.0, "train_total_steps": 4081441.0, "train_total_episodes": 2044.0, "train_loaded_steps": 1999414.0, "train_loaded_episodes": 1032.0}
{"step": 16332856, "train_return": 20.0, "train_length": 1773.0, "train_total_steps": 4083214.0, "train_total_episodes": 2045.0, "train_loaded_steps": 1999173.0, "train_loaded_episodes": 1032.0}
{"step": 16339252, "kl_loss": 1.36043824634552, "image_loss": 3772.0, "reward_loss": 0.9191045152664185, "discount_loss": 0.007753108341991902, "model_kl": 1.3604382146835328, "prior_ent": 26.50009379272461, "post_ent": 25.14965534057617, "model_loss": 3773.09394609375, "model_loss_scale": 1024.0, "model_grad_norm": 3.4243282596588136, "actor_loss": -0.00036287279900861907, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03377852883040905, "critic_loss": 0.9182782430648804, "critic_loss_scale": 110939.3408, "critic_grad_norm": Infinity, "reward_mean": 0.007446787663642317, "reward_std": 0.08259108580350875, "reward_normed_mean": 0.007446787663642317, "reward_normed_std": 0.08259108580350875, "critic_slow": 5.505366337585449, "critic_target": 5.506942819976807, "actor_ent": 1.3972189460754394, "actor_ent_scale": 0.0010000000474974513, "critic": 5.506389148712159, "fps": 113.76357368704944}
{"step": 16340028, "train_return": 19.0, "train_length": 1793.0, "train_total_steps": 4085007.0, "train_total_episodes": 2046.0, "train_loaded_steps": 1998821.0, "train_loaded_episodes": 1032.0}
{"step": 16347716, "train_return": 18.0, "train_length": 1922.0, "train_total_steps": 4086929.0, "train_total_episodes": 2047.0, "train_loaded_steps": 1998551.0, "train_loaded_episodes": 1032.0}
{"step": 16354968, "train_return": 18.0, "train_length": 1813.0, "train_total_steps": 4088742.0, "train_total_episodes": 2048.0, "train_loaded_steps": 1998624.0, "train_loaded_episodes": 1032.0}
{"step": 16363188, "train_return": 17.0, "train_length": 2055.0, "train_total_steps": 4090797.0, "train_total_episodes": 2049.0, "train_loaded_steps": 1998728.0, "train_loaded_episodes": 1032.0}
{"step": 16371292, "train_return": 17.0, "train_length": 2026.0, "train_total_steps": 4092823.0, "train_total_episodes": 2050.0, "train_loaded_steps": 1998823.0, "train_loaded_episodes": 1032.0}
{"step": 16378884, "train_return": 17.0, "train_length": 1898.0, "train_total_steps": 4094721.0, "train_total_episodes": 2051.0, "train_loaded_steps": 1998790.0, "train_loaded_episodes": 1032.0}
{"step": 16379252, "kl_loss": 1.4189385156631469, "image_loss": 3772.0, "reward_loss": 0.9191094427108765, "discount_loss": 0.00774212543964386, "model_kl": 1.4189384834289551, "prior_ent": 26.579296484375, "post_ent": 25.184163568115235, "model_loss": 3773.09974296875, "model_loss_scale": 1268.1216, "model_grad_norm": 4.308202693939209, "actor_loss": 0.0016971376860397869, "actor_loss_scale": 9314710.3232, "actor_grad_norm": 0.03554449756145477, "critic_loss": 0.9205661299705505, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.38520098237991335, "reward_mean": 0.007378292801510543, "reward_std": 0.08236034996509552, "reward_normed_mean": 0.007378292801510543, "reward_normed_std": 0.08236034996509552, "critic_slow": 5.5416120986938475, "critic_target": 5.544895106124878, "actor_ent": 1.3969259233474731, "actor_ent_scale": 0.0010000000474974513, "critic": 5.544219418334961, "fps": 113.92235485395966}
{"step": 16387552, "train_return": 14.0, "train_length": 2167.0, "train_total_steps": 4096888.0, "train_total_episodes": 2052.0, "train_loaded_steps": 1999283.0, "train_loaded_episodes": 1032.0}
{"step": 16394388, "train_return": 20.0, "train_length": 1709.0, "train_total_steps": 4098597.0, "train_total_episodes": 2053.0, "train_loaded_steps": 1998843.0, "train_loaded_episodes": 1032.0}
{"step": 16402404, "train_return": 18.0, "train_length": 2004.0, "train_total_steps": 4100601.0, "train_total_episodes": 2054.0, "train_loaded_steps": 1998518.0, "train_loaded_episodes": 1032.0}
{"step": 16409132, "train_return": 21.0, "train_length": 1682.0, "train_total_steps": 4102283.0, "train_total_episodes": 2055.0, "train_loaded_steps": 1998472.0, "train_loaded_episodes": 1032.0}
{"step": 16415984, "train_return": 20.0, "train_length": 1713.0, "train_total_steps": 4103996.0, "train_total_episodes": 2056.0, "train_loaded_steps": 1998364.0, "train_loaded_episodes": 1032.0}
{"step": 16419252, "kl_loss": 1.369400962638855, "image_loss": 3772.0, "reward_loss": 0.9191112768173217, "discount_loss": 0.007744643767178059, "model_kl": 1.3694009300231933, "prior_ent": 26.494284335327148, "post_ent": 25.13999792175293, "model_loss": 3773.094806640625, "model_loss_scale": 2048.0, "model_grad_norm": 4.85525395565033, "actor_loss": 0.0015048759283206891, "actor_loss_scale": 9811315.9168, "actor_grad_norm": Infinity, "critic_loss": 0.9191009738922119, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.34059705940485, "reward_mean": 0.007391647829674185, "reward_std": 0.08209067549705505, "reward_normed_mean": 0.007391647829674185, "reward_normed_std": 0.08209067549705505, "critic_slow": 5.549447968673706, "critic_target": 5.551474977493286, "actor_ent": 1.3792592611312866, "actor_ent_scale": 0.0010000000474974513, "critic": 5.551078728866577, "fps": 113.01208389170012}
{"step": 16423908, "train_return": 16.0, "train_length": 1981.0, "train_total_steps": 4105977.0, "train_total_episodes": 2057.0, "train_loaded_steps": 1998466.0, "train_loaded_episodes": 1032.0}
{"step": 16430548, "train_return": 21.0, "train_length": 1660.0, "train_total_steps": 4107637.0, "train_total_episodes": 2058.0, "train_loaded_steps": 1997851.0, "train_loaded_episodes": 1032.0}
{"step": 16437848, "train_return": 19.0, "train_length": 1825.0, "train_total_steps": 4109462.0, "train_total_episodes": 2059.0, "train_loaded_steps": 1999676.0, "train_loaded_episodes": 1033.0}
{"step": 16446584, "train_return": 15.0, "train_length": 2184.0, "train_total_steps": 4111646.0, "train_total_episodes": 2060.0, "train_loaded_steps": 1999949.0, "train_loaded_episodes": 1033.0}
{"step": 16453612, "train_return": 20.0, "train_length": 1757.0, "train_total_steps": 4113403.0, "train_total_episodes": 2061.0, "train_loaded_steps": 1999732.0, "train_loaded_episodes": 1033.0}
{"step": 16459252, "kl_loss": 1.3831975128173828, "image_loss": 3772.0, "reward_loss": 0.9191184969902039, "discount_loss": 0.0077534971602261065, "model_kl": 1.3831974794387818, "prior_ent": 26.541036450195314, "post_ent": 25.176441375732423, "model_loss": 3773.09623828125, "model_loss_scale": 1241.9072, "model_grad_norm": Infinity, "actor_loss": -0.0027400467974250204, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.036115797954797746, "critic_loss": 0.9203390277862549, "critic_loss_scale": 72561.4592, "critic_grad_norm": 0.3577966076374054, "reward_mean": 0.007304030235763639, "reward_std": 0.08202968776226044, "reward_normed_mean": 0.007304030235763639, "reward_normed_std": 0.08202968776226044, "critic_slow": 5.533517961883545, "critic_target": 5.534340364456177, "actor_ent": 1.3762852821350098, "actor_ent_scale": 0.0010000000474974513, "critic": 5.5339752910614015, "fps": 114.32429732180958}
{"step": 16460344, "train_return": 21.0, "train_length": 1683.0, "train_total_steps": 4115086.0, "train_total_episodes": 2062.0, "train_loaded_steps": 1999614.0, "train_loaded_episodes": 1033.0}
{"step": 16468028, "train_return": 18.0, "train_length": 1921.0, "train_total_steps": 4117007.0, "train_total_episodes": 2063.0, "train_loaded_steps": 1999535.0, "train_loaded_episodes": 1033.0}
{"step": 16475840, "train_return": 16.0, "train_length": 1953.0, "train_total_steps": 4118960.0, "train_total_episodes": 2064.0, "train_loaded_steps": 1999719.0, "train_loaded_episodes": 1033.0}
{"step": 16482652, "train_return": 21.0, "train_length": 1703.0, "train_total_steps": 4120663.0, "train_total_episodes": 2065.0, "train_loaded_steps": 1999423.0, "train_loaded_episodes": 1033.0}
{"step": 16490792, "train_return": 16.0, "train_length": 2035.0, "train_total_steps": 4122698.0, "train_total_episodes": 2066.0, "train_loaded_steps": 1999408.0, "train_loaded_episodes": 1033.0}
{"step": 16499252, "kl_loss": 1.3601819114685059, "image_loss": 3772.0, "reward_loss": 0.9191194757461548, "discount_loss": 0.007755607648938894, "model_kl": 1.3601818782806396, "prior_ent": 26.56911330566406, "post_ent": 25.219248291015624, "model_loss": 3773.093952734375, "model_loss_scale": 1024.0, "model_grad_norm": 4.918381496238709, "actor_loss": -0.005410008009243757, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03639975455701351, "critic_loss": 0.9201758535385132, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3447804587304592, "reward_mean": 0.0073979646697407584, "reward_std": 0.08231435436606407, "reward_normed_mean": 0.0073979646697407584, "reward_normed_std": 0.08231435436606407, "critic_slow": 5.575474493408203, "critic_target": 5.5749536216735835, "actor_ent": 1.3921330810546875, "actor_ent_scale": 0.0010000000474974513, "critic": 5.574899421691894, "fps": 116.28096109323373}
{"step": 16499520, "train_return": 15.0, "train_length": 2182.0, "train_total_steps": 4124880.0, "train_total_episodes": 2067.0, "train_loaded_steps": 1999914.0, "train_loaded_episodes": 1033.0}
{"step": 16507392, "train_return": 17.0, "train_length": 1968.0, "train_total_steps": 4126848.0, "train_total_episodes": 2068.0, "train_loaded_steps": 1999992.0, "train_loaded_episodes": 1033.0}
{"step": 16514252, "train_return": 20.0, "train_length": 1715.0, "train_total_steps": 4128563.0, "train_total_episodes": 2069.0, "train_loaded_steps": 1999559.0, "train_loaded_episodes": 1033.0}
{"step": 16522808, "train_return": 16.0, "train_length": 2139.0, "train_total_steps": 4130702.0, "train_total_episodes": 2070.0, "train_loaded_steps": 1999986.0, "train_loaded_episodes": 1033.0}
{"step": 16530548, "train_return": 17.0, "train_length": 1935.0, "train_total_steps": 4132637.0, "train_total_episodes": 2071.0, "train_loaded_steps": 1999725.0, "train_loaded_episodes": 1033.0}
{"step": 16538224, "train_return": 17.0, "train_length": 1919.0, "train_total_steps": 4134556.0, "train_total_episodes": 2072.0, "train_loaded_steps": 1999808.0, "train_loaded_episodes": 1033.0}
{"step": 16539252, "kl_loss": 1.3716093868255614, "image_loss": 3772.0, "reward_loss": 0.9191181683540344, "discount_loss": 0.007755007947981358, "model_kl": 1.371609355545044, "prior_ent": 26.661833029174804, "post_ent": 25.302897158813476, "model_loss": 3773.0950890625, "model_loss_scale": 1024.0, "model_grad_norm": 5.001923103332519, "actor_loss": -0.006389796824990481, "actor_loss_scale": 8442295.0912, "actor_grad_norm": Infinity, "critic_loss": 0.9199640717506409, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3604389130949974, "reward_mean": 0.007442462410929147, "reward_std": 0.08215269803404808, "reward_normed_mean": 0.007442462410929147, "reward_normed_std": 0.08215269803404808, "critic_slow": 5.570421779632569, "critic_target": 5.569720376586914, "actor_ent": 1.4507887264251709, "actor_ent_scale": 0.0010000000474974513, "critic": 5.5696102760314945, "fps": 117.16324091391891}
{"step": 16546844, "train_return": 14.0, "train_length": 2155.0, "train_total_steps": 4136711.0, "train_total_episodes": 2073.0, "train_loaded_steps": 1999538.0, "train_loaded_episodes": 1033.0}
{"step": 16554044, "train_return": 19.0, "train_length": 1800.0, "train_total_steps": 4138511.0, "train_total_episodes": 2074.0, "train_loaded_steps": 1999299.0, "train_loaded_episodes": 1033.0}
{"step": 16561416, "train_return": 19.0, "train_length": 1843.0, "train_total_steps": 4140354.0, "train_total_episodes": 2075.0, "train_loaded_steps": 1999314.0, "train_loaded_episodes": 1033.0}
{"step": 16569188, "train_return": 17.0, "train_length": 1943.0, "train_total_steps": 4142297.0, "train_total_episodes": 2076.0, "train_loaded_steps": 1999404.0, "train_loaded_episodes": 1033.0}
{"step": 16576472, "train_return": 19.0, "train_length": 1821.0, "train_total_steps": 4144118.0, "train_total_episodes": 2077.0, "train_loaded_steps": 1999257.0, "train_loaded_episodes": 1033.0}
{"step": 16579252, "kl_loss": 1.3856558109283448, "image_loss": 3772.00019609375, "reward_loss": 0.9190965576171874, "discount_loss": 0.007748825411498547, "model_kl": 1.3856557834625245, "prior_ent": 26.421132064819336, "post_ent": 25.051673345947265, "model_loss": 3773.09663984375, "model_loss_scale": 1625.2928, "model_grad_norm": 4.903846000862122, "actor_loss": -0.006826155397420916, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03661110254824162, "critic_loss": 0.9210423295021057, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.34637121260762216, "reward_mean": 0.00742919703386724, "reward_std": 0.08256698972582817, "reward_normed_mean": 0.00742919703386724, "reward_normed_std": 0.08256698972582817, "critic_slow": 5.561571469116211, "critic_target": 5.5607101852417, "actor_ent": 1.4402059309005737, "actor_ent_scale": 0.0010000000474974513, "critic": 5.560558740234375, "fps": 114.558773217671}
{"step": 16583992, "train_return": 18.0, "train_length": 1880.0, "train_total_steps": 4145998.0, "train_total_episodes": 2078.0, "train_loaded_steps": 1998813.0, "train_loaded_episodes": 1033.0}
{"step": 16591424, "train_return": 18.0, "train_length": 1858.0, "train_total_steps": 4147856.0, "train_total_episodes": 2079.0, "train_loaded_steps": 1998958.0, "train_loaded_episodes": 1033.0}
{"step": 16598044, "train_return": 21.0, "train_length": 1655.0, "train_total_steps": 4149511.0, "train_total_episodes": 2080.0, "train_loaded_steps": 1998547.0, "train_loaded_episodes": 1033.0}
{"step": 16606264, "train_return": 16.0, "train_length": 2055.0, "train_total_steps": 4151566.0, "train_total_episodes": 2081.0, "train_loaded_steps": 1998733.0, "train_loaded_episodes": 1033.0}
{"step": 16613788, "train_return": 18.0, "train_length": 1881.0, "train_total_steps": 4153447.0, "train_total_episodes": 2082.0, "train_loaded_steps": 1998312.0, "train_loaded_episodes": 1033.0}
{"step": 16619252, "kl_loss": 1.3892343595504761, "image_loss": 3772.0, "reward_loss": 0.9191213766098022, "discount_loss": 0.007743935725837946, "model_kl": 1.389234327697754, "prior_ent": 26.644300469970702, "post_ent": 25.270935348510744, "model_loss": 3773.0967921875, "model_loss_scale": 2048.0, "model_grad_norm": 4.910883827781677, "actor_loss": -0.007110698744546971, "actor_loss_scale": 7153804.9024, "actor_grad_norm": Infinity, "critic_loss": 0.92090782995224, "critic_loss_scale": 178887.0656, "critic_grad_norm": Infinity, "reward_mean": 0.007306014530174434, "reward_std": 0.08248263469934464, "reward_normed_mean": 0.007306014530174434, "reward_normed_std": 0.08248263469934464, "critic_slow": 5.519065021896362, "critic_target": 5.51749121055603, "actor_ent": 1.408289084625244, "actor_ent_scale": 0.0010000000474974513, "critic": 5.517301001358033, "fps": 115.54035022404233}
{"step": 16621212, "train_return": 19.0, "train_length": 1856.0, "train_total_steps": 4155303.0, "train_total_episodes": 2083.0, "train_loaded_steps": 1997996.0, "train_loaded_episodes": 1033.0}
{"step": 16628808, "train_return": 18.0, "train_length": 1899.0, "train_total_steps": 4157202.0, "train_total_episodes": 2084.0, "train_loaded_steps": 1999895.0, "train_loaded_episodes": 1034.0}
{"step": 16636396, "train_return": 18.0, "train_length": 1897.0, "train_total_steps": 4159099.0, "train_total_episodes": 2085.0, "train_loaded_steps": 1997469.0, "train_loaded_episodes": 1033.0}
{"step": 16645008, "train_return": 15.0, "train_length": 2153.0, "train_total_steps": 4161252.0, "train_total_episodes": 2086.0, "train_loaded_steps": 1999622.0, "train_loaded_episodes": 1034.0}
{"step": 16653184, "train_return": 15.0, "train_length": 2044.0, "train_total_steps": 4163296.0, "train_total_episodes": 2087.0, "train_loaded_steps": 1999535.0, "train_loaded_episodes": 1034.0}
{"step": 16659252, "kl_loss": 1.3822567848205567, "image_loss": 3772.000187890625, "reward_loss": 0.919131368637085, "discount_loss": 0.007756993861496448, "model_kl": 1.3822567562103272, "prior_ent": 26.5418327545166, "post_ent": 25.17830440673828, "model_loss": 3773.096358203125, "model_loss_scale": 2048.0, "model_grad_norm": 4.922511549568176, "actor_loss": -0.005432430950202979, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.03522718016505241, "critic_loss": 0.9194344029426574, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3268180739402771, "reward_mean": 0.0073867467143572865, "reward_std": 0.08207690542936324, "reward_normed_mean": 0.0073867467143572865, "reward_normed_std": 0.08207690542936324, "critic_slow": 5.476056880187988, "critic_target": 5.474891737365723, "actor_ent": 1.4001810409545898, "actor_ent_scale": 0.0010000000474974513, "critic": 5.474731745910645, "fps": 114.69653422860661}
{"step": 16662356, "train_return": 14.0, "train_length": 2293.0, "train_total_steps": 4165589.0, "train_total_episodes": 2088.0, "train_loaded_steps": 1999828.0, "train_loaded_episodes": 1034.0}
{"step": 16670552, "train_return": 16.0, "train_length": 2049.0, "train_total_steps": 4167638.0, "train_total_episodes": 2089.0, "train_loaded_steps": 1999937.0, "train_loaded_episodes": 1034.0}
{"step": 16677860, "train_return": 19.0, "train_length": 1827.0, "train_total_steps": 4169465.0, "train_total_episodes": 2090.0, "train_loaded_steps": 1999826.0, "train_loaded_episodes": 1034.0}
{"step": 16686080, "train_return": 16.0, "train_length": 2055.0, "train_total_steps": 4171520.0, "train_total_episodes": 2091.0, "train_loaded_steps": 1999889.0, "train_loaded_episodes": 1034.0}
{"step": 16693616, "train_return": 18.0, "train_length": 1884.0, "train_total_steps": 4173404.0, "train_total_episodes": 2092.0, "train_loaded_steps": 1999854.0, "train_loaded_episodes": 1034.0}
{"step": 16699252, "kl_loss": 1.343120401763916, "image_loss": 3772.0, "reward_loss": 0.9191059265136718, "discount_loss": 0.007741412618011236, "model_kl": 1.3431203706741333, "prior_ent": 26.576008578491212, "post_ent": 25.241528826904297, "model_loss": 3773.092146484375, "model_loss_scale": 2840.9856, "model_grad_norm": 4.433024983787536, "actor_loss": -0.004332352631184039, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.03464247749447823, "critic_loss": 0.9181379387855529, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.31725144160985946, "reward_mean": 0.007541715060721617, "reward_std": 0.08287831439375877, "reward_normed_mean": 0.007541715060721617, "reward_normed_std": 0.08287831439375877, "critic_slow": 5.3520660430908205, "critic_target": 5.350773474884033, "actor_ent": 1.4157410493850708, "actor_ent_scale": 0.0010000000474974513, "critic": 5.350726607513428, "fps": 111.92560320815731}
{"step": 16700968, "train_return": 19.0, "train_length": 1838.0, "train_total_steps": 4175242.0, "train_total_episodes": 2093.0, "train_loaded_steps": 1999924.0, "train_loaded_episodes": 1034.0}
{"step": 16708700, "train_return": 17.0, "train_length": 1933.0, "train_total_steps": 4177175.0, "train_total_episodes": 2094.0, "train_loaded_steps": 1999984.0, "train_loaded_episodes": 1034.0}
{"step": 16715728, "train_return": 20.0, "train_length": 1757.0, "train_total_steps": 4178932.0, "train_total_episodes": 2095.0, "train_loaded_steps": 1999983.0, "train_loaded_episodes": 1034.0}
{"step": 16723620, "train_return": 18.0, "train_length": 1973.0, "train_total_steps": 4180905.0, "train_total_episodes": 2096.0, "train_loaded_steps": 1999920.0, "train_loaded_episodes": 1034.0}
{"step": 16730848, "train_return": 19.0, "train_length": 1807.0, "train_total_steps": 4182712.0, "train_total_episodes": 2097.0, "train_loaded_steps": 1999703.0, "train_loaded_episodes": 1034.0}
{"step": 16737936, "train_return": 20.0, "train_length": 1772.0, "train_total_steps": 4184484.0, "train_total_episodes": 2098.0, "train_loaded_steps": 1999524.0, "train_loaded_episodes": 1034.0}
{"step": 16739252, "kl_loss": 1.3493585578918457, "image_loss": 3772.0, "reward_loss": 0.9191218006134033, "discount_loss": 0.007760870707780123, "model_kl": 1.3493585252761842, "prior_ent": 26.534161798095703, "post_ent": 25.195713165283202, "model_loss": 3773.09289609375, "model_loss_scale": 4096.0, "model_grad_norm": 4.86561957397461, "actor_loss": -0.007924683340839692, "actor_loss_scale": 4590246.2976, "actor_grad_norm": 0.03478953727185726, "critic_loss": 0.9184507508277893, "critic_loss_scale": 132330.2912, "critic_grad_norm": Infinity, "reward_mean": 0.007438014135614503, "reward_std": 0.08301984319686889, "reward_normed_mean": 0.007438014135614503, "reward_normed_std": 0.08301984319686889, "critic_slow": 5.4250987529754635, "critic_target": 5.424000220870972, "actor_ent": 1.3852256589889527, "actor_ent_scale": 0.0010000000474974513, "critic": 5.4241020851135255, "fps": 114.1558810446176}
{"step": 16745216, "train_return": 19.0, "train_length": 1820.0, "train_total_steps": 4186304.0, "train_total_episodes": 2099.0, "train_loaded_steps": 1999237.0, "train_loaded_episodes": 1034.0}
{"step": 16752480, "train_return": 19.0, "train_length": 1816.0, "train_total_steps": 4188120.0, "train_total_episodes": 2100.0, "train_loaded_steps": 1998985.0, "train_loaded_episodes": 1034.0}
{"step": 16759880, "train_return": 19.0, "train_length": 1850.0, "train_total_steps": 4189970.0, "train_total_episodes": 2101.0, "train_loaded_steps": 1998815.0, "train_loaded_episodes": 1034.0}
{"step": 16767852, "train_return": 17.0, "train_length": 1993.0, "train_total_steps": 4191963.0, "train_total_episodes": 2102.0, "train_loaded_steps": 1998985.0, "train_loaded_episodes": 1034.0}
{"step": 16775552, "train_return": 17.0, "train_length": 1925.0, "train_total_steps": 4193888.0, "train_total_episodes": 2103.0, "train_loaded_steps": 1999053.0, "train_loaded_episodes": 1034.0}
{"step": 16779252, "kl_loss": 1.3581389163970947, "image_loss": 3772.000187890625, "reward_loss": 0.9190929000854492, "discount_loss": 0.007742203986644745, "model_kl": 1.358138882446289, "prior_ent": 26.399990853881835, "post_ent": 25.052181408691407, "model_loss": 3773.0938375, "model_loss_scale": 4096.0, "model_grad_norm": 4.811068536758423, "actor_loss": -0.00820161231911461, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03312720037996769, "critic_loss": 0.9184223373413086, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.27262504892349243, "reward_mean": 0.007369908409938216, "reward_std": 0.08279685658812523, "reward_normed_mean": 0.007369908409938216, "reward_normed_std": 0.08279685658812523, "critic_slow": 5.448802696609497, "critic_target": 5.44684328956604, "actor_ent": 1.4426341051101685, "actor_ent_scale": 0.0010000000474974513, "critic": 5.446888845825195, "fps": 115.60454295956485}
{"step": 16783304, "train_return": 19.0, "train_length": 1938.0, "train_total_steps": 4195826.0, "train_total_episodes": 2104.0, "train_loaded_steps": 1999128.0, "train_loaded_episodes": 1034.0}
{"step": 16790872, "train_return": 19.0, "train_length": 1892.0, "train_total_steps": 4197718.0, "train_total_episodes": 2105.0, "train_loaded_steps": 1998958.0, "train_loaded_episodes": 1034.0}
{"step": 16799424, "train_return": 18.0, "train_length": 2138.0, "train_total_steps": 4199856.0, "train_total_episodes": 2106.0, "train_loaded_steps": 1999287.0, "train_loaded_episodes": 1034.0}
{"step": 16807224, "train_return": 17.0, "train_length": 1950.0, "train_total_steps": 4201806.0, "train_total_episodes": 2107.0, "train_loaded_steps": 1999230.0, "train_loaded_episodes": 1034.0}
{"step": 16805804, "eval_return": 19.0, "eval_length": 1818.0, "eval_total_steps": 41508.0, "eval_total_episodes": 21.0, "eval_loaded_steps": 41529.0, "eval_loaded_episodes": 21.0}
{"step": 16805808, "kl_loss": 1.4481923580169678, "image_loss": 3772.0, "reward_loss": 0.9192079901695251, "discount_loss": 0.00774521566927433, "model_kl": 1.4481922388076782, "prior_ent": 26.494375228881836, "post_ent": 25.08365249633789, "model_loss": 3773.102783203125, "model_loss_scale": 16384.0, "model_grad_norm": 5.822054862976074, "actor_loss": 0.007934533059597015, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.06010758876800537, "critic_loss": 0.931384265422821, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.1916925311088562, "reward_mean": 0.007978830486536026, "reward_std": 0.09078523516654968, "reward_normed_mean": 0.007978830486536026, "reward_normed_std": 0.09078523516654968, "critic_slow": 4.711705207824707, "critic_target": 4.7213029861450195, "actor_ent": 1.193995714187622, "actor_ent_scale": 0.0010000000474974513, "critic": 4.712889671325684, "fps": 0.0}
{"step": 16812904, "train_return": 18.0, "train_length": 1775.0, "train_total_steps": 4203226.0, "train_total_episodes": 2108.0, "train_loaded_steps": 1999184.0, "train_loaded_episodes": 1034.0}
{"step": 16820596, "train_return": 16.0, "train_length": 1923.0, "train_total_steps": 4205149.0, "train_total_episodes": 2109.0, "train_loaded_steps": 1999128.0, "train_loaded_episodes": 1034.0}
{"step": 16827552, "train_return": 20.0, "train_length": 1739.0, "train_total_steps": 4206888.0, "train_total_episodes": 2110.0, "train_loaded_steps": 1999053.0, "train_loaded_episodes": 1034.0}
{"step": 16835120, "train_return": 19.0, "train_length": 1892.0, "train_total_steps": 4208780.0, "train_total_episodes": 2111.0, "train_loaded_steps": 1999119.0, "train_loaded_episodes": 1034.0}
{"step": 16841944, "train_return": 21.0, "train_length": 1706.0, "train_total_steps": 4210486.0, "train_total_episodes": 2112.0, "train_loaded_steps": 1998520.0, "train_loaded_episodes": 1034.0}
{"step": 16845808, "kl_loss": 1.4075924499511718, "image_loss": 3772.0, "reward_loss": 0.9191078689575195, "discount_loss": 0.007750813520699739, "model_kl": 1.4075924200057983, "prior_ent": 26.608027227783204, "post_ent": 25.213830053710936, "model_loss": 3773.098658203125, "model_loss_scale": 2084.0448, "model_grad_norm": Infinity, "actor_loss": 0.005171380351600237, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.041038343161344526, "critic_loss": 0.9249275943756103, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.396732981467247, "reward_mean": 0.007444712923350744, "reward_std": 0.08270244529247284, "reward_normed_mean": 0.007444712923350744, "reward_normed_std": 0.08270244529247284, "critic_slow": 5.347299411010742, "critic_target": 5.352225124359131, "actor_ent": 1.260676289176941, "actor_ent_scale": 0.0010000000474974513, "critic": 5.35215534286499, "fps": 112.84364565716594}
{"step": 16850172, "train_return": 16.0, "train_length": 2057.0, "train_total_steps": 4212543.0, "train_total_episodes": 2113.0, "train_loaded_steps": 1998560.0, "train_loaded_episodes": 1034.0}
{"step": 16857732, "train_return": 19.0, "train_length": 1890.0, "train_total_steps": 4214433.0, "train_total_episodes": 2114.0, "train_loaded_steps": 1998655.0, "train_loaded_episodes": 1034.0}
{"step": 16864832, "train_return": 20.0, "train_length": 1775.0, "train_total_steps": 4216208.0, "train_total_episodes": 2115.0, "train_loaded_steps": 1998486.0, "train_loaded_episodes": 1034.0}
{"step": 16871472, "train_return": 21.0, "train_length": 1660.0, "train_total_steps": 4217868.0, "train_total_episodes": 2116.0, "train_loaded_steps": 1997951.0, "train_loaded_episodes": 1034.0}
{"step": 16879976, "train_return": 16.0, "train_length": 2126.0, "train_total_steps": 4219994.0, "train_total_episodes": 2117.0, "train_loaded_steps": 1997851.0, "train_loaded_episodes": 1034.0}
{"step": 16885808, "kl_loss": 1.3844588499069215, "image_loss": 3772.0, "reward_loss": 0.919108246421814, "discount_loss": 0.007741932773590088, "model_kl": 1.3844588165283203, "prior_ent": 26.486634286499022, "post_ent": 25.118812576293944, "model_loss": 3773.09629765625, "model_loss_scale": 2048.0, "model_grad_norm": 4.295747078704834, "actor_loss": 0.003921235610346775, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.0404350132972002, "critic_loss": 0.9222428122520446, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.38852456270456315, "reward_mean": 0.007434750558680389, "reward_std": 0.08292819248437881, "reward_normed_mean": 0.007434750558680389, "reward_normed_std": 0.08292819248437881, "critic_slow": 5.443037490844727, "critic_target": 5.445185192108155, "actor_ent": 1.3432394104003906, "actor_ent_scale": 0.0010000000474974513, "critic": 5.445015790557862, "fps": 113.90713880971805}
{"step": 16887228, "train_return": 19.0, "train_length": 1813.0, "train_total_steps": 4221807.0, "train_total_episodes": 2118.0, "train_loaded_steps": 1999664.0, "train_loaded_episodes": 1035.0}
{"step": 16894792, "train_return": 18.0, "train_length": 1891.0, "train_total_steps": 4223698.0, "train_total_episodes": 2119.0, "train_loaded_steps": 1999706.0, "train_loaded_episodes": 1035.0}
{"step": 16902616, "train_return": 17.0, "train_length": 1956.0, "train_total_steps": 4225654.0, "train_total_episodes": 2120.0, "train_loaded_steps": 1999815.0, "train_loaded_episodes": 1035.0}
{"step": 16910176, "train_return": 18.0, "train_length": 1890.0, "train_total_steps": 4227544.0, "train_total_episodes": 2121.0, "train_loaded_steps": 1999795.0, "train_loaded_episodes": 1035.0}
{"step": 16917740, "train_return": 18.0, "train_length": 1891.0, "train_total_steps": 4229435.0, "train_total_episodes": 2122.0, "train_loaded_steps": 1999765.0, "train_loaded_episodes": 1035.0}
{"step": 16925448, "train_return": 17.0, "train_length": 1927.0, "train_total_steps": 4231362.0, "train_total_episodes": 2123.0, "train_loaded_steps": 1999775.0, "train_loaded_episodes": 1035.0}
{"step": 16925808, "kl_loss": 1.3580755352020264, "image_loss": 3772.0, "reward_loss": 0.9191036429405213, "discount_loss": 0.007741476185619831, "model_kl": 1.3580755073547364, "prior_ent": 26.37375249938965, "post_ent": 25.027686126708986, "model_loss": 3773.09364453125, "model_loss_scale": 2048.0, "model_grad_norm": 4.8949721256256105, "actor_loss": -0.0034015834460951735, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.039063925305008886, "critic_loss": 0.9206687539100648, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.41981392481327057, "reward_mean": 0.007275575700728223, "reward_std": 0.08272341709136963, "reward_normed_mean": 0.007275575700728223, "reward_normed_std": 0.08272341709136963, "critic_slow": 5.5110304695129395, "critic_target": 5.512146195983886, "actor_ent": 1.346238885307312, "actor_ent_scale": 0.0010000000474974513, "critic": 5.511927083587646, "fps": 115.3568172306963}
{"step": 16933380, "train_return": 17.0, "train_length": 1983.0, "train_total_steps": 4233345.0, "train_total_episodes": 2124.0, "train_loaded_steps": 1999585.0, "train_loaded_episodes": 1035.0}
{"step": 16940128, "train_return": 21.0, "train_length": 1687.0, "train_total_steps": 4235032.0, "train_total_episodes": 2125.0, "train_loaded_steps": 1998783.0, "train_loaded_episodes": 1035.0}
{"step": 16947388, "train_return": 19.0, "train_length": 1815.0, "train_total_steps": 4236847.0, "train_total_episodes": 2126.0, "train_loaded_steps": 1998683.0, "train_loaded_episodes": 1035.0}
{"step": 16955360, "train_return": 16.0, "train_length": 1993.0, "train_total_steps": 4238840.0, "train_total_episodes": 2127.0, "train_loaded_steps": 1998472.0, "train_loaded_episodes": 1035.0}
{"step": 16962788, "train_return": 18.0, "train_length": 1857.0, "train_total_steps": 4240697.0, "train_total_episodes": 2128.0, "train_loaded_steps": 1998536.0, "train_loaded_episodes": 1035.0}
{"step": 16965808, "kl_loss": 1.3914973516464233, "image_loss": 3772.0, "reward_loss": 0.9191200830459595, "discount_loss": 0.007754074290394783, "model_kl": 1.391497317123413, "prior_ent": 26.524733276367186, "post_ent": 25.15040087890625, "model_loss": 3773.097071875, "model_loss_scale": 3676.5696, "model_grad_norm": 4.926020118522644, "actor_loss": -8.019282694676804e-05, "actor_loss_scale": 59087.2576, "actor_grad_norm": 0.04025421053469181, "critic_loss": 0.9229164121627808, "critic_loss_scale": 59087.2576, "critic_grad_norm": 0.44775811632871626, "reward_mean": 0.0073530879160147375, "reward_std": 0.08277420638799668, "reward_normed_mean": 0.0073530879160147375, "reward_normed_std": 0.08277420638799668, "critic_slow": 5.507420866394043, "critic_target": 5.5097401950836185, "actor_ent": 1.3284539459228515, "actor_ent_scale": 0.0010000000474974513, "critic": 5.509442829895019, "fps": 115.14690671817573}
{"step": 16970060, "train_return": 18.0, "train_length": 1818.0, "train_total_steps": 4242515.0, "train_total_episodes": 2129.0, "train_loaded_steps": 1998233.0, "train_loaded_episodes": 1035.0}
{"step": 16976868, "train_return": 21.0, "train_length": 1702.0, "train_total_steps": 4244217.0, "train_total_episodes": 2130.0, "train_loaded_steps": 1999935.0, "train_loaded_episodes": 1036.0}
{"step": 16984604, "train_return": 16.0, "train_length": 1934.0, "train_total_steps": 4246151.0, "train_total_episodes": 2131.0, "train_loaded_steps": 1998159.0, "train_loaded_episodes": 1035.0}
{"step": 16992224, "train_return": 17.0, "train_length": 1905.0, "train_total_steps": 4248056.0, "train_total_episodes": 2132.0, "train_loaded_steps": 1998257.0, "train_loaded_episodes": 1035.0}
{"step": 16999184, "train_return": 20.0, "train_length": 1740.0, "train_total_steps": 4249796.0, "train_total_episodes": 2133.0, "train_loaded_steps": 1999997.0, "train_loaded_episodes": 1036.0}
{"step": 17005808, "kl_loss": 1.3377883510589599, "image_loss": 3772.0, "reward_loss": 0.9191273203849792, "discount_loss": 0.007741215765476227, "model_kl": 1.3377883224487304, "prior_ent": 26.4811948425293, "post_ent": 25.152820776367186, "model_loss": 3773.091633984375, "model_loss_scale": 4096.0, "model_grad_norm": 4.9524490869522095, "actor_loss": -0.002367719664904871, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.03702449332475662, "critic_loss": 0.919609414768219, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.3980938243627548, "reward_mean": 0.007422563791682478, "reward_std": 0.08328249389529228, "reward_normed_mean": 0.007422563791682478, "reward_normed_std": 0.08328249389529228, "critic_slow": 5.52654923248291, "critic_target": 5.527413555145264, "actor_ent": 1.4033210355758667, "actor_ent_scale": 0.0010000000474974513, "critic": 5.527070207977295, "fps": 114.15732626873178}
{"step": 17006420, "train_return": 20.0, "train_length": 1809.0, "train_total_steps": 4251605.0, "train_total_episodes": 2134.0, "train_loaded_steps": 1999944.0, "train_loaded_episodes": 1036.0}
{"step": 17013436, "train_return": 20.0, "train_length": 1754.0, "train_total_steps": 4253359.0, "train_total_episodes": 2135.0, "train_loaded_steps": 1999689.0, "train_loaded_episodes": 1036.0}
{"step": 17020828, "train_return": 19.0, "train_length": 1848.0, "train_total_steps": 4255207.0, "train_total_episodes": 2136.0, "train_loaded_steps": 1999590.0, "train_loaded_episodes": 1036.0}
{"step": 17029272, "train_return": 18.0, "train_length": 2111.0, "train_total_steps": 4257318.0, "train_total_episodes": 2137.0, "train_loaded_steps": 1999973.0, "train_loaded_episodes": 1036.0}
{"step": 17036516, "train_return": 18.0, "train_length": 1811.0, "train_total_steps": 4259129.0, "train_total_episodes": 2138.0, "train_loaded_steps": 1997921.0, "train_loaded_episodes": 1035.0}
{"step": 17043348, "train_return": 21.0, "train_length": 1708.0, "train_total_steps": 4260837.0, "train_total_episodes": 2139.0, "train_loaded_steps": 1999629.0, "train_loaded_episodes": 1036.0}
{"step": 17045808, "kl_loss": 1.3590200735092164, "image_loss": 3772.0, "reward_loss": 0.9191343185424805, "discount_loss": 0.007744822513312101, "model_kl": 1.3590200437545776, "prior_ent": 26.42438641662598, "post_ent": 25.076151028442382, "model_loss": 3773.093793359375, "model_loss_scale": 4096.0, "model_grad_norm": 5.049088918876648, "actor_loss": -0.003718173911271151, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.037071213656663896, "critic_loss": 0.9192747776031495, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.3969871557593346, "reward_mean": 0.007370225100824609, "reward_std": 0.08242657830119134, "reward_normed_mean": 0.007370225100824609, "reward_normed_std": 0.08242657830119134, "critic_slow": 5.559152750396729, "critic_target": 5.560106062698364, "actor_ent": 1.3824691261291504, "actor_ent_scale": 0.0010000000474974513, "critic": 5.559592009353637, "fps": 112.4844241550672}
{"step": 17050452, "train_return": 19.0, "train_length": 1776.0, "train_total_steps": 4262613.0, "train_total_episodes": 2140.0, "train_loaded_steps": 1999444.0, "train_loaded_episodes": 1036.0}
{"step": 17058120, "train_return": 17.0, "train_length": 1917.0, "train_total_steps": 4264530.0, "train_total_episodes": 2141.0, "train_loaded_steps": 1999292.0, "train_loaded_episodes": 1036.0}
{"step": 17067084, "train_return": 15.0, "train_length": 2241.0, "train_total_steps": 4266771.0, "train_total_episodes": 2142.0, "train_loaded_steps": 1999614.0, "train_loaded_episodes": 1036.0}
{"step": 17074264, "train_return": 18.0, "train_length": 1795.0, "train_total_steps": 4268566.0, "train_total_episodes": 2143.0, "train_loaded_steps": 1999653.0, "train_loaded_episodes": 1036.0}
{"step": 17081724, "train_return": 18.0, "train_length": 1865.0, "train_total_steps": 4270431.0, "train_total_episodes": 2144.0, "train_loaded_steps": 1999681.0, "train_loaded_episodes": 1036.0}
{"step": 17085808, "kl_loss": 1.3679024879455566, "image_loss": 3772.0, "reward_loss": 0.9191232253074646, "discount_loss": 0.007744932541996241, "model_kl": 1.3679024585723878, "prior_ent": 26.415505001831054, "post_ent": 25.063368368530274, "model_loss": 3773.094658984375, "model_loss_scale": 6533.9392, "model_grad_norm": 4.881683892440796, "actor_loss": -0.005496220745868049, "actor_loss_scale": 105067.3152, "actor_grad_norm": 0.03650364235043526, "critic_loss": 0.9186035443305969, "critic_loss_scale": 105067.3152, "critic_grad_norm": 0.3779314997792244, "reward_mean": 0.0074017776594031606, "reward_std": 0.08247187808156013, "reward_normed_mean": 0.0074017776594031606, "reward_normed_std": 0.08247187808156013, "critic_slow": 5.523898912811279, "critic_target": 5.523469238662719, "actor_ent": 1.3964790563583374, "actor_ent_scale": 0.0010000000474974513, "critic": 5.523036083984375, "fps": 112.90118106768999}
{"step": 17089284, "train_return": 18.0, "train_length": 1890.0, "train_total_steps": 4272321.0, "train_total_episodes": 2145.0, "train_loaded_steps": 1999383.0, "train_loaded_episodes": 1036.0}
{"step": 17096364, "train_return": 19.0, "train_length": 1770.0, "train_total_steps": 4274091.0, "train_total_episodes": 2146.0, "train_loaded_steps": 1998916.0, "train_loaded_episodes": 1036.0}
{"step": 17104308, "train_return": 17.0, "train_length": 1986.0, "train_total_steps": 4276077.0, "train_total_episodes": 2147.0, "train_loaded_steps": 1999061.0, "train_loaded_episodes": 1036.0}
{"step": 17110956, "train_return": 21.0, "train_length": 1662.0, "train_total_steps": 4277739.0, "train_total_episodes": 2148.0, "train_loaded_steps": 1998498.0, "train_loaded_episodes": 1036.0}
{"step": 17117768, "train_return": 21.0, "train_length": 1703.0, "train_total_steps": 4279442.0, "train_total_episodes": 2149.0, "train_loaded_steps": 1998274.0, "train_loaded_episodes": 1036.0}
{"step": 17125056, "train_return": 19.0, "train_length": 1822.0, "train_total_steps": 4281264.0, "train_total_episodes": 2150.0, "train_loaded_steps": 1998149.0, "train_loaded_episodes": 1036.0}
{"step": 17125808, "kl_loss": 1.4019577541351318, "image_loss": 3772.0, "reward_loss": 0.9191112694740295, "discount_loss": 0.0077592335537076, "model_kl": 1.4019577224731445, "prior_ent": 26.32352416687012, "post_ent": 24.941947695922853, "model_loss": 3773.098134375, "model_loss_scale": 8192.0, "model_grad_norm": 5.0113580001831055, "actor_loss": -0.008324334641743918, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.035999846091866496, "critic_loss": 0.9187952473640442, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3690646583557129, "reward_mean": 0.007284910708543611, "reward_std": 0.08240450284481049, "reward_normed_mean": 0.007284910708543611, "reward_normed_std": 0.08240450284481049, "critic_slow": 5.560546392822266, "critic_target": 5.558786725616455, "actor_ent": 1.3898966857910156, "actor_ent_scale": 0.0010000000474974513, "critic": 5.558282670593262, "fps": 112.20480416825028}
{"step": 17132648, "train_return": 18.0, "train_length": 1898.0, "train_total_steps": 4283162.0, "train_total_episodes": 2151.0, "train_loaded_steps": 1998225.0, "train_loaded_episodes": 1036.0}
{"step": 17140312, "train_return": 18.0, "train_length": 1916.0, "train_total_steps": 4285078.0, "train_total_episodes": 2152.0, "train_loaded_steps": 1997990.0, "train_loaded_episodes": 1036.0}
{"step": 17148380, "train_return": 14.0, "train_length": 2017.0, "train_total_steps": 4287095.0, "train_total_episodes": 2153.0, "train_loaded_steps": 1998074.0, "train_loaded_episodes": 1036.0}
{"step": 17155428, "train_return": 19.0, "train_length": 1762.0, "train_total_steps": 4288857.0, "train_total_episodes": 2154.0, "train_loaded_steps": 1999836.0, "train_loaded_episodes": 1037.0}
{"step": 17162456, "train_return": 20.0, "train_length": 1757.0, "train_total_steps": 4290614.0, "train_total_episodes": 2155.0, "train_loaded_steps": 1999711.0, "train_loaded_episodes": 1037.0}
{"step": 17165808, "kl_loss": 1.3685713388442993, "image_loss": 3772.0, "reward_loss": 0.919118110370636, "discount_loss": 0.0077423109374940395, "model_kl": 1.3685713077545165, "prior_ent": 26.386908502197265, "post_ent": 25.03058283081055, "model_loss": 3773.094719140625, "model_loss_scale": 8192.0, "model_grad_norm": 4.911804726791382, "actor_loss": -0.00788295713904663, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.03557571275532246, "critic_loss": 0.9194411496162415, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.3891007627725601, "reward_mean": 0.00720238476684317, "reward_std": 0.08244760555028915, "reward_normed_mean": 0.00720238476684317, "reward_normed_std": 0.08244760555028915, "critic_slow": 5.526254684829712, "critic_target": 5.524334832382202, "actor_ent": 1.4001091178894043, "actor_ent_scale": 0.0010000000474974513, "critic": 5.5238655696868895, "fps": 113.23152512942785}
{"step": 17169776, "train_return": 19.0, "train_length": 1830.0, "train_total_steps": 4292444.0, "train_total_episodes": 2156.0, "train_loaded_steps": 1999096.0, "train_loaded_episodes": 1037.0}
{"step": 17177372, "train_return": 18.0, "train_length": 1899.0, "train_total_steps": 4294343.0, "train_total_episodes": 2157.0, "train_loaded_steps": 1998784.0, "train_loaded_episodes": 1037.0}
{"step": 17177172, "eval_return": 20.0, "eval_length": 1739.0, "eval_total_steps": 43325.0, "eval_total_episodes": 22.0, "eval_loaded_steps": 43347.0, "eval_loaded_episodes": 22.0}
{"step": 17177176, "kl_loss": 1.4096949100494385, "image_loss": 3772.0, "reward_loss": 0.9192474484443665, "discount_loss": 0.007735567167401314, "model_kl": 1.409694790840149, "prior_ent": 26.31537437438965, "post_ent": 24.929319381713867, "model_loss": 3773.098876953125, "model_loss_scale": 16384.0, "model_grad_norm": 5.843520641326904, "actor_loss": 0.02540869265794754, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02990332804620266, "critic_loss": 0.9133162498474121, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.2401728481054306, "reward_mean": 0.010508310981094837, "reward_std": 0.08140391111373901, "reward_normed_mean": 0.010508310981094837, "reward_normed_std": 0.08140391111373901, "critic_slow": 5.340366363525391, "critic_target": 5.361401557922363, "actor_ent": 1.17734694480896, "actor_ent_scale": 0.0010000000474974513, "critic": 5.3491621017456055, "fps": 0.0}
{"step": 17185024, "train_return": 17.0, "train_length": 1963.0, "train_total_steps": 4296256.0, "train_total_episodes": 2158.0, "train_loaded_steps": 1998311.0, "train_loaded_episodes": 1037.0}
{"step": 17192644, "train_return": 18.0, "train_length": 1905.0, "train_total_steps": 4298161.0, "train_total_episodes": 2159.0, "train_loaded_steps": 1998220.0, "train_loaded_episodes": 1037.0}
{"step": 17199632, "train_return": 21.0, "train_length": 1747.0, "train_total_steps": 4299908.0, "train_total_episodes": 2160.0, "train_loaded_steps": 1999967.0, "train_loaded_episodes": 1038.0}
{"step": 17207732, "train_return": 16.0, "train_length": 2025.0, "train_total_steps": 4301933.0, "train_total_episodes": 2161.0, "train_loaded_steps": 1998037.0, "train_loaded_episodes": 1037.0}
{"step": 17214748, "train_return": 20.0, "train_length": 1754.0, "train_total_steps": 4303687.0, "train_total_episodes": 2162.0, "train_loaded_steps": 1999791.0, "train_loaded_episodes": 1038.0}
{"step": 17217176, "kl_loss": 1.4020565088272094, "image_loss": 3772.0, "reward_loss": 0.9190944858551026, "discount_loss": 0.0077434616431593896, "model_kl": 1.4020564754486085, "prior_ent": 26.501231185913085, "post_ent": 25.116210876464844, "model_loss": 3773.098048046875, "model_loss_scale": 2084.0448, "model_grad_norm": Infinity, "actor_loss": 0.0028462943908278246, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.04211932757198811, "critic_loss": 0.9239953434944153, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.36431959057450297, "reward_mean": 0.007419135547894985, "reward_std": 0.08278061106204987, "reward_normed_mean": 0.007419135547894985, "reward_normed_std": 0.08278061106204987, "critic_slow": 5.388274654388428, "critic_target": 5.392066013336182, "actor_ent": 1.258195757484436, "actor_ent_scale": 0.0010000000474974513, "critic": 5.391983428192138, "fps": 114.80211077560364}
{"step": 17222352, "train_return": 19.0, "train_length": 1901.0, "train_total_steps": 4305588.0, "train_total_episodes": 2163.0, "train_loaded_steps": 1999567.0, "train_loaded_episodes": 1038.0}
{"step": 17229468, "train_return": 19.0, "train_length": 1779.0, "train_total_steps": 4307367.0, "train_total_episodes": 2164.0, "train_loaded_steps": 1999164.0, "train_loaded_episodes": 1038.0}
{"step": 17236684, "train_return": 19.0, "train_length": 1804.0, "train_total_steps": 4309171.0, "train_total_episodes": 2165.0, "train_loaded_steps": 1998703.0, "train_loaded_episodes": 1038.0}
{"step": 17244864, "train_return": 16.0, "train_length": 2045.0, "train_total_steps": 4311216.0, "train_total_episodes": 2166.0, "train_loaded_steps": 1998899.0, "train_loaded_episodes": 1038.0}
{"step": 17252652, "train_return": 17.0, "train_length": 1947.0, "train_total_steps": 4313163.0, "train_total_episodes": 2167.0, "train_loaded_steps": 1998746.0, "train_loaded_episodes": 1038.0}
{"step": 17257176, "kl_loss": 1.3770708868026733, "image_loss": 3772.0, "reward_loss": 0.9190996501922607, "discount_loss": 0.007740839555859566, "model_kl": 1.3770708560943603, "prior_ent": 26.574841668701172, "post_ent": 25.20919070739746, "model_loss": 3773.0955375, "model_loss_scale": 2048.0, "model_grad_norm": 4.244711020278931, "actor_loss": 0.0018936530687875348, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.039272366666793825, "critic_loss": 0.9216351706504822, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.4178853072166443, "reward_mean": 0.007477502063056454, "reward_std": 0.0829446317076683, "reward_normed_mean": 0.007477502063056454, "reward_normed_std": 0.0829446317076683, "critic_slow": 5.398076583862305, "critic_target": 5.400156315612793, "actor_ent": 1.328982795906067, "actor_ent_scale": 0.0010000000474974513, "critic": 5.399754041671753, "fps": 115.15267080445695}
{"step": 17259936, "train_return": 19.0, "train_length": 1821.0, "train_total_steps": 4314984.0, "train_total_episodes": 2168.0, "train_loaded_steps": 1998267.0, "train_loaded_episodes": 1038.0}
{"step": 17267328, "train_return": 19.0, "train_length": 1848.0, "train_total_steps": 4316832.0, "train_total_episodes": 2169.0, "train_loaded_steps": 1998209.0, "train_loaded_episodes": 1038.0}
{"step": 17276156, "train_return": 16.0, "train_length": 2207.0, "train_total_steps": 4319039.0, "train_total_episodes": 2170.0, "train_loaded_steps": 1998630.0, "train_loaded_episodes": 1038.0}
{"step": 17283600, "train_return": 18.0, "train_length": 1861.0, "train_total_steps": 4320900.0, "train_total_episodes": 2171.0, "train_loaded_steps": 1998198.0, "train_loaded_episodes": 1038.0}
{"step": 17291868, "train_return": 17.0, "train_length": 2067.0, "train_total_steps": 4322967.0, "train_total_episodes": 2172.0, "train_loaded_steps": 1998395.0, "train_loaded_episodes": 1038.0}
{"step": 17297176, "kl_loss": 1.370881385421753, "image_loss": 3772.0, "reward_loss": 0.9191120649337768, "discount_loss": 0.007741205571591854, "model_kl": 1.3708813528060912, "prior_ent": 26.359692715454102, "post_ent": 25.008030862426757, "model_loss": 3773.094932421875, "model_loss_scale": 2048.0, "model_grad_norm": 4.958720206642151, "actor_loss": -0.0003635761011602881, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.0388150609344244, "critic_loss": 0.9214283444404602, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.4302752779006958, "reward_mean": 0.007505275569926016, "reward_std": 0.08273797624111176, "reward_normed_mean": 0.007505275569926016, "reward_normed_std": 0.08273797624111176, "critic_slow": 5.405681889343262, "critic_target": 5.408061668395996, "actor_ent": 1.3526005046844483, "actor_ent_scale": 0.0010000000474974513, "critic": 5.407708060455322, "fps": 116.00556876259797}
{"step": 17300000, "train_return": 17.0, "train_length": 2033.0, "train_total_steps": 4325000.0, "train_total_episodes": 2173.0, "train_loaded_steps": 1998392.0, "train_loaded_episodes": 1038.0}
{"step": 17308300, "train_return": 15.0, "train_length": 2075.0, "train_total_steps": 4327075.0, "train_total_episodes": 2174.0, "train_loaded_steps": 1998393.0, "train_loaded_episodes": 1038.0}
{"step": 17316116, "train_return": 16.0, "train_length": 1954.0, "train_total_steps": 4329029.0, "train_total_episodes": 2175.0, "train_loaded_steps": 1998289.0, "train_loaded_episodes": 1038.0}
{"step": 17323728, "train_return": 19.0, "train_length": 1903.0, "train_total_steps": 4330932.0, "train_total_episodes": 2176.0, "train_loaded_steps": 1998389.0, "train_loaded_episodes": 1038.0}
{"step": 17330456, "train_return": 21.0, "train_length": 1682.0, "train_total_steps": 4332614.0, "train_total_episodes": 2177.0, "train_loaded_steps": 1997953.0, "train_loaded_episodes": 1038.0}
{"step": 17337176, "kl_loss": 1.3766508628845215, "image_loss": 3772.0, "reward_loss": 0.9191087146759033, "discount_loss": 0.007741818676143885, "model_kl": 1.3766508317947388, "prior_ent": 26.517245693969727, "post_ent": 25.156701861572266, "model_loss": 3773.095508984375, "model_loss_scale": 3676.5696, "model_grad_norm": 4.848238069343567, "actor_loss": -0.0035607481510960496, "actor_loss_scale": 59087.2576, "actor_grad_norm": 0.036228165087103845, "critic_loss": 0.9184373342514038, "critic_loss_scale": 59087.2576, "critic_grad_norm": 0.36646495137214663, "reward_mean": 0.00744431786458008, "reward_std": 0.0829328492462635, "reward_normed_mean": 0.00744431786458008, "reward_normed_std": 0.0829328492462635, "critic_slow": 5.369731533432007, "critic_target": 5.369606997299194, "actor_ent": 1.3666297157287597, "actor_ent_scale": 0.0010000000474974513, "critic": 5.369137334442138, "fps": 113.93842991309081}
{"step": 17337760, "train_return": 18.0, "train_length": 1826.0, "train_total_steps": 4334440.0, "train_total_episodes": 2178.0, "train_loaded_steps": 1999779.0, "train_loaded_episodes": 1039.0}
{"step": 17345212, "train_return": 18.0, "train_length": 1863.0, "train_total_steps": 4336303.0, "train_total_episodes": 2179.0, "train_loaded_steps": 1999581.0, "train_loaded_episodes": 1039.0}
{"step": 17351852, "train_return": 21.0, "train_length": 1660.0, "train_total_steps": 4337963.0, "train_total_episodes": 2180.0, "train_loaded_steps": 1999062.0, "train_loaded_episodes": 1039.0}
{"step": 17359532, "train_return": 19.0, "train_length": 1920.0, "train_total_steps": 4339883.0, "train_total_episodes": 2181.0, "train_loaded_steps": 1998747.0, "train_loaded_episodes": 1039.0}
{"step": 17368272, "train_return": 14.0, "train_length": 2185.0, "train_total_steps": 4342068.0, "train_total_episodes": 2182.0, "train_loaded_steps": 1998763.0, "train_loaded_episodes": 1039.0}
{"step": 17376280, "train_return": 18.0, "train_length": 2002.0, "train_total_steps": 4344070.0, "train_total_episodes": 2183.0, "train_loaded_steps": 1998596.0, "train_loaded_episodes": 1039.0}
{"step": 17377176, "kl_loss": 1.4042165487289429, "image_loss": 3772.0002, "reward_loss": 0.9191124916076661, "discount_loss": 0.007741363424062729, "model_kl": 1.4042165176391601, "prior_ent": 26.60106254272461, "post_ent": 25.218594473266602, "model_loss": 3773.0984734375, "model_loss_scale": 4096.0, "model_grad_norm": 4.966513493537903, "actor_loss": -0.009284752011380624, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.03621510463654995, "critic_loss": 0.9188623520851136, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.39504809728860857, "reward_mean": 0.00754426953450893, "reward_std": 0.08306494877338409, "reward_normed_mean": 0.00754426953450893, "reward_normed_std": 0.08306494877338409, "critic_slow": 5.411171162414551, "critic_target": 5.409546542358399, "actor_ent": 1.3677026626586914, "actor_ent_scale": 0.0010000000474974513, "critic": 5.40929449005127, "fps": 114.32423834886121}
{"step": 17384144, "train_return": 16.0, "train_length": 1966.0, "train_total_steps": 4346036.0, "train_total_episodes": 2184.0, "train_loaded_steps": 1998726.0, "train_loaded_episodes": 1039.0}
{"step": 17391476, "train_return": 19.0, "train_length": 1833.0, "train_total_steps": 4347869.0, "train_total_episodes": 2185.0, "train_loaded_steps": 1998820.0, "train_loaded_episodes": 1039.0}
{"step": 17399064, "train_return": 17.0, "train_length": 1897.0, "train_total_steps": 4349766.0, "train_total_episodes": 2186.0, "train_loaded_steps": 1998693.0, "train_loaded_episodes": 1039.0}
{"step": 17406508, "train_return": 19.0, "train_length": 1861.0, "train_total_steps": 4351627.0, "train_total_episodes": 2187.0, "train_loaded_steps": 1998732.0, "train_loaded_episodes": 1039.0}
{"step": 17413332, "train_return": 21.0, "train_length": 1706.0, "train_total_steps": 4353333.0, "train_total_episodes": 2188.0, "train_loaded_steps": 1998292.0, "train_loaded_episodes": 1039.0}
{"step": 17417176, "kl_loss": 1.3719146949768066, "image_loss": 3772.0, "reward_loss": 0.9191159193992615, "discount_loss": 0.0077409146301448345, "model_kl": 1.371914667701721, "prior_ent": 26.48784989013672, "post_ent": 25.127677084350587, "model_loss": 3773.095035546875, "model_loss_scale": 4096.0, "model_grad_norm": 4.841765011787414, "actor_loss": -0.009761682356113306, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.03541501956731081, "critic_loss": 0.9186221994400025, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.3648625310063362, "reward_mean": 0.007560475663840771, "reward_std": 0.08279848397374154, "reward_normed_mean": 0.007560475663840771, "reward_normed_std": 0.08279848397374154, "critic_slow": 5.350244636917115, "critic_target": 5.347901650238037, "actor_ent": 1.4033519430160522, "actor_ent_scale": 0.0010000000474974513, "critic": 5.347616267013549, "fps": 115.3601450741485}
{"step": 17420344, "train_return": 20.0, "train_length": 1753.0, "train_total_steps": 4355086.0, "train_total_episodes": 2189.0, "train_loaded_steps": 1997857.0, "train_loaded_episodes": 1039.0}
{"step": 17427748, "train_return": 18.0, "train_length": 1851.0, "train_total_steps": 4356937.0, "train_total_episodes": 2190.0, "train_loaded_steps": 1999708.0, "train_loaded_episodes": 1040.0}
{"step": 17434756, "train_return": 20.0, "train_length": 1752.0, "train_total_steps": 4358689.0, "train_total_episodes": 2191.0, "train_loaded_steps": 1999544.0, "train_loaded_episodes": 1040.0}
{"step": 17441384, "train_return": 21.0, "train_length": 1657.0, "train_total_steps": 4360346.0, "train_total_episodes": 2192.0, "train_loaded_steps": 1999184.0, "train_loaded_episodes": 1040.0}
{"step": 17449908, "train_return": 17.0, "train_length": 2131.0, "train_total_steps": 4362477.0, "train_total_episodes": 2193.0, "train_loaded_steps": 1999288.0, "train_loaded_episodes": 1040.0}
{"step": 17456752, "train_return": 20.0, "train_length": 1711.0, "train_total_steps": 4364188.0, "train_total_episodes": 2194.0, "train_loaded_steps": 1999243.0, "train_loaded_episodes": 1040.0}
{"step": 17457176, "kl_loss": 1.3342292974472045, "image_loss": 3772.000187890625, "reward_loss": 0.9191143196105958, "discount_loss": 0.007760982116311789, "model_kl": 1.3342292707443237, "prior_ent": 26.558617227172853, "post_ent": 25.23349528503418, "model_loss": 3773.09156328125, "model_loss_scale": 6533.9392, "model_grad_norm": 4.592717916297913, "actor_loss": -0.005328588902307092, "actor_loss_scale": 105067.3152, "actor_grad_norm": 0.03422629928588867, "critic_loss": 0.9184661444664002, "critic_loss_scale": 68262.2976, "critic_grad_norm": Infinity, "reward_mean": 0.00765868141297251, "reward_std": 0.08261031810045243, "reward_normed_mean": 0.00765868141297251, "reward_normed_std": 0.08261031810045243, "critic_slow": 5.363037071609497, "critic_target": 5.361978282546997, "actor_ent": 1.3925103935241698, "actor_ent_scale": 0.0010000000474974513, "critic": 5.361416430282593, "fps": 114.58442130046659}
{"step": 17465088, "train_return": 17.0, "train_length": 2084.0, "train_total_steps": 4366272.0, "train_total_episodes": 2195.0, "train_loaded_steps": 1999600.0, "train_loaded_episodes": 1040.0}
{"step": 17472380, "train_return": 20.0, "train_length": 1823.0, "train_total_steps": 4368095.0, "train_total_episodes": 2196.0, "train_loaded_steps": 1999521.0, "train_loaded_episodes": 1040.0}
{"step": 17479720, "train_return": 19.0, "train_length": 1835.0, "train_total_steps": 4369930.0, "train_total_episodes": 2197.0, "train_loaded_steps": 1999313.0, "train_loaded_episodes": 1040.0}
{"step": 17487172, "train_return": 18.0, "train_length": 1863.0, "train_total_steps": 4371793.0, "train_total_episodes": 2198.0, "train_loaded_steps": 1999361.0, "train_loaded_episodes": 1040.0}
{"step": 17494316, "train_return": 20.0, "train_length": 1786.0, "train_total_steps": 4373579.0, "train_total_episodes": 2199.0, "train_loaded_steps": 1999298.0, "train_loaded_episodes": 1040.0}
{"step": 17497176, "kl_loss": 1.338310983276367, "image_loss": 3772.0, "reward_loss": 0.9191094824790954, "discount_loss": 0.00774096519574523, "model_kl": 1.3383109565734863, "prior_ent": 26.390704748535157, "post_ent": 25.06024299621582, "model_loss": 3773.091681640625, "model_loss_scale": 8192.0, "model_grad_norm": 4.9652171167373655, "actor_loss": -0.004592867588390436, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.03518931110054255, "critic_loss": 0.9186102011680602, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.31911739899516106, "reward_mean": 0.007426876124925911, "reward_std": 0.08245246853232384, "reward_normed_mean": 0.007426876124925911, "reward_normed_std": 0.08245246853232384, "critic_slow": 5.242122100830078, "critic_target": 5.241884637451172, "actor_ent": 1.4003224655151367, "actor_ent_scale": 0.0010000000474974513, "critic": 5.241517495727539, "fps": 114.38445116801793}
{"step": 17502332, "train_return": 16.0, "train_length": 2004.0, "train_total_steps": 4375583.0, "train_total_episodes": 2200.0, "train_loaded_steps": 1999049.0, "train_loaded_episodes": 1040.0}
{"step": 17509232, "train_return": 20.0, "train_length": 1725.0, "train_total_steps": 4377308.0, "train_total_episodes": 2201.0, "train_loaded_steps": 1998946.0, "train_loaded_episodes": 1040.0}
{"step": 17516824, "train_return": 18.0, "train_length": 1898.0, "train_total_steps": 4379206.0, "train_total_episodes": 2202.0, "train_loaded_steps": 1999074.0, "train_loaded_episodes": 1040.0}
{"step": 17523900, "train_return": 19.0, "train_length": 1769.0, "train_total_steps": 4380975.0, "train_total_episodes": 2203.0, "train_loaded_steps": 1998741.0, "train_loaded_episodes": 1040.0}
{"step": 17531424, "train_return": 18.0, "train_length": 1881.0, "train_total_steps": 4382856.0, "train_total_episodes": 2204.0, "train_loaded_steps": 1998552.0, "train_loaded_episodes": 1040.0}
{"step": 17537176, "kl_loss": 1.510242125892639, "image_loss": 3772.0, "reward_loss": 0.9191100402832031, "discount_loss": 0.007886103498190642, "model_kl": 1.5102420946121216, "prior_ent": 26.362369076538087, "post_ent": 24.897528646850585, "model_loss": 3773.10959765625, "model_loss_scale": 8192.0, "model_grad_norm": 5.36481509513855, "actor_loss": 0.0003817921906709671, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.04208797148764133, "critic_loss": 0.9281196215629578, "critic_loss_scale": 60293.12, "critic_grad_norm": Infinity, "reward_mean": 0.007467698822263628, "reward_std": 0.08262195048332215, "reward_normed_mean": 0.007467698822263628, "reward_normed_std": 0.08262195048332215, "critic_slow": 5.224501490402222, "critic_target": 5.22733398399353, "actor_ent": 1.3568061017990112, "actor_ent_scale": 0.0010000000474974513, "critic": 5.226800523376465, "fps": 113.1941307507968}
{"step": 17539292, "train_return": 17.0, "train_length": 1967.0, "train_total_steps": 4384823.0, "train_total_episodes": 2205.0, "train_loaded_steps": 1998501.0, "train_loaded_episodes": 1040.0}
{"step": 17546752, "train_return": 18.0, "train_length": 1865.0, "train_total_steps": 4386688.0, "train_total_episodes": 2206.0, "train_loaded_steps": 1998386.0, "train_loaded_episodes": 1040.0}
{"step": 17553936, "train_return": 19.0, "train_length": 1796.0, "train_total_steps": 4388484.0, "train_total_episodes": 2207.0, "train_loaded_steps": 1998373.0, "train_loaded_episodes": 1040.0}
{"step": 17561340, "train_return": 19.0, "train_length": 1851.0, "train_total_steps": 4390335.0, "train_total_episodes": 2208.0, "train_loaded_steps": 1998314.0, "train_loaded_episodes": 1040.0}
{"step": 17568792, "train_return": 18.0, "train_length": 1863.0, "train_total_steps": 4392198.0, "train_total_episodes": 2209.0, "train_loaded_steps": 1998331.0, "train_loaded_episodes": 1040.0}
{"step": 17576008, "train_return": 19.0, "train_length": 1804.0, "train_total_steps": 4394002.0, "train_total_episodes": 2210.0, "train_loaded_steps": 1998141.0, "train_loaded_episodes": 1040.0}
{"step": 17577176, "kl_loss": 1.4126560918807984, "image_loss": 3772.0, "reward_loss": 0.9191110074996949, "discount_loss": 0.007760959206521511, "model_kl": 1.412656057548523, "prior_ent": 26.413805374145507, "post_ent": 25.017276034545898, "model_loss": 3773.099216796875, "model_loss_scale": 11429.4784, "model_grad_norm": 4.1887819688797, "actor_loss": -0.0058705068178416695, "actor_loss_scale": 183920.2304, "actor_grad_norm": 0.039689918872714045, "critic_loss": 0.9222459860801697, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.27412764427661895, "reward_mean": 0.007431422521639615, "reward_std": 0.08198137726783752, "reward_normed_mean": 0.007431422521639615, "reward_normed_std": 0.08198137726783752, "critic_slow": 5.247833277511597, "critic_target": 5.2467871746063235, "actor_ent": 1.3333539505004883, "actor_ent_scale": 0.0010000000474974513, "critic": 5.247053526687622, "fps": 114.64022067648821}
{"step": 17583288, "train_return": 19.0, "train_length": 1820.0, "train_total_steps": 4395822.0, "train_total_episodes": 2211.0, "train_loaded_steps": 1999961.0, "train_loaded_episodes": 1041.0}
{"step": 17590304, "train_return": 20.0, "train_length": 1754.0, "train_total_steps": 4397576.0, "train_total_episodes": 2212.0, "train_loaded_steps": 1999610.0, "train_loaded_episodes": 1041.0}
{"step": 17597356, "train_return": 20.0, "train_length": 1763.0, "train_total_steps": 4399339.0, "train_total_episodes": 2213.0, "train_loaded_steps": 1999285.0, "train_loaded_episodes": 1041.0}
{"step": 17605228, "train_return": 17.0, "train_length": 1968.0, "train_total_steps": 4401307.0, "train_total_episodes": 2214.0, "train_loaded_steps": 1999126.0, "train_loaded_episodes": 1041.0}
{"step": 17612828, "train_return": 18.0, "train_length": 1900.0, "train_total_steps": 4403207.0, "train_total_episodes": 2215.0, "train_loaded_steps": 1999371.0, "train_loaded_episodes": 1041.0}
{"step": 17617176, "kl_loss": 1.381993111038208, "image_loss": 3772.0, "reward_loss": 0.919129046535492, "discount_loss": 0.007767040184140205, "model_kl": 1.3819930782318115, "prior_ent": 26.489432186889648, "post_ent": 25.12136837158203, "model_loss": 3773.09619375, "model_loss_scale": 16384.0, "model_grad_norm": 5.043014119148254, "actor_loss": -0.0022449764835939276, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.03899954854249954, "critic_loss": 0.9228439435005188, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.34002745797634126, "reward_mean": 0.007411432357842568, "reward_std": 0.08169297994375228, "reward_normed_mean": 0.007411432357842568, "reward_normed_std": 0.08169297994375228, "critic_slow": 5.29139133529663, "critic_target": 5.292780004882813, "actor_ent": 1.3736208255767823, "actor_ent_scale": 0.0010000000474974513, "critic": 5.2929107940673825, "fps": 113.77498486794212}
{"step": 17619628, "train_return": 21.0, "train_length": 1700.0, "train_total_steps": 4404907.0, "train_total_episodes": 2216.0, "train_loaded_steps": 1999232.0, "train_loaded_episodes": 1041.0}
{"step": 17627260, "train_return": 17.0, "train_length": 1908.0, "train_total_steps": 4406815.0, "train_total_episodes": 2217.0, "train_loaded_steps": 1999233.0, "train_loaded_episodes": 1041.0}
{"step": 17635216, "train_return": 18.0, "train_length": 1989.0, "train_total_steps": 4408804.0, "train_total_episodes": 2218.0, "train_loaded_steps": 1999202.0, "train_loaded_episodes": 1041.0}
{"step": 17643052, "train_return": 18.0, "train_length": 1959.0, "train_total_steps": 4410763.0, "train_total_episodes": 2219.0, "train_loaded_steps": 1998924.0, "train_loaded_episodes": 1041.0}
{"step": 17651148, "train_return": 16.0, "train_length": 2024.0, "train_total_steps": 4412787.0, "train_total_episodes": 2220.0, "train_loaded_steps": 1999058.0, "train_loaded_episodes": 1041.0}
{"step": 17657176, "kl_loss": 1.3552115495681762, "image_loss": 3772.0, "reward_loss": 0.9191191783905029, "discount_loss": 0.007781821162998677, "model_kl": 1.3552115203857422, "prior_ent": 26.436320883178713, "post_ent": 25.089313021850586, "model_loss": 3773.0935703125, "model_loss_scale": 15099.4944, "model_grad_norm": Infinity, "actor_loss": -0.004151468265638323, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.03671615661680699, "critic_loss": 0.9182822813987732, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.27585790246725084, "reward_mean": 0.007498291715141386, "reward_std": 0.08316057121157647, "reward_normed_mean": 0.007498291715141386, "reward_normed_std": 0.08316057121157647, "critic_slow": 5.277705905532837, "critic_target": 5.278304844284057, "actor_ent": 1.3451710510253907, "actor_ent_scale": 0.0010000000474974513, "critic": 5.278154197311402, "fps": 114.71401838285126}
{"step": 17658536, "train_return": 19.0, "train_length": 1847.0, "train_total_steps": 4414634.0, "train_total_episodes": 2221.0, "train_loaded_steps": 1999129.0, "train_loaded_episodes": 1041.0}
{"step": 17667764, "train_return": 13.0, "train_length": 2307.0, "train_total_steps": 4416941.0, "train_total_episodes": 2222.0, "train_loaded_steps": 1999418.0, "train_loaded_episodes": 1041.0}
{"step": 17675368, "train_return": 17.0, "train_length": 1901.0, "train_total_steps": 4418842.0, "train_total_episodes": 2223.0, "train_loaded_steps": 1999569.0, "train_loaded_episodes": 1041.0}
{"step": 17683396, "train_return": 18.0, "train_length": 2007.0, "train_total_steps": 4420849.0, "train_total_episodes": 2224.0, "train_loaded_steps": 1999609.0, "train_loaded_episodes": 1041.0}
{"step": 17690760, "train_return": 18.0, "train_length": 1841.0, "train_total_steps": 4422690.0, "train_total_episodes": 2225.0, "train_loaded_steps": 1999702.0, "train_loaded_episodes": 1041.0}
{"step": 17697176, "kl_loss": 1.3388823234558105, "image_loss": 3772.0, "reward_loss": 0.9191084389686585, "discount_loss": 0.007742180866003036, "model_kl": 1.3388822929382325, "prior_ent": 26.37052602233887, "post_ent": 25.038609066772462, "model_loss": 3773.091731640625, "model_loss_scale": 8192.0, "model_grad_norm": 4.978534941291809, "actor_loss": -0.006990791982779046, "actor_loss_scale": 315411.6608, "actor_grad_norm": 0.033670347467064855, "critic_loss": 0.9173795930862427, "critic_loss_scale": 64225.28, "critic_grad_norm": 0.26476286636590957, "reward_mean": 0.007573491550795734, "reward_std": 0.08243887829780579, "reward_normed_mean": 0.007573491550795734, "reward_normed_std": 0.08243887829780579, "critic_slow": 5.278521604537964, "critic_target": 5.277896639633179, "actor_ent": 1.3574754156112672, "actor_ent_scale": 0.0010000000474974513, "critic": 5.277689720916748, "fps": 112.96254551248114}
{"step": 17698332, "train_return": 18.0, "train_length": 1893.0, "train_total_steps": 4424583.0, "train_total_episodes": 2226.0, "train_loaded_steps": 1999775.0, "train_loaded_episodes": 1041.0}
{"step": 17706136, "train_return": 18.0, "train_length": 1951.0, "train_total_steps": 4426534.0, "train_total_episodes": 2227.0, "train_loaded_steps": 1999759.0, "train_loaded_episodes": 1041.0}
{"step": 17713080, "train_return": 20.0, "train_length": 1736.0, "train_total_steps": 4428270.0, "train_total_episodes": 2228.0, "train_loaded_steps": 1999628.0, "train_loaded_episodes": 1041.0}
{"step": 17720296, "train_return": 19.0, "train_length": 1804.0, "train_total_steps": 4430074.0, "train_total_episodes": 2229.0, "train_loaded_steps": 1999482.0, "train_loaded_episodes": 1041.0}
{"step": 17727740, "train_return": 18.0, "train_length": 1861.0, "train_total_steps": 4431935.0, "train_total_episodes": 2230.0, "train_loaded_steps": 1999347.0, "train_loaded_episodes": 1041.0}
{"step": 17735072, "train_return": 19.0, "train_length": 1833.0, "train_total_steps": 4433768.0, "train_total_episodes": 2231.0, "train_loaded_steps": 1999001.0, "train_loaded_episodes": 1041.0}
{"step": 17737176, "kl_loss": 1.34924219455719, "image_loss": 3772.0, "reward_loss": 0.9191266917228699, "discount_loss": 0.007744959159195423, "model_kl": 1.349242165374756, "prior_ent": 26.44029285583496, "post_ent": 25.10325424194336, "model_loss": 3773.0928078125, "model_loss_scale": 8192.0, "model_grad_norm": 4.734200396156311, "actor_loss": -0.006317515688009734, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.03346728419959545, "critic_loss": 0.917968588066101, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.274610319006443, "reward_mean": 0.007581001834431663, "reward_std": 0.08188927730321884, "reward_normed_mean": 0.007581001834431663, "reward_normed_std": 0.08188927730321884, "critic_slow": 5.187922194290161, "critic_target": 5.187448664855957, "actor_ent": 1.3939104042053223, "actor_ent_scale": 0.0010000000474974513, "critic": 5.187309387588501, "fps": 113.79739234689418}
{"step": 17743988, "train_return": 16.0, "train_length": 2229.0, "train_total_steps": 4435997.0, "train_total_episodes": 2232.0, "train_loaded_steps": 1999040.0, "train_loaded_episodes": 1041.0}
{"step": 17752476, "train_return": 16.0, "train_length": 2122.0, "train_total_steps": 4438119.0, "train_total_episodes": 2233.0, "train_loaded_steps": 1999297.0, "train_loaded_episodes": 1041.0}
{"step": 17760632, "train_return": 16.0, "train_length": 2039.0, "train_total_steps": 4440158.0, "train_total_episodes": 2234.0, "train_loaded_steps": 1999185.0, "train_loaded_episodes": 1041.0}
{"step": 17769036, "train_return": 17.0, "train_length": 2101.0, "train_total_steps": 4442259.0, "train_total_episodes": 2235.0, "train_loaded_steps": 1999438.0, "train_loaded_episodes": 1041.0}
{"step": 17777148, "train_return": 16.0, "train_length": 2028.0, "train_total_steps": 4444287.0, "train_total_episodes": 2236.0, "train_loaded_steps": 1999649.0, "train_loaded_episodes": 1041.0}
{"step": 17777176, "kl_loss": 1.3718817905426026, "image_loss": 3772.0001921875, "reward_loss": 0.9191064093589782, "discount_loss": 0.007771193718910217, "model_kl": 1.3718817602157594, "prior_ent": 26.517055923461914, "post_ent": 25.162764825439453, "model_loss": 3773.095365234375, "model_loss_scale": 2662.4, "model_grad_norm": Infinity, "actor_loss": -0.007698693462635856, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.03330279807448387, "critic_loss": 0.9175096097946167, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.271603808003664, "reward_mean": 0.0074917211186140776, "reward_std": 0.08264775232076645, "reward_normed_mean": 0.0074917211186140776, "reward_normed_std": 0.08264775232076645, "critic_slow": 5.198508795547485, "critic_target": 5.197990043258667, "actor_ent": 1.3879298028945923, "actor_ent_scale": 0.0010000000474974513, "critic": 5.197817489242554, "fps": 116.03139955565491}
{"step": 17784816, "train_return": 19.0, "train_length": 1917.0, "train_total_steps": 4446204.0, "train_total_episodes": 2237.0, "train_loaded_steps": 1999370.0, "train_loaded_episodes": 1041.0}
{"step": 17792596, "train_return": 18.0, "train_length": 1945.0, "train_total_steps": 4448149.0, "train_total_episodes": 2238.0, "train_loaded_steps": 1998827.0, "train_loaded_episodes": 1041.0}
{"step": 17799772, "train_return": 18.0, "train_length": 1794.0, "train_total_steps": 4449943.0, "train_total_episodes": 2239.0, "train_loaded_steps": 1998649.0, "train_loaded_episodes": 1041.0}
{"step": 17807916, "train_return": 15.0, "train_length": 2036.0, "train_total_steps": 4451979.0, "train_total_episodes": 2240.0, "train_loaded_steps": 1998803.0, "train_loaded_episodes": 1041.0}
{"step": 17815880, "train_return": 17.0, "train_length": 1991.0, "train_total_steps": 4453970.0, "train_total_episodes": 2241.0, "train_loaded_steps": 1998951.0, "train_loaded_episodes": 1041.0}
{"step": 17817176, "kl_loss": 1.330294602394104, "image_loss": 3772.0, "reward_loss": 0.919106295967102, "discount_loss": 0.007741503701359034, "model_kl": 1.3302945686340333, "prior_ent": 26.418721990966798, "post_ent": 25.096266439819335, "model_loss": 3773.090873046875, "model_loss_scale": 1024.0, "model_grad_norm": 1.9147663328170776, "actor_loss": -0.006533221805188805, "actor_loss_scale": 525965.7216, "actor_grad_norm": 0.03234921335875988, "critic_loss": 0.9171107844352722, "critic_loss_scale": 115343.36, "critic_grad_norm": 0.2674577233731747, "reward_mean": 0.007592846636101603, "reward_std": 0.08304244142770767, "reward_normed_mean": 0.007592846636101603, "reward_normed_std": 0.08304244142770767, "critic_slow": 5.201680895233154, "critic_target": 5.201135573577881, "actor_ent": 1.4110546125411987, "actor_ent_scale": 0.0010000000474974513, "critic": 5.200969306564331, "fps": 115.64708551638321}
{"step": 17823004, "train_return": 19.0, "train_length": 1781.0, "train_total_steps": 4455751.0, "train_total_episodes": 2242.0, "train_loaded_steps": 1998607.0, "train_loaded_episodes": 1041.0}
{"step": 17830240, "train_return": 19.0, "train_length": 1809.0, "train_total_steps": 4457560.0, "train_total_episodes": 2243.0, "train_loaded_steps": 1998488.0, "train_loaded_episodes": 1041.0}
{"step": 17837296, "train_return": 20.0, "train_length": 1764.0, "train_total_steps": 4459324.0, "train_total_episodes": 2244.0, "train_loaded_steps": 1998194.0, "train_loaded_episodes": 1041.0}
{"step": 17844044, "train_return": 21.0, "train_length": 1687.0, "train_total_steps": 4461011.0, "train_total_episodes": 2245.0, "train_loaded_steps": 1999881.0, "train_loaded_episodes": 1042.0}
{"step": 17852008, "train_return": 16.0, "train_length": 1991.0, "train_total_steps": 4463002.0, "train_total_episodes": 2246.0, "train_loaded_steps": 1999703.0, "train_loaded_episodes": 1042.0}
{"step": 17857176, "kl_loss": 1.3416234813690187, "image_loss": 3772.0002, "reward_loss": 0.9191115127563476, "discount_loss": 0.007749023476243019, "model_kl": 1.3416234540939331, "prior_ent": 26.32451953125, "post_ent": 24.99275131530762, "model_loss": 3773.09225390625, "model_loss_scale": 1024.0, "model_grad_norm": 3.5129140100479126, "actor_loss": -0.006751836718712002, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.031568486255407334, "critic_loss": 0.9171647046089172, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2803075282096863, "reward_mean": 0.007584385699033737, "reward_std": 0.08301226037144661, "reward_normed_mean": 0.007584385699033737, "reward_normed_std": 0.08301226037144661, "critic_slow": 5.216108967971802, "critic_target": 5.215873768615722, "actor_ent": 1.3990360187530517, "actor_ent_scale": 0.0010000000474974513, "critic": 5.2157055866241455, "fps": 116.25057838023622}
{"step": 17859452, "train_return": 20.0, "train_length": 1861.0, "train_total_steps": 4464863.0, "train_total_episodes": 2247.0, "train_loaded_steps": 1999466.0, "train_loaded_episodes": 1042.0}
{"step": 17866920, "train_return": 18.0, "train_length": 1867.0, "train_total_steps": 4466730.0, "train_total_episodes": 2248.0, "train_loaded_steps": 1999035.0, "train_loaded_episodes": 1042.0}
{"step": 17873884, "train_return": 20.0, "train_length": 1741.0, "train_total_steps": 4468471.0, "train_total_episodes": 2249.0, "train_loaded_steps": 1998832.0, "train_loaded_episodes": 1042.0}
{"step": 17881396, "train_return": 17.0, "train_length": 1878.0, "train_total_steps": 4470349.0, "train_total_episodes": 2250.0, "train_loaded_steps": 1998584.0, "train_loaded_episodes": 1042.0}
{"step": 17888852, "train_return": 20.0, "train_length": 1864.0, "train_total_steps": 4472213.0, "train_total_episodes": 2251.0, "train_loaded_steps": 1998460.0, "train_loaded_episodes": 1042.0}
{"step": 17896320, "train_return": 17.0, "train_length": 1867.0, "train_total_steps": 4474080.0, "train_total_episodes": 2252.0, "train_loaded_steps": 1998253.0, "train_loaded_episodes": 1042.0}
{"step": 17897176, "kl_loss": 1.3440947998046875, "image_loss": 3772.0, "reward_loss": 0.9191059838294983, "discount_loss": 0.007757121409475804, "model_kl": 1.3440947681427002, "prior_ent": 26.35973726196289, "post_ent": 25.027050482177735, "model_loss": 3773.092326171875, "model_loss_scale": 1600.7168, "model_grad_norm": 4.627058775520324, "actor_loss": -0.007219636298774276, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.0306231481552124, "critic_loss": 0.9173028748512269, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.272878055369854, "reward_mean": 0.007394780074805022, "reward_std": 0.08273372672796249, "reward_normed_mean": 0.007394780074805022, "reward_normed_std": 0.08273372672796249, "critic_slow": 5.239354473495483, "critic_target": 5.238630110931396, "actor_ent": 1.405346628189087, "actor_ent_scale": 0.0010000000474974513, "critic": 5.2385206722259525, "fps": 116.18175015731511}
{"step": 17904352, "train_return": 16.0, "train_length": 2008.0, "train_total_steps": 4476088.0, "train_total_episodes": 2253.0, "train_loaded_steps": 1998331.0, "train_loaded_episodes": 1042.0}
{"step": 17911816, "train_return": 18.0, "train_length": 1866.0, "train_total_steps": 4477954.0, "train_total_episodes": 2254.0, "train_loaded_steps": 1998436.0, "train_loaded_episodes": 1042.0}
{"step": 17919476, "train_return": 16.0, "train_length": 1915.0, "train_total_steps": 4479869.0, "train_total_episodes": 2255.0, "train_loaded_steps": 1998505.0, "train_loaded_episodes": 1042.0}
{"step": 17926420, "train_return": 20.0, "train_length": 1736.0, "train_total_steps": 4481605.0, "train_total_episodes": 2256.0, "train_loaded_steps": 1998529.0, "train_loaded_episodes": 1042.0}
{"step": 17933468, "train_return": 19.0, "train_length": 1762.0, "train_total_steps": 4483367.0, "train_total_episodes": 2257.0, "train_loaded_steps": 1998492.0, "train_loaded_episodes": 1042.0}
{"step": 17937176, "kl_loss": 1.3486506786346435, "image_loss": 3772.0, "reward_loss": 0.9191045636177063, "discount_loss": 0.0077418268956243996, "model_kl": 1.3486506448745728, "prior_ent": 26.4104198059082, "post_ent": 25.07169705200195, "model_loss": 3773.09271484375, "model_loss_scale": 2048.0, "model_grad_norm": 4.688965853118897, "actor_loss": -0.008314813619852066, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.029618288645148278, "critic_loss": 0.917333846950531, "critic_loss_scale": 181193.9328, "critic_grad_norm": Infinity, "reward_mean": 0.007450856812763959, "reward_std": 0.08278549435138702, "reward_normed_mean": 0.007450856812763959, "reward_normed_std": 0.08278549435138702, "critic_slow": 5.17731216583252, "critic_target": 5.1769822998046875, "actor_ent": 1.4495254108428954, "actor_ent_scale": 0.0010000000474974513, "critic": 5.176899436569214, "fps": 114.22196547956132}
{"step": 17941828, "train_return": 15.0, "train_length": 2090.0, "train_total_steps": 4485457.0, "train_total_episodes": 2258.0, "train_loaded_steps": 1998690.0, "train_loaded_episodes": 1042.0}
{"step": 17949032, "train_return": 19.0, "train_length": 1801.0, "train_total_steps": 4487258.0, "train_total_episodes": 2259.0, "train_loaded_steps": 1998296.0, "train_loaded_episodes": 1042.0}
{"step": 17956956, "train_return": 18.0, "train_length": 1981.0, "train_total_steps": 4489239.0, "train_total_episodes": 2260.0, "train_loaded_steps": 1998612.0, "train_loaded_episodes": 1042.0}
{"step": 17964160, "train_return": 20.0, "train_length": 1801.0, "train_total_steps": 4491040.0, "train_total_episodes": 2261.0, "train_loaded_steps": 1998391.0, "train_loaded_episodes": 1042.0}
{"step": 17971496, "train_return": 18.0, "train_length": 1834.0, "train_total_steps": 4492874.0, "train_total_episodes": 2262.0, "train_loaded_steps": 1998301.0, "train_loaded_episodes": 1042.0}
{"step": 17977176, "kl_loss": 1.3344630250930787, "image_loss": 3772.0, "reward_loss": 0.9191044423103333, "discount_loss": 0.007755945718288422, "model_kl": 1.3344629976272584, "prior_ent": 26.301952111816405, "post_ent": 24.980255618286133, "model_loss": 3773.09135234375, "model_loss_scale": 2048.0, "model_grad_norm": 4.778497853851318, "actor_loss": -0.007611456678995455, "actor_loss_scale": 1890792.2432, "actor_grad_norm": 0.030895684181153776, "critic_loss": 0.9174590769767761, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.30487380439043044, "reward_mean": 0.007659590496798046, "reward_std": 0.08305164501667023, "reward_normed_mean": 0.007659590496798046, "reward_normed_std": 0.08305164501667023, "critic_slow": 5.1130745880126955, "critic_target": 5.112879241943359, "actor_ent": 1.4270236377716063, "actor_ent_scale": 0.0010000000474974513, "critic": 5.112744384002686, "fps": 119.1388099542595}
{"step": 17978868, "train_return": 19.0, "train_length": 1843.0, "train_total_steps": 4494717.0, "train_total_episodes": 2263.0, "train_loaded_steps": 1998159.0, "train_loaded_episodes": 1042.0}
{"step": 17986724, "train_return": 18.0, "train_length": 1964.0, "train_total_steps": 4496681.0, "train_total_episodes": 2264.0, "train_loaded_steps": 1998241.0, "train_loaded_episodes": 1042.0}
{"step": 17993948, "train_return": 19.0, "train_length": 1806.0, "train_total_steps": 4498487.0, "train_total_episodes": 2265.0, "train_loaded_steps": 1998161.0, "train_loaded_episodes": 1042.0}
{"step": 18001424, "train_return": 18.0, "train_length": 1869.0, "train_total_steps": 4500356.0, "train_total_episodes": 2266.0, "train_loaded_steps": 1998207.0, "train_loaded_episodes": 1042.0}
{"step": 18009876, "train_return": 16.0, "train_length": 2113.0, "train_total_steps": 4502469.0, "train_total_episodes": 2267.0, "train_loaded_steps": 1998307.0, "train_loaded_episodes": 1042.0}
{"step": 18017176, "kl_loss": 1.3939330957412719, "image_loss": 3772.0, "reward_loss": 0.9191162317276002, "discount_loss": 0.007751331371814013, "model_kl": 1.3939330644607544, "prior_ent": 26.25287680969238, "post_ent": 24.884080987548828, "model_loss": 3773.097293359375, "model_loss_scale": 2791.8336, "model_grad_norm": 4.908304508590699, "actor_loss": -0.007582398589447257, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.03314714482575655, "critic_loss": 0.9195567873001098, "critic_loss_scale": 99509.8624, "critic_grad_norm": Infinity, "reward_mean": 0.0076437293875962495, "reward_std": 0.08239254765510559, "reward_normed_mean": 0.0076437293875962495, "reward_normed_std": 0.08239254765510559, "critic_slow": 5.2076370258331295, "critic_target": 5.207302417755127, "actor_ent": 1.4246551124572755, "actor_ent_scale": 0.0010000000474974513, "critic": 5.206894869613648, "fps": 115.65243268371965}
{"step": 18017456, "train_return": 19.0, "train_length": 1895.0, "train_total_steps": 4504364.0, "train_total_episodes": 2268.0, "train_loaded_steps": 1998224.0, "train_loaded_episodes": 1042.0}
{"step": 18024112, "train_return": 21.0, "train_length": 1664.0, "train_total_steps": 4506028.0, "train_total_episodes": 2269.0, "train_loaded_steps": 1999888.0, "train_loaded_episodes": 1043.0}
{"step": 18033900, "train_return": 15.0, "train_length": 2447.0, "train_total_steps": 4508475.0, "train_total_episodes": 2270.0, "train_loaded_steps": 1998584.0, "train_loaded_episodes": 1042.0}
{"step": 18041396, "train_return": 17.0, "train_length": 1874.0, "train_total_steps": 4510349.0, "train_total_episodes": 2271.0, "train_loaded_steps": 1998586.0, "train_loaded_episodes": 1042.0}
{"step": 18048868, "train_return": 18.0, "train_length": 1868.0, "train_total_steps": 4512217.0, "train_total_episodes": 2272.0, "train_loaded_steps": 1998571.0, "train_loaded_episodes": 1042.0}
{"step": 18055688, "train_return": 21.0, "train_length": 1705.0, "train_total_steps": 4513922.0, "train_total_episodes": 2273.0, "train_loaded_steps": 1998217.0, "train_loaded_episodes": 1042.0}
{"step": 18057176, "kl_loss": 1.3535081998825074, "image_loss": 3772.0, "reward_loss": 0.9191272121429443, "discount_loss": 0.0077651883885264394, "model_kl": 1.3535081674575806, "prior_ent": 26.345794107055664, "post_ent": 25.000524771118165, "model_loss": 3773.093338671875, "model_loss_scale": 4096.0, "model_grad_norm": 4.8437085527420045, "actor_loss": -0.008511585288064089, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.03240007919222117, "critic_loss": 0.9178706045150757, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.28342512009739873, "reward_mean": 0.0074987731694243845, "reward_std": 0.08154630088806153, "reward_normed_mean": 0.0074987731694243845, "reward_normed_std": 0.08154630088806153, "critic_slow": 5.164117109298706, "critic_target": 5.163497186279296, "actor_ent": 1.4358259204864503, "actor_ent_scale": 0.0010000000474974513, "critic": 5.163210944747925, "fps": 115.79887445716189}
{"step": 18062416, "train_return": 21.0, "train_length": 1682.0, "train_total_steps": 4515604.0, "train_total_episodes": 2274.0, "train_loaded_steps": 1999899.0, "train_loaded_episodes": 1043.0}
{"step": 18069248, "train_return": 20.0, "train_length": 1708.0, "train_total_steps": 4517312.0, "train_total_episodes": 2275.0, "train_loaded_steps": 1999650.0, "train_loaded_episodes": 1043.0}
{"step": 18076868, "train_return": 18.0, "train_length": 1905.0, "train_total_steps": 4519217.0, "train_total_episodes": 2276.0, "train_loaded_steps": 1999155.0, "train_loaded_episodes": 1043.0}
{"step": 18084920, "train_return": 18.0, "train_length": 2013.0, "train_total_steps": 4521230.0, "train_total_episodes": 2277.0, "train_loaded_steps": 1999191.0, "train_loaded_episodes": 1043.0}
{"step": 18092792, "train_return": 16.0, "train_length": 1968.0, "train_total_steps": 4523198.0, "train_total_episodes": 2278.0, "train_loaded_steps": 1998820.0, "train_loaded_episodes": 1043.0}
{"step": 18097176, "kl_loss": 1.36044502658844, "image_loss": 3772.0002, "reward_loss": 0.9191166988372803, "discount_loss": 0.007775126214325428, "model_kl": 1.360444994354248, "prior_ent": 26.396820556640623, "post_ent": 25.052819140625, "model_loss": 3773.09427109375, "model_loss_scale": 4096.0, "model_grad_norm": 4.476738478088379, "actor_loss": -0.007296753081833594, "actor_loss_scale": 3362154.0864, "actor_grad_norm": 0.03321514205932617, "critic_loss": 0.9180374953269959, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.2631528495311737, "reward_mean": 0.007492194159072824, "reward_std": 0.08293091852068901, "reward_normed_mean": 0.007492194159072824, "reward_normed_std": 0.08293091852068901, "critic_slow": 5.158845586013794, "critic_target": 5.1588058700561525, "actor_ent": 1.431906911468506, "actor_ent_scale": 0.0010000000474974513, "critic": 5.158647411727905, "fps": 115.17957529182014}
{"step": 18100504, "train_return": 18.0, "train_length": 1928.0, "train_total_steps": 4525126.0, "train_total_episodes": 2279.0, "train_loaded_steps": 1998805.0, "train_loaded_episodes": 1043.0}
{"step": 18108264, "train_return": 17.0, "train_length": 1940.0, "train_total_steps": 4527066.0, "train_total_episodes": 2280.0, "train_loaded_steps": 1998865.0, "train_loaded_episodes": 1043.0}
{"step": 18115560, "train_return": 18.0, "train_length": 1824.0, "train_total_steps": 4528890.0, "train_total_episodes": 2281.0, "train_loaded_steps": 1998850.0, "train_loaded_episodes": 1043.0}
{"step": 18123808, "train_return": 14.0, "train_length": 2062.0, "train_total_steps": 4530952.0, "train_total_episodes": 2282.0, "train_loaded_steps": 1999202.0, "train_loaded_episodes": 1043.0}
{"step": 18131580, "train_return": 18.0, "train_length": 1943.0, "train_total_steps": 4532895.0, "train_total_episodes": 2283.0, "train_loaded_steps": 1999174.0, "train_loaded_episodes": 1043.0}
{"step": 18137176, "kl_loss": 1.3343411815643311, "image_loss": 3772.0, "reward_loss": 0.919107485961914, "discount_loss": 0.007742000882327556, "model_kl": 1.3343411533355714, "prior_ent": 26.20934372253418, "post_ent": 24.884244146728516, "model_loss": 3773.0912828125, "model_loss_scale": 4764.4672, "model_grad_norm": 4.751802291107178, "actor_loss": -0.006999253863515333, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.031153776425123215, "critic_loss": 0.9169253666877747, "critic_loss_scale": 83990.9376, "critic_grad_norm": 0.2382676447033882, "reward_mean": 0.0074974278486894036, "reward_std": 0.08281551780104637, "reward_normed_mean": 0.0074974278486894036, "reward_normed_std": 0.08281551780104637, "critic_slow": 5.1300042007446285, "critic_target": 5.129151901245117, "actor_ent": 1.425681721687317, "actor_ent_scale": 0.0010000000474974513, "critic": 5.128918285369873, "fps": 116.22674286281229}
{"step": 18138464, "train_return": 20.0, "train_length": 1721.0, "train_total_steps": 4534616.0, "train_total_episodes": 2284.0, "train_loaded_steps": 1999010.0, "train_loaded_episodes": 1043.0}
{"step": 18145780, "train_return": 18.0, "train_length": 1829.0, "train_total_steps": 4536445.0, "train_total_episodes": 2285.0, "train_loaded_steps": 1998947.0, "train_loaded_episodes": 1043.0}
{"step": 18152628, "train_return": 20.0, "train_length": 1712.0, "train_total_steps": 4538157.0, "train_total_episodes": 2286.0, "train_loaded_steps": 1998252.0, "train_loaded_episodes": 1043.0}
{"step": 18160644, "train_return": 17.0, "train_length": 2004.0, "train_total_steps": 4540161.0, "train_total_episodes": 2287.0, "train_loaded_steps": 1998548.0, "train_loaded_episodes": 1043.0}
{"step": 18167908, "train_return": 19.0, "train_length": 1816.0, "train_total_steps": 4541977.0, "train_total_episodes": 2288.0, "train_loaded_steps": 1998574.0, "train_loaded_episodes": 1043.0}
{"step": 18175500, "train_return": 18.0, "train_length": 1898.0, "train_total_steps": 4543875.0, "train_total_episodes": 2289.0, "train_loaded_steps": 1998461.0, "train_loaded_episodes": 1043.0}
{"step": 18177172, "eval_return": 14.0, "eval_length": 2030.0, "eval_total_steps": 45064.0, "eval_total_episodes": 23.0, "eval_loaded_steps": 45086.0, "eval_loaded_episodes": 23.0}
{"step": 18177176, "kl_loss": 1.3613627655029297, "image_loss": 3772.0, "reward_loss": 0.9191044769287109, "discount_loss": 0.007774469054490328, "model_kl": 1.3613627328872682, "prior_ent": 26.525676962280272, "post_ent": 25.177871282958986, "model_loss": 3773.094136328125, "model_loss_scale": 8192.0, "model_grad_norm": 4.794483315467835, "actor_loss": -0.007640586210938636, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.030632391077280045, "critic_loss": 0.9169070288658142, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.29213776166439054, "reward_mean": 0.007632684226799756, "reward_std": 0.08291093399524689, "reward_normed_mean": 0.007632684226799756, "reward_normed_std": 0.08291093399524689, "critic_slow": 5.163169944381714, "critic_target": 5.162962706375122, "actor_ent": 1.4365324851989747, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1624707569122315, "fps": 111.33768587448648}
{"step": 18182912, "train_return": 19.0, "train_length": 1853.0, "train_total_steps": 4545728.0, "train_total_episodes": 2290.0, "train_loaded_steps": 1998362.0, "train_loaded_episodes": 1043.0}
{"step": 18190548, "train_return": 18.0, "train_length": 1909.0, "train_total_steps": 4547637.0, "train_total_episodes": 2291.0, "train_loaded_steps": 1998377.0, "train_loaded_episodes": 1043.0}
{"step": 18198560, "train_return": 16.0, "train_length": 2003.0, "train_total_steps": 4549640.0, "train_total_episodes": 2292.0, "train_loaded_steps": 1998229.0, "train_loaded_episodes": 1043.0}
{"step": 18206356, "train_return": 16.0, "train_length": 1949.0, "train_total_steps": 4551589.0, "train_total_episodes": 2293.0, "train_loaded_steps": 1998386.0, "train_loaded_episodes": 1043.0}
{"step": 18213836, "train_return": 18.0, "train_length": 1870.0, "train_total_steps": 4553459.0, "train_total_episodes": 2294.0, "train_loaded_steps": 1998318.0, "train_loaded_episodes": 1043.0}
{"step": 18217176, "kl_loss": 1.3440335494995117, "image_loss": 3772.0, "reward_loss": 0.9190755086898804, "discount_loss": 0.007764055924862623, "model_kl": 1.3440335191726684, "prior_ent": 26.20446618347168, "post_ent": 24.869552770996094, "model_loss": 3773.09233359375, "model_loss_scale": 8192.0, "model_grad_norm": 4.804967071342468, "actor_loss": -0.004552336913670297, "actor_loss_scale": 5885447.3728, "actor_grad_norm": 0.03130589380115271, "critic_loss": 0.9166918333053589, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.21680553722977638, "reward_mean": 0.007596304771583527, "reward_std": 0.08299782319068909, "reward_normed_mean": 0.007596304771583527, "reward_normed_std": 0.08299782319068909, "critic_slow": 5.090063400650024, "critic_target": 5.091271311187744, "actor_ent": 1.426192494392395, "actor_ent_scale": 0.0010000000474974513, "critic": 5.090825100708008, "fps": 113.85770440992853}
{"step": 18221968, "train_return": 18.0, "train_length": 2033.0, "train_total_steps": 4555492.0, "train_total_episodes": 2295.0, "train_loaded_steps": 1998559.0, "train_loaded_episodes": 1043.0}
{"step": 18229120, "train_return": 19.0, "train_length": 1788.0, "train_total_steps": 4557280.0, "train_total_episodes": 2296.0, "train_loaded_steps": 1998242.0, "train_loaded_episodes": 1043.0}
{"step": 18236008, "train_return": 20.0, "train_length": 1722.0, "train_total_steps": 4559002.0, "train_total_episodes": 2297.0, "train_loaded_steps": 1999964.0, "train_loaded_episodes": 1044.0}
{"step": 18243276, "train_return": 18.0, "train_length": 1817.0, "train_total_steps": 4560819.0, "train_total_episodes": 2298.0, "train_loaded_steps": 1999660.0, "train_loaded_episodes": 1044.0}
{"step": 18250940, "train_return": 18.0, "train_length": 1916.0, "train_total_steps": 4562735.0, "train_total_episodes": 2299.0, "train_loaded_steps": 1999898.0, "train_loaded_episodes": 1044.0}
{"step": 18257176, "kl_loss": 1.3787829380035401, "image_loss": 3772.0, "reward_loss": 0.9191106795310974, "discount_loss": 0.007742436019331216, "model_kl": 1.3787829080581666, "prior_ent": 26.060535443115235, "post_ent": 24.703948263549805, "model_loss": 3773.09573125, "model_loss_scale": 8192.0, "model_grad_norm": 4.863676575660706, "actor_loss": -0.004194206875321106, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.03130661322176456, "critic_loss": 0.9164554421424865, "critic_loss_scale": 141767.4752, "critic_grad_norm": 0.24757787992954255, "reward_mean": 0.007515357934916392, "reward_std": 0.08270856139063835, "reward_normed_mean": 0.007515357934916392, "reward_normed_std": 0.08270856139063835, "critic_slow": 5.121330062866211, "critic_target": 5.122260087966919, "actor_ent": 1.4159239459991455, "actor_ent_scale": 0.0010000000474974513, "critic": 5.122150574111939, "fps": 118.99755919621818}
{"step": 18258176, "train_return": 19.0, "train_length": 1809.0, "train_total_steps": 4564544.0, "train_total_episodes": 2300.0, "train_loaded_steps": 1999970.0, "train_loaded_episodes": 1044.0}
{"step": 18268432, "train_return": 3.0, "train_length": 2564.0, "train_total_steps": 4567108.0, "train_total_episodes": 2301.0, "train_loaded_steps": 1998380.0, "train_loaded_episodes": 1043.0}
{"step": 18275532, "train_return": 19.0, "train_length": 1775.0, "train_total_steps": 4568883.0, "train_total_episodes": 2302.0, "train_loaded_steps": 1998361.0, "train_loaded_episodes": 1043.0}
{"step": 18282956, "train_return": 18.0, "train_length": 1856.0, "train_total_steps": 4570739.0, "train_total_episodes": 2303.0, "train_loaded_steps": 1998326.0, "train_loaded_episodes": 1043.0}
{"step": 18291156, "train_return": 15.0, "train_length": 2050.0, "train_total_steps": 4572789.0, "train_total_episodes": 2304.0, "train_loaded_steps": 1998511.0, "train_loaded_episodes": 1043.0}
{"step": 18297176, "kl_loss": 1.3301349699020386, "image_loss": 3772.0, "reward_loss": 0.9190939562797547, "discount_loss": 0.0077416488572955135, "model_kl": 1.330134942626953, "prior_ent": 26.2248157623291, "post_ent": 24.900517541503906, "model_loss": 3773.090846484375, "model_loss_scale": 16082.5344, "model_grad_norm": 4.681338446426391, "actor_loss": -0.004256377598522522, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.030967071399092674, "critic_loss": 0.9164605293273925, "critic_loss_scale": 163997.2864, "critic_grad_norm": Infinity, "reward_mean": 0.007544477905309759, "reward_std": 0.08333899743556976, "reward_normed_mean": 0.007544477905309759, "reward_normed_std": 0.08333899743556976, "critic_slow": 5.169055793380737, "critic_target": 5.170129447174072, "actor_ent": 1.4335072902679444, "actor_ent_scale": 0.0010000000474974513, "critic": 5.170110657882691, "fps": 113.95496253568788}
{"step": 18299056, "train_return": 17.0, "train_length": 1975.0, "train_total_steps": 4574764.0, "train_total_episodes": 2305.0, "train_loaded_steps": 1998410.0, "train_loaded_episodes": 1043.0}
{"step": 18306640, "train_return": 17.0, "train_length": 1896.0, "train_total_steps": 4576660.0, "train_total_episodes": 2306.0, "train_loaded_steps": 1998469.0, "train_loaded_episodes": 1043.0}
{"step": 18314832, "train_return": 16.0, "train_length": 2048.0, "train_total_steps": 4578708.0, "train_total_episodes": 2307.0, "train_loaded_steps": 1998560.0, "train_loaded_episodes": 1043.0}
{"step": 18322204, "train_return": 19.0, "train_length": 1843.0, "train_total_steps": 4580551.0, "train_total_episodes": 2308.0, "train_loaded_steps": 1998745.0, "train_loaded_episodes": 1043.0}
{"step": 18329304, "train_return": 19.0, "train_length": 1775.0, "train_total_steps": 4582326.0, "train_total_episodes": 2309.0, "train_loaded_steps": 1998772.0, "train_loaded_episodes": 1043.0}
{"step": 18337176, "kl_loss": 1.3387581092834473, "image_loss": 3772.0, "reward_loss": 0.9191023720741271, "discount_loss": 0.00774089420363307, "model_kl": 1.338758080291748, "prior_ent": 26.265773229980468, "post_ent": 24.938914547729492, "model_loss": 3773.09170859375, "model_loss_scale": 16384.0, "model_grad_norm": 4.787449705696106, "actor_loss": -0.005615632990353333, "actor_loss_scale": 10093173.1456, "actor_grad_norm": 0.029310907538235186, "critic_loss": 0.9156382102012635, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.23102238135635852, "reward_mean": 0.007581917436234653, "reward_std": 0.08336821405291557, "reward_normed_mean": 0.007581917436234653, "reward_normed_std": 0.08336821405291557, "critic_slow": 5.103372092819214, "critic_target": 5.105048700714112, "actor_ent": 1.4463329904556275, "actor_ent_scale": 0.0010000000474974513, "critic": 5.104894159698486, "fps": 114.58741429489812}
{"step": 18337352, "train_return": 17.0, "train_length": 2012.0, "train_total_steps": 4584338.0, "train_total_episodes": 2310.0, "train_loaded_steps": 1998841.0, "train_loaded_episodes": 1043.0}
{"step": 18345380, "train_return": 17.0, "train_length": 2007.0, "train_total_steps": 4586345.0, "train_total_episodes": 2311.0, "train_loaded_steps": 1998911.0, "train_loaded_episodes": 1043.0}
{"step": 18352972, "train_return": 18.0, "train_length": 1898.0, "train_total_steps": 4588243.0, "train_total_episodes": 2312.0, "train_loaded_steps": 1998813.0, "train_loaded_episodes": 1043.0}
{"step": 18359804, "train_return": 21.0, "train_length": 1708.0, "train_total_steps": 4589951.0, "train_total_episodes": 2313.0, "train_loaded_steps": 1998394.0, "train_loaded_episodes": 1043.0}
{"step": 18367044, "train_return": 20.0, "train_length": 1810.0, "train_total_steps": 4591761.0, "train_total_episodes": 2314.0, "train_loaded_steps": 1998170.0, "train_loaded_episodes": 1043.0}
{"step": 18374392, "train_return": 18.0, "train_length": 1837.0, "train_total_steps": 4593598.0, "train_total_episodes": 2315.0, "train_loaded_steps": 1997918.0, "train_loaded_episodes": 1043.0}
{"step": 18377176, "kl_loss": 1.3392670360565186, "image_loss": 3772.0, "reward_loss": 0.9190914511680603, "discount_loss": 0.007740976805984974, "model_kl": 1.3392670043945312, "prior_ent": 26.198397229003906, "post_ent": 24.872455841064454, "model_loss": 3773.091753125, "model_loss_scale": 16384.0, "model_grad_norm": 4.878211864280701, "actor_loss": -0.0056418612681271045, "actor_loss_scale": 12790949.4784, "actor_grad_norm": Infinity, "critic_loss": 0.9170288885116578, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2698558031976223, "reward_mean": 0.007565007382596378, "reward_std": 0.08311036546230316, "reward_normed_mean": 0.007565007382596378, "reward_normed_std": 0.08311036546230316, "critic_slow": 5.181578955078125, "critic_target": 5.182341654968262, "actor_ent": 1.4410186710357666, "actor_ent_scale": 0.0010000000474974513, "critic": 5.182465951919555, "fps": 116.50987217583639}
{"step": 18381036, "train_return": 21.0, "train_length": 1661.0, "train_total_steps": 4595259.0, "train_total_episodes": 2316.0, "train_loaded_steps": 1999579.0, "train_loaded_episodes": 1044.0}
{"step": 18388380, "train_return": 19.0, "train_length": 1836.0, "train_total_steps": 4597095.0, "train_total_episodes": 2317.0, "train_loaded_steps": 1999398.0, "train_loaded_episodes": 1044.0}
{"step": 18395512, "train_return": 19.0, "train_length": 1783.0, "train_total_steps": 4598878.0, "train_total_episodes": 2318.0, "train_loaded_steps": 1999217.0, "train_loaded_episodes": 1044.0}
{"step": 18402924, "train_return": 18.0, "train_length": 1853.0, "train_total_steps": 4600731.0, "train_total_episodes": 2319.0, "train_loaded_steps": 1998917.0, "train_loaded_episodes": 1044.0}
{"step": 18410984, "train_return": 19.0, "train_length": 2015.0, "train_total_steps": 4602746.0, "train_total_episodes": 2320.0, "train_loaded_steps": 1998785.0, "train_loaded_episodes": 1044.0}
{"step": 18417176, "kl_loss": 1.347723720550537, "image_loss": 3772.0, "reward_loss": 0.9191023762702942, "discount_loss": 0.007740694197267294, "model_kl": 1.3477236917495727, "prior_ent": 26.37655679321289, "post_ent": 25.041472396850587, "model_loss": 3773.09260234375, "model_loss_scale": 17118.0032, "model_grad_norm": Infinity, "actor_loss": -0.0030113200305138888, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.031705699127912525, "critic_loss": 0.9163072417259216, "critic_loss_scale": 203004.3136, "critic_grad_norm": 0.2408538946866989, "reward_mean": 0.00762096873242408, "reward_std": 0.08330357283949852, "reward_normed_mean": 0.00762096873242408, "reward_normed_std": 0.08330357283949852, "critic_slow": 5.15345013923645, "critic_target": 5.154677935028076, "actor_ent": 1.4365197036743165, "actor_ent_scale": 0.0010000000474974513, "critic": 5.154766375732422, "fps": 114.34496286693265}
{"step": 18418252, "train_return": 18.0, "train_length": 1817.0, "train_total_steps": 4604563.0, "train_total_episodes": 2321.0, "train_loaded_steps": 1998789.0, "train_loaded_episodes": 1044.0}
{"step": 18426140, "train_return": 17.0, "train_length": 1972.0, "train_total_steps": 4606535.0, "train_total_episodes": 2322.0, "train_loaded_steps": 1999038.0, "train_loaded_episodes": 1044.0}
{"step": 18433888, "train_return": 19.0, "train_length": 1937.0, "train_total_steps": 4608472.0, "train_total_episodes": 2323.0, "train_loaded_steps": 1998870.0, "train_loaded_episodes": 1044.0}
{"step": 18441612, "train_return": 17.0, "train_length": 1931.0, "train_total_steps": 4610403.0, "train_total_episodes": 2324.0, "train_loaded_steps": 1998741.0, "train_loaded_episodes": 1044.0}
{"step": 18450820, "train_return": 10.0, "train_length": 2302.0, "train_total_steps": 4612705.0, "train_total_episodes": 2325.0, "train_loaded_steps": 1999055.0, "train_loaded_episodes": 1044.0}
{"step": 18457176, "kl_loss": 1.3477575191497804, "image_loss": 3772.0, "reward_loss": 0.9191017813682556, "discount_loss": 0.007741166330128908, "model_kl": 1.3477574892044066, "prior_ent": 26.288178125, "post_ent": 24.955173950195313, "model_loss": 3773.09260859375, "model_loss_scale": 16384.0, "model_grad_norm": 4.638721941566467, "actor_loss": -0.004852619374831556, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.032501320332288745, "critic_loss": 0.9178648031234741, "critic_loss_scale": 158964.1216, "critic_grad_norm": Infinity, "reward_mean": 0.007550966916919424, "reward_std": 0.08268359196782112, "reward_normed_mean": 0.007550966916919424, "reward_normed_std": 0.08268359196782112, "critic_slow": 5.115574959182739, "critic_target": 5.117047163772583, "actor_ent": 1.4546006395339965, "actor_ent_scale": 0.0010000000474974513, "critic": 5.117324050903321, "fps": 117.04005598406486}
{"step": 18457920, "train_return": 19.0, "train_length": 1775.0, "train_total_steps": 4614480.0, "train_total_episodes": 2326.0, "train_loaded_steps": 1998900.0, "train_loaded_episodes": 1044.0}
{"step": 18465300, "train_return": 19.0, "train_length": 1845.0, "train_total_steps": 4616325.0, "train_total_episodes": 2327.0, "train_loaded_steps": 1998953.0, "train_loaded_episodes": 1044.0}
{"step": 18473600, "train_return": 14.0, "train_length": 2075.0, "train_total_steps": 4618400.0, "train_total_episodes": 2328.0, "train_loaded_steps": 1999199.0, "train_loaded_episodes": 1044.0}
{"step": 18481708, "train_return": 17.0, "train_length": 2027.0, "train_total_steps": 4620427.0, "train_total_episodes": 2329.0, "train_loaded_steps": 1999420.0, "train_loaded_episodes": 1044.0}
{"step": 18490320, "train_return": 15.0, "train_length": 2153.0, "train_total_steps": 4622580.0, "train_total_episodes": 2330.0, "train_loaded_steps": 1999697.0, "train_loaded_episodes": 1044.0}
{"step": 18496940, "train_return": 21.0, "train_length": 1655.0, "train_total_steps": 4624235.0, "train_total_episodes": 2331.0, "train_loaded_steps": 1999363.0, "train_loaded_episodes": 1044.0}
{"step": 18497176, "kl_loss": 1.3385664838790894, "image_loss": 3772.0, "reward_loss": 0.9191164196968079, "discount_loss": 0.007741508029401302, "model_kl": 1.3385664527893066, "prior_ent": 26.254659716796876, "post_ent": 24.92896666870117, "model_loss": 3773.091712109375, "model_loss_scale": 16384.0, "model_grad_norm": 4.836882243156433, "actor_loss": -0.0036888181836286092, "actor_loss_scale": 10697152.9216, "actor_grad_norm": 0.030937983071804048, "critic_loss": 0.916476444530487, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2422116709828377, "reward_mean": 0.007318465652968734, "reward_std": 0.08251696360111237, "reward_normed_mean": 0.007318465652968734, "reward_normed_std": 0.08251696360111237, "critic_slow": 5.117645516586304, "critic_target": 5.11909525566101, "actor_ent": 1.45726551361084, "actor_ent_scale": 0.0010000000474974513, "critic": 5.119094371032715, "fps": 113.31553514128998}
{"step": 18504256, "train_return": 19.0, "train_length": 1829.0, "train_total_steps": 4626064.0, "train_total_episodes": 2332.0, "train_loaded_steps": 1998990.0, "train_loaded_episodes": 1044.0}
{"step": 18511784, "train_return": 19.0, "train_length": 1882.0, "train_total_steps": 4627946.0, "train_total_episodes": 2333.0, "train_loaded_steps": 1999077.0, "train_loaded_episodes": 1044.0}
{"step": 18519192, "train_return": 18.0, "train_length": 1852.0, "train_total_steps": 4629798.0, "train_total_episodes": 2334.0, "train_loaded_steps": 1998984.0, "train_loaded_episodes": 1044.0}
{"step": 18526788, "train_return": 17.0, "train_length": 1899.0, "train_total_steps": 4631697.0, "train_total_episodes": 2335.0, "train_loaded_steps": 1999010.0, "train_loaded_episodes": 1044.0}
{"step": 18534748, "train_return": 16.0, "train_length": 1990.0, "train_total_steps": 4633687.0, "train_total_episodes": 2336.0, "train_loaded_steps": 1998918.0, "train_loaded_episodes": 1044.0}
{"step": 18537176, "kl_loss": 1.3366197980880736, "image_loss": 3772.0, "reward_loss": 0.9190900099754333, "discount_loss": 0.0077409843377768996, "model_kl": 1.3366197668075561, "prior_ent": 26.243868991088867, "post_ent": 24.918455645751955, "model_loss": 3773.091486328125, "model_loss_scale": 20237.5168, "model_grad_norm": Infinity, "actor_loss": -0.005175651340345212, "actor_loss_scale": 10938744.832, "actor_grad_norm": Infinity, "critic_loss": 0.9155198519706726, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.21810392295122147, "reward_mean": 0.00767109573725611, "reward_std": 0.0838114316046238, "reward_normed_mean": 0.00767109573725611, "reward_normed_std": 0.0838114316046238, "critic_slow": 5.113539728164673, "critic_target": 5.115105173110962, "actor_ent": 1.4603793586730958, "actor_ent_scale": 0.0010000000474974513, "critic": 5.1150073722839355, "fps": 115.54418815502005}
{"step": 18543396, "train_return": 16.0, "train_length": 2162.0, "train_total_steps": 4635849.0, "train_total_episodes": 2337.0, "train_loaded_steps": 1999289.0, "train_loaded_episodes": 1044.0}
{"step": 18551272, "train_return": 18.0, "train_length": 1969.0, "train_total_steps": 4637818.0, "train_total_episodes": 2338.0, "train_loaded_steps": 1998979.0, "train_loaded_episodes": 1044.0}
{"step": 18558340, "train_return": 19.0, "train_length": 1767.0, "train_total_steps": 4639585.0, "train_total_episodes": 2339.0, "train_loaded_steps": 1998823.0, "train_loaded_episodes": 1044.0}
{"step": 18565728, "train_return": 18.0, "train_length": 1847.0, "train_total_steps": 4641432.0, "train_total_episodes": 2340.0, "train_loaded_steps": 1998755.0, "train_loaded_episodes": 1044.0}
{"step": 18573680, "train_return": 19.0, "train_length": 1988.0, "train_total_steps": 4643420.0, "train_total_episodes": 2341.0, "train_loaded_steps": 1999062.0, "train_loaded_episodes": 1044.0}
{"step": 18577176, "kl_loss": 1.3434381185531616, "image_loss": 3772.0002, "reward_loss": 0.9191138571739197, "discount_loss": 0.007842031376063823, "model_kl": 1.3434380893707276, "prior_ent": 26.45254861755371, "post_ent": 25.121956796264648, "model_loss": 3773.092897265625, "model_loss_scale": 16331.5712, "model_grad_norm": Infinity, "actor_loss": -0.004572050000485615, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.031202156659960747, "critic_loss": 0.9165532321929931, "critic_loss_scale": 208037.4784, "critic_grad_norm": 0.26981242585778237, "reward_mean": 0.007340614192816429, "reward_std": 0.08251903911828995, "reward_normed_mean": 0.007340614192816429, "reward_normed_std": 0.08251903911828995, "critic_slow": 5.122027577209472, "critic_target": 5.122589134216309, "actor_ent": 1.4236800512313843, "actor_ent_scale": 0.0010000000474974513, "critic": 5.122611505126953, "fps": 117.67134152819054}
{"step": 18581584, "train_return": 18.0, "train_length": 1976.0, "train_total_steps": 4645396.0, "train_total_episodes": 2342.0, "train_loaded_steps": 1999024.0, "train_loaded_episodes": 1044.0}
{"step": 18589484, "train_return": 17.0, "train_length": 1975.0, "train_total_steps": 4647371.0, "train_total_episodes": 2343.0, "train_loaded_steps": 1999167.0, "train_loaded_episodes": 1044.0}
{"step": 18598440, "train_return": 16.0, "train_length": 2239.0, "train_total_steps": 4649610.0, "train_total_episodes": 2344.0, "train_loaded_steps": 1999333.0, "train_loaded_episodes": 1044.0}
{"step": 18605564, "train_return": 20.0, "train_length": 1781.0, "train_total_steps": 4651391.0, "train_total_episodes": 2345.0, "train_loaded_steps": 1998909.0, "train_loaded_episodes": 1044.0}
{"step": 18612400, "train_return": 20.0, "train_length": 1709.0, "train_total_steps": 4653100.0, "train_total_episodes": 2346.0, "train_loaded_steps": 1998584.0, "train_loaded_episodes": 1044.0}
{"step": 18617176, "kl_loss": 1.328366056060791, "image_loss": 3772.0, "reward_loss": 0.9190894255638122, "discount_loss": 0.007752896026521921, "model_kl": 1.328366026878357, "prior_ent": 26.261203927612303, "post_ent": 24.941083065795898, "model_loss": 3773.09071953125, "model_loss_scale": 8192.0, "model_grad_norm": 4.478357963562011, "actor_loss": -0.006769666183635127, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.02977173676341772, "critic_loss": 0.9160138931274414, "critic_loss_scale": 138831.4624, "critic_grad_norm": Infinity, "reward_mean": 0.007574424081481993, "reward_std": 0.08308688374757767, "reward_normed_mean": 0.007574424081481993, "reward_normed_std": 0.08308688374757767, "critic_slow": 5.104898549652099, "critic_target": 5.104972559738159, "actor_ent": 1.45725660572052, "actor_ent_scale": 0.0010000000474974513, "critic": 5.104793830108642, "fps": 115.47132677494054}
{"step": 18620596, "train_return": 15.0, "train_length": 2049.0, "train_total_steps": 4655149.0, "train_total_episodes": 2347.0, "train_loaded_steps": 1998602.0, "train_loaded_episodes": 1044.0}
{"step": 18627848, "train_return": 19.0, "train_length": 1813.0, "train_total_steps": 4656962.0, "train_total_episodes": 2348.0, "train_loaded_steps": 1998376.0, "train_loaded_episodes": 1044.0}
{"step": 18635672, "train_return": 18.0, "train_length": 1956.0, "train_total_steps": 4658918.0, "train_total_episodes": 2349.0, "train_loaded_steps": 1998328.0, "train_loaded_episodes": 1044.0}
{"step": 18642552, "train_return": 20.0, "train_length": 1720.0, "train_total_steps": 4660638.0, "train_total_episodes": 2350.0, "train_loaded_steps": 1997564.0, "train_loaded_episodes": 1044.0}
{"step": 18649788, "train_return": 19.0, "train_length": 1809.0, "train_total_steps": 4662447.0, "train_total_episodes": 2351.0, "train_loaded_steps": 1999373.0, "train_loaded_episodes": 1045.0}
{"step": 18657176, "kl_loss": 1.34807875289917, "image_loss": 3772.0, "reward_loss": 0.9191045008659363, "discount_loss": 0.007744219897687435, "model_kl": 1.3480787240982055, "prior_ent": 26.212324975585936, "post_ent": 24.878077157592774, "model_loss": 3773.092665234375, "model_loss_scale": 8192.0, "model_grad_norm": 4.6320640031814575, "actor_loss": -0.007562180474284105, "actor_loss_scale": 12549357.568, "actor_grad_norm": 0.028936379408836366, "critic_loss": 0.9162004538536072, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.23727134246826173, "reward_mean": 0.007631039311271161, "reward_std": 0.08322263373136521, "reward_normed_mean": 0.007631039311271161, "reward_normed_std": 0.08322263373136521, "critic_slow": 5.170164187240601, "critic_target": 5.170190674209595, "actor_ent": 1.478912546157837, "actor_ent_scale": 0.0010000000474974513, "critic": 5.170166257858276, "fps": 114.0603269342545}
{"step": 18657920, "train_return": 15.0, "train_length": 2033.0, "train_total_steps": 4664480.0, "train_total_episodes": 2352.0, "train_loaded_steps": 1999538.0, "train_loaded_episodes": 1045.0}
{"step": 18665216, "train_return": 19.0, "train_length": 1824.0, "train_total_steps": 4666304.0, "train_total_episodes": 2353.0, "train_loaded_steps": 1999104.0, "train_loaded_episodes": 1045.0}
{"step": 18672544, "train_return": 18.0, "train_length": 1832.0, "train_total_steps": 4668136.0, "train_total_episodes": 2354.0, "train_loaded_steps": 1999114.0, "train_loaded_episodes": 1045.0}
{"step": 18679908, "train_return": 18.0, "train_length": 1841.0, "train_total_steps": 4669977.0, "train_total_episodes": 2355.0, "train_loaded_steps": 1998880.0, "train_loaded_episodes": 1045.0}
{"step": 18687100, "train_return": 20.0, "train_length": 1798.0, "train_total_steps": 4671775.0, "train_total_episodes": 2356.0, "train_loaded_steps": 1998870.0, "train_loaded_episodes": 1045.0}
{"step": 18694848, "train_return": 18.0, "train_length": 1937.0, "train_total_steps": 4673712.0, "train_total_episodes": 2357.0, "train_loaded_steps": 1998990.0, "train_loaded_episodes": 1045.0}
{"step": 18697176, "kl_loss": 1.3503803203582763, "image_loss": 3772.0, "reward_loss": 0.9190892028808594, "discount_loss": 0.007755194929987192, "model_kl": 1.3503802894592285, "prior_ent": 26.341310473632813, "post_ent": 25.0069318939209, "model_loss": 3773.092930078125, "model_loss_scale": 8192.0, "model_grad_norm": 4.766806701087952, "actor_loss": -0.0037923562893643977, "actor_loss_scale": 8381897.1136, "actor_grad_norm": Infinity, "critic_loss": 0.9192368495941162, "critic_loss_scale": 67056.4352, "critic_grad_norm": Infinity, "reward_mean": 0.007531275558238849, "reward_std": 0.08297111955881119, "reward_normed_mean": 0.007531275558238849, "reward_normed_std": 0.08297111955881119, "critic_slow": 5.065798318481446, "critic_target": 5.066841820907593, "actor_ent": 1.4386246250152588, "actor_ent_scale": 0.0010000000474974513, "critic": 5.066879536437988, "fps": 116.95265540087914}
{"step": 18703236, "train_return": 16.0, "train_length": 2097.0, "train_total_steps": 4675809.0, "train_total_episodes": 2358.0, "train_loaded_steps": 1998943.0, "train_loaded_episodes": 1045.0}
{"step": 18712220, "train_return": 15.0, "train_length": 2246.0, "train_total_steps": 4678055.0, "train_total_episodes": 2359.0, "train_loaded_steps": 1999369.0, "train_loaded_episodes": 1045.0}
{"step": 18719280, "train_return": 19.0, "train_length": 1765.0, "train_total_steps": 4679820.0, "train_total_episodes": 2360.0, "train_loaded_steps": 1999390.0, "train_loaded_episodes": 1045.0}
{"step": 18726480, "train_return": 20.0, "train_length": 1800.0, "train_total_steps": 4681620.0, "train_total_episodes": 2361.0, "train_loaded_steps": 1999510.0, "train_loaded_episodes": 1045.0}
{"step": 18733772, "train_return": 20.0, "train_length": 1823.0, "train_total_steps": 4683443.0, "train_total_episodes": 2362.0, "train_loaded_steps": 1999421.0, "train_loaded_episodes": 1045.0}
{"step": 18737176, "kl_loss": 1.3583163074493407, "image_loss": 3772.0, "reward_loss": 0.9191068323135376, "discount_loss": 0.007771182937920094, "model_kl": 1.3583162759780885, "prior_ent": 26.400895523071288, "post_ent": 25.05839260559082, "model_loss": 3773.093825, "model_loss_scale": 14798.0288, "model_grad_norm": 4.72302080039978, "actor_loss": -0.005049563902252703, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.030194678695499896, "critic_loss": 0.9153674862861634, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.22483152412176133, "reward_mean": 0.007660293774679303, "reward_std": 0.08294221826791763, "reward_normed_mean": 0.007660293774679303, "reward_normed_std": 0.08294221826791763, "critic_slow": 5.064506645965576, "critic_target": 5.065445029067993, "actor_ent": 1.4300997756958007, "actor_ent_scale": 0.0010000000474974513, "critic": 5.065410550689697, "fps": 117.5675612086688}
{"step": 18742276, "train_return": 15.0, "train_length": 2126.0, "train_total_steps": 4685569.0, "train_total_episodes": 2363.0, "train_loaded_steps": 1999734.0, "train_loaded_episodes": 1045.0}
{"step": 18750948, "train_return": 16.0, "train_length": 2168.0, "train_total_steps": 4687737.0, "train_total_episodes": 2364.0, "train_loaded_steps": 1999803.0, "train_loaded_episodes": 1045.0}
{"step": 18759148, "train_return": 17.0, "train_length": 2050.0, "train_total_steps": 4689787.0, "train_total_episodes": 2365.0, "train_loaded_steps": 1998132.0, "train_loaded_episodes": 1044.0}
{"step": 18767220, "train_return": 17.0, "train_length": 2018.0, "train_total_steps": 4691805.0, "train_total_episodes": 2366.0, "train_loaded_steps": 1998201.0, "train_loaded_episodes": 1044.0}
{"step": 18773852, "train_return": 21.0, "train_length": 1658.0, "train_total_steps": 4693463.0, "train_total_episodes": 2367.0, "train_loaded_steps": 1999859.0, "train_loaded_episodes": 1045.0}
{"step": 18777176, "kl_loss": 1.3378990783691407, "image_loss": 3772.0002, "reward_loss": 0.9191014442443848, "discount_loss": 0.0077601178959012035, "model_kl": 1.3378990484237672, "prior_ent": 26.300968029785157, "post_ent": 24.973398522949218, "model_loss": 3773.09192734375, "model_loss_scale": 15649.9968, "model_grad_norm": Infinity, "actor_loss": -0.008253939026058652, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.030736117616295813, "critic_loss": 0.9173151219367981, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.24334033974409103, "reward_mean": 0.00754325982183218, "reward_std": 0.08298261964321137, "reward_normed_mean": 0.00754325982183218, "reward_normed_std": 0.08298261964321137, "critic_slow": 5.065137170791626, "critic_target": 5.06513730392456, "actor_ent": 1.4555608648300171, "actor_ent_scale": 0.0010000000474974513, "critic": 5.065215898895263, "fps": 115.92015513116112}
{"step": 18781964, "train_return": 17.0, "train_length": 2028.0, "train_total_steps": 4695491.0, "train_total_episodes": 2368.0, "train_loaded_steps": 1999900.0, "train_loaded_episodes": 1045.0}
{"step": 18789764, "train_return": 17.0, "train_length": 1950.0, "train_total_steps": 4697441.0, "train_total_episodes": 2369.0, "train_loaded_steps": 1999919.0, "train_loaded_episodes": 1045.0}
{"step": 18797492, "train_return": 16.0, "train_length": 1932.0, "train_total_steps": 4699373.0, "train_total_episodes": 2370.0, "train_loaded_steps": 1997981.0, "train_loaded_episodes": 1044.0}
{"step": 18805436, "train_return": 17.0, "train_length": 1986.0, "train_total_steps": 4701359.0, "train_total_episodes": 2371.0, "train_loaded_steps": 1999967.0, "train_loaded_episodes": 1045.0}
{"step": 18812076, "train_return": 21.0, "train_length": 1660.0, "train_total_steps": 4703019.0, "train_total_episodes": 2372.0, "train_loaded_steps": 1999777.0, "train_loaded_episodes": 1045.0}
{"step": 18817176, "kl_loss": 1.348401958656311, "image_loss": 3772.0, "reward_loss": 0.9190917936325074, "discount_loss": 0.007756314597278833, "model_kl": 1.3484019323349, "prior_ent": 26.092825561523437, "post_ent": 24.753849014282228, "model_loss": 3773.09273828125, "model_loss_scale": 8192.0, "model_grad_norm": 4.570257377243042, "actor_loss": -0.006411943142866949, "actor_loss_scale": 6100195.7376, "actor_grad_norm": 0.029199641633033752, "critic_loss": 0.9160793621063232, "critic_loss_scale": 47238.3488, "critic_grad_norm": 0.2258264045357704, "reward_mean": 0.007459626441262662, "reward_std": 0.08323547521829605, "reward_normed_mean": 0.007459626441262662, "reward_normed_std": 0.08323547521829605, "critic_slow": 5.090380852127075, "critic_target": 5.091331127929688, "actor_ent": 1.4740343519210815, "actor_ent_scale": 0.0010000000474974513, "critic": 5.091437968826294, "fps": 116.25573136858702}
{"step": 18819420, "train_return": 20.0, "train_length": 1836.0, "train_total_steps": 4704855.0, "train_total_episodes": 2373.0, "train_loaded_steps": 1999776.0, "train_loaded_episodes": 1045.0}
{"step": 18826348, "train_return": 20.0, "train_length": 1732.0, "train_total_steps": 4706587.0, "train_total_episodes": 2374.0, "train_loaded_steps": 1999707.0, "train_loaded_episodes": 1045.0}
{"step": 18834044, "train_return": 18.0, "train_length": 1924.0, "train_total_steps": 4708511.0, "train_total_episodes": 2375.0, "train_loaded_steps": 1999858.0, "train_loaded_episodes": 1045.0}
{"step": 18841288, "train_return": 19.0, "train_length": 1811.0, "train_total_steps": 4710322.0, "train_total_episodes": 2376.0, "train_loaded_steps": 1999639.0, "train_loaded_episodes": 1045.0}
{"step": 18849024, "train_return": 17.0, "train_length": 1934.0, "train_total_steps": 4712256.0, "train_total_episodes": 2377.0, "train_loaded_steps": 1999571.0, "train_loaded_episodes": 1045.0}
{"step": 18857104, "train_return": 18.0, "train_length": 2020.0, "train_total_steps": 4714276.0, "train_total_episodes": 2378.0, "train_loaded_steps": 1999617.0, "train_loaded_episodes": 1045.0}
{"step": 18857176, "kl_loss": 1.3206516422271728, "image_loss": 3772.0, "reward_loss": 0.9190834788322448, "discount_loss": 0.007741440637409687, "model_kl": 1.3206516132354735, "prior_ent": 26.120548556518553, "post_ent": 24.809791494750975, "model_loss": 3773.089876953125, "model_loss_scale": 8192.0, "model_grad_norm": 4.45761665763855, "actor_loss": -0.00738012411994132, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.028360174864530564, "critic_loss": 0.9151591864585876, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.22529855373501778, "reward_mean": 0.007573575804010034, "reward_std": 0.0839924025774002, "reward_normed_mean": 0.007573575804010034, "reward_normed_std": 0.0839924025774002, "critic_slow": 5.043892273712158, "critic_target": 5.044096998214721, "actor_ent": 1.4651947799682616, "actor_ent_scale": 0.0010000000474974513, "critic": 5.04407719078064, "fps": 113.41105657039598}
{"step": 18864900, "train_return": 18.0, "train_length": 1949.0, "train_total_steps": 4716225.0, "train_total_episodes": 2379.0, "train_loaded_steps": 1999589.0, "train_loaded_episodes": 1045.0}
{"step": 18872808, "train_return": 17.0, "train_length": 1977.0, "train_total_steps": 4718202.0, "train_total_episodes": 2380.0, "train_loaded_steps": 1999674.0, "train_loaded_episodes": 1045.0}
{"step": 18880400, "train_return": 17.0, "train_length": 1898.0, "train_total_steps": 4720100.0, "train_total_episodes": 2381.0, "train_loaded_steps": 1999729.0, "train_loaded_episodes": 1045.0}
{"step": 18888800, "train_return": 17.0, "train_length": 2100.0, "train_total_steps": 4722200.0, "train_total_episodes": 2382.0, "train_loaded_steps": 1999921.0, "train_loaded_episodes": 1045.0}
{"step": 18896012, "train_return": 18.0, "train_length": 1803.0, "train_total_steps": 4724003.0, "train_total_episodes": 2383.0, "train_loaded_steps": 1999866.0, "train_loaded_episodes": 1045.0}
{"step": 18897176, "kl_loss": 1.3361253349304199, "image_loss": 3772.0, "reward_loss": 0.9190939801216126, "discount_loss": 0.007741762594133616, "model_kl": 1.336125302696228, "prior_ent": 26.08847875366211, "post_ent": 24.761877117919923, "model_loss": 3773.091448046875, "model_loss_scale": 8192.0, "model_grad_norm": 4.65949501953125, "actor_loss": -0.007834298127940564, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.028687554366886615, "critic_loss": 0.9154254195213318, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.21822874153852462, "reward_mean": 0.007620187321957201, "reward_std": 0.0835972695529461, "reward_normed_mean": 0.007620187321957201, "reward_normed_std": 0.0835972695529461, "critic_slow": 5.009031092453003, "critic_target": 5.00976035194397, "actor_ent": 1.4647116136550904, "actor_ent_scale": 0.0010000000474974513, "critic": 5.009699347686768, "fps": 114.11265146651714}
{"step": 18902992, "train_return": 19.0, "train_length": 1745.0, "train_total_steps": 4725748.0, "train_total_episodes": 2384.0, "train_loaded_steps": 1999688.0, "train_loaded_episodes": 1045.0}
{"step": 18910536, "train_return": 19.0, "train_length": 1886.0, "train_total_steps": 4727634.0, "train_total_episodes": 2385.0, "train_loaded_steps": 1999550.0, "train_loaded_episodes": 1045.0}
{"step": 18918976, "train_return": 15.0, "train_length": 2110.0, "train_total_steps": 4729744.0, "train_total_episodes": 2386.0, "train_loaded_steps": 1999777.0, "train_loaded_episodes": 1045.0}
{"step": 18928144, "train_return": 14.0, "train_length": 2292.0, "train_total_steps": 4732036.0, "train_total_episodes": 2387.0, "train_loaded_steps": 1998570.0, "train_loaded_episodes": 1044.0}
{"step": 18936692, "train_return": 13.0, "train_length": 2137.0, "train_total_steps": 4734173.0, "train_total_episodes": 2388.0, "train_loaded_steps": 1998592.0, "train_loaded_episodes": 1044.0}
{"step": 18937176, "kl_loss": 1.3498513597488404, "image_loss": 3772.0, "reward_loss": 0.9190733247756958, "discount_loss": 0.007754472158849239, "model_kl": 1.3498513290405274, "prior_ent": 26.138786492919923, "post_ent": 24.806147583007814, "model_loss": 3773.0928625, "model_loss_scale": 15479.6032, "model_grad_norm": 4.757102312850952, "actor_loss": -0.008237754365592263, "actor_loss_scale": 9207336.1408, "actor_grad_norm": Infinity, "critic_loss": 0.9160590808868408, "critic_loss_scale": 81369.4976, "critic_grad_norm": 0.21818261863589286, "reward_mean": 0.007724951553100255, "reward_std": 0.08354453161954879, "reward_normed_mean": 0.007724951553100255, "reward_normed_std": 0.08354453161954879, "critic_slow": 5.004001919174194, "critic_target": 5.004704690170288, "actor_ent": 1.4514875560760498, "actor_ent_scale": 0.0010000000474974513, "critic": 5.004480823516846, "fps": 113.42664839398628}
{"step": 18944368, "train_return": 18.0, "train_length": 1919.0, "train_total_steps": 4736092.0, "train_total_episodes": 2389.0, "train_loaded_steps": 1998691.0, "train_loaded_episodes": 1044.0}
{"step": 18952212, "train_return": 18.0, "train_length": 1961.0, "train_total_steps": 4738053.0, "train_total_episodes": 2390.0, "train_loaded_steps": 1998817.0, "train_loaded_episodes": 1044.0}
{"step": 18959308, "train_return": 19.0, "train_length": 1774.0, "train_total_steps": 4739827.0, "train_total_episodes": 2391.0, "train_loaded_steps": 1998524.0, "train_loaded_episodes": 1044.0}
{"step": 18966620, "train_return": 19.0, "train_length": 1828.0, "train_total_steps": 4741655.0, "train_total_episodes": 2392.0, "train_loaded_steps": 1998637.0, "train_loaded_episodes": 1044.0}
{"step": 18975080, "train_return": 15.0, "train_length": 2115.0, "train_total_steps": 4743770.0, "train_total_episodes": 2393.0, "train_loaded_steps": 1998968.0, "train_loaded_episodes": 1044.0}
{"step": 18977176, "kl_loss": 1.3590473909378051, "image_loss": 3772.0, "reward_loss": 0.9191002687454224, "discount_loss": 0.007741572856158018, "model_kl": 1.3590473600387574, "prior_ent": 26.344457971191407, "post_ent": 25.00525168457031, "model_loss": 3773.0937421875, "model_loss_scale": 16384.0, "model_grad_norm": 4.625877285194397, "actor_loss": -0.010341645554668502, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.02828634628355503, "critic_loss": 0.9163057117462158, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.23404256741404533, "reward_mean": 0.007554682516341563, "reward_std": 0.08309265291690826, "reward_normed_mean": 0.007554682516341563, "reward_normed_std": 0.08309265291690826, "critic_slow": 5.034192654800415, "critic_target": 5.033636550521851, "actor_ent": 1.4726281127929688, "actor_ent_scale": 0.0010000000474974513, "critic": 5.0334225830078125, "fps": 115.81160848933071}
{"step": 18982480, "train_return": 19.0, "train_length": 1850.0, "train_total_steps": 4745620.0, "train_total_episodes": 2394.0, "train_loaded_steps": 1998755.0, "train_loaded_episodes": 1044.0}
{"step": 18990212, "train_return": 18.0, "train_length": 1933.0, "train_total_steps": 4747553.0, "train_total_episodes": 2395.0, "train_loaded_steps": 1998979.0, "train_loaded_episodes": 1044.0}
{"step": 18998388, "train_return": 17.0, "train_length": 2044.0, "train_total_steps": 4749597.0, "train_total_episodes": 2396.0, "train_loaded_steps": 1999185.0, "train_loaded_episodes": 1044.0}
{"step": 19005788, "train_return": 19.0, "train_length": 1850.0, "train_total_steps": 4751447.0, "train_total_episodes": 2397.0, "train_loaded_steps": 1998965.0, "train_loaded_episodes": 1044.0}
{"step": 19012888, "train_return": 20.0, "train_length": 1775.0, "train_total_steps": 4753222.0, "train_total_episodes": 2398.0, "train_loaded_steps": 1999028.0, "train_loaded_episodes": 1044.0}
{"step": 19017176, "kl_loss": 1.342410495376587, "image_loss": 3772.0, "reward_loss": 0.9191085357666016, "discount_loss": 0.007748025872558355, "model_kl": 1.342410461807251, "prior_ent": 26.443008758544924, "post_ent": 25.109839166259764, "model_loss": 3773.09211484375, "model_loss_scale": 16384.0, "model_grad_norm": 4.670295888900757, "actor_loss": -0.007951285566261504, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.02784512788057327, "critic_loss": 0.9154686870574951, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.25149966186285017, "reward_mean": 0.007340138334967196, "reward_std": 0.08256209094524383, "reward_normed_mean": 0.007340138334967196, "reward_normed_std": 0.08256209094524383, "critic_slow": 5.002902582168579, "critic_target": 5.002487758255005, "actor_ent": 1.4793716571807862, "actor_ent_scale": 0.0010000000474974513, "critic": 5.002324306488037, "fps": 114.35432627075875}
{"step": 19020820, "train_return": 18.0, "train_length": 1983.0, "train_total_steps": 4755205.0, "train_total_episodes": 2399.0, "train_loaded_steps": 1999134.0, "train_loaded_episodes": 1044.0}
{"step": 19028424, "train_return": 18.0, "train_length": 1901.0, "train_total_steps": 4757106.0, "train_total_episodes": 2400.0, "train_loaded_steps": 1999023.0, "train_loaded_episodes": 1044.0}
{"step": 19036328, "train_return": 17.0, "train_length": 1976.0, "train_total_steps": 4759082.0, "train_total_episodes": 2401.0, "train_loaded_steps": 1999235.0, "train_loaded_episodes": 1044.0}
{"step": 19043576, "train_return": 19.0, "train_length": 1812.0, "train_total_steps": 4760894.0, "train_total_episodes": 2402.0, "train_loaded_steps": 1999115.0, "train_loaded_episodes": 1044.0}
{"step": 19051588, "train_return": 17.0, "train_length": 2003.0, "train_total_steps": 4762897.0, "train_total_episodes": 2403.0, "train_loaded_steps": 1999296.0, "train_loaded_episodes": 1044.0}
{"step": 19057176, "kl_loss": 1.3290925231933595, "image_loss": 3772.0, "reward_loss": 0.9191033373832702, "discount_loss": 0.007741192550212145, "model_kl": 1.32909249458313, "prior_ent": 26.251815689086914, "post_ent": 24.937743008422853, "model_loss": 3773.090749609375, "model_loss_scale": 20211.3024, "model_grad_norm": Infinity, "actor_loss": -0.004872089129372034, "actor_loss_scale": 8157082.4192, "actor_grad_norm": Infinity, "critic_loss": 0.9183321623802185, "critic_loss_scale": 128240.8448, "critic_grad_norm": Infinity, "reward_mean": 0.007636557755153626, "reward_std": 0.08292225561141968, "reward_normed_mean": 0.007636557755153626, "reward_normed_std": 0.08292225561141968, "critic_slow": 4.998603120040894, "critic_target": 5.000210550689697, "actor_ent": 1.461792972946167, "actor_ent_scale": 0.0010000000474974513, "critic": 5.000232441711426, "fps": 116.95200694048421}
{"step": 19058636, "train_return": 20.0, "train_length": 1762.0, "train_total_steps": 4764659.0, "train_total_episodes": 2404.0, "train_loaded_steps": 1999236.0, "train_loaded_episodes": 1044.0}
{"step": 19066640, "train_return": 17.0, "train_length": 2001.0, "train_total_steps": 4766660.0, "train_total_episodes": 2405.0, "train_loaded_steps": 1999106.0, "train_loaded_episodes": 1044.0}
{"step": 19075060, "train_return": 17.0, "train_length": 2105.0, "train_total_steps": 4768765.0, "train_total_episodes": 2406.0, "train_loaded_steps": 1999282.0, "train_loaded_episodes": 1044.0}
{"step": 19081708, "train_return": 21.0, "train_length": 1662.0, "train_total_steps": 4770427.0, "train_total_episodes": 2407.0, "train_loaded_steps": 1998909.0, "train_loaded_episodes": 1044.0}
{"step": 19089192, "train_return": 18.0, "train_length": 1871.0, "train_total_steps": 4772298.0, "train_total_episodes": 2408.0, "train_loaded_steps": 1999108.0, "train_loaded_episodes": 1044.0}
{"step": 19097176, "kl_loss": 1.3095795162200927, "image_loss": 3772.0, "reward_loss": 0.9190972072601319, "discount_loss": 0.007761159507930279, "model_kl": 1.309579489517212, "prior_ent": 26.23589143066406, "post_ent": 24.9314079498291, "model_loss": 3773.088893359375, "model_loss_scale": 16384.0, "model_grad_norm": 4.352761011695862, "actor_loss": -0.005421419065526788, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.02939925825446844, "critic_loss": 0.9165547401428222, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.2338253553509712, "reward_mean": 0.007399987597810105, "reward_std": 0.08278622109293937, "reward_normed_mean": 0.007399987597810105, "reward_normed_std": 0.08278622109293937, "critic_slow": 5.018074864578247, "critic_target": 5.01793046875, "actor_ent": 1.3985485786437988, "actor_ent_scale": 0.0010000000474974513, "critic": 5.017740495681763, "fps": 118.46758083709636}
{"step": 19097276, "train_return": 17.0, "train_length": 2021.0, "train_total_steps": 4774319.0, "train_total_episodes": 2409.0, "train_loaded_steps": 1998986.0, "train_loaded_episodes": 1044.0}
{"step": 19104384, "train_return": 19.0, "train_length": 1777.0, "train_total_steps": 4776096.0, "train_total_episodes": 2410.0, "train_loaded_steps": 1998724.0, "train_loaded_episodes": 1044.0}
{"step": 19111432, "train_return": 21.0, "train_length": 1762.0, "train_total_steps": 4777858.0, "train_total_episodes": 2411.0, "train_loaded_steps": 1998277.0, "train_loaded_episodes": 1044.0}
{"step": 19118560, "train_return": 20.0, "train_length": 1782.0, "train_total_steps": 4779640.0, "train_total_episodes": 2412.0, "train_loaded_steps": 1998139.0, "train_loaded_episodes": 1044.0}
{"step": 19127020, "train_return": 16.0, "train_length": 2115.0, "train_total_steps": 4781755.0, "train_total_episodes": 2413.0, "train_loaded_steps": 1998100.0, "train_loaded_episodes": 1044.0}
{"step": 19134180, "train_return": 19.0, "train_length": 1790.0, "train_total_steps": 4783545.0, "train_total_episodes": 2414.0, "train_loaded_steps": 1999890.0, "train_loaded_episodes": 1045.0}
{"step": 19137176, "kl_loss": 1.3207978425979614, "image_loss": 3772.0, "reward_loss": 0.9190855949401856, "discount_loss": 0.007741883040219545, "model_kl": 1.3207978160858154, "prior_ent": 26.267659387207033, "post_ent": 24.956303506469727, "model_loss": 3773.089905078125, "model_loss_scale": 16384.0, "model_grad_norm": 4.805921503067017, "actor_loss": -0.006987716594871017, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.027047195659577847, "critic_loss": 0.9152270728111267, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.19494734558463098, "reward_mean": 0.007228910115617327, "reward_std": 0.08286396070718766, "reward_normed_mean": 0.007228910115617327, "reward_normed_std": 0.08286396070718766, "critic_slow": 4.975228604507446, "critic_target": 4.974944220733643, "actor_ent": 1.4511296228408814, "actor_ent_scale": 0.0010000000474974513, "critic": 4.974817094421387, "fps": 116.82963002937056}
{"step": 19142400, "train_return": 17.0, "train_length": 2055.0, "train_total_steps": 4785600.0, "train_total_episodes": 2415.0, "train_loaded_steps": 1998084.0, "train_loaded_episodes": 1044.0}
{"step": 19150560, "train_return": 18.0, "train_length": 2040.0, "train_total_steps": 4787640.0, "train_total_episodes": 2416.0, "train_loaded_steps": 1998264.0, "train_loaded_episodes": 1044.0}
{"step": 19158664, "train_return": 18.0, "train_length": 2026.0, "train_total_steps": 4789666.0, "train_total_episodes": 2417.0, "train_loaded_steps": 1998632.0, "train_loaded_episodes": 1044.0}
{"step": 19165480, "train_return": 21.0, "train_length": 1704.0, "train_total_steps": 4791370.0, "train_total_episodes": 2418.0, "train_loaded_steps": 1998685.0, "train_loaded_episodes": 1044.0}
{"step": 19172312, "train_return": 20.0, "train_length": 1708.0, "train_total_steps": 4793078.0, "train_total_episodes": 2419.0, "train_loaded_steps": 1998547.0, "train_loaded_episodes": 1044.0}
{"step": 19177172, "eval_return": 20.0, "eval_length": 1787.0, "eval_total_steps": 47094.0, "eval_total_episodes": 24.0, "eval_loaded_steps": 47116.0, "eval_loaded_episodes": 24.0}
{"step": 19177176, "kl_loss": 1.3374425769805909, "image_loss": 3772.0, "reward_loss": 0.9190992246627807, "discount_loss": 0.0077417423076927665, "model_kl": 1.3374425445556641, "prior_ent": 26.30831506958008, "post_ent": 24.98317432861328, "model_loss": 3773.091587890625, "model_loss_scale": 16934.5024, "model_grad_norm": Infinity, "actor_loss": -0.006651112237991765, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.027430610024929046, "critic_loss": 0.9156785223960876, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.21630128362178802, "reward_mean": 0.00771825854065828, "reward_std": 0.08336610847711563, "reward_normed_mean": 0.00771825854065828, "reward_normed_std": 0.08336610847711563, "critic_slow": 5.012651258468628, "critic_target": 5.013154993057251, "actor_ent": 1.466522187614441, "actor_ent_scale": 0.0010000000474974513, "critic": 5.013040208053589, "fps": 106.95712600165123}
{"step": 19179276, "train_return": 20.0, "train_length": 1741.0, "train_total_steps": 4794819.0, "train_total_episodes": 2420.0, "train_loaded_steps": 1998524.0, "train_loaded_episodes": 1044.0}
{"step": 19186260, "train_return": 19.0, "train_length": 1746.0, "train_total_steps": 4796565.0, "train_total_episodes": 2421.0, "train_loaded_steps": 1998064.0, "train_loaded_episodes": 1044.0}
{"step": 19193540, "train_return": 19.0, "train_length": 1820.0, "train_total_steps": 4798385.0, "train_total_episodes": 2422.0, "train_loaded_steps": 1999884.0, "train_loaded_episodes": 1045.0}
{"step": 19200688, "train_return": 19.0, "train_length": 1787.0, "train_total_steps": 4800172.0, "train_total_episodes": 2423.0, "train_loaded_steps": 1999833.0, "train_loaded_episodes": 1045.0}
{"step": 19208200, "train_return": 18.0, "train_length": 1878.0, "train_total_steps": 4802050.0, "train_total_episodes": 2424.0, "train_loaded_steps": 1998311.0, "train_loaded_episodes": 1044.0}
{"step": 19215220, "train_return": 20.0, "train_length": 1755.0, "train_total_steps": 4803805.0, "train_total_episodes": 2425.0, "train_loaded_steps": 1998261.0, "train_loaded_episodes": 1044.0}
{"step": 19217176, "kl_loss": 1.3388842679977417, "image_loss": 3772.0, "reward_loss": 0.9190881024360656, "discount_loss": 0.0077422001972794535, "model_kl": 1.338884241294861, "prior_ent": 26.26755198059082, "post_ent": 24.94263135070801, "model_loss": 3773.091717578125, "model_loss_scale": 4258.2016, "model_grad_norm": Infinity, "actor_loss": -0.008354594092944171, "actor_loss_scale": 3838627.0208, "actor_grad_norm": 0.02663043314665556, "critic_loss": 0.9152744713783264, "critic_loss_scale": 120795.9552, "critic_grad_norm": 0.20823835497498513, "reward_mean": 0.007603967242329963, "reward_std": 0.08339088475108147, "reward_normed_mean": 0.007603967242329963, "reward_normed_std": 0.08339088475108147, "critic_slow": 4.98325824394226, "critic_target": 4.982773338317871, "actor_ent": 1.4885892978668214, "actor_ent_scale": 0.0010000000474974513, "critic": 4.982546441650391, "fps": 113.03354712244882}
{"step": 19222768, "train_return": 18.0, "train_length": 1887.0, "train_total_steps": 4805692.0, "train_total_episodes": 2426.0, "train_loaded_steps": 1998160.0, "train_loaded_episodes": 1044.0}
{"step": 19230316, "train_return": 18.0, "train_length": 1887.0, "train_total_steps": 4807579.0, "train_total_episodes": 2427.0, "train_loaded_steps": 1998268.0, "train_loaded_episodes": 1044.0}
{"step": 19237788, "train_return": 18.0, "train_length": 1868.0, "train_total_steps": 4809447.0, "train_total_episodes": 2428.0, "train_loaded_steps": 1998474.0, "train_loaded_episodes": 1044.0}
{"step": 19245716, "train_return": 16.0, "train_length": 1982.0, "train_total_steps": 4811429.0, "train_total_episodes": 2429.0, "train_loaded_steps": 1998663.0, "train_loaded_episodes": 1044.0}
{"step": 19252364, "train_return": 21.0, "train_length": 1662.0, "train_total_steps": 4813091.0, "train_total_episodes": 2430.0, "train_loaded_steps": 1998296.0, "train_loaded_episodes": 1044.0}
{"step": 19257176, "kl_loss": 1.3693740592956543, "image_loss": 3772.0, "reward_loss": 0.9191126436233521, "discount_loss": 0.007781119312345982, "model_kl": 1.3693740282058715, "prior_ent": 26.121156256103514, "post_ent": 24.772681045532227, "model_loss": 3773.09498671875, "model_loss_scale": 1024.0, "model_grad_norm": 1.6458431025505067, "actor_loss": -0.0068686935621924934, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.028607512651383876, "critic_loss": 0.9158529604911804, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.2511728909015655, "reward_mean": 0.00748897007338237, "reward_std": 0.082868925511837, "reward_normed_mean": 0.00748897007338237, "reward_normed_std": 0.082868925511837, "critic_slow": 4.943213910293579, "critic_target": 4.943713111114502, "actor_ent": 1.460708702468872, "actor_ent_scale": 0.0010000000474974513, "critic": 4.943559921264648, "fps": 116.65411181102948}
{"step": 19260284, "train_return": 16.0, "train_length": 1980.0, "train_total_steps": 4815071.0, "train_total_episodes": 2431.0, "train_loaded_steps": 1998444.0, "train_loaded_episodes": 1044.0}
{"step": 19267312, "train_return": 20.0, "train_length": 1757.0, "train_total_steps": 4816828.0, "train_total_episodes": 2432.0, "train_loaded_steps": 1998489.0, "train_loaded_episodes": 1044.0}
{"step": 19275928, "train_return": 15.0, "train_length": 2154.0, "train_total_steps": 4818982.0, "train_total_episodes": 2433.0, "train_loaded_steps": 1998729.0, "train_loaded_episodes": 1044.0}
{"step": 19283448, "train_return": 18.0, "train_length": 1880.0, "train_total_steps": 4820862.0, "train_total_episodes": 2434.0, "train_loaded_steps": 1998537.0, "train_loaded_episodes": 1044.0}
{"step": 19291616, "train_return": 17.0, "train_length": 2042.0, "train_total_steps": 4822904.0, "train_total_episodes": 2435.0, "train_loaded_steps": 1998675.0, "train_loaded_episodes": 1044.0}
{"step": 19297176, "kl_loss": 1.3277476097106933, "image_loss": 3772.0, "reward_loss": 0.9190888759613037, "discount_loss": 0.007742386778444052, "model_kl": 1.3277475841522217, "prior_ent": 26.15775050048828, "post_ent": 24.8419042388916, "model_loss": 3773.09060546875, "model_loss_scale": 1024.0, "model_grad_norm": 3.3643100299835207, "actor_loss": -0.007578909141139593, "actor_loss_scale": 4194304.0, "actor_grad_norm": 0.02779404319524765, "critic_loss": 0.9166072241783142, "critic_loss_scale": 85878.3744, "critic_grad_norm": Infinity, "reward_mean": 0.0074397074017906566, "reward_std": 0.08263855382204056, "reward_normed_mean": 0.0074397074017906566, "reward_normed_std": 0.08263855382204056, "critic_slow": 4.9706971557617186, "critic_target": 4.970449391555786, "actor_ent": 1.4669475130081178, "actor_ent_scale": 0.0010000000474974513, "critic": 4.969885120010376, "fps": 116.82147431834042}
{"step": 19299384, "train_return": 19.0, "train_length": 1942.0, "train_total_steps": 4824846.0, "train_total_episodes": 2436.0, "train_loaded_steps": 1998783.0, "train_loaded_episodes": 1044.0}
{"step": 19307424, "train_return": 18.0, "train_length": 2010.0, "train_total_steps": 4826856.0, "train_total_episodes": 2437.0, "train_loaded_steps": 1998913.0, "train_loaded_episodes": 1044.0}
{"step": 19314264, "train_return": 20.0, "train_length": 1710.0, "train_total_steps": 4828566.0, "train_total_episodes": 2438.0, "train_loaded_steps": 1998867.0, "train_loaded_episodes": 1044.0}
{"step": 19321164, "train_return": 20.0, "train_length": 1725.0, "train_total_steps": 4830291.0, "train_total_episodes": 2439.0, "train_loaded_steps": 1998613.0, "train_loaded_episodes": 1044.0}
{"step": 19328024, "train_return": 20.0, "train_length": 1715.0, "train_total_steps": 4832006.0, "train_total_episodes": 2440.0, "train_loaded_steps": 1998543.0, "train_loaded_episodes": 1044.0}
{"step": 19335716, "train_return": 18.0, "train_length": 1923.0, "train_total_steps": 4833929.0, "train_total_episodes": 2441.0, "train_loaded_steps": 1998284.0, "train_loaded_episodes": 1044.0}
{"step": 19337176, "kl_loss": 1.3233825227737426, "image_loss": 3772.0, "reward_loss": 0.9190952987670898, "discount_loss": 0.007755207129567862, "model_kl": 1.323382495689392, "prior_ent": 26.036584786987305, "post_ent": 24.723254107666015, "model_loss": 3773.0902421875, "model_loss_scale": 1607.2704, "model_grad_norm": 4.202040090370178, "actor_loss": -0.008019000688858796, "actor_loss_scale": 6838393.2416, "actor_grad_norm": 0.026526355516910554, "critic_loss": 0.914683731842041, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.21435366367697717, "reward_mean": 0.0074625951516907665, "reward_std": 0.08280686410069465, "reward_normed_mean": 0.0074625951516907665, "reward_normed_std": 0.08280686410069465, "critic_slow": 4.985686124420166, "critic_target": 4.9855192714691166, "actor_ent": 1.4879559295654297, "actor_ent_scale": 0.0010000000474974513, "critic": 4.985389352798462, "fps": 117.43342907318551}
{"step": 19343072, "train_return": 19.0, "train_length": 1839.0, "train_total_steps": 4835768.0, "train_total_episodes": 2442.0, "train_loaded_steps": 1998389.0, "train_loaded_episodes": 1044.0}
{"step": 19349916, "train_return": 20.0, "train_length": 1711.0, "train_total_steps": 4837479.0, "train_total_episodes": 2443.0, "train_loaded_steps": 1997902.0, "train_loaded_episodes": 1044.0}
{"step": 19356752, "train_return": 20.0, "train_length": 1709.0, "train_total_steps": 4839188.0, "train_total_episodes": 2444.0, "train_loaded_steps": 1999611.0, "train_loaded_episodes": 1045.0}
{"step": 19364020, "train_return": 19.0, "train_length": 1817.0, "train_total_steps": 4841005.0, "train_total_episodes": 2445.0, "train_loaded_steps": 1999614.0, "train_loaded_episodes": 1045.0}
{"step": 19372360, "train_return": 16.0, "train_length": 2085.0, "train_total_steps": 4843090.0, "train_total_episodes": 2446.0, "train_loaded_steps": 1999738.0, "train_loaded_episodes": 1045.0}
{"step": 19377176, "kl_loss": 1.351079603767395, "image_loss": 3772.0, "reward_loss": 0.9190953656196594, "discount_loss": 0.007770607836544514, "model_kl": 1.3510795747756958, "prior_ent": 26.23632308959961, "post_ent": 24.899079028320312, "model_loss": 3773.0930984375, "model_loss_scale": 2048.0, "model_grad_norm": 4.568258327484131, "actor_loss": -0.005816613548170426, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.02751986361294985, "critic_loss": 0.9154415460586548, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.21797177320122718, "reward_mean": 0.007591534898104146, "reward_std": 0.08288484141230583, "reward_normed_mean": 0.007591534898104146, "reward_normed_std": 0.08288484141230583, "critic_slow": 4.962537007904053, "critic_target": 4.963824129486084, "actor_ent": 1.483444853591919, "actor_ent_scale": 0.0010000000474974513, "critic": 4.9638856590271, "fps": 113.67272671295419}
{"step": 19379420, "train_return": 20.0, "train_length": 1765.0, "train_total_steps": 4844855.0, "train_total_episodes": 2447.0, "train_loaded_steps": 1999608.0, "train_loaded_episodes": 1045.0}
{"step": 19387024, "train_return": 18.0, "train_length": 1901.0, "train_total_steps": 4846756.0, "train_total_episodes": 2448.0, "train_loaded_steps": 1999405.0, "train_loaded_episodes": 1045.0}
{"step": 19394624, "train_return": 16.0, "train_length": 1900.0, "train_total_steps": 4848656.0, "train_total_episodes": 2449.0, "train_loaded_steps": 1999420.0, "train_loaded_episodes": 1045.0}
{"step": 19401920, "train_return": 19.0, "train_length": 1824.0, "train_total_steps": 4850480.0, "train_total_episodes": 2450.0, "train_loaded_steps": 1999341.0, "train_loaded_episodes": 1045.0}
{"step": 19410032, "train_return": 16.0, "train_length": 2028.0, "train_total_steps": 4852508.0, "train_total_episodes": 2451.0, "train_loaded_steps": 1999571.0, "train_loaded_episodes": 1045.0}
{"step": 19417176, "kl_loss": 1.3479690481185913, "image_loss": 3772.0, "reward_loss": 0.9190767254829407, "discount_loss": 0.007745935130119324, "model_kl": 1.3479690210342408, "prior_ent": 26.212552029418944, "post_ent": 24.884655850219726, "model_loss": 3773.092634375, "model_loss_scale": 2048.0, "model_grad_norm": 4.484792080688477, "actor_loss": -0.006671073217666708, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.027522059239447116, "critic_loss": 0.9153181070327758, "critic_loss_scale": 97622.4256, "critic_grad_norm": 0.20561366626024247, "reward_mean": 0.007508992442674935, "reward_std": 0.08284931578040124, "reward_normed_mean": 0.007508992442674935, "reward_normed_std": 0.08284931578040124, "critic_slow": 4.943094923782349, "critic_target": 4.944036917495728, "actor_ent": 1.4723199129104614, "actor_ent_scale": 0.0010000000474974513, "critic": 4.943791687393189, "fps": 120.04490309906556}
{"step": 19417948, "train_return": 17.0, "train_length": 1979.0, "train_total_steps": 4854487.0, "train_total_episodes": 2452.0, "train_loaded_steps": 1999658.0, "train_loaded_episodes": 1045.0}
{"step": 19425144, "train_return": 19.0, "train_length": 1799.0, "train_total_steps": 4856286.0, "train_total_episodes": 2453.0, "train_loaded_steps": 1999548.0, "train_loaded_episodes": 1045.0}
{"step": 19431780, "train_return": 21.0, "train_length": 1659.0, "train_total_steps": 4857945.0, "train_total_episodes": 2454.0, "train_loaded_steps": 1999332.0, "train_loaded_episodes": 1045.0}
{"step": 19439632, "train_return": 17.0, "train_length": 1963.0, "train_total_steps": 4859908.0, "train_total_episodes": 2455.0, "train_loaded_steps": 1999510.0, "train_loaded_episodes": 1045.0}
{"step": 19446848, "train_return": 19.0, "train_length": 1804.0, "train_total_steps": 4861712.0, "train_total_episodes": 2456.0, "train_loaded_steps": 1999498.0, "train_loaded_episodes": 1045.0}
{"step": 19453912, "train_return": 21.0, "train_length": 1766.0, "train_total_steps": 4863478.0, "train_total_episodes": 2457.0, "train_loaded_steps": 1999598.0, "train_loaded_episodes": 1045.0}
{"step": 19457176, "kl_loss": 1.3489025300979613, "image_loss": 3772.00019609375, "reward_loss": 0.9191154072761536, "discount_loss": 0.007742303743213415, "model_kl": 1.348902501296997, "prior_ent": 26.36324341125488, "post_ent": 25.023381115722657, "model_loss": 3773.092945703125, "model_loss_scale": 2804.9408, "model_grad_norm": 4.522406762886047, "actor_loss": -0.008042173266177998, "actor_loss_scale": 11636677.0176, "actor_grad_norm": Infinity, "critic_loss": 0.9174812024116517, "critic_loss_scale": 130233.1392, "critic_grad_norm": Infinity, "reward_mean": 0.007553502066340297, "reward_std": 0.08244966576695442, "reward_normed_mean": 0.007553502066340297, "reward_normed_std": 0.08244966576695442, "critic_slow": 5.004379565811157, "critic_target": 5.004236497879028, "actor_ent": 1.4731599466323853, "actor_ent_scale": 0.0010000000474974513, "critic": 5.0043930896759035, "fps": 116.14249147133994}
{"step": 19462308, "train_return": 17.0, "train_length": 2099.0, "train_total_steps": 4865577.0, "train_total_episodes": 2458.0, "train_loaded_steps": 1999969.0, "train_loaded_episodes": 1045.0}
{"step": 19469112, "train_return": 21.0, "train_length": 1701.0, "train_total_steps": 4867278.0, "train_total_episodes": 2459.0, "train_loaded_steps": 1999957.0, "train_loaded_episodes": 1045.0}
{"step": 19476600, "train_return": 18.0, "train_length": 1872.0, "train_total_steps": 4869150.0, "train_total_episodes": 2460.0, "train_loaded_steps": 1998353.0, "train_loaded_episodes": 1044.0}
{"step": 19484592, "train_return": 17.0, "train_length": 1998.0, "train_total_steps": 4871148.0, "train_total_episodes": 2461.0, "train_loaded_steps": 1998535.0, "train_loaded_episodes": 1044.0}
{"step": 19493756, "train_return": 13.0, "train_length": 2291.0, "train_total_steps": 4873439.0, "train_total_episodes": 2462.0, "train_loaded_steps": 1998800.0, "train_loaded_episodes": 1044.0}
{"step": 19497176, "kl_loss": 1.3504743766784668, "image_loss": 3772.0, "reward_loss": 0.9190823684692383, "discount_loss": 0.007742155458778143, "model_kl": 1.3504743463516236, "prior_ent": 26.417393814086914, "post_ent": 25.079286212158202, "model_loss": 3773.092863671875, "model_loss_scale": 4096.0, "model_grad_norm": 4.5533331811904905, "actor_loss": -0.005279062771888857, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.02771151344180107, "critic_loss": 0.9160924258232117, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.2073093668997288, "reward_mean": 0.007618209184287116, "reward_std": 0.08315558623671532, "reward_normed_mean": 0.007618209184287116, "reward_normed_std": 0.08315558623671532, "critic_slow": 5.072118346786499, "critic_target": 5.073443840408325, "actor_ent": 1.4382244571685792, "actor_ent_scale": 0.0010000000474974513, "critic": 5.073323394012451, "fps": 120.4698034653198}
{"step": 19501196, "train_return": 18.0, "train_length": 1860.0, "train_total_steps": 4875299.0, "train_total_episodes": 2463.0, "train_loaded_steps": 1998617.0, "train_loaded_episodes": 1044.0}
{"step": 19508616, "train_return": 18.0, "train_length": 1855.0, "train_total_steps": 4877154.0, "train_total_episodes": 2464.0, "train_loaded_steps": 1998537.0, "train_loaded_episodes": 1044.0}
{"step": 19515684, "train_return": 19.0, "train_length": 1767.0, "train_total_steps": 4878921.0, "train_total_episodes": 2465.0, "train_loaded_steps": 1998646.0, "train_loaded_episodes": 1044.0}
{"step": 19524024, "train_return": 16.0, "train_length": 2085.0, "train_total_steps": 4881006.0, "train_total_episodes": 2466.0, "train_loaded_steps": 1998938.0, "train_loaded_episodes": 1044.0}
{"step": 19531692, "train_return": 17.0, "train_length": 1917.0, "train_total_steps": 4882923.0, "train_total_episodes": 2467.0, "train_loaded_steps": 1999139.0, "train_loaded_episodes": 1044.0}
{"step": 19537176, "kl_loss": 1.3298995193481444, "image_loss": 3772.0, "reward_loss": 0.9190944237709046, "discount_loss": 0.007762482106685639, "model_kl": 1.3298994916915894, "prior_ent": 26.493005947875975, "post_ent": 25.172855075073244, "model_loss": 3773.090931640625, "model_loss_scale": 4096.0, "model_grad_norm": 4.530615928840637, "actor_loss": -0.006431567899572837, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.026991232301294802, "critic_loss": 0.9156928359985351, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.20586161103248596, "reward_mean": 0.007561731445835903, "reward_std": 0.0831418432533741, "reward_normed_mean": 0.007561731445835903, "reward_normed_std": 0.0831418432533741, "critic_slow": 5.053375788879395, "critic_target": 5.053724140167236, "actor_ent": 1.4378247470855714, "actor_ent_scale": 0.0010000000474974513, "critic": 5.053650986862182, "fps": 119.25607357171782}
{"step": 19539008, "train_return": 18.0, "train_length": 1829.0, "train_total_steps": 4884752.0, "train_total_episodes": 2468.0, "train_loaded_steps": 1999258.0, "train_loaded_episodes": 1044.0}
{"step": 19547128, "train_return": 17.0, "train_length": 2030.0, "train_total_steps": 4886782.0, "train_total_episodes": 2469.0, "train_loaded_steps": 1999553.0, "train_loaded_episodes": 1044.0}
{"step": 19554616, "train_return": 18.0, "train_length": 1872.0, "train_total_steps": 4888654.0, "train_total_episodes": 2470.0, "train_loaded_steps": 1999416.0, "train_loaded_episodes": 1044.0}
{"step": 19563036, "train_return": 16.0, "train_length": 2105.0, "train_total_steps": 4890759.0, "train_total_episodes": 2471.0, "train_loaded_steps": 1999639.0, "train_loaded_episodes": 1044.0}
{"step": 19571008, "train_return": 19.0, "train_length": 1993.0, "train_total_steps": 4892752.0, "train_total_episodes": 2472.0, "train_loaded_steps": 1999680.0, "train_loaded_episodes": 1044.0}
{"step": 19577176, "kl_loss": 1.328093846321106, "image_loss": 3772.0, "reward_loss": 0.9190870223999024, "discount_loss": 0.007770362686365843, "model_kl": 1.328093816757202, "prior_ent": 26.367879577636717, "post_ent": 25.050167129516602, "model_loss": 3773.09076953125, "model_loss_scale": 4790.6816, "model_grad_norm": 4.486692858886719, "actor_loss": -0.007291238228027941, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.027777436339855195, "critic_loss": 0.915401901626587, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.18778846110105515, "reward_mean": 0.0075213731937110425, "reward_std": 0.08272214068174362, "reward_normed_mean": 0.0075213731937110425, "reward_normed_std": 0.08272214068174362, "critic_slow": 5.053979037094116, "critic_target": 5.053522090148926, "actor_ent": 1.48538189163208, "actor_ent_scale": 0.0010000000474974513, "critic": 5.053300996017456, "fps": 117.48108725372433}
{"step": 19577848, "train_return": 21.0, "train_length": 1710.0, "train_total_steps": 4894462.0, "train_total_episodes": 2473.0, "train_loaded_steps": 1999542.0, "train_loaded_episodes": 1044.0}
{"step": 19585576, "train_return": 19.0, "train_length": 1932.0, "train_total_steps": 4896394.0, "train_total_episodes": 2474.0, "train_loaded_steps": 1999513.0, "train_loaded_episodes": 1044.0}
{"step": 19592484, "train_return": 20.0, "train_length": 1727.0, "train_total_steps": 4898121.0, "train_total_episodes": 2475.0, "train_loaded_steps": 1999382.0, "train_loaded_episodes": 1044.0}
{"step": 19599656, "train_return": 19.0, "train_length": 1793.0, "train_total_steps": 4899914.0, "train_total_episodes": 2476.0, "train_loaded_steps": 1999387.0, "train_loaded_episodes": 1044.0}
{"step": 19606508, "train_return": 20.0, "train_length": 1713.0, "train_total_steps": 4901627.0, "train_total_episodes": 2477.0, "train_loaded_steps": 1999339.0, "train_loaded_episodes": 1044.0}
{"step": 19613388, "train_return": 21.0, "train_length": 1720.0, "train_total_steps": 4903347.0, "train_total_episodes": 2478.0, "train_loaded_steps": 1998943.0, "train_loaded_episodes": 1044.0}
{"step": 19617176, "kl_loss": 1.3120160936355592, "image_loss": 3772.0, "reward_loss": 0.9190919289588928, "discount_loss": 0.007753367111831904, "model_kl": 1.3120160655975341, "prior_ent": 26.24498453063965, "post_ent": 24.942454217529296, "model_loss": 3773.089089453125, "model_loss_scale": 8192.0, "model_grad_norm": 4.4379373561859135, "actor_loss": -0.007019086602429161, "actor_loss_scale": 11368241.5616, "actor_grad_norm": Infinity, "critic_loss": 0.9152178758621216, "critic_loss_scale": 118803.6608, "critic_grad_norm": 0.20084969753623008, "reward_mean": 0.0075992136199958624, "reward_std": 0.08331394223570823, "reward_normed_mean": 0.0075992136199958624, "reward_normed_std": 0.08331394223570823, "critic_slow": 5.025470862197876, "critic_target": 5.026016949081421, "actor_ent": 1.4858164876937867, "actor_ent_scale": 0.0010000000474974513, "critic": 5.025920892333985, "fps": 120.34531975290648}
{"step": 19620612, "train_return": 19.0, "train_length": 1806.0, "train_total_steps": 4905153.0, "train_total_episodes": 2479.0, "train_loaded_steps": 1998721.0, "train_loaded_episodes": 1044.0}
{"step": 19628568, "train_return": 16.0, "train_length": 1989.0, "train_total_steps": 4907142.0, "train_total_episodes": 2480.0, "train_loaded_steps": 1998411.0, "train_loaded_episodes": 1044.0}
{"step": 19635924, "train_return": 19.0, "train_length": 1839.0, "train_total_steps": 4908981.0, "train_total_episodes": 2481.0, "train_loaded_steps": 1998201.0, "train_loaded_episodes": 1044.0}
{"step": 19644444, "train_return": 14.0, "train_length": 2130.0, "train_total_steps": 4911111.0, "train_total_episodes": 2482.0, "train_loaded_steps": 1998470.0, "train_loaded_episodes": 1044.0}
{"step": 19651956, "train_return": 18.0, "train_length": 1878.0, "train_total_steps": 4912989.0, "train_total_episodes": 2483.0, "train_loaded_steps": 1998507.0, "train_loaded_episodes": 1044.0}
{"step": 19657176, "kl_loss": 1.30521886882782, "image_loss": 3772.0, "reward_loss": 0.9190742053031922, "discount_loss": 0.007741216281056404, "model_kl": 1.305218843460083, "prior_ent": 26.147979473876955, "post_ent": 24.85077760925293, "model_loss": 3773.08833671875, "model_loss_scale": 8192.0, "model_grad_norm": 4.589330639839172, "actor_loss": -0.005448987699160353, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.027623848268389702, "critic_loss": 0.9151260896682739, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.18799154153466224, "reward_mean": 0.007622037857212126, "reward_std": 0.08371518508791924, "reward_normed_mean": 0.007622037857212126, "reward_normed_std": 0.08371518508791924, "critic_slow": 5.012252541351319, "critic_target": 5.0132492206573485, "actor_ent": 1.4930548900604248, "actor_ent_scale": 0.0010000000474974513, "critic": 5.013113270568848, "fps": 120.37850417712336}
{"step": 19659604, "train_return": 17.0, "train_length": 1912.0, "train_total_steps": 4914901.0, "train_total_episodes": 2484.0, "train_loaded_steps": 1998396.0, "train_loaded_episodes": 1044.0}
{"step": 19667228, "train_return": 18.0, "train_length": 1906.0, "train_total_steps": 4916807.0, "train_total_episodes": 2485.0, "train_loaded_steps": 1998545.0, "train_loaded_episodes": 1044.0}
{"step": 19674496, "train_return": 18.0, "train_length": 1817.0, "train_total_steps": 4918624.0, "train_total_episodes": 2486.0, "train_loaded_steps": 1998448.0, "train_loaded_episodes": 1044.0}
{"step": 19681124, "train_return": 21.0, "train_length": 1657.0, "train_total_steps": 4920281.0, "train_total_episodes": 2487.0, "train_loaded_steps": 1998140.0, "train_loaded_episodes": 1044.0}
{"step": 19690652, "train_return": 13.0, "train_length": 2382.0, "train_total_steps": 4922663.0, "train_total_episodes": 2488.0, "train_loaded_steps": 1998705.0, "train_loaded_episodes": 1044.0}
{"step": 19697176, "kl_loss": 1.3274985748291015, "image_loss": 3772.0, "reward_loss": 0.9190978406906128, "discount_loss": 0.007743894036859274, "model_kl": 1.3274985460281372, "prior_ent": 26.08771629638672, "post_ent": 24.772082275390623, "model_loss": 3773.09059453125, "model_loss_scale": 8192.0, "model_grad_norm": 4.625608765602112, "actor_loss": -0.00638529650765704, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.02884790843427181, "critic_loss": 0.9162048099517822, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.219565184789896, "reward_mean": 0.007548735017073341, "reward_std": 0.08316801380515099, "reward_normed_mean": 0.007548735017073341, "reward_normed_std": 0.08316801380515099, "critic_slow": 5.050454177093506, "critic_target": 5.050710803222656, "actor_ent": 1.5000147970199584, "actor_ent_scale": 0.0010000000474974513, "critic": 5.050737939834595, "fps": 119.30327969403584}
{"step": 19697832, "train_return": 19.0, "train_length": 1795.0, "train_total_steps": 4924458.0, "train_total_episodes": 2489.0, "train_loaded_steps": 1998641.0, "train_loaded_episodes": 1044.0}
{"step": 19704800, "train_return": 20.0, "train_length": 1742.0, "train_total_steps": 4926200.0, "train_total_episodes": 2490.0, "train_loaded_steps": 1998622.0, "train_loaded_episodes": 1044.0}
{"step": 19711968, "train_return": 18.0, "train_length": 1792.0, "train_total_steps": 4927992.0, "train_total_episodes": 2491.0, "train_loaded_steps": 1998666.0, "train_loaded_episodes": 1044.0}
{"step": 19719120, "train_return": 19.0, "train_length": 1788.0, "train_total_steps": 4929780.0, "train_total_episodes": 2492.0, "train_loaded_steps": 1998545.0, "train_loaded_episodes": 1044.0}
{"step": 19726716, "train_return": 19.0, "train_length": 1899.0, "train_total_steps": 4931679.0, "train_total_episodes": 2493.0, "train_loaded_steps": 1998627.0, "train_loaded_episodes": 1044.0}
{"step": 19733344, "train_return": 21.0, "train_length": 1657.0, "train_total_steps": 4933336.0, "train_total_episodes": 2494.0, "train_loaded_steps": 1998253.0, "train_loaded_episodes": 1044.0}
{"step": 19737176, "kl_loss": 1.3761892528533937, "image_loss": 3772.0, "reward_loss": 0.9191024925231933, "discount_loss": 0.007750806100666523, "model_kl": 1.3761892250061034, "prior_ent": 26.002309005737306, "post_ent": 24.648796780395507, "model_loss": 3773.09550546875, "model_loss_scale": 15951.4624, "model_grad_norm": Infinity, "actor_loss": -0.006785574445116799, "actor_loss_scale": 10804527.104, "actor_grad_norm": 0.029417189879715443, "critic_loss": 0.9177243286132812, "critic_loss_scale": 98880.7168, "critic_grad_norm": Infinity, "reward_mean": 0.00753468875149265, "reward_std": 0.08280558640956878, "reward_normed_mean": 0.00753468875149265, "reward_normed_std": 0.08280558640956878, "critic_slow": 4.948902111053467, "critic_target": 4.949100235366822, "actor_ent": 1.4574190362930297, "actor_ent_scale": 0.0010000000474974513, "critic": 4.9490852684021, "fps": 118.96725656368905}
{"step": 19740656, "train_return": 18.0, "train_length": 1828.0, "train_total_steps": 4935164.0, "train_total_episodes": 2495.0, "train_loaded_steps": 1998054.0, "train_loaded_episodes": 1044.0}
{"step": 19748052, "train_return": 17.0, "train_length": 1849.0, "train_total_steps": 4937013.0, "train_total_episodes": 2496.0, "train_loaded_steps": 1999903.0, "train_loaded_episodes": 1045.0}
{"step": 19756056, "train_return": 18.0, "train_length": 2001.0, "train_total_steps": 4939014.0, "train_total_episodes": 2497.0, "train_loaded_steps": 1997868.0, "train_loaded_episodes": 1044.0}
{"step": 19763960, "train_return": 17.0, "train_length": 1976.0, "train_total_steps": 4940990.0, "train_total_episodes": 2498.0, "train_loaded_steps": 1999844.0, "train_loaded_episodes": 1045.0}
{"step": 19770900, "train_return": 20.0, "train_length": 1735.0, "train_total_steps": 4942725.0, "train_total_episodes": 2499.0, "train_loaded_steps": 1999627.0, "train_loaded_episodes": 1045.0}
{"step": 19777176, "kl_loss": 1.3499702239990234, "image_loss": 3772.0002, "reward_loss": 0.9190953229904175, "discount_loss": 0.007779606210440397, "model_kl": 1.3499701986312866, "prior_ent": 26.080510891723634, "post_ent": 24.740557150268554, "model_loss": 3773.093221875, "model_loss_scale": 8192.0, "model_grad_norm": 4.614105804061889, "actor_loss": -0.0040486712449754126, "actor_loss_scale": 8912057.1392, "actor_grad_norm": Infinity, "critic_loss": 0.9163167042732239, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.2156179903626442, "reward_mean": 0.007662269374169409, "reward_std": 0.08327577759027481, "reward_normed_mean": 0.007662269374169409, "reward_normed_std": 0.08327577759027481, "critic_slow": 4.951740314102173, "critic_target": 4.953760821533203, "actor_ent": 1.4296110626220704, "actor_ent_scale": 0.0010000000474974513, "critic": 4.9537798698425295, "fps": 119.11535047845511}
{"step": 19778996, "train_return": 16.0, "train_length": 2024.0, "train_total_steps": 4944749.0, "train_total_episodes": 2500.0, "train_loaded_steps": 1999995.0, "train_loaded_episodes": 1045.0}
{"step": 19786728, "train_return": 18.0, "train_length": 1933.0, "train_total_steps": 4946682.0, "train_total_episodes": 2501.0, "train_loaded_steps": 1998104.0, "train_loaded_episodes": 1044.0}
{"step": 19794336, "train_return": 16.0, "train_length": 1902.0, "train_total_steps": 4948584.0, "train_total_episodes": 2502.0, "train_loaded_steps": 1998014.0, "train_loaded_episodes": 1044.0}
{"step": 19802244, "train_return": 18.0, "train_length": 1977.0, "train_total_steps": 4950561.0, "train_total_episodes": 2503.0, "train_loaded_steps": 1999991.0, "train_loaded_episodes": 1045.0}
{"step": 19809344, "train_return": 19.0, "train_length": 1775.0, "train_total_steps": 4952336.0, "train_total_episodes": 2504.0, "train_loaded_steps": 1999824.0, "train_loaded_episodes": 1045.0}
{"step": 19816192, "train_return": 20.0, "train_length": 1712.0, "train_total_steps": 4954048.0, "train_total_episodes": 2505.0, "train_loaded_steps": 1999664.0, "train_loaded_episodes": 1045.0}
{"step": 19817176, "kl_loss": 1.3002180946350097, "image_loss": 3772.0, "reward_loss": 0.9190895295143128, "discount_loss": 0.00774157782420516, "model_kl": 1.3002180723190309, "prior_ent": 26.05691109313965, "post_ent": 24.76398175048828, "model_loss": 3773.087850390625, "model_loss_scale": 8192.0, "model_grad_norm": 4.227370051765442, "actor_loss": -0.00525202482927416, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.028757655292749405, "critic_loss": 0.9152479128837585, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.20676661180257797, "reward_mean": 0.007407550080865621, "reward_std": 0.08287989597320557, "reward_normed_mean": 0.007407550080865621, "reward_normed_std": 0.08287989597320557, "critic_slow": 4.911247491455078, "critic_target": 4.9124924839019775, "actor_ent": 1.4515689279556274, "actor_ent_scale": 0.0010000000474974513, "critic": 4.912412003326416, "fps": 120.19427664174522}
{"step": 19824676, "train_return": 15.0, "train_length": 2121.0, "train_total_steps": 4956169.0, "train_total_episodes": 2506.0, "train_loaded_steps": 1999898.0, "train_loaded_episodes": 1045.0}
{"step": 19832016, "train_return": 19.0, "train_length": 1835.0, "train_total_steps": 4958004.0, "train_total_episodes": 2507.0, "train_loaded_steps": 1999437.0, "train_loaded_episodes": 1045.0}
{"step": 19839552, "train_return": 18.0, "train_length": 1884.0, "train_total_steps": 4959888.0, "train_total_episodes": 2508.0, "train_loaded_steps": 1999429.0, "train_loaded_episodes": 1045.0}
{"step": 19847360, "train_return": 18.0, "train_length": 1952.0, "train_total_steps": 4961840.0, "train_total_episodes": 2509.0, "train_loaded_steps": 1999451.0, "train_loaded_episodes": 1045.0}
{"step": 19855792, "train_return": 19.0, "train_length": 2108.0, "train_total_steps": 4963948.0, "train_total_episodes": 2510.0, "train_loaded_steps": 1999415.0, "train_loaded_episodes": 1045.0}
{"step": 19857176, "kl_loss": 1.3816800485610963, "image_loss": 3772.0, "reward_loss": 0.919100617980957, "discount_loss": 0.0077412445083260535, "model_kl": 1.3816800216674805, "prior_ent": 25.89495535583496, "post_ent": 24.53906413269043, "model_loss": 3773.096004296875, "model_loss_scale": 8192.0, "model_grad_norm": 4.4481427318573, "actor_loss": -0.005509765898459591, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.028621194754540922, "critic_loss": 0.9153030741691589, "critic_loss_scale": 89024.1024, "critic_grad_norm": 0.22508066394925116, "reward_mean": 0.007419633291615173, "reward_std": 0.08287530317306518, "reward_normed_mean": 0.007419633291615173, "reward_normed_std": 0.08287530317306518, "critic_slow": 4.9786252010345455, "critic_target": 4.9793818588256835, "actor_ent": 1.4579815759658814, "actor_ent_scale": 0.0010000000474974513, "critic": 4.979258715438843, "fps": 120.66736865396923}
{"step": 19863244, "train_return": 18.0, "train_length": 1863.0, "train_total_steps": 4965811.0, "train_total_episodes": 2511.0, "train_loaded_steps": 1999375.0, "train_loaded_episodes": 1045.0}
{"step": 19871540, "train_return": 16.0, "train_length": 2074.0, "train_total_steps": 4967885.0, "train_total_episodes": 2512.0, "train_loaded_steps": 1999677.0, "train_loaded_episodes": 1045.0}
{"step": 19878788, "train_return": 20.0, "train_length": 1812.0, "train_total_steps": 4969697.0, "train_total_episodes": 2513.0, "train_loaded_steps": 1999827.0, "train_loaded_episodes": 1045.0}
{"step": 19886344, "train_return": 16.0, "train_length": 1889.0, "train_total_steps": 4971586.0, "train_total_episodes": 2514.0, "train_loaded_steps": 1999753.0, "train_loaded_episodes": 1045.0}
{"step": 19894380, "train_return": 17.0, "train_length": 2009.0, "train_total_steps": 4973595.0, "train_total_episodes": 2515.0, "train_loaded_steps": 1999979.0, "train_loaded_episodes": 1045.0}
{"step": 19897176, "kl_loss": 1.340475117301941, "image_loss": 3772.0001921875, "reward_loss": 0.9190825479507446, "discount_loss": 0.007741137798130513, "model_kl": 1.3404750881195069, "prior_ent": 26.01160216369629, "post_ent": 24.679736486816406, "model_loss": 3773.0920515625, "model_loss_scale": 8323.072, "model_grad_norm": Infinity, "actor_loss": -0.005758322276908439, "actor_loss_scale": 9448928.0512, "actor_grad_norm": Infinity, "critic_loss": 0.9160010004997253, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.23485479685664176, "reward_mean": 0.00751363435620442, "reward_std": 0.08254426165223122, "reward_normed_mean": 0.00751363435620442, "reward_normed_std": 0.08254426165223122, "critic_slow": 5.011672023010254, "critic_target": 5.012445628738403, "actor_ent": 1.474457548904419, "actor_ent_scale": 0.0010000000474974513, "critic": 5.012306287384034, "fps": 120.14747655420608}
{"step": 19902664, "train_return": 15.0, "train_length": 2071.0, "train_total_steps": 4975666.0, "train_total_episodes": 2516.0, "train_loaded_steps": 1998419.0, "train_loaded_episodes": 1044.0}
{"step": 19909952, "train_return": 20.0, "train_length": 1822.0, "train_total_steps": 4977488.0, "train_total_episodes": 2517.0, "train_loaded_steps": 1998383.0, "train_loaded_episodes": 1044.0}
{"step": 19917724, "train_return": 16.0, "train_length": 1943.0, "train_total_steps": 4979431.0, "train_total_episodes": 2518.0, "train_loaded_steps": 1998308.0, "train_loaded_episodes": 1044.0}
{"step": 19924684, "train_return": 20.0, "train_length": 1740.0, "train_total_steps": 4981171.0, "train_total_episodes": 2519.0, "train_loaded_steps": 1998180.0, "train_loaded_episodes": 1044.0}
{"step": 19933036, "train_return": 14.0, "train_length": 2088.0, "train_total_steps": 4983259.0, "train_total_episodes": 2520.0, "train_loaded_steps": 1998300.0, "train_loaded_episodes": 1044.0}
{"step": 19937176, "kl_loss": 1.3426959825515747, "image_loss": 3772.0001921875, "reward_loss": 0.9190924042701721, "discount_loss": 0.00775568114221096, "model_kl": 1.3426959512710572, "prior_ent": 26.227330917358397, "post_ent": 24.89496396179199, "model_loss": 3773.092359375, "model_loss_scale": 8192.0, "model_grad_norm": 4.526439056777954, "actor_loss": -0.006960050739342114, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.028454232960939407, "critic_loss": 0.9157069027900696, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.22143239663243294, "reward_mean": 0.0073548663672874685, "reward_std": 0.08235376372337341, "reward_normed_mean": 0.0073548663672874685, "reward_normed_std": 0.08235376372337341, "critic_slow": 5.013199882888794, "critic_target": 5.013484922790528, "actor_ent": 1.4469573904037476, "actor_ent_scale": 0.0010000000474974513, "critic": 5.013230188751221, "fps": 116.55758512233201}
{"step": 19940280, "train_return": 19.0, "train_length": 1811.0, "train_total_steps": 4985070.0, "train_total_episodes": 2521.0, "train_loaded_steps": 1998101.0, "train_loaded_episodes": 1044.0}
{"step": 19947300, "train_return": 20.0, "train_length": 1755.0, "train_total_steps": 4986825.0, "train_total_episodes": 2522.0, "train_loaded_steps": 1999856.0, "train_loaded_episodes": 1045.0}
{"step": 19954268, "train_return": 20.0, "train_length": 1742.0, "train_total_steps": 4988567.0, "train_total_episodes": 2523.0, "train_loaded_steps": 1999594.0, "train_loaded_episodes": 1045.0}
{"step": 19962456, "train_return": 17.0, "train_length": 2047.0, "train_total_steps": 4990614.0, "train_total_episodes": 2524.0, "train_loaded_steps": 1999644.0, "train_loaded_episodes": 1045.0}
{"step": 19970956, "train_return": 15.0, "train_length": 2125.0, "train_total_steps": 4992739.0, "train_total_episodes": 2525.0, "train_loaded_steps": 1998265.0, "train_loaded_episodes": 1044.0}
{"step": 19977176, "kl_loss": 1.331468549156189, "image_loss": 3772.0002, "reward_loss": 0.9190903885841369, "discount_loss": 0.007743367612361908, "model_kl": 1.3314685199737548, "prior_ent": 26.187630755615235, "post_ent": 24.866522872924804, "model_loss": 3773.09117890625, "model_loss_scale": 8192.0, "model_grad_norm": 4.328578419876099, "actor_loss": -0.005876355769083602, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.028496971002221108, "critic_loss": 0.9151852223396302, "critic_loss_scale": 151833.8048, "critic_grad_norm": 0.20045553427934645, "reward_mean": 0.007624911892280216, "reward_std": 0.08320776072144509, "reward_normed_mean": 0.007624911892280216, "reward_normed_std": 0.08320776072144509, "critic_slow": 5.005120964431763, "critic_target": 5.005945001602173, "actor_ent": 1.459266308403015, "actor_ent_scale": 0.0010000000474974513, "critic": 5.005634794235229, "fps": 115.5498676180042}
{"step": 19978844, "train_return": 16.0, "train_length": 1972.0, "train_total_steps": 4994711.0, "train_total_episodes": 2526.0, "train_loaded_steps": 1998365.0, "train_loaded_episodes": 1044.0}
{"step": 19985952, "train_return": 19.0, "train_length": 1777.0, "train_total_steps": 4996488.0, "train_total_episodes": 2527.0, "train_loaded_steps": 1998463.0, "train_loaded_episodes": 1044.0}
{"step": 19993336, "train_return": 18.0, "train_length": 1846.0, "train_total_steps": 4998334.0, "train_total_episodes": 2528.0, "train_loaded_steps": 1998580.0, "train_loaded_episodes": 1044.0}
{"step": 20000792, "train_return": 18.0, "train_length": 1864.0, "train_total_steps": 5000198.0, "train_total_episodes": 2529.0, "train_loaded_steps": 1998703.0, "train_loaded_episodes": 1044.0}
{"step": 20007988, "train_return": 19.0, "train_length": 1799.0, "train_total_steps": 5001997.0, "train_total_episodes": 2530.0, "train_loaded_steps": 1998799.0, "train_loaded_episodes": 1044.0}
{"step": 20014828, "train_return": 21.0, "train_length": 1710.0, "train_total_steps": 5003707.0, "train_total_episodes": 2531.0, "train_loaded_steps": 1998345.0, "train_loaded_episodes": 1044.0}
{"step": 20017176, "kl_loss": 1.3107288549423217, "image_loss": 3772.0, "reward_loss": 0.919077630329132, "discount_loss": 0.007755301847308874, "model_kl": 1.310728826713562, "prior_ent": 26.057843972778322, "post_ent": 24.75608912963867, "model_loss": 3773.088953125, "model_loss_scale": 13159.6288, "model_grad_norm": 4.410904704666137, "actor_loss": -0.0050668942191347014, "actor_loss_scale": 11838003.6096, "actor_grad_norm": 0.02761244978159666, "critic_loss": 0.9151224899291992, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.19924716755151747, "reward_mean": 0.007556451037712395, "reward_std": 0.08305353922843933, "reward_normed_mean": 0.007556451037712395, "reward_normed_std": 0.08305353922843933, "critic_slow": 4.996775064086914, "critic_target": 4.998312665939331, "actor_ent": 1.4624253759384156, "actor_ent_scale": 0.0010000000474974513, "critic": 4.997977627182006, "fps": 116.1092634575148}
{"step": 20022440, "train_return": 18.0, "train_length": 1903.0, "train_total_steps": 5005610.0, "train_total_episodes": 2532.0, "train_loaded_steps": 1998342.0, "train_loaded_episodes": 1044.0}
{"step": 20030244, "train_return": 18.0, "train_length": 1951.0, "train_total_steps": 5007561.0, "train_total_episodes": 2533.0, "train_loaded_steps": 1998629.0, "train_loaded_episodes": 1044.0}
{"step": 20037800, "train_return": 18.0, "train_length": 1889.0, "train_total_steps": 5009450.0, "train_total_episodes": 2534.0, "train_loaded_steps": 1998491.0, "train_loaded_episodes": 1044.0}
{"step": 20045336, "train_return": 18.0, "train_length": 1884.0, "train_total_steps": 5011334.0, "train_total_episodes": 2535.0, "train_loaded_steps": 1998546.0, "train_loaded_episodes": 1044.0}
{"step": 20052528, "train_return": 19.0, "train_length": 1798.0, "train_total_steps": 5013132.0, "train_total_episodes": 2536.0, "train_loaded_steps": 1998493.0, "train_loaded_episodes": 1044.0}
{"step": 20057176, "kl_loss": 1.3432145761489869, "image_loss": 3772.0, "reward_loss": 0.9191003889083862, "discount_loss": 0.007782145780324936, "model_kl": 1.3432145391464234, "prior_ent": 26.277423541259765, "post_ent": 24.94537080078125, "model_loss": 3773.092360546875, "model_loss_scale": 16384.0, "model_grad_norm": 4.588679187774658, "actor_loss": -0.006174278578080702, "actor_loss_scale": 9475771.5968, "actor_grad_norm": Infinity, "critic_loss": 0.9144951316833496, "critic_loss_scale": 262144.0, "critic_grad_norm": 0.21871980753540993, "reward_mean": 0.007589892796054483, "reward_std": 0.08317885857224465, "reward_normed_mean": 0.007589892796054483, "reward_normed_std": 0.08317885857224465, "critic_slow": 4.989294287490845, "critic_target": 4.989528586578369, "actor_ent": 1.4461174495697022, "actor_ent_scale": 0.0010000000474974513, "critic": 4.989058723068237, "fps": 114.99474852538133}
{"step": 20059168, "train_return": 21.0, "train_length": 1660.0, "train_total_steps": 5014792.0, "train_total_episodes": 2537.0, "train_loaded_steps": 1998190.0, "train_loaded_episodes": 1044.0}
{"step": 20067424, "train_return": 15.0, "train_length": 2064.0, "train_total_steps": 5016856.0, "train_total_episodes": 2538.0, "train_loaded_steps": 1998469.0, "train_loaded_episodes": 1044.0}
{"step": 20074716, "train_return": 19.0, "train_length": 1823.0, "train_total_steps": 5018679.0, "train_total_episodes": 2539.0, "train_loaded_steps": 1998456.0, "train_loaded_episodes": 1044.0}
{"step": 20081776, "train_return": 20.0, "train_length": 1765.0, "train_total_steps": 5020444.0, "train_total_episodes": 2540.0, "train_loaded_steps": 1997984.0, "train_loaded_episodes": 1044.0}
{"step": 20089444, "train_return": 18.0, "train_length": 1917.0, "train_total_steps": 5022361.0, "train_total_episodes": 2541.0, "train_loaded_steps": 1999901.0, "train_loaded_episodes": 1045.0}
{"step": 20096088, "train_return": 21.0, "train_length": 1661.0, "train_total_steps": 5024022.0, "train_total_episodes": 2542.0, "train_loaded_steps": 1999706.0, "train_loaded_episodes": 1045.0}
{"step": 20097176, "kl_loss": 1.3498765884399415, "image_loss": 3772.0, "reward_loss": 0.9190908113479614, "discount_loss": 0.0077531071692705155, "model_kl": 1.3498765577316285, "prior_ent": 25.913167123413086, "post_ent": 24.580999105834962, "model_loss": 3773.0928796875, "model_loss_scale": 11429.4784, "model_grad_norm": Infinity, "actor_loss": -0.004198566400664277, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.028108376790583135, "critic_loss": 0.9158840940475463, "critic_loss_scale": 128450.56, "critic_grad_norm": Infinity, "reward_mean": 0.007269615026144311, "reward_std": 0.08246481086015701, "reward_normed_mean": 0.007269615026144311, "reward_normed_std": 0.08246481086015701, "critic_slow": 5.017861441040039, "critic_target": 5.019127796173096, "actor_ent": 1.4583444627761841, "actor_ent_scale": 0.0010000000474974513, "critic": 5.018701774597168, "fps": 117.41351042674852}
{"step": 20105300, "train_return": 10.0, "train_length": 2303.0, "train_total_steps": 5026325.0, "train_total_episodes": 2543.0, "train_loaded_steps": 1999983.0, "train_loaded_episodes": 1045.0}
{"step": 20114048, "train_return": 14.0, "train_length": 2187.0, "train_total_steps": 5028512.0, "train_total_episodes": 2544.0, "train_loaded_steps": 1998349.0, "train_loaded_episodes": 1044.0}
{"step": 20121992, "train_return": 16.0, "train_length": 1986.0, "train_total_steps": 5030498.0, "train_total_episodes": 2545.0, "train_loaded_steps": 1998539.0, "train_loaded_episodes": 1044.0}
{"step": 20129480, "train_return": 17.0, "train_length": 1872.0, "train_total_steps": 5032370.0, "train_total_episodes": 2546.0, "train_loaded_steps": 1998409.0, "train_loaded_episodes": 1044.0}
{"step": 20137176, "kl_loss": 1.3198574825286866, "image_loss": 3772.0, "reward_loss": 0.9190990392684937, "discount_loss": 0.007741554320603609, "model_kl": 1.3198574562072753, "prior_ent": 26.167385748291014, "post_ent": 24.857977307128905, "model_loss": 3773.089821875, "model_loss_scale": 8192.0, "model_grad_norm": 4.4444264295578, "actor_loss": -0.005598830042110058, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.027319703620672226, "critic_loss": 0.9150236829757691, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.20741907191872597, "reward_mean": 0.007552214458608069, "reward_std": 0.08346619980335236, "reward_normed_mean": 0.007552214458608069, "reward_normed_std": 0.08346619980335236, "critic_slow": 4.988399546051025, "critic_target": 4.989125596237183, "actor_ent": 1.4768868841171265, "actor_ent_scale": 0.0010000000474974513, "critic": 4.988807009506226, "fps": 113.63744221050474}
{"step": 20137596, "train_return": 16.0, "train_length": 2029.0, "train_total_steps": 5034399.0, "train_total_episodes": 2547.0, "train_loaded_steps": 1998584.0, "train_loaded_episodes": 1044.0}
{"step": 20146016, "train_return": 19.0, "train_length": 2105.0, "train_total_steps": 5036504.0, "train_total_episodes": 2548.0, "train_loaded_steps": 1998892.0, "train_loaded_episodes": 1044.0}
{"step": 20152988, "train_return": 20.0, "train_length": 1743.0, "train_total_steps": 5038247.0, "train_total_episodes": 2549.0, "train_loaded_steps": 1998681.0, "train_loaded_episodes": 1044.0}
{"step": 20160376, "train_return": 17.0, "train_length": 1847.0, "train_total_steps": 5040094.0, "train_total_episodes": 2550.0, "train_loaded_steps": 1998748.0, "train_loaded_episodes": 1044.0}
{"step": 20169272, "train_return": 15.0, "train_length": 2224.0, "train_total_steps": 5042318.0, "train_total_episodes": 2551.0, "train_loaded_steps": 1998644.0, "train_loaded_episodes": 1044.0}
{"step": 20176496, "train_return": 18.0, "train_length": 1806.0, "train_total_steps": 5044124.0, "train_total_episodes": 2552.0, "train_loaded_steps": 1998456.0, "train_loaded_episodes": 1044.0}
{"step": 20177172, "eval_return": 12.0, "eval_length": 2232.0, "eval_total_steps": 48881.0, "eval_total_episodes": 25.0, "eval_loaded_steps": 48903.0, "eval_loaded_episodes": 25.0}
{"step": 20177176, "kl_loss": 1.3290356822967528, "image_loss": 3772.0, "reward_loss": 0.9190855314254761, "discount_loss": 0.007749606344848871, "model_kl": 1.3290356519699096, "prior_ent": 26.249920248413087, "post_ent": 24.933399014282227, "model_loss": 3773.09075859375, "model_loss_scale": 8192.0, "model_grad_norm": 4.589617601013184, "actor_loss": -0.005749133352431818, "actor_loss_scale": 9771050.5984, "actor_grad_norm": Infinity, "critic_loss": 0.9151325744628906, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.19896459184288978, "reward_mean": 0.007513638534024358, "reward_std": 0.08337831140756607, "reward_normed_mean": 0.007513638534024358, "reward_normed_std": 0.08337831140756607, "critic_slow": 5.0057210308074955, "critic_target": 5.006786568069458, "actor_ent": 1.483914976119995, "actor_ent_scale": 0.0010000000474974513, "critic": 5.006316770935059, "fps": 109.95429292249221}
{"step": 20183152, "train_return": 21.0, "train_length": 1664.0, "train_total_steps": 5045788.0, "train_total_episodes": 2553.0, "train_loaded_steps": 1998293.0, "train_loaded_episodes": 1044.0}
{"step": 20190712, "train_return": 16.0, "train_length": 1890.0, "train_total_steps": 5047678.0, "train_total_episodes": 2554.0, "train_loaded_steps": 1998048.0, "train_loaded_episodes": 1044.0}
{"step": 20197944, "train_return": 19.0, "train_length": 1808.0, "train_total_steps": 5049486.0, "train_total_episodes": 2555.0, "train_loaded_steps": 1999856.0, "train_loaded_episodes": 1045.0}
{"step": 20204584, "train_return": 21.0, "train_length": 1660.0, "train_total_steps": 5051146.0, "train_total_episodes": 2556.0, "train_loaded_steps": 1999578.0, "train_loaded_episodes": 1045.0}
{"step": 20212448, "train_return": 17.0, "train_length": 1966.0, "train_total_steps": 5053112.0, "train_total_episodes": 2557.0, "train_loaded_steps": 1999695.0, "train_loaded_episodes": 1045.0}
{"step": 20217176, "kl_loss": 1.33824061126709, "image_loss": 3772.0002, "reward_loss": 0.9190943163871765, "discount_loss": 0.007741289769858122, "model_kl": 1.3382405841827392, "prior_ent": 26.152645401000978, "post_ent": 24.82807941894531, "model_loss": 3773.091850390625, "model_loss_scale": 11508.1216, "model_grad_norm": 4.476299856567382, "actor_loss": -0.0037842333832581064, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.027871774174273015, "critic_loss": 0.9151974715232849, "critic_loss_scale": 87136.6656, "critic_grad_norm": 0.19943023647665978, "reward_mean": 0.007623288920708001, "reward_std": 0.08294627164006234, "reward_normed_mean": 0.007623288920708001, "reward_normed_std": 0.08294627164006234, "critic_slow": 4.977503631591797, "critic_target": 4.980113718414307, "actor_ent": 1.4849255060195923, "actor_ent_scale": 0.0010000000474974513, "critic": 4.979592789459229, "fps": 116.53935497067837}
{"step": 20220076, "train_return": 17.0, "train_length": 1907.0, "train_total_steps": 5055019.0, "train_total_episodes": 2558.0, "train_loaded_steps": 1999723.0, "train_loaded_episodes": 1045.0}
{"step": 20228260, "train_return": 16.0, "train_length": 2046.0, "train_total_steps": 5057065.0, "train_total_episodes": 2559.0, "train_loaded_steps": 1999718.0, "train_loaded_episodes": 1045.0}
{"step": 20236040, "train_return": 16.0, "train_length": 1945.0, "train_total_steps": 5059010.0, "train_total_episodes": 2560.0, "train_loaded_steps": 1999761.0, "train_loaded_episodes": 1045.0}
{"step": 20244036, "train_return": 17.0, "train_length": 1999.0, "train_total_steps": 5061009.0, "train_total_episodes": 2561.0, "train_loaded_steps": 1999845.0, "train_loaded_episodes": 1045.0}
{"step": 20251076, "train_return": 19.0, "train_length": 1760.0, "train_total_steps": 5062769.0, "train_total_episodes": 2562.0, "train_loaded_steps": 1999668.0, "train_loaded_episodes": 1045.0}
{"step": 20257176, "kl_loss": 1.32603426322937, "image_loss": 3772.0, "reward_loss": 0.9190828924179077, "discount_loss": 0.007741074930876494, "model_kl": 1.326034235572815, "prior_ent": 26.05811238708496, "post_ent": 24.743485848999022, "model_loss": 3773.09041484375, "model_loss_scale": 16384.0, "model_grad_norm": 4.513233696174622, "actor_loss": -0.0035580892566944387, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.02759618730843067, "critic_loss": 0.9147664440155029, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.1920144443899393, "reward_mean": 0.007525097843748517, "reward_std": 0.08281980175971985, "reward_normed_mean": 0.007525097843748517, "reward_normed_std": 0.08281980175971985, "critic_slow": 5.001087484741211, "critic_target": 5.003138024520874, "actor_ent": 1.469830456161499, "actor_ent_scale": 0.0010000000474974513, "critic": 5.002654487991333, "fps": 115.1742110361942}
{"step": 20258060, "train_return": 20.0, "train_length": 1746.0, "train_total_steps": 5064515.0, "train_total_episodes": 2563.0, "train_loaded_steps": 1999476.0, "train_loaded_episodes": 1045.0}
{"step": 20266040, "train_return": 16.0, "train_length": 1995.0, "train_total_steps": 5066510.0, "train_total_episodes": 2564.0, "train_loaded_steps": 1999471.0, "train_loaded_episodes": 1045.0}
{"step": 20273664, "train_return": 18.0, "train_length": 1906.0, "train_total_steps": 5068416.0, "train_total_episodes": 2565.0, "train_loaded_steps": 1999373.0, "train_loaded_episodes": 1045.0}
{"step": 20281740, "train_return": 17.0, "train_length": 2019.0, "train_total_steps": 5070435.0, "train_total_episodes": 2566.0, "train_loaded_steps": 1999534.0, "train_loaded_episodes": 1045.0}
{"step": 20289428, "train_return": 19.0, "train_length": 1922.0, "train_total_steps": 5072357.0, "train_total_episodes": 2567.0, "train_loaded_steps": 1999484.0, "train_loaded_episodes": 1045.0}
{"step": 20296556, "train_return": 21.0, "train_length": 1782.0, "train_total_steps": 5074139.0, "train_total_episodes": 2568.0, "train_loaded_steps": 1999605.0, "train_loaded_episodes": 1045.0}
{"step": 20297176, "kl_loss": 1.314425443840027, "image_loss": 3772.0, "reward_loss": 0.9190824892044067, "discount_loss": 0.007741352744400501, "model_kl": 1.3144254142761231, "prior_ent": 26.017614434814455, "post_ent": 24.71339450378418, "model_loss": 3773.089255859375, "model_loss_scale": 16384.0, "model_grad_norm": 4.411966587638855, "actor_loss": -0.0036245774041482946, "actor_loss_scale": 8563091.0464, "actor_grad_norm": Infinity, "critic_loss": 0.9151994071960449, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.1896749972820282, "reward_mean": 0.007531964969448746, "reward_std": 0.08309105338454247, "reward_normed_mean": 0.007531964969448746, "reward_normed_std": 0.08309105338454247, "critic_slow": 5.104068732070923, "critic_target": 5.105212302398682, "actor_ent": 1.4512930671691895, "actor_ent_scale": 0.0010000000474974513, "critic": 5.104688148498536, "fps": 117.19447379280547}
{"step": 20304740, "train_return": 15.0, "train_length": 2046.0, "train_total_steps": 5076185.0, "train_total_episodes": 2569.0, "train_loaded_steps": 1999880.0, "train_loaded_episodes": 1045.0}
{"step": 20313036, "train_return": 15.0, "train_length": 2074.0, "train_total_steps": 5078259.0, "train_total_episodes": 2570.0, "train_loaded_steps": 1999946.0, "train_loaded_episodes": 1045.0}
{"step": 20320004, "train_return": 20.0, "train_length": 1742.0, "train_total_steps": 5080001.0, "train_total_episodes": 2571.0, "train_loaded_steps": 1999818.0, "train_loaded_episodes": 1045.0}
{"step": 20327212, "train_return": 19.0, "train_length": 1802.0, "train_total_steps": 5081803.0, "train_total_episodes": 2572.0, "train_loaded_steps": 1999811.0, "train_loaded_episodes": 1045.0}
{"step": 20334328, "train_return": 20.0, "train_length": 1779.0, "train_total_steps": 5083582.0, "train_total_episodes": 2573.0, "train_loaded_steps": 1999771.0, "train_loaded_episodes": 1045.0}
{"step": 20337176, "kl_loss": 1.3077444871902466, "image_loss": 3772.0, "reward_loss": 0.9190790493965149, "discount_loss": 0.0077412200309336186, "model_kl": 1.3077444620132446, "prior_ent": 26.012513973999024, "post_ent": 24.713864385986327, "model_loss": 3773.088585546875, "model_loss_scale": 16698.5728, "model_grad_norm": Infinity, "actor_loss": -0.00625884713618434, "actor_loss_scale": 8388608.0, "actor_grad_norm": 0.02896303652524948, "critic_loss": 0.9155072485923768, "critic_loss_scale": 148058.9312, "critic_grad_norm": 0.20687294941544532, "reward_mean": 0.007617469251155853, "reward_std": 0.08283254390358925, "reward_normed_mean": 0.007617469251155853, "reward_normed_std": 0.08283254390358925, "critic_slow": 5.031982682800293, "critic_target": 5.032114919281006, "actor_ent": 1.4700568174362183, "actor_ent_scale": 0.0010000000474974513, "critic": 5.031858563613891, "fps": 114.08190443264105}
{"step": 20341860, "train_return": 19.0, "train_length": 1883.0, "train_total_steps": 5085465.0, "train_total_episodes": 2574.0, "train_loaded_steps": 1999807.0, "train_loaded_episodes": 1045.0}
{"step": 20340192, "eval_return": 18.0, "eval_length": 1932.0, "eval_total_steps": 51109.0, "eval_total_episodes": 26.0, "eval_loaded_steps": 51135.0, "eval_loaded_episodes": 26.0}
{"step": 20340196, "kl_loss": 1.2527143955230713, "image_loss": 3772.0, "reward_loss": 0.9190201759338379, "discount_loss": 0.007745134644210339, "model_kl": 1.2527143955230713, "prior_ent": 26.103857040405273, "post_ent": 24.887598037719727, "model_loss": 3773.0830078125, "model_loss_scale": 16384.0, "model_grad_norm": 5.321377277374268, "actor_loss": 0.0038424935191869736, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.040355321019887924, "critic_loss": 0.9246471524238586, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.19168800115585327, "reward_mean": 0.010239172726869583, "reward_std": 0.08418016880750656, "reward_normed_mean": 0.010239172726869583, "reward_normed_std": 0.08418016880750656, "critic_slow": 5.121142387390137, "critic_target": 5.131450653076172, "actor_ent": 1.4531301259994507, "actor_ent_scale": 0.0010000000474974513, "critic": 5.122788429260254, "fps": 0.0}
{"step": 20347008, "train_return": 20.0, "train_length": 1704.0, "train_total_steps": 5086752.0, "train_total_episodes": 2575.0, "train_loaded_steps": 1999599.0, "train_loaded_episodes": 1045.0}
{"step": 20354280, "train_return": 19.0, "train_length": 1818.0, "train_total_steps": 5088570.0, "train_total_episodes": 2576.0, "train_loaded_steps": 1999482.0, "train_loaded_episodes": 1045.0}
{"step": 20361772, "train_return": 18.0, "train_length": 1873.0, "train_total_steps": 5090443.0, "train_total_episodes": 2577.0, "train_loaded_steps": 1999469.0, "train_loaded_episodes": 1045.0}
{"step": 20369616, "train_return": 17.0, "train_length": 1961.0, "train_total_steps": 5092404.0, "train_total_episodes": 2578.0, "train_loaded_steps": 1999364.0, "train_loaded_episodes": 1045.0}
{"step": 20377076, "train_return": 19.0, "train_length": 1865.0, "train_total_steps": 5094269.0, "train_total_episodes": 2579.0, "train_loaded_steps": 1999264.0, "train_loaded_episodes": 1045.0}
{"step": 20380196, "kl_loss": 1.311701530456543, "image_loss": 3772.0, "reward_loss": 0.9190882457733154, "discount_loss": 0.007741582865267992, "model_kl": 1.3117015048980714, "prior_ent": 26.090439428710937, "post_ent": 24.784118228149413, "model_loss": 3773.08898828125, "model_loss_scale": 4122.2144, "model_grad_norm": Infinity, "actor_loss": -0.005031542958864884, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02706370014101267, "critic_loss": 0.914169613647461, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.18204409655630588, "reward_mean": 0.007597236947342753, "reward_std": 0.08290465351343156, "reward_normed_mean": 0.007597236947342753, "reward_normed_std": 0.08290465351343156, "critic_slow": 4.989935181808471, "critic_target": 4.991837000656128, "actor_ent": 1.4911865177154542, "actor_ent_scale": 0.0010000000474974513, "critic": 4.9914263870239255, "fps": 114.58049348686679}
{"step": 20385268, "train_return": 17.0, "train_length": 2048.0, "train_total_steps": 5096317.0, "train_total_episodes": 2580.0, "train_loaded_steps": 1999558.0, "train_loaded_episodes": 1045.0}
{"step": 20392620, "train_return": 18.0, "train_length": 1838.0, "train_total_steps": 5098155.0, "train_total_episodes": 2581.0, "train_loaded_steps": 1999358.0, "train_loaded_episodes": 1045.0}
{"step": 20399852, "train_return": 19.0, "train_length": 1808.0, "train_total_steps": 5099963.0, "train_total_episodes": 2582.0, "train_loaded_steps": 1999386.0, "train_loaded_episodes": 1045.0}
{"step": 20407544, "train_return": 19.0, "train_length": 1923.0, "train_total_steps": 5101886.0, "train_total_episodes": 2583.0, "train_loaded_steps": 1999424.0, "train_loaded_episodes": 1045.0}
{"step": 20415556, "train_return": 17.0, "train_length": 2003.0, "train_total_steps": 5103889.0, "train_total_episodes": 2584.0, "train_loaded_steps": 1999767.0, "train_loaded_episodes": 1045.0}
{"step": 20420196, "kl_loss": 1.3667895414352418, "image_loss": 3772.0, "reward_loss": 0.9190886232376099, "discount_loss": 0.00774090672954917, "model_kl": 1.366789510154724, "prior_ent": 25.858029418945314, "post_ent": 24.507698138427735, "model_loss": 3773.094499609375, "model_loss_scale": 4096.0, "model_grad_norm": 4.055132269859314, "actor_loss": -0.005617664484248963, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.028927446089684963, "critic_loss": 0.9154829598426819, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.21927664104104042, "reward_mean": 0.007414375716936775, "reward_std": 0.08268872320652008, "reward_normed_mean": 0.007414375716936775, "reward_normed_std": 0.08268872320652008, "critic_slow": 4.978399294281006, "critic_target": 4.978862825775146, "actor_ent": 1.4672135522842407, "actor_ent_scale": 0.0010000000474974513, "critic": 4.978532427215576, "fps": 114.41242713302756}
{"step": 20423052, "train_return": 18.0, "train_length": 1874.0, "train_total_steps": 5105763.0, "train_total_episodes": 2585.0, "train_loaded_steps": 1999782.0, "train_loaded_episodes": 1045.0}
{"step": 20431812, "train_return": 14.0, "train_length": 2190.0, "train_total_steps": 5107953.0, "train_total_episodes": 2586.0, "train_loaded_steps": 1999953.0, "train_loaded_episodes": 1045.0}
{"step": 20439136, "train_return": 19.0, "train_length": 1831.0, "train_total_steps": 5109784.0, "train_total_episodes": 2587.0, "train_loaded_steps": 1999995.0, "train_loaded_episodes": 1045.0}
{"step": 20446216, "train_return": 20.0, "train_length": 1770.0, "train_total_steps": 5111554.0, "train_total_episodes": 2588.0, "train_loaded_steps": 1999981.0, "train_loaded_episodes": 1045.0}
{"step": 20453452, "train_return": 19.0, "train_length": 1809.0, "train_total_steps": 5113363.0, "train_total_episodes": 2589.0, "train_loaded_steps": 1999872.0, "train_loaded_episodes": 1045.0}
{"step": 20460196, "kl_loss": 1.3113174648284913, "image_loss": 3772.0001921875, "reward_loss": 0.9190706838607788, "discount_loss": 0.0077411553211510185, "model_kl": 1.311317437171936, "prior_ent": 26.049893872070314, "post_ent": 24.74816911621094, "model_loss": 3773.089119140625, "model_loss_scale": 4096.0, "model_grad_norm": 4.447669813537598, "actor_loss": -0.0062366595146624605, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02794088286310434, "critic_loss": 0.9140318458557128, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.1827142741769552, "reward_mean": 0.007615152563527227, "reward_std": 0.08307868646979331, "reward_normed_mean": 0.007615152563527227, "reward_normed_std": 0.08307868646979331, "critic_slow": 5.031335510253906, "critic_target": 5.031996992874146, "actor_ent": 1.4700328531265259, "actor_ent_scale": 0.0010000000474974513, "critic": 5.031837390899658, "fps": 114.70188356527271}
{"step": 20461784, "train_return": 16.0, "train_length": 2083.0, "train_total_steps": 5115446.0, "train_total_episodes": 2590.0, "train_loaded_steps": 1999981.0, "train_loaded_episodes": 1045.0}
{"step": 20468792, "train_return": 20.0, "train_length": 1752.0, "train_total_steps": 5117198.0, "train_total_episodes": 2591.0, "train_loaded_steps": 1999745.0, "train_loaded_episodes": 1045.0}
{"step": 20475736, "train_return": 20.0, "train_length": 1736.0, "train_total_steps": 5118934.0, "train_total_episodes": 2592.0, "train_loaded_steps": 1999485.0, "train_loaded_episodes": 1045.0}
{"step": 20483524, "train_return": 17.0, "train_length": 1947.0, "train_total_steps": 5120881.0, "train_total_episodes": 2593.0, "train_loaded_steps": 1999726.0, "train_loaded_episodes": 1045.0}
{"step": 20491268, "train_return": 18.0, "train_length": 1936.0, "train_total_steps": 5122817.0, "train_total_episodes": 2594.0, "train_loaded_steps": 1999647.0, "train_loaded_episodes": 1045.0}
{"step": 20498676, "train_return": 18.0, "train_length": 1852.0, "train_total_steps": 5124669.0, "train_total_episodes": 2595.0, "train_loaded_steps": 1999236.0, "train_loaded_episodes": 1045.0}
{"step": 20500196, "kl_loss": 1.2980674303054809, "image_loss": 3772.0, "reward_loss": 0.9190650120735169, "discount_loss": 0.007741049443930387, "model_kl": 1.2980674036026, "prior_ent": 26.096403924560548, "post_ent": 24.805654656982423, "model_loss": 3773.087604296875, "model_loss_scale": 7359.6928, "model_grad_norm": 4.226326598930359, "actor_loss": -0.006643919812637614, "actor_loss_scale": 59087.2576, "actor_grad_norm": 0.02857777126580477, "critic_loss": 0.9154683059692382, "critic_loss_scale": 59087.2576, "critic_grad_norm": 0.20466110685765743, "reward_mean": 0.007470420420021401, "reward_std": 0.08288657771348953, "reward_normed_mean": 0.007470420420021401, "reward_normed_std": 0.08288657771348953, "critic_slow": 4.993483763885498, "critic_target": 4.993491421890258, "actor_ent": 1.4737807935714722, "actor_ent_scale": 0.0010000000474974513, "critic": 4.993374306106567, "fps": 114.963322933961}
{"step": 20505412, "train_return": 21.0, "train_length": 1684.0, "train_total_steps": 5126353.0, "train_total_episodes": 2596.0, "train_loaded_steps": 1998982.0, "train_loaded_episodes": 1045.0}
{"step": 20512680, "train_return": 18.0, "train_length": 1817.0, "train_total_steps": 5128170.0, "train_total_episodes": 2597.0, "train_loaded_steps": 1999031.0, "train_loaded_episodes": 1045.0}
{"step": 20520124, "train_return": 18.0, "train_length": 1861.0, "train_total_steps": 5130031.0, "train_total_episodes": 2598.0, "train_loaded_steps": 1998900.0, "train_loaded_episodes": 1045.0}
{"step": 20526760, "train_return": 21.0, "train_length": 1659.0, "train_total_steps": 5131690.0, "train_total_episodes": 2599.0, "train_loaded_steps": 1998676.0, "train_loaded_episodes": 1045.0}
{"step": 20534704, "train_return": 17.0, "train_length": 1986.0, "train_total_steps": 5133676.0, "train_total_episodes": 2600.0, "train_loaded_steps": 1998698.0, "train_loaded_episodes": 1045.0}
{"step": 20540196, "kl_loss": 1.3106527751922608, "image_loss": 3772.0, "reward_loss": 0.9190756296157837, "discount_loss": 0.007740936058014632, "model_kl": 1.3106527500152587, "prior_ent": 26.04414870605469, "post_ent": 24.74249580383301, "model_loss": 3773.088869140625, "model_loss_scale": 8192.0, "model_grad_norm": 4.554655456733704, "actor_loss": -0.0038956847869820194, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.028165146626532078, "critic_loss": 0.9149152486801148, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.18721272533535957, "reward_mean": 0.0076774147110059855, "reward_std": 0.08366540769338608, "reward_normed_mean": 0.0076774147110059855, "reward_normed_std": 0.08366540769338608, "critic_slow": 4.999425961303711, "critic_target": 5.001690801620484, "actor_ent": 1.4610889104843139, "actor_ent_scale": 0.0010000000474974513, "critic": 5.001347822570801, "fps": 115.47020635273327}
{"step": 20542740, "train_return": 17.0, "train_length": 2009.0, "train_total_steps": 5135685.0, "train_total_episodes": 2601.0, "train_loaded_steps": 1998080.0, "train_loaded_episodes": 1045.0}
{"step": 20550060, "train_return": 18.0, "train_length": 1830.0, "train_total_steps": 5137515.0, "train_total_episodes": 2602.0, "train_loaded_steps": 1999910.0, "train_loaded_episodes": 1046.0}
{"step": 20558340, "train_return": 16.0, "train_length": 2070.0, "train_total_steps": 5139585.0, "train_total_episodes": 2603.0, "train_loaded_steps": 1998095.0, "train_loaded_episodes": 1045.0}
{"step": 20566564, "train_return": 17.0, "train_length": 2056.0, "train_total_steps": 5141641.0, "train_total_episodes": 2604.0, "train_loaded_steps": 1998385.0, "train_loaded_episodes": 1045.0}
{"step": 20573572, "train_return": 20.0, "train_length": 1752.0, "train_total_steps": 5143393.0, "train_total_episodes": 2605.0, "train_loaded_steps": 1998335.0, "train_loaded_episodes": 1045.0}
{"step": 20580196, "kl_loss": 1.323140594482422, "image_loss": 3772.0, "reward_loss": 0.9190955308914185, "discount_loss": 0.007741125401854515, "model_kl": 1.3231405633926392, "prior_ent": 26.05544372253418, "post_ent": 24.74327247619629, "model_loss": 3773.090142578125, "model_loss_scale": 8192.0, "model_grad_norm": 4.31658809967041, "actor_loss": -0.004143721700632886, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.02978589536100626, "critic_loss": 0.9168171948432923, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.24356653923392296, "reward_mean": 0.007565257591102272, "reward_std": 0.08309677162766457, "reward_normed_mean": 0.007565257591102272, "reward_normed_std": 0.08309677162766457, "critic_slow": 5.072293756103516, "critic_target": 5.074268563461303, "actor_ent": 1.4438503170013428, "actor_ent_scale": 0.0010000000474974513, "critic": 5.073998728561401, "fps": 117.78694533816878}
{"step": 20581192, "train_return": 19.0, "train_length": 1905.0, "train_total_steps": 5145298.0, "train_total_episodes": 2606.0, "train_loaded_steps": 1998474.0, "train_loaded_episodes": 1045.0}
{"step": 20588880, "train_return": 17.0, "train_length": 1922.0, "train_total_steps": 5147220.0, "train_total_episodes": 2607.0, "train_loaded_steps": 1998155.0, "train_loaded_episodes": 1045.0}
{"step": 20595724, "train_return": 20.0, "train_length": 1711.0, "train_total_steps": 5148931.0, "train_total_episodes": 2608.0, "train_loaded_steps": 1999866.0, "train_loaded_episodes": 1046.0}
{"step": 20604156, "train_return": 15.0, "train_length": 2108.0, "train_total_steps": 5151039.0, "train_total_episodes": 2609.0, "train_loaded_steps": 1999835.0, "train_loaded_episodes": 1046.0}
{"step": 20611580, "train_return": 19.0, "train_length": 1856.0, "train_total_steps": 5152895.0, "train_total_episodes": 2610.0, "train_loaded_steps": 1999843.0, "train_loaded_episodes": 1046.0}
{"step": 20618924, "train_return": 17.0, "train_length": 1836.0, "train_total_steps": 5154731.0, "train_total_episodes": 2611.0, "train_loaded_steps": 1999857.0, "train_loaded_episodes": 1046.0}
{"step": 20620196, "kl_loss": 1.3094211233139037, "image_loss": 3772.0, "reward_loss": 0.9190741144180298, "discount_loss": 0.0077408466026186945, "model_kl": 1.3094210922241212, "prior_ent": 26.059489678955078, "post_ent": 24.761896572875976, "model_loss": 3773.08874765625, "model_loss_scale": 13080.9856, "model_grad_norm": 4.463265251541138, "actor_loss": -0.006359279854578199, "actor_loss_scale": 105067.3152, "actor_grad_norm": 0.02851058484762907, "critic_loss": 0.9152704889297485, "critic_loss_scale": 105067.3152, "critic_grad_norm": 0.1949632450699806, "reward_mean": 0.0077269241331610825, "reward_std": 0.08351777610182762, "reward_normed_mean": 0.0077269241331610825, "reward_normed_std": 0.08351777610182762, "critic_slow": 5.067030180358887, "critic_target": 5.067789317703247, "actor_ent": 1.4816312757492065, "actor_ent_scale": 0.0010000000474974513, "critic": 5.067640607452392, "fps": 115.8048294997876}
{"step": 20625840, "train_return": 19.0, "train_length": 1729.0, "train_total_steps": 5156460.0, "train_total_episodes": 2612.0, "train_loaded_steps": 1999832.0, "train_loaded_episodes": 1046.0}
{"step": 20633108, "train_return": 19.0, "train_length": 1817.0, "train_total_steps": 5158277.0, "train_total_episodes": 2613.0, "train_loaded_steps": 1999691.0, "train_loaded_episodes": 1046.0}
{"step": 20641216, "train_return": 17.0, "train_length": 2027.0, "train_total_steps": 5160304.0, "train_total_episodes": 2614.0, "train_loaded_steps": 1998131.0, "train_loaded_episodes": 1045.0}
{"step": 20649144, "train_return": 16.0, "train_length": 1982.0, "train_total_steps": 5162286.0, "train_total_episodes": 2615.0, "train_loaded_steps": 1998055.0, "train_loaded_episodes": 1045.0}
{"step": 20656540, "train_return": 19.0, "train_length": 1849.0, "train_total_steps": 5164135.0, "train_total_episodes": 2616.0, "train_loaded_steps": 1999904.0, "train_loaded_episodes": 1046.0}
{"step": 20660196, "kl_loss": 1.3318402717590332, "image_loss": 3772.0, "reward_loss": 0.9190953937530517, "discount_loss": 0.007741125098615885, "model_kl": 1.3318402473449706, "prior_ent": 25.998994583129882, "post_ent": 24.683351263427735, "model_loss": 3773.091018359375, "model_loss_scale": 16384.0, "model_grad_norm": 4.340741897773743, "actor_loss": -0.009287217109464108, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.026742931704223157, "critic_loss": 0.9143308812141419, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.19160080276727676, "reward_mean": 0.007521120478352532, "reward_std": 0.08244660093188286, "reward_normed_mean": 0.007521120478352532, "reward_normed_std": 0.08244660093188286, "critic_slow": 5.094990299224854, "critic_target": 5.094123778152466, "actor_ent": 1.4873426572799682, "actor_ent_scale": 0.0010000000474974513, "critic": 5.093940607833862, "fps": 117.18632681814941}
{"step": 20664528, "train_return": 17.0, "train_length": 1997.0, "train_total_steps": 5166132.0, "train_total_episodes": 2617.0, "train_loaded_steps": 1998129.0, "train_loaded_episodes": 1045.0}
{"step": 20672160, "train_return": 17.0, "train_length": 1908.0, "train_total_steps": 5168040.0, "train_total_episodes": 2618.0, "train_loaded_steps": 1998238.0, "train_loaded_episodes": 1045.0}
{"step": 20680412, "train_return": 16.0, "train_length": 2063.0, "train_total_steps": 5170103.0, "train_total_episodes": 2619.0, "train_loaded_steps": 1998447.0, "train_loaded_episodes": 1045.0}
{"step": 20687316, "train_return": 20.0, "train_length": 1726.0, "train_total_steps": 5171829.0, "train_total_episodes": 2620.0, "train_loaded_steps": 1998316.0, "train_loaded_episodes": 1045.0}
{"step": 20694544, "train_return": 19.0, "train_length": 1807.0, "train_total_steps": 5173636.0, "train_total_episodes": 2621.0, "train_loaded_steps": 1998212.0, "train_loaded_episodes": 1045.0}
{"step": 20700196, "kl_loss": 1.31080367603302, "image_loss": 3772.000187890625, "reward_loss": 0.9190682629585266, "discount_loss": 0.007741503327339887, "model_kl": 1.310803649520874, "prior_ent": 26.050213803100586, "post_ent": 24.749018771362305, "model_loss": 3773.0890765625, "model_loss_scale": 13225.1648, "model_grad_norm": Infinity, "actor_loss": -0.008536785144056194, "actor_loss_scale": 131072.0, "actor_grad_norm": 0.02721322984993458, "critic_loss": 0.9143680668830871, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.17864785487651824, "reward_mean": 0.007617384081054479, "reward_std": 0.08286384920477867, "reward_normed_mean": 0.007617384081054479, "reward_normed_std": 0.08286384920477867, "critic_slow": 5.108606167984009, "critic_target": 5.107585478591919, "actor_ent": 1.4929588039398194, "actor_ent_scale": 0.0010000000474974513, "critic": 5.107470485687256, "fps": 116.74456137376684}
{"step": 20701160, "train_return": 21.0, "train_length": 1654.0, "train_total_steps": 5175290.0, "train_total_episodes": 2622.0, "train_loaded_steps": 1999866.0, "train_loaded_episodes": 1046.0}
{"step": 20708948, "train_return": 16.0, "train_length": 1947.0, "train_total_steps": 5177237.0, "train_total_episodes": 2623.0, "train_loaded_steps": 1998342.0, "train_loaded_episodes": 1045.0}
{"step": 20716836, "train_return": 17.0, "train_length": 1972.0, "train_total_steps": 5179209.0, "train_total_episodes": 2624.0, "train_loaded_steps": 1998458.0, "train_loaded_episodes": 1045.0}
{"step": 20723744, "train_return": 20.0, "train_length": 1727.0, "train_total_steps": 5180936.0, "train_total_episodes": 2625.0, "train_loaded_steps": 1998477.0, "train_loaded_episodes": 1045.0}
{"step": 20732264, "train_return": 16.0, "train_length": 2130.0, "train_total_steps": 5183066.0, "train_total_episodes": 2626.0, "train_loaded_steps": 1998627.0, "train_loaded_episodes": 1045.0}
{"step": 20740196, "kl_loss": 1.3138494018554687, "image_loss": 3772.0, "reward_loss": 0.9190784517288209, "discount_loss": 0.007741122711449861, "model_kl": 1.31384937210083, "prior_ent": 25.95713878479004, "post_ent": 24.654438818359374, "model_loss": 3773.089191015625, "model_loss_scale": 8192.0, "model_grad_norm": 4.250510737419129, "actor_loss": -0.009397287786437664, "actor_loss_scale": 183920.2304, "actor_grad_norm": 0.027680280382931233, "critic_loss": 0.914849789428711, "critic_loss_scale": 183920.2304, "critic_grad_norm": 0.21207552558779716, "reward_mean": 0.007521682804392185, "reward_std": 0.08345092092752457, "reward_normed_mean": 0.007521682804392185, "reward_normed_std": 0.08345092092752457, "critic_slow": 5.0869394954681395, "critic_target": 5.086163528060913, "actor_ent": 1.4680325860977173, "actor_ent_scale": 0.0010000000474974513, "critic": 5.0858215217590335, "fps": 112.9961889261071}
{"step": 20740664, "train_return": 15.0, "train_length": 2100.0, "train_total_steps": 5185166.0, "train_total_episodes": 2627.0, "train_loaded_steps": 1998773.0, "train_loaded_episodes": 1045.0}
{"step": 20747640, "train_return": 20.0, "train_length": 1744.0, "train_total_steps": 5186910.0, "train_total_episodes": 2628.0, "train_loaded_steps": 1998477.0, "train_loaded_episodes": 1045.0}
{"step": 20754592, "train_return": 20.0, "train_length": 1738.0, "train_total_steps": 5188648.0, "train_total_episodes": 2629.0, "train_loaded_steps": 1998167.0, "train_loaded_episodes": 1045.0}
{"step": 20762096, "train_return": 19.0, "train_length": 1876.0, "train_total_steps": 5190524.0, "train_total_episodes": 2630.0, "train_loaded_steps": 1998192.0, "train_loaded_episodes": 1045.0}
{"step": 20770432, "train_return": 16.0, "train_length": 2084.0, "train_total_steps": 5192608.0, "train_total_episodes": 2631.0, "train_loaded_steps": 1998565.0, "train_loaded_episodes": 1045.0}
{"step": 20778004, "train_return": 19.0, "train_length": 1893.0, "train_total_steps": 5194501.0, "train_total_episodes": 2632.0, "train_loaded_steps": 1998674.0, "train_loaded_episodes": 1045.0}
{"step": 20780196, "kl_loss": 1.3237159881591798, "image_loss": 3772.0, "reward_loss": 0.9190781765937805, "discount_loss": 0.007740979331731796, "model_kl": 1.3237159614562988, "prior_ent": 26.081724136352538, "post_ent": 24.769732388305663, "model_loss": 3773.090178125, "model_loss_scale": 8192.0, "model_grad_norm": 4.356116751480102, "actor_loss": -0.008107203407364432, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.028659278389811516, "critic_loss": 0.9154130212783813, "critic_loss_scale": 238026.752, "critic_grad_norm": Infinity, "reward_mean": 0.007500747648663856, "reward_std": 0.08326180821657181, "reward_normed_mean": 0.007500747648663856, "reward_normed_std": 0.08326180821657181, "critic_slow": 5.054841467666626, "critic_target": 5.054155227279663, "actor_ent": 1.4631678323745727, "actor_ent_scale": 0.0010000000474974513, "critic": 5.054126036834717, "fps": 114.78760133619613}
{"step": 20785584, "train_return": 18.0, "train_length": 1895.0, "train_total_steps": 5196396.0, "train_total_episodes": 2633.0, "train_loaded_steps": 1998698.0, "train_loaded_episodes": 1045.0}
{"step": 20792660, "train_return": 19.0, "train_length": 1769.0, "train_total_steps": 5198165.0, "train_total_episodes": 2634.0, "train_loaded_steps": 1998433.0, "train_loaded_episodes": 1045.0}
{"step": 20800404, "train_return": 18.0, "train_length": 1936.0, "train_total_steps": 5200101.0, "train_total_episodes": 2635.0, "train_loaded_steps": 1998155.0, "train_loaded_episodes": 1045.0}
{"step": 20808824, "train_return": 17.0, "train_length": 2105.0, "train_total_steps": 5202206.0, "train_total_episodes": 2636.0, "train_loaded_steps": 1997918.0, "train_loaded_episodes": 1045.0}
{"step": 20817356, "train_return": 16.0, "train_length": 2133.0, "train_total_steps": 5204339.0, "train_total_episodes": 2637.0, "train_loaded_steps": 1997824.0, "train_loaded_episodes": 1045.0}
{"step": 20820196, "kl_loss": 1.3192335845947265, "image_loss": 3772.0, "reward_loss": 0.9190845811843872, "discount_loss": 0.00774129937440157, "model_kl": 1.3192335586547852, "prior_ent": 26.018181771850585, "post_ent": 24.70956722717285, "model_loss": 3773.08974453125, "model_loss_scale": 9712.4352, "model_grad_norm": 4.399017925071717, "actor_loss": -0.009417728637375694, "actor_loss_scale": 262144.0, "actor_grad_norm": 0.02728787558525801, "critic_loss": 0.9151488679885864, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.20012781134843827, "reward_mean": 0.007609395014028996, "reward_std": 0.08297629532814026, "reward_normed_mean": 0.007609395014028996, "reward_normed_std": 0.08297629532814026, "critic_slow": 5.039728004837036, "critic_target": 5.038835771942138, "actor_ent": 1.4854096061706543, "actor_ent_scale": 0.0010000000474974513, "critic": 5.038648918151855, "fps": 113.98391670478668}
{"step": 20824488, "train_return": 20.0, "train_length": 1783.0, "train_total_steps": 5206122.0, "train_total_episodes": 2638.0, "train_loaded_steps": 1999607.0, "train_loaded_episodes": 1046.0}
{"step": 20831340, "train_return": 20.0, "train_length": 1713.0, "train_total_steps": 5207835.0, "train_total_episodes": 2639.0, "train_loaded_steps": 1999500.0, "train_loaded_episodes": 1046.0}
{"step": 20838404, "train_return": 20.0, "train_length": 1766.0, "train_total_steps": 5209601.0, "train_total_episodes": 2640.0, "train_loaded_steps": 1999261.0, "train_loaded_episodes": 1046.0}
{"step": 20846636, "train_return": 16.0, "train_length": 2058.0, "train_total_steps": 5211659.0, "train_total_episodes": 2641.0, "train_loaded_steps": 1998902.0, "train_loaded_episodes": 1046.0}
{"step": 20853980, "train_return": 19.0, "train_length": 1836.0, "train_total_steps": 5213495.0, "train_total_episodes": 2642.0, "train_loaded_steps": 1998695.0, "train_loaded_episodes": 1046.0}
{"step": 20860196, "kl_loss": 1.3117431083679199, "image_loss": 3772.000187890625, "reward_loss": 0.9190796068191528, "discount_loss": 0.0077414250291883945, "model_kl": 1.3117430818557738, "prior_ent": 25.968641409301757, "post_ent": 24.66850644836426, "model_loss": 3773.089184765625, "model_loss_scale": 16384.0, "model_grad_norm": 4.365956104278564, "actor_loss": -0.007374978059041313, "actor_loss_scale": 315411.6608, "actor_grad_norm": 0.027520172861218453, "critic_loss": 0.9151458402633667, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.20670416821837426, "reward_mean": 0.00764419511128217, "reward_std": 0.08303456354141235, "reward_normed_mean": 0.00764419511128217, "reward_normed_std": 0.08303456354141235, "critic_slow": 5.066476560592651, "critic_target": 5.066730014801025, "actor_ent": 1.4992934452056885, "actor_ent_scale": 0.0010000000474974513, "critic": 5.066347268295288, "fps": 116.21719680497}
{"step": 20861160, "train_return": 19.0, "train_length": 1795.0, "train_total_steps": 5215290.0, "train_total_episodes": 2643.0, "train_loaded_steps": 1998680.0, "train_loaded_episodes": 1046.0}
{"step": 20868440, "train_return": 20.0, "train_length": 1820.0, "train_total_steps": 5217110.0, "train_total_episodes": 2644.0, "train_loaded_steps": 1998148.0, "train_loaded_episodes": 1046.0}
{"step": 20875308, "train_return": 20.0, "train_length": 1717.0, "train_total_steps": 5218827.0, "train_total_episodes": 2645.0, "train_loaded_steps": 1999865.0, "train_loaded_episodes": 1047.0}
{"step": 20884088, "train_return": 15.0, "train_length": 2195.0, "train_total_steps": 5221022.0, "train_total_episodes": 2646.0, "train_loaded_steps": 1998254.0, "train_loaded_episodes": 1046.0}
{"step": 20891892, "train_return": 18.0, "train_length": 1951.0, "train_total_steps": 5222973.0, "train_total_episodes": 2647.0, "train_loaded_steps": 1998278.0, "train_loaded_episodes": 1046.0}
{"step": 20898848, "train_return": 20.0, "train_length": 1739.0, "train_total_steps": 5224712.0, "train_total_episodes": 2648.0, "train_loaded_steps": 1997947.0, "train_loaded_episodes": 1046.0}
{"step": 20900196, "kl_loss": 1.331719723701477, "image_loss": 3772.0, "reward_loss": 0.9190980659484863, "discount_loss": 0.007874436320364475, "model_kl": 1.3317196926116943, "prior_ent": 25.9514766998291, "post_ent": 24.63284883117676, "model_loss": 3773.09167265625, "model_loss_scale": 16384.0, "model_grad_norm": 4.20798479347229, "actor_loss": -0.0024817256048321724, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.033442715410888196, "critic_loss": 0.9211409738540649, "critic_loss_scale": 76755.7632, "critic_grad_norm": Infinity, "reward_mean": 0.007613818998099305, "reward_std": 0.08275575746893883, "reward_normed_mean": 0.007613818998099305, "reward_normed_std": 0.08275575746893883, "critic_slow": 4.982019669342041, "critic_target": 4.984552685928345, "actor_ent": 1.4043270198822022, "actor_ent_scale": 0.0010000000474974513, "critic": 4.9845472534179684, "fps": 116.52387528046718}
{"step": 20906960, "train_return": 17.0, "train_length": 2028.0, "train_total_steps": 5226740.0, "train_total_episodes": 2649.0, "train_loaded_steps": 1999975.0, "train_loaded_episodes": 1047.0}
{"step": 20913800, "train_return": 20.0, "train_length": 1710.0, "train_total_steps": 5228450.0, "train_total_episodes": 2650.0, "train_loaded_steps": 1999894.0, "train_loaded_episodes": 1047.0}
{"step": 20921828, "train_return": 17.0, "train_length": 2007.0, "train_total_steps": 5230457.0, "train_total_episodes": 2651.0, "train_loaded_steps": 1998295.0, "train_loaded_episodes": 1046.0}
{"step": 20928912, "train_return": 19.0, "train_length": 1771.0, "train_total_steps": 5232228.0, "train_total_episodes": 2652.0, "train_loaded_steps": 1997995.0, "train_loaded_episodes": 1046.0}
{"step": 20936232, "train_return": 19.0, "train_length": 1830.0, "train_total_steps": 5234058.0, "train_total_episodes": 2653.0, "train_loaded_steps": 1999825.0, "train_loaded_episodes": 1047.0}
{"step": 20940196, "kl_loss": 1.348142834663391, "image_loss": 3772.0, "reward_loss": 0.9190769344329834, "discount_loss": 0.007771537750214338, "model_kl": 1.348142809867859, "prior_ent": 26.144177493286133, "post_ent": 24.811799688720704, "model_loss": 3773.092771875, "model_loss_scale": 16384.0, "model_grad_norm": 4.400743793869019, "actor_loss": -0.005240979106945451, "actor_loss_scale": 524288.0, "actor_grad_norm": 0.030715070286393167, "critic_loss": 0.9179332885742187, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.22576291678845883, "reward_mean": 0.007539343064092099, "reward_std": 0.08241783606410026, "reward_normed_mean": 0.007539343064092099, "reward_normed_std": 0.08241783606410026, "critic_slow": 5.014439133834839, "critic_target": 5.013241901397705, "actor_ent": 1.404319567298889, "actor_ent_scale": 0.0010000000474974513, "critic": 5.0129971607208255, "fps": 115.66949488327268}
{"step": 20943784, "train_return": 18.0, "train_length": 1888.0, "train_total_steps": 5235946.0, "train_total_episodes": 2654.0, "train_loaded_steps": 1999988.0, "train_loaded_episodes": 1047.0}
{"step": 20952164, "train_return": 16.0, "train_length": 2095.0, "train_total_steps": 5238041.0, "train_total_episodes": 2655.0, "train_loaded_steps": 1998525.0, "train_loaded_episodes": 1046.0}
{"step": 20959424, "train_return": 19.0, "train_length": 1815.0, "train_total_steps": 5239856.0, "train_total_episodes": 2656.0, "train_loaded_steps": 1998433.0, "train_loaded_episodes": 1046.0}
{"step": 20966516, "train_return": 19.0, "train_length": 1773.0, "train_total_steps": 5241629.0, "train_total_episodes": 2657.0, "train_loaded_steps": 1998355.0, "train_loaded_episodes": 1046.0}
{"step": 20974832, "train_return": 16.0, "train_length": 2079.0, "train_total_steps": 5243708.0, "train_total_episodes": 2658.0, "train_loaded_steps": 1998274.0, "train_loaded_episodes": 1046.0}
{"step": 20980196, "kl_loss": 1.318850909614563, "image_loss": 3772.0, "reward_loss": 0.9190897136688232, "discount_loss": 0.007748470465093851, "model_kl": 1.318850882911682, "prior_ent": 26.040680712890627, "post_ent": 24.732979525756836, "model_loss": 3773.0897375, "model_loss_scale": 18271.4368, "model_grad_norm": Infinity, "actor_loss": -0.004491310485907889, "actor_loss_scale": 525965.7216, "actor_grad_norm": 0.027956989777088166, "critic_loss": 0.9148869637489319, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.17536624580621718, "reward_mean": 0.007523811880033463, "reward_std": 0.08310948303341865, "reward_normed_mean": 0.007523811880033463, "reward_normed_std": 0.08310948303341865, "critic_slow": 4.976705339431763, "critic_target": 4.977422872161865, "actor_ent": 1.4489425769805908, "actor_ent_scale": 0.0010000000474974513, "critic": 4.977220366287232, "fps": 114.89155311782152}
{"step": 20982548, "train_return": 18.0, "train_length": 1929.0, "train_total_steps": 5245637.0, "train_total_episodes": 2659.0, "train_loaded_steps": 1998225.0, "train_loaded_episodes": 1046.0}
{"step": 20989392, "train_return": 20.0, "train_length": 1711.0, "train_total_steps": 5247348.0, "train_total_episodes": 2660.0, "train_loaded_steps": 1999936.0, "train_loaded_episodes": 1047.0}
{"step": 20996728, "train_return": 19.0, "train_length": 1834.0, "train_total_steps": 5249182.0, "train_total_episodes": 2661.0, "train_loaded_steps": 1998123.0, "train_loaded_episodes": 1046.0}
{"step": 21005036, "train_return": 15.0, "train_length": 2077.0, "train_total_steps": 5251259.0, "train_total_episodes": 2662.0, "train_loaded_steps": 1998148.0, "train_loaded_episodes": 1046.0}
{"step": 21013088, "train_return": 17.0, "train_length": 2013.0, "train_total_steps": 5253272.0, "train_total_episodes": 2663.0, "train_loaded_steps": 1998075.0, "train_loaded_episodes": 1046.0}
{"step": 21020196, "kl_loss": 1.318110283470154, "image_loss": 3772.0, "reward_loss": 0.9190923504829407, "discount_loss": 0.007771264749765396, "model_kl": 1.318110255432129, "prior_ent": 26.160099908447265, "post_ent": 24.85508187866211, "model_loss": 3773.089787109375, "model_loss_scale": 16384.0, "model_grad_norm": 4.2938513841629025, "actor_loss": -0.004684566356323193, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.027021318763494492, "critic_loss": 0.9148095134735107, "critic_loss_scale": 106745.0368, "critic_grad_norm": 0.19151486244797705, "reward_mean": 0.007673173550050706, "reward_std": 0.08332807686924934, "reward_normed_mean": 0.007673173550050706, "reward_normed_std": 0.08332807686924934, "critic_slow": 4.944042528533935, "critic_target": 4.945333753204346, "actor_ent": 1.474946838760376, "actor_ent_scale": 0.0010000000474974513, "critic": 4.945051058959961, "fps": 116.30006582060874}
{"step": 21021420, "train_return": 15.0, "train_length": 2083.0, "train_total_steps": 5255355.0, "train_total_episodes": 2664.0, "train_loaded_steps": 1998220.0, "train_loaded_episodes": 1046.0}
{"step": 21028948, "train_return": 17.0, "train_length": 1882.0, "train_total_steps": 5257237.0, "train_total_episodes": 2665.0, "train_loaded_steps": 1998039.0, "train_loaded_episodes": 1046.0}
{"step": 21036524, "train_return": 18.0, "train_length": 1894.0, "train_total_steps": 5259131.0, "train_total_episodes": 2666.0, "train_loaded_steps": 1999933.0, "train_loaded_episodes": 1047.0}
{"step": 21044684, "train_return": 15.0, "train_length": 2040.0, "train_total_steps": 5261171.0, "train_total_episodes": 2667.0, "train_loaded_steps": 1998363.0, "train_loaded_episodes": 1046.0}
{"step": 21052892, "train_return": 15.0, "train_length": 2052.0, "train_total_steps": 5263223.0, "train_total_episodes": 2668.0, "train_loaded_steps": 1998291.0, "train_loaded_episodes": 1046.0}
{"step": 21059752, "train_return": 20.0, "train_length": 1715.0, "train_total_steps": 5264938.0, "train_total_episodes": 2669.0, "train_loaded_steps": 1997982.0, "train_loaded_episodes": 1046.0}
{"step": 21060196, "kl_loss": 1.3123002647399902, "image_loss": 3772.0, "reward_loss": 0.9190623294830322, "discount_loss": 0.007741173403710127, "model_kl": 1.3123002401351929, "prior_ent": 26.04504389038086, "post_ent": 24.74044970703125, "model_loss": 3773.0890265625, "model_loss_scale": 16384.0, "model_grad_norm": 4.424885632133484, "actor_loss": -0.005491516557606519, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.028761476247012616, "critic_loss": 0.9158758755683899, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.19128970336019993, "reward_mean": 0.007382140531204641, "reward_std": 0.08281510670781135, "reward_normed_mean": 0.007382140531204641, "reward_normed_std": 0.08281510670781135, "critic_slow": 4.952311659240722, "critic_target": 4.953259262084961, "actor_ent": 1.485412188911438, "actor_ent_scale": 0.0010000000474974513, "critic": 4.953378385543823, "fps": 118.0687365729418}
{"step": 21067580, "train_return": 17.0, "train_length": 1957.0, "train_total_steps": 5266895.0, "train_total_episodes": 2670.0, "train_loaded_steps": 1999939.0, "train_loaded_episodes": 1047.0}
{"step": 21075476, "train_return": 18.0, "train_length": 1974.0, "train_total_steps": 5268869.0, "train_total_episodes": 2671.0, "train_loaded_steps": 1999930.0, "train_loaded_episodes": 1047.0}
{"step": 21082776, "train_return": 19.0, "train_length": 1825.0, "train_total_steps": 5270694.0, "train_total_episodes": 2672.0, "train_loaded_steps": 1999747.0, "train_loaded_episodes": 1047.0}
{"step": 21089876, "train_return": 19.0, "train_length": 1775.0, "train_total_steps": 5272469.0, "train_total_episodes": 2673.0, "train_loaded_steps": 1999539.0, "train_loaded_episodes": 1047.0}
{"step": 21097768, "train_return": 17.0, "train_length": 1973.0, "train_total_steps": 5274442.0, "train_total_episodes": 2674.0, "train_loaded_steps": 1999511.0, "train_loaded_episodes": 1047.0}
{"step": 21100196, "kl_loss": 1.2942851308822632, "image_loss": 3772.0, "reward_loss": 0.9190664796829223, "discount_loss": 0.007740761010348797, "model_kl": 1.2942851062774658, "prior_ent": 26.00699725036621, "post_ent": 24.722196383666994, "model_loss": 3773.087216796875, "model_loss_scale": 20578.304, "model_grad_norm": Infinity, "actor_loss": -0.006453562638530275, "actor_loss_scale": 1048576.0, "actor_grad_norm": 0.026919181326031685, "critic_loss": 0.914440888595581, "critic_loss_scale": 131072.0, "critic_grad_norm": 0.17026094582676887, "reward_mean": 0.007602522243087878, "reward_std": 0.08366543162465095, "reward_normed_mean": 0.007602522243087878, "reward_normed_std": 0.08366543162465095, "critic_slow": 4.9239913249969485, "critic_target": 4.924615376663208, "actor_ent": 1.4957706140518188, "actor_ent_scale": 0.0010000000474974513, "critic": 4.924558106613159, "fps": 116.93106791600046}
{"step": 21104960, "train_return": 20.0, "train_length": 1798.0, "train_total_steps": 5276240.0, "train_total_episodes": 2675.0, "train_loaded_steps": 1999356.0, "train_loaded_episodes": 1047.0}
{"step": 21112528, "train_return": 20.0, "train_length": 1892.0, "train_total_steps": 5278132.0, "train_total_episodes": 2676.0, "train_loaded_steps": 1999435.0, "train_loaded_episodes": 1047.0}
{"step": 21119272, "train_return": 21.0, "train_length": 1686.0, "train_total_steps": 5279818.0, "train_total_episodes": 2677.0, "train_loaded_steps": 1999240.0, "train_loaded_episodes": 1047.0}
{"step": 21127692, "train_return": 17.0, "train_length": 2105.0, "train_total_steps": 5281923.0, "train_total_episodes": 2678.0, "train_loaded_steps": 1999421.0, "train_loaded_episodes": 1047.0}
{"step": 21135520, "train_return": 17.0, "train_length": 1957.0, "train_total_steps": 5283880.0, "train_total_episodes": 2679.0, "train_loaded_steps": 1999048.0, "train_loaded_episodes": 1047.0}
{"step": 21140196, "kl_loss": 1.3323205688476563, "image_loss": 3772.0002, "reward_loss": 0.9190824484825134, "discount_loss": 0.007741471281647682, "model_kl": 1.3323205429077147, "prior_ent": 26.061553326416014, "post_ent": 24.747444494628905, "model_loss": 3773.091253515625, "model_loss_scale": 16384.0, "model_grad_norm": 4.454892080688476, "actor_loss": -0.008118145958543755, "actor_loss_scale": 1890792.2432, "actor_grad_norm": 0.0283629405900836, "critic_loss": 0.9165339385986329, "critic_loss_scale": 129079.7056, "critic_grad_norm": Infinity, "reward_mean": 0.007570105919323941, "reward_std": 0.08317842741608619, "reward_normed_mean": 0.007570105919323941, "reward_normed_std": 0.08317842741608619, "critic_slow": 4.932357104873657, "critic_target": 4.932255331039428, "actor_ent": 1.513501830291748, "actor_ent_scale": 0.0010000000474974513, "critic": 4.932574003982544, "fps": 114.4616469959453}
{"step": 21143464, "train_return": 16.0, "train_length": 1986.0, "train_total_steps": 5285866.0, "train_total_episodes": 2680.0, "train_loaded_steps": 1999131.0, "train_loaded_episodes": 1047.0}
{"step": 21150080, "train_return": 21.0, "train_length": 1654.0, "train_total_steps": 5287520.0, "train_total_episodes": 2681.0, "train_loaded_steps": 1998471.0, "train_loaded_episodes": 1047.0}
{"step": 21156964, "train_return": 20.0, "train_length": 1721.0, "train_total_steps": 5289241.0, "train_total_episodes": 2682.0, "train_loaded_steps": 1998286.0, "train_loaded_episodes": 1047.0}
{"step": 21165092, "train_return": 15.0, "train_length": 2032.0, "train_total_steps": 5291273.0, "train_total_episodes": 2683.0, "train_loaded_steps": 1998379.0, "train_loaded_episodes": 1047.0}
{"step": 21172100, "train_return": 19.0, "train_length": 1752.0, "train_total_steps": 5293025.0, "train_total_episodes": 2684.0, "train_loaded_steps": 1998137.0, "train_loaded_episodes": 1047.0}
{"step": 21180196, "kl_loss": 1.3515799953460694, "image_loss": 3772.0, "reward_loss": 0.9190962615013123, "discount_loss": 0.007741260943561793, "model_kl": 1.351579968070984, "prior_ent": 26.024402261352538, "post_ent": 24.68877644958496, "model_loss": 3773.09298828125, "model_loss_scale": 16384.0, "model_grad_norm": 4.220045455741882, "actor_loss": -0.00669319945947791, "actor_loss_scale": 2097152.0, "actor_grad_norm": 0.034922848300635814, "critic_loss": 0.9211631405830383, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.26556754333376886, "reward_mean": 0.007562606128281914, "reward_std": 0.08253049967288971, "reward_normed_mean": 0.007562606128281914, "reward_normed_std": 0.08253049967288971, "critic_slow": 4.829971824645996, "critic_target": 4.830925591278076, "actor_ent": 1.4727525133132935, "actor_ent_scale": 0.0010000000474974513, "critic": 4.831132939529419, "fps": 114.9141827692005}
{"step": 21180656, "train_return": 14.0, "train_length": 2139.0, "train_total_steps": 5295164.0, "train_total_episodes": 2685.0, "train_loaded_steps": 1998378.0, "train_loaded_episodes": 1047.0}
{"step": 21188080, "train_return": 19.0, "train_length": 1856.0, "train_total_steps": 5297020.0, "train_total_episodes": 2686.0, "train_loaded_steps": 1998448.0, "train_loaded_episodes": 1047.0}
{"step": 21196324, "train_return": 17.0, "train_length": 2061.0, "train_total_steps": 5299081.0, "train_total_episodes": 2687.0, "train_loaded_steps": 1998623.0, "train_loaded_episodes": 1047.0}
{"step": 21204400, "train_return": 17.0, "train_length": 2019.0, "train_total_steps": 5301100.0, "train_total_episodes": 2688.0, "train_loaded_steps": 1998708.0, "train_loaded_episodes": 1047.0}
{"step": 21212636, "train_return": 15.0, "train_length": 2059.0, "train_total_steps": 5303159.0, "train_total_episodes": 2689.0, "train_loaded_steps": 1998877.0, "train_loaded_episodes": 1047.0}
{"step": 21212176, "eval_return": 20.0, "eval_length": 1769.0, "eval_total_steps": 53040.0, "eval_total_episodes": 27.0, "eval_loaded_steps": 53067.0, "eval_loaded_episodes": 27.0}
{"step": 21212180, "kl_loss": 1.303371787071228, "image_loss": 3772.0, "reward_loss": 0.9189406633377075, "discount_loss": 0.007745121140033007, "model_kl": 1.303371787071228, "prior_ent": 26.040678024291992, "post_ent": 24.750070571899414, "model_loss": 3773.088134765625, "model_loss_scale": 16384.0, "model_grad_norm": 5.324859142303467, "actor_loss": 0.01914631575345993, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.028881143778562546, "critic_loss": 0.9170774221420288, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.36587873101234436, "reward_mean": 0.011430966667830944, "reward_std": 0.08241850882768631, "reward_normed_mean": 0.011430966667830944, "reward_normed_std": 0.08241850882768631, "critic_slow": 5.204553127288818, "critic_target": 5.225854396820068, "actor_ent": 1.4633910655975342, "actor_ent_scale": 0.0010000000474974513, "critic": 5.202725410461426, "fps": 0.0}
{"step": 21219344, "train_return": 19.0, "train_length": 1792.0, "train_total_steps": 5304836.0, "train_total_episodes": 2690.0, "train_loaded_steps": 1998795.0, "train_loaded_episodes": 1047.0}
{"step": 21226640, "train_return": 19.0, "train_length": 1824.0, "train_total_steps": 5306660.0, "train_total_episodes": 2691.0, "train_loaded_steps": 1998713.0, "train_loaded_episodes": 1047.0}
{"step": 21234100, "train_return": 19.0, "train_length": 1865.0, "train_total_steps": 5308525.0, "train_total_episodes": 2692.0, "train_loaded_steps": 1998437.0, "train_loaded_episodes": 1047.0}
{"step": 21241056, "train_return": 20.0, "train_length": 1739.0, "train_total_steps": 5310264.0, "train_total_episodes": 2693.0, "train_loaded_steps": 1998370.0, "train_loaded_episodes": 1047.0}
{"step": 21241040, "eval_return": 18.0, "eval_length": 1869.0, "eval_total_steps": 54808.0, "eval_total_episodes": 28.0, "eval_loaded_steps": 54836.0, "eval_loaded_episodes": 28.0}
{"step": 21241044, "kl_loss": 1.376319408416748, "image_loss": 3772.0, "reward_loss": 0.9191458225250244, "discount_loss": 0.007745165843516588, "model_kl": 1.376319408416748, "prior_ent": 26.135547637939453, "post_ent": 24.794374465942383, "model_loss": 3773.095703125, "model_loss_scale": 16384.0, "model_grad_norm": 5.325451374053955, "actor_loss": -0.0012178653851151466, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.0277898907661438, "critic_loss": 0.9185971617698669, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.050025951117277145, "reward_mean": 0.005979365669190884, "reward_std": 0.07856082171201706, "reward_normed_mean": 0.005979365669190884, "reward_normed_std": 0.07856082171201706, "critic_slow": 5.131009578704834, "critic_target": 5.131114482879639, "actor_ent": 1.4478205442428589, "actor_ent_scale": 0.0010000000474974513, "critic": 5.129095554351807, "fps": 0.0}
{"step": 21248424, "train_return": 19.0, "train_length": 1846.0, "train_total_steps": 5312106.0, "train_total_episodes": 2694.0, "train_loaded_steps": 1998431.0, "train_loaded_episodes": 1047.0}
{"step": 21256672, "train_return": 14.0, "train_length": 2062.0, "train_total_steps": 5314168.0, "train_total_episodes": 2695.0, "train_loaded_steps": 1998598.0, "train_loaded_episodes": 1047.0}
{"step": 21264072, "train_return": 18.0, "train_length": 1850.0, "train_total_steps": 5316018.0, "train_total_episodes": 2696.0, "train_loaded_steps": 1998649.0, "train_loaded_episodes": 1047.0}
{"step": 21271556, "train_return": 18.0, "train_length": 1871.0, "train_total_steps": 5317889.0, "train_total_episodes": 2697.0, "train_loaded_steps": 1998716.0, "train_loaded_episodes": 1047.0}
{"step": 21279028, "train_return": 19.0, "train_length": 1868.0, "train_total_steps": 5319757.0, "train_total_episodes": 2698.0, "train_loaded_steps": 1998344.0, "train_loaded_episodes": 1047.0}
{"step": 21281044, "kl_loss": 1.3113481975555419, "image_loss": 3772.0002, "reward_loss": 0.9190930021286011, "discount_loss": 0.00774521334245801, "model_kl": 1.3113481733322143, "prior_ent": 26.162499520874025, "post_ent": 24.858718988037108, "model_loss": 3773.0891828125, "model_loss_scale": 4122.2144, "model_grad_norm": Infinity, "actor_loss": -0.004627580231137108, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02805393202006817, "critic_loss": 0.9156984256744385, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.21528454717993736, "reward_mean": 0.007526148578850552, "reward_std": 0.08260443738102913, "reward_normed_mean": 0.007526148578850552, "reward_normed_std": 0.08260443738102913, "critic_slow": 4.987019568634033, "critic_target": 4.988703981399536, "actor_ent": 1.4815803352355956, "actor_ent_scale": 0.0010000000474974513, "critic": 4.988386993026733, "fps": 107.21806863765062}
{"step": 21285972, "train_return": 20.0, "train_length": 1736.0, "train_total_steps": 5321493.0, "train_total_episodes": 2699.0, "train_loaded_steps": 1998115.0, "train_loaded_episodes": 1047.0}
{"step": 21293448, "train_return": 18.0, "train_length": 1869.0, "train_total_steps": 5323362.0, "train_total_episodes": 2700.0, "train_loaded_steps": 1999984.0, "train_loaded_episodes": 1048.0}
{"step": 21300532, "train_return": 19.0, "train_length": 1771.0, "train_total_steps": 5325133.0, "train_total_episodes": 2701.0, "train_loaded_steps": 1999646.0, "train_loaded_episodes": 1048.0}
{"step": 21307384, "train_return": 20.0, "train_length": 1713.0, "train_total_steps": 5326846.0, "train_total_episodes": 2702.0, "train_loaded_steps": 1999489.0, "train_loaded_episodes": 1048.0}
{"step": 21314540, "train_return": 19.0, "train_length": 1789.0, "train_total_steps": 5328635.0, "train_total_episodes": 2703.0, "train_loaded_steps": 1999403.0, "train_loaded_episodes": 1048.0}
{"step": 21321044, "kl_loss": 1.3342584911346436, "image_loss": 3772.0002, "reward_loss": 0.9190813639640808, "discount_loss": 0.0077614331491291525, "model_kl": 1.3342584642410278, "prior_ent": 25.945668142700196, "post_ent": 24.626239248657228, "model_loss": 3773.09154453125, "model_loss_scale": 4096.0, "model_grad_norm": 3.9645629144668577, "actor_loss": -0.0049482132113807895, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02949744999408722, "critic_loss": 0.9160013039588928, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.21387561851143838, "reward_mean": 0.007503121198317968, "reward_std": 0.08354029398560524, "reward_normed_mean": 0.007503121198317968, "reward_normed_std": 0.08354029398560524, "critic_slow": 5.010942524719238, "critic_target": 5.011746311569214, "actor_ent": 1.4667813520431519, "actor_ent_scale": 0.0010000000474974513, "critic": 5.011658164596557, "fps": 108.80703554549989}
{"step": 21322500, "train_return": 17.0, "train_length": 1990.0, "train_total_steps": 5330625.0, "train_total_episodes": 2704.0, "train_loaded_steps": 1999446.0, "train_loaded_episodes": 1048.0}
{"step": 21330024, "train_return": 18.0, "train_length": 1881.0, "train_total_steps": 5332506.0, "train_total_episodes": 2705.0, "train_loaded_steps": 1999448.0, "train_loaded_episodes": 1048.0}
{"step": 21338020, "train_return": 16.0, "train_length": 1999.0, "train_total_steps": 5334505.0, "train_total_episodes": 2706.0, "train_loaded_steps": 1999288.0, "train_loaded_episodes": 1048.0}
{"step": 21345836, "train_return": 17.0, "train_length": 1954.0, "train_total_steps": 5336459.0, "train_total_episodes": 2707.0, "train_loaded_steps": 1999488.0, "train_loaded_episodes": 1048.0}
{"step": 21353232, "train_return": 19.0, "train_length": 1849.0, "train_total_steps": 5338308.0, "train_total_episodes": 2708.0, "train_loaded_steps": 1998945.0, "train_loaded_episodes": 1048.0}
{"step": 21361044, "kl_loss": 1.3317680004119874, "image_loss": 3772.0, "reward_loss": 0.9190874031066895, "discount_loss": 0.0077413487307727335, "model_kl": 1.331767972946167, "prior_ent": 26.134000732421875, "post_ent": 24.816048385620118, "model_loss": 3773.090997265625, "model_loss_scale": 4096.0, "model_grad_norm": 4.275040817451477, "actor_loss": -0.005307916811345058, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02881179301291704, "critic_loss": 0.9149212615013123, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.19858035678565503, "reward_mean": 0.007440673468913883, "reward_std": 0.08289024869799613, "reward_normed_mean": 0.007440673468913883, "reward_normed_std": 0.08289024869799613, "critic_slow": 4.997387634277343, "critic_target": 4.9977761726379395, "actor_ent": 1.4642394283294677, "actor_ent_scale": 0.0010000000474974513, "critic": 4.997715057754516, "fps": 109.51644418338563}
{"step": 21361212, "train_return": 17.0, "train_length": 1995.0, "train_total_steps": 5340303.0, "train_total_episodes": 2709.0, "train_loaded_steps": 1999183.0, "train_loaded_episodes": 1048.0}
{"step": 21368248, "train_return": 20.0, "train_length": 1759.0, "train_total_steps": 5342062.0, "train_total_episodes": 2710.0, "train_loaded_steps": 1998853.0, "train_loaded_episodes": 1048.0}
{"step": 21376356, "train_return": 17.0, "train_length": 2027.0, "train_total_steps": 5344089.0, "train_total_episodes": 2711.0, "train_loaded_steps": 1999212.0, "train_loaded_episodes": 1048.0}
{"step": 21383824, "train_return": 17.0, "train_length": 1867.0, "train_total_steps": 5345956.0, "train_total_episodes": 2712.0, "train_loaded_steps": 1999348.0, "train_loaded_episodes": 1048.0}
{"step": 21391820, "train_return": 16.0, "train_length": 1999.0, "train_total_steps": 5347955.0, "train_total_episodes": 2713.0, "train_loaded_steps": 1999527.0, "train_loaded_episodes": 1048.0}
{"step": 21399776, "train_return": 18.0, "train_length": 1989.0, "train_total_steps": 5349944.0, "train_total_episodes": 2714.0, "train_loaded_steps": 1999438.0, "train_loaded_episodes": 1048.0}
{"step": 21401044, "kl_loss": 1.307270940208435, "image_loss": 3772.0, "reward_loss": 0.9190804662704468, "discount_loss": 0.007741636368632316, "model_kl": 1.307270913696289, "prior_ent": 26.027161431884764, "post_ent": 24.72629371032715, "model_loss": 3773.088544140625, "model_loss_scale": 7359.6928, "model_grad_norm": 4.40967578086853, "actor_loss": -0.005344513349910267, "actor_loss_scale": 59087.2576, "actor_grad_norm": 0.02791318723410368, "critic_loss": 0.9147016436576844, "critic_loss_scale": 59087.2576, "critic_grad_norm": 0.18472747455239297, "reward_mean": 0.007559797642752528, "reward_std": 0.08329669787287712, "reward_normed_mean": 0.007559797642752528, "reward_normed_std": 0.08329669787287712, "critic_slow": 4.998408460617066, "critic_target": 4.999755011367798, "actor_ent": 1.4533706033706666, "actor_ent_scale": 0.0010000000474974513, "critic": 4.999480948257446, "fps": 109.84847950385661}
{"step": 21407360, "train_return": 18.0, "train_length": 1896.0, "train_total_steps": 5351840.0, "train_total_episodes": 2715.0, "train_loaded_steps": 1999546.0, "train_loaded_episodes": 1048.0}
{"step": 21416728, "train_return": 13.0, "train_length": 2342.0, "train_total_steps": 5354182.0, "train_total_episodes": 2716.0, "train_loaded_steps": 1999752.0, "train_loaded_episodes": 1048.0}
{"step": 21423984, "train_return": 18.0, "train_length": 1814.0, "train_total_steps": 5355996.0, "train_total_episodes": 2717.0, "train_loaded_steps": 1999439.0, "train_loaded_episodes": 1048.0}
{"step": 21431240, "train_return": 19.0, "train_length": 1814.0, "train_total_steps": 5357810.0, "train_total_episodes": 2718.0, "train_loaded_steps": 1999517.0, "train_loaded_episodes": 1048.0}
{"step": 21438716, "train_return": 19.0, "train_length": 1869.0, "train_total_steps": 5359679.0, "train_total_episodes": 2719.0, "train_loaded_steps": 1999521.0, "train_loaded_episodes": 1048.0}
{"step": 21441044, "kl_loss": 1.3293287803649902, "image_loss": 3772.0, "reward_loss": 0.9190851198196411, "discount_loss": 0.007740925084799528, "model_kl": 1.3293287553787232, "prior_ent": 26.043095166015625, "post_ent": 24.72902537536621, "model_loss": 3773.090745703125, "model_loss_scale": 8192.0, "model_grad_norm": 4.138357147216797, "actor_loss": -0.008454888770167599, "actor_loss_scale": 65536.0, "actor_grad_norm": 0.027048378609120845, "critic_loss": 0.9148126235961914, "critic_loss_scale": 65536.0, "critic_grad_norm": 0.207327817350626, "reward_mean": 0.007690048636030406, "reward_std": 0.08326962228417396, "reward_normed_mean": 0.007690048636030406, "reward_normed_std": 0.08326962228417396, "critic_slow": 5.006192143249511, "critic_target": 5.005827057266235, "actor_ent": 1.4663669109344482, "actor_ent_scale": 0.0010000000474974513, "critic": 5.005683758926391, "fps": 86.55538751903818}
{"step": 21438612, "eval_return": 16.0, "eval_length": 2061.0, "eval_total_steps": 56676.0, "eval_total_episodes": 29.0, "eval_loaded_steps": 56705.0, "eval_loaded_episodes": 29.0}
{"step": 21438616, "kl_loss": 1.3666926622390747, "image_loss": 3772.0, "reward_loss": 0.9192125201225281, "discount_loss": 0.00774513790383935, "model_kl": 1.3666925430297852, "prior_ent": 26.478759765625, "post_ent": 25.1639347076416, "model_loss": 3773.0947265625, "model_loss_scale": 16384.0, "model_grad_norm": 5.378061771392822, "actor_loss": 0.004638970363885164, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.03171813488006592, "critic_loss": 0.9181451797485352, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.11049234122037888, "reward_mean": 0.006823549047112465, "reward_std": 0.07912518829107285, "reward_normed_mean": 0.006823549047112465, "reward_normed_std": 0.07912518829107285, "critic_slow": 5.462824821472168, "critic_target": 5.466894626617432, "actor_ent": 1.4286922216415405, "actor_ent_scale": 0.0010000000474974513, "critic": 5.458383560180664, "fps": 0.0}
{"step": 21446196, "train_return": 17.0, "train_length": 1896.0, "train_total_steps": 5361549.0, "train_total_episodes": 2720.0, "train_loaded_steps": 1999686.0, "train_loaded_episodes": 1048.0}
{"step": 21453036, "train_return": 20.0, "train_length": 1710.0, "train_total_steps": 5363259.0, "train_total_episodes": 2721.0, "train_loaded_steps": 1999352.0, "train_loaded_episodes": 1048.0}
{"step": 21461188, "train_return": 16.0, "train_length": 2038.0, "train_total_steps": 5365297.0, "train_total_episodes": 2722.0, "train_loaded_steps": 1999344.0, "train_loaded_episodes": 1048.0}
{"step": 21468640, "train_return": 18.0, "train_length": 1863.0, "train_total_steps": 5367160.0, "train_total_episodes": 2723.0, "train_loaded_steps": 1999108.0, "train_loaded_episodes": 1048.0}
{"step": 21476200, "train_return": 18.0, "train_length": 1890.0, "train_total_steps": 5369050.0, "train_total_episodes": 2724.0, "train_loaded_steps": 1999126.0, "train_loaded_episodes": 1048.0}
{"step": 21478616, "kl_loss": 1.3092206117630005, "image_loss": 3772.0, "reward_loss": 0.9190939480781555, "discount_loss": 0.007741785226762295, "model_kl": 1.3092205890655517, "prior_ent": 26.128074084472658, "post_ent": 24.82557639160156, "model_loss": 3773.08875546875, "model_loss_scale": 4122.2144, "model_grad_norm": Infinity, "actor_loss": -0.004674814645232982, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.027639225152134895, "critic_loss": 0.9147221534729004, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.1899528470337391, "reward_mean": 0.007470236219465733, "reward_std": 0.08253551783561706, "reward_normed_mean": 0.007470236219465733, "reward_normed_std": 0.08253551783561706, "critic_slow": 4.975348751068116, "critic_target": 4.9769659358978275, "actor_ent": 1.488563485145569, "actor_ent_scale": 0.0010000000474974513, "critic": 4.976456964492798, "fps": 105.18708533067073}
{"step": 21483236, "train_return": 20.0, "train_length": 1759.0, "train_total_steps": 5370809.0, "train_total_episodes": 2725.0, "train_loaded_steps": 1999224.0, "train_loaded_episodes": 1048.0}
{"step": 21491168, "train_return": 17.0, "train_length": 1983.0, "train_total_steps": 5372792.0, "train_total_episodes": 2726.0, "train_loaded_steps": 1999177.0, "train_loaded_episodes": 1048.0}
{"step": 21500560, "train_return": 14.0, "train_length": 2348.0, "train_total_steps": 5375140.0, "train_total_episodes": 2727.0, "train_loaded_steps": 1999779.0, "train_loaded_episodes": 1048.0}
{"step": 21507188, "train_return": 21.0, "train_length": 1657.0, "train_total_steps": 5376797.0, "train_total_episodes": 2728.0, "train_loaded_steps": 1999699.0, "train_loaded_episodes": 1048.0}
{"step": 21515492, "train_return": 15.0, "train_length": 2076.0, "train_total_steps": 5378873.0, "train_total_episodes": 2729.0, "train_loaded_steps": 1999989.0, "train_loaded_episodes": 1048.0}
{"step": 21518616, "kl_loss": 1.3199784791946412, "image_loss": 3772.0, "reward_loss": 0.9190860341072082, "discount_loss": 0.00774101242646575, "model_kl": 1.3199784494400024, "prior_ent": 26.108584661865233, "post_ent": 24.79841290283203, "model_loss": 3773.089813671875, "model_loss_scale": 4096.0, "model_grad_norm": 4.047801969718933, "actor_loss": -0.006924465720931767, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.03321195842921734, "critic_loss": 0.9194215878486633, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.23359210968613625, "reward_mean": 0.007568063851073384, "reward_std": 0.08321107819676399, "reward_normed_mean": 0.007568063851073384, "reward_normed_std": 0.08321107819676399, "critic_slow": 4.953559366989135, "critic_target": 4.9541140563964845, "actor_ent": 1.4712210472106935, "actor_ent_scale": 0.0010000000474974513, "critic": 4.953705561828613, "fps": 105.07252157430906}
{"step": 21523160, "train_return": 18.0, "train_length": 1917.0, "train_total_steps": 5380790.0, "train_total_episodes": 2730.0, "train_loaded_steps": 1998157.0, "train_loaded_episodes": 1047.0}
{"step": 21530592, "train_return": 18.0, "train_length": 1858.0, "train_total_steps": 5382648.0, "train_total_episodes": 2731.0, "train_loaded_steps": 1998192.0, "train_loaded_episodes": 1047.0}
{"step": 21538128, "train_return": 18.0, "train_length": 1884.0, "train_total_steps": 5384532.0, "train_total_episodes": 2732.0, "train_loaded_steps": 1998274.0, "train_loaded_episodes": 1047.0}
{"step": 21545540, "train_return": 18.0, "train_length": 1853.0, "train_total_steps": 5386385.0, "train_total_episodes": 2733.0, "train_loaded_steps": 1998277.0, "train_loaded_episodes": 1047.0}
{"step": 21545484, "eval_return": 20.0, "eval_length": 1763.0, "eval_total_steps": 58736.0, "eval_total_episodes": 30.0, "eval_loaded_steps": 58766.0, "eval_loaded_episodes": 30.0}
{"step": 21545488, "kl_loss": 1.3583729267120361, "image_loss": 3772.0, "reward_loss": 0.918945848941803, "discount_loss": 0.0077354381792247295, "model_kl": 1.3583728075027466, "prior_ent": 26.306303024291992, "post_ent": 24.991918563842773, "model_loss": 3773.09326171875, "model_loss_scale": 16384.0, "model_grad_norm": 5.2968339920043945, "actor_loss": 0.018185846507549286, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.026523055508732796, "critic_loss": 0.909727156162262, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.244733527302742, "reward_mean": 0.008184556849300861, "reward_std": 0.06452227383852005, "reward_normed_mean": 0.008184556849300861, "reward_normed_std": 0.06452227383852005, "critic_slow": 4.7320966720581055, "critic_target": 4.746024131774902, "actor_ent": 1.417398452758789, "actor_ent_scale": 0.0010000000474974513, "critic": 4.7313995361328125, "fps": 0.0}
{"step": 21552504, "train_return": 19.0, "train_length": 1755.0, "train_total_steps": 5388126.0, "train_total_episodes": 2734.0, "train_loaded_steps": 1998193.0, "train_loaded_episodes": 1047.0}
{"step": 21559952, "train_return": 19.0, "train_length": 1862.0, "train_total_steps": 5389988.0, "train_total_episodes": 2735.0, "train_loaded_steps": 1998095.0, "train_loaded_episodes": 1047.0}
{"step": 21566772, "train_return": 20.0, "train_length": 1705.0, "train_total_steps": 5391693.0, "train_total_episodes": 2736.0, "train_loaded_steps": 1999800.0, "train_loaded_episodes": 1048.0}
{"step": 21566760, "eval_return": 18.0, "eval_length": 1887.0, "eval_total_steps": 60498.0, "eval_total_episodes": 31.0, "eval_loaded_steps": 60529.0, "eval_loaded_episodes": 31.0}
{"step": 21566764, "kl_loss": 1.467234492301941, "image_loss": 3772.0, "reward_loss": 0.9189472198486328, "discount_loss": 0.007745301816612482, "model_kl": 1.467234492301941, "prior_ent": 26.149198532104492, "post_ent": 24.792387008666992, "model_loss": 3773.1044921875, "model_loss_scale": 16384.0, "model_grad_norm": 5.211287975311279, "actor_loss": 0.007946819998323917, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.024796972051262856, "critic_loss": 0.9121138453483582, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.21007193624973297, "reward_mean": 0.00996157992631197, "reward_std": 0.08167626708745956, "reward_normed_mean": 0.00996157992631197, "reward_normed_std": 0.08167626708745956, "critic_slow": 4.79158878326416, "critic_target": 4.805648326873779, "actor_ent": 1.4626524448394775, "actor_ent_scale": 0.0010000000474974513, "critic": 4.7884392738342285, "fps": 0.0}
{"step": 21574192, "train_return": 18.0, "train_length": 1858.0, "train_total_steps": 5393548.0, "train_total_episodes": 2737.0, "train_loaded_steps": 1999522.0, "train_loaded_episodes": 1048.0}
{"step": 21582608, "train_return": 17.0, "train_length": 2104.0, "train_total_steps": 5395652.0, "train_total_episodes": 2738.0, "train_loaded_steps": 1999574.0, "train_loaded_episodes": 1048.0}
{"step": 21589804, "train_return": 20.0, "train_length": 1799.0, "train_total_steps": 5397451.0, "train_total_episodes": 2739.0, "train_loaded_steps": 1999442.0, "train_loaded_episodes": 1048.0}
{"step": 21597212, "train_return": 19.0, "train_length": 1852.0, "train_total_steps": 5399303.0, "train_total_episodes": 2740.0, "train_loaded_steps": 1998973.0, "train_loaded_episodes": 1048.0}
{"step": 21604372, "train_return": 19.0, "train_length": 1790.0, "train_total_steps": 5401093.0, "train_total_episodes": 2741.0, "train_loaded_steps": 1998839.0, "train_loaded_episodes": 1048.0}
{"step": 21606764, "kl_loss": 1.3075553829193116, "image_loss": 3772.0, "reward_loss": 0.9190741435050964, "discount_loss": 0.007742510535567999, "model_kl": 1.3075553552627563, "prior_ent": 26.092571896362305, "post_ent": 24.793297158813477, "model_loss": 3773.088569921875, "model_loss_scale": 4122.2144, "model_grad_norm": Infinity, "actor_loss": -0.006328126724314643, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.027882764349877836, "critic_loss": 0.9151671399116517, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.18880175101161004, "reward_mean": 0.007714723392389715, "reward_std": 0.08336654049158096, "reward_normed_mean": 0.007714723392389715, "reward_normed_std": 0.08336654049158096, "critic_slow": 4.989402627944946, "critic_target": 4.990421489715576, "actor_ent": 1.4728817602157593, "actor_ent_scale": 0.0010000000474974513, "critic": 4.990151456451416, "fps": 104.28727913775406}
{"step": 21612868, "train_return": 14.0, "train_length": 2124.0, "train_total_steps": 5403217.0, "train_total_episodes": 2742.0, "train_loaded_steps": 1999138.0, "train_loaded_episodes": 1048.0}
{"step": 21620976, "train_return": 18.0, "train_length": 2027.0, "train_total_steps": 5405244.0, "train_total_episodes": 2743.0, "train_loaded_steps": 1999171.0, "train_loaded_episodes": 1048.0}
{"step": 21620948, "eval_return": 18.0, "eval_length": 1974.0, "eval_total_steps": 62384.0, "eval_total_episodes": 32.0, "eval_loaded_steps": 62416.0, "eval_loaded_episodes": 32.0}
{"step": 21620952, "kl_loss": 1.358900785446167, "image_loss": 3772.0, "reward_loss": 0.9189413189888, "discount_loss": 0.0077355592511594296, "model_kl": 1.358900785446167, "prior_ent": 26.104177474975586, "post_ent": 24.818374633789062, "model_loss": 3773.093505859375, "model_loss_scale": 16384.0, "model_grad_norm": 5.283735752105713, "actor_loss": 0.030476881191134453, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.029686449095606804, "critic_loss": 0.9094629883766174, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.44112804532051086, "reward_mean": 0.012906637042760849, "reward_std": 0.08566127717494965, "reward_normed_mean": 0.012906637042760849, "reward_normed_std": 0.08566127717494965, "critic_slow": 5.459150791168213, "critic_target": 5.489352703094482, "actor_ent": 1.471682071685791, "actor_ent_scale": 0.0010000000474974513, "critic": 5.456061363220215, "fps": 0.0}
{"step": 21628380, "train_return": 19.0, "train_length": 1858.0, "train_total_steps": 5407095.0, "train_total_episodes": 2744.0, "train_loaded_steps": 1999266.0, "train_loaded_episodes": 1048.0}
{"step": 21635200, "train_return": 21.0, "train_length": 1705.0, "train_total_steps": 5408800.0, "train_total_episodes": 2745.0, "train_loaded_steps": 1999067.0, "train_loaded_episodes": 1048.0}
{"step": 21643256, "train_return": 17.0, "train_length": 2014.0, "train_total_steps": 5410814.0, "train_total_episodes": 2746.0, "train_loaded_steps": 1999321.0, "train_loaded_episodes": 1048.0}
{"step": 21650800, "train_return": 18.0, "train_length": 1886.0, "train_total_steps": 5412700.0, "train_total_episodes": 2747.0, "train_loaded_steps": 1999305.0, "train_loaded_episodes": 1048.0}
{"step": 21659000, "train_return": 15.0, "train_length": 2050.0, "train_total_steps": 5414750.0, "train_total_episodes": 2748.0, "train_loaded_steps": 1999569.0, "train_loaded_episodes": 1048.0}
{"step": 21660952, "kl_loss": 1.296052331161499, "image_loss": 3772.0, "reward_loss": 0.9190790872573853, "discount_loss": 0.007742495001107455, "model_kl": 1.2960523040771483, "prior_ent": 26.109236911010743, "post_ent": 24.81970327758789, "model_loss": 3773.087430078125, "model_loss_scale": 4122.2144, "model_grad_norm": Infinity, "actor_loss": -0.004860399636588408, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.026602088770270347, "critic_loss": 0.9146320793151855, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.1840630813896656, "reward_mean": 0.007566226079873741, "reward_std": 0.08279004946351051, "reward_normed_mean": 0.007566226079873741, "reward_normed_std": 0.08279004946351051, "critic_slow": 4.996156032180786, "critic_target": 4.997743341827393, "actor_ent": 1.50483831615448, "actor_ent_scale": 0.0010000000474974513, "critic": 4.997437992095947, "fps": 103.9219233102366}
{"step": 21658980, "eval_return": 15.0, "eval_length": 2014.0, "eval_total_steps": 64357.0, "eval_total_episodes": 33.0, "eval_loaded_steps": 64390.0, "eval_loaded_episodes": 33.0}
{"step": 21658984, "kl_loss": 1.3031635284423828, "image_loss": 3772.0, "reward_loss": 0.9189414381980896, "discount_loss": 0.007745108567178249, "model_kl": 1.3031634092330933, "prior_ent": 26.200183868408203, "post_ent": 24.944252014160156, "model_loss": 3773.088134765625, "model_loss_scale": 16384.0, "model_grad_norm": 5.324258804321289, "actor_loss": 0.030004272237420082, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02539612352848053, "critic_loss": 0.9164716005325317, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.3951667845249176, "reward_mean": 0.008671400137245655, "reward_std": 0.07656238973140717, "reward_normed_mean": 0.008671400137245655, "reward_normed_std": 0.07656238973140717, "critic_slow": 5.302944183349609, "critic_target": 5.326786994934082, "actor_ent": 1.4681072235107422, "actor_ent_scale": 0.0010000000474974513, "critic": 5.2995076179504395, "fps": 0.0}
{"step": 21667216, "train_return": 16.0, "train_length": 2059.0, "train_total_steps": 5416804.0, "train_total_episodes": 2749.0, "train_loaded_steps": 1999673.0, "train_loaded_episodes": 1048.0}
{"step": 21674204, "train_return": 20.0, "train_length": 1747.0, "train_total_steps": 5418551.0, "train_total_episodes": 2750.0, "train_loaded_steps": 1999758.0, "train_loaded_episodes": 1048.0}
{"step": 21681888, "train_return": 18.0, "train_length": 1921.0, "train_total_steps": 5420472.0, "train_total_episodes": 2751.0, "train_loaded_steps": 1999728.0, "train_loaded_episodes": 1048.0}
{"step": 21688696, "train_return": 21.0, "train_length": 1702.0, "train_total_steps": 5422174.0, "train_total_episodes": 2752.0, "train_loaded_steps": 1999568.0, "train_loaded_episodes": 1048.0}
{"step": 21696280, "train_return": 17.0, "train_length": 1896.0, "train_total_steps": 5424070.0, "train_total_episodes": 2753.0, "train_loaded_steps": 1999481.0, "train_loaded_episodes": 1048.0}
{"step": 21698984, "kl_loss": 1.2926192705154418, "image_loss": 3772.0, "reward_loss": 0.9190927352905274, "discount_loss": 0.007747590123862028, "model_kl": 1.292619248199463, "prior_ent": 26.10541226501465, "post_ent": 24.8198904296875, "model_loss": 3773.0871265625, "model_loss_scale": 4122.2144, "model_grad_norm": Infinity, "actor_loss": -0.005082077268906869, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.026686003902554514, "critic_loss": 0.9144794943809509, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.19203628177046775, "reward_mean": 0.007577128426544368, "reward_std": 0.08272241376638413, "reward_normed_mean": 0.007577128426544368, "reward_normed_std": 0.08272241376638413, "critic_slow": 5.025226961135864, "critic_target": 5.02669418258667, "actor_ent": 1.4941999563217163, "actor_ent_scale": 0.0010000000474974513, "critic": 5.026334698104859, "fps": 102.26288415978529}
{"step": 21696260, "eval_return": 16.0, "eval_length": 2057.0, "eval_total_steps": 66370.0, "eval_total_episodes": 34.0, "eval_loaded_steps": 66404.0, "eval_loaded_episodes": 34.0}
{"step": 21696264, "kl_loss": 1.3875938653945923, "image_loss": 3772.0, "reward_loss": 0.9191600680351257, "discount_loss": 0.007726119831204414, "model_kl": 1.3875938653945923, "prior_ent": 26.255939483642578, "post_ent": 24.968881607055664, "model_loss": 3773.096435546875, "model_loss_scale": 16384.0, "model_grad_norm": 5.478283405303955, "actor_loss": 0.017777660861611366, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.03185850754380226, "critic_loss": 0.9037493467330933, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.2770722806453705, "reward_mean": 0.009144502691924572, "reward_std": 0.0789739117026329, "reward_normed_mean": 0.009144502691924572, "reward_normed_std": 0.0789739117026329, "critic_slow": 4.867554187774658, "critic_target": 4.880784034729004, "actor_ent": 1.4396651983261108, "actor_ent_scale": 0.0010000000474974513, "critic": 4.863393306732178, "fps": 0.0}
{"step": 21703188, "train_return": 20.0, "train_length": 1732.0, "train_total_steps": 5425797.0, "train_total_episodes": 2754.0, "train_loaded_steps": 1999331.0, "train_loaded_episodes": 1048.0}
{"step": 21710564, "train_return": 18.0, "train_length": 1844.0, "train_total_steps": 5427641.0, "train_total_episodes": 2755.0, "train_loaded_steps": 1999379.0, "train_loaded_episodes": 1048.0}
{"step": 21717980, "train_return": 18.0, "train_length": 1854.0, "train_total_steps": 5429495.0, "train_total_episodes": 2756.0, "train_loaded_steps": 1999423.0, "train_loaded_episodes": 1048.0}
{"step": 21725368, "train_return": 19.0, "train_length": 1847.0, "train_total_steps": 5431342.0, "train_total_episodes": 2757.0, "train_loaded_steps": 1999319.0, "train_loaded_episodes": 1048.0}
{"step": 21732708, "train_return": 19.0, "train_length": 1835.0, "train_total_steps": 5433177.0, "train_total_episodes": 2758.0, "train_loaded_steps": 1999152.0, "train_loaded_episodes": 1048.0}
{"step": 21736264, "kl_loss": 1.3290083744049073, "image_loss": 3772.0, "reward_loss": 0.9190968954086304, "discount_loss": 0.007741765940934419, "model_kl": 1.3290083513259887, "prior_ent": 26.06488901977539, "post_ent": 24.74750669250488, "model_loss": 3773.090733984375, "model_loss_scale": 4122.2144, "model_grad_norm": Infinity, "actor_loss": -0.005898700343308155, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.027812464414536952, "critic_loss": 0.9151624717712402, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.1854347564339638, "reward_mean": 0.007604855808103457, "reward_std": 0.08309227516651153, "reward_normed_mean": 0.007604855808103457, "reward_normed_std": 0.08309227516651153, "critic_slow": 4.9962918647766115, "critic_target": 4.997179859542847, "actor_ent": 1.4930400987625123, "actor_ent_scale": 0.0010000000474974513, "critic": 4.996876695632935, "fps": 59.60855074486502}
{"step": 21740236, "train_return": 18.0, "train_length": 1882.0, "train_total_steps": 5435059.0, "train_total_episodes": 2759.0, "train_loaded_steps": 1999001.0, "train_loaded_episodes": 1048.0}
{"step": 21740212, "eval_return": 19.0, "eval_length": 1861.0, "eval_total_steps": 68426.0, "eval_total_episodes": 35.0, "eval_loaded_steps": 68461.0, "eval_loaded_episodes": 35.0}
{"step": 21740216, "kl_loss": 1.4115147590637207, "image_loss": 3772.0, "reward_loss": 0.9189649820327759, "discount_loss": 0.007735574617981911, "model_kl": 1.4115146398544312, "prior_ent": 26.110265731811523, "post_ent": 24.753446578979492, "model_loss": 3773.0986328125, "model_loss_scale": 16384.0, "model_grad_norm": 5.171018123626709, "actor_loss": -0.0012737257638946176, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.030257144942879677, "critic_loss": 0.9163504242897034, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.0756133422255516, "reward_mean": 0.006422162055969238, "reward_std": 0.07086668163537979, "reward_normed_mean": 0.006422162055969238, "reward_normed_std": 0.07086668163537979, "critic_slow": 3.892568349838257, "critic_target": 3.8906478881835938, "actor_ent": 1.458754539489746, "actor_ent_scale": 0.0010000000474974513, "critic": 3.8924973011016846, "fps": 0.0}
{"step": 21747384, "train_return": 19.0, "train_length": 1793.0, "train_total_steps": 5436846.0, "train_total_episodes": 2760.0, "train_loaded_steps": 1999134.0, "train_loaded_episodes": 1048.0}
{"step": 21754116, "train_return": 21.0, "train_length": 1683.0, "train_total_steps": 5438529.0, "train_total_episodes": 2761.0, "train_loaded_steps": 1998686.0, "train_loaded_episodes": 1048.0}
{"step": 21762828, "train_return": 17.0, "train_length": 2178.0, "train_total_steps": 5440707.0, "train_total_episodes": 2762.0, "train_loaded_steps": 1999009.0, "train_loaded_episodes": 1048.0}
{"step": 21770688, "train_return": 17.0, "train_length": 1965.0, "train_total_steps": 5442672.0, "train_total_episodes": 2763.0, "train_loaded_steps": 1999047.0, "train_loaded_episodes": 1048.0}
{"step": 21778224, "train_return": 17.0, "train_length": 1884.0, "train_total_steps": 5444556.0, "train_total_episodes": 2764.0, "train_loaded_steps": 1999121.0, "train_loaded_episodes": 1048.0}
{"step": 21780216, "kl_loss": 1.3080249290466308, "image_loss": 3772.0, "reward_loss": 0.9190838388442993, "discount_loss": 0.0077441530346870424, "model_kl": 1.3080249059677125, "prior_ent": 26.098084158325197, "post_ent": 24.797213244628907, "model_loss": 3773.08863515625, "model_loss_scale": 4122.2144, "model_grad_norm": Infinity, "actor_loss": -0.005208435945362726, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.027791136547923086, "critic_loss": 0.9147658820152282, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.19376721658110618, "reward_mean": 0.007506969755608588, "reward_std": 0.0824719526708126, "reward_normed_mean": 0.007506969755608588, "reward_normed_std": 0.0824719526708126, "critic_slow": 5.03576907081604, "critic_target": 5.036735607910156, "actor_ent": 1.4834390783309936, "actor_ent_scale": 0.0010000000474974513, "critic": 5.036259831619263, "fps": 13.327914458603804}
{"step": 21786328, "train_return": 17.0, "train_length": 2026.0, "train_total_steps": 5446582.0, "train_total_episodes": 2765.0, "train_loaded_steps": 1999320.0, "train_loaded_episodes": 1048.0}
{"step": 21793400, "train_return": 19.0, "train_length": 1768.0, "train_total_steps": 5448350.0, "train_total_episodes": 2766.0, "train_loaded_steps": 1999295.0, "train_loaded_episodes": 1048.0}
{"step": 21801452, "train_return": 18.0, "train_length": 2013.0, "train_total_steps": 5450363.0, "train_total_episodes": 2767.0, "train_loaded_steps": 1999302.0, "train_loaded_episodes": 1048.0}
{"step": 21808372, "train_return": 20.0, "train_length": 1730.0, "train_total_steps": 5452093.0, "train_total_episodes": 2768.0, "train_loaded_steps": 1999226.0, "train_loaded_episodes": 1048.0}
{"step": 21816420, "train_return": 16.0, "train_length": 2012.0, "train_total_steps": 5454105.0, "train_total_episodes": 2769.0, "train_loaded_steps": 1999468.0, "train_loaded_episodes": 1048.0}
{"step": 21820216, "kl_loss": 1.3654245370864868, "image_loss": 3772.0, "reward_loss": 0.9190941467285156, "discount_loss": 0.007741093868017196, "model_kl": 1.3654245067596436, "prior_ent": 26.196479943847656, "post_ent": 24.855631509399416, "model_loss": 3773.094366015625, "model_loss_scale": 4096.0, "model_grad_norm": 4.100863217544556, "actor_loss": -0.007012570989702363, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02888890523016453, "critic_loss": 0.915213702583313, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.20627907145619392, "reward_mean": 0.007468081057909876, "reward_std": 0.08313279005289077, "reward_normed_mean": 0.007468081057909876, "reward_normed_std": 0.08313279005289077, "critic_slow": 4.94778479347229, "critic_target": 4.947852155303955, "actor_ent": 1.4481766771316529, "actor_ent_scale": 0.0010000000474974513, "critic": 4.9475172348022465, "fps": 52.72622100031462}
{"step": 21823140, "train_return": 21.0, "train_length": 1680.0, "train_total_steps": 5455785.0, "train_total_episodes": 2770.0, "train_loaded_steps": 1999362.0, "train_loaded_episodes": 1048.0}
{"step": 21830916, "train_return": 17.0, "train_length": 1944.0, "train_total_steps": 5457729.0, "train_total_episodes": 2771.0, "train_loaded_steps": 1999486.0, "train_loaded_episodes": 1048.0}
{"step": 21830868, "eval_return": 19.0, "eval_length": 1858.0, "eval_total_steps": 70286.0, "eval_total_episodes": 36.0, "eval_loaded_steps": 70322.0, "eval_loaded_episodes": 36.0}
{"step": 21830872, "kl_loss": 1.382615327835083, "image_loss": 3772.0, "reward_loss": 0.9189411401748657, "discount_loss": 0.007735483814030886, "model_kl": 1.3826152086257935, "prior_ent": 26.088586807250977, "post_ent": 24.72980499267578, "model_loss": 3773.095703125, "model_loss_scale": 16384.0, "model_grad_norm": 5.295764446258545, "actor_loss": 0.021942511200904846, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.0239787008613348, "critic_loss": 0.9076598286628723, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.3567412495613098, "reward_mean": 0.010831861756742, "reward_std": 0.08168233186006546, "reward_normed_mean": 0.010831861756742, "reward_normed_std": 0.08168233186006546, "critic_slow": 5.128274917602539, "critic_target": 5.149744987487793, "actor_ent": 1.4555736780166626, "actor_ent_scale": 0.0010000000474974513, "critic": 5.126535892486572, "fps": 0.0}
{"step": 21837872, "train_return": 20.0, "train_length": 1751.0, "train_total_steps": 5459468.0, "train_total_episodes": 2772.0, "train_loaded_steps": 1999272.0, "train_loaded_episodes": 1048.0}
{"step": 21845656, "train_return": 17.0, "train_length": 1946.0, "train_total_steps": 5461414.0, "train_total_episodes": 2773.0, "train_loaded_steps": 1999427.0, "train_loaded_episodes": 1048.0}
{"step": 21852660, "train_return": 19.0, "train_length": 1751.0, "train_total_steps": 5463165.0, "train_total_episodes": 2774.0, "train_loaded_steps": 1999032.0, "train_loaded_episodes": 1048.0}
{"step": 21860392, "train_return": 17.0, "train_length": 1933.0, "train_total_steps": 5465098.0, "train_total_episodes": 2775.0, "train_loaded_steps": 1999029.0, "train_loaded_episodes": 1048.0}
{"step": 21867440, "train_return": 20.0, "train_length": 1762.0, "train_total_steps": 5466860.0, "train_total_episodes": 2776.0, "train_loaded_steps": 1998999.0, "train_loaded_episodes": 1048.0}
{"step": 21870872, "kl_loss": 1.3134522024154662, "image_loss": 3772.0, "reward_loss": 0.9190965300559998, "discount_loss": 0.007742690303176642, "model_kl": 1.313452175140381, "prior_ent": 26.030729083251952, "post_ent": 24.72435224609375, "model_loss": 3773.08919140625, "model_loss_scale": 4122.2144, "model_grad_norm": Infinity, "actor_loss": -0.005641689184136339, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02711356193870306, "critic_loss": 0.9150001933097839, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.18549646670222283, "reward_mean": 0.00757451305820141, "reward_std": 0.08288443304896355, "reward_normed_mean": 0.00757451305820141, "reward_normed_std": 0.08288443304896355, "critic_slow": 5.010326853561401, "critic_target": 5.0117936576843265, "actor_ent": 1.4904243968963624, "actor_ent_scale": 0.0010000000474974513, "critic": 5.011491186141968, "fps": 60.44591828537274}
{"step": 21876116, "train_return": 16.0, "train_length": 2169.0, "train_total_steps": 5469029.0, "train_total_episodes": 2777.0, "train_loaded_steps": 1999208.0, "train_loaded_episodes": 1048.0}
{"step": 21884076, "train_return": 16.0, "train_length": 1990.0, "train_total_steps": 5471019.0, "train_total_episodes": 2778.0, "train_loaded_steps": 1999330.0, "train_loaded_episodes": 1048.0}
{"step": 21891432, "train_return": 18.0, "train_length": 1839.0, "train_total_steps": 5472858.0, "train_total_episodes": 2779.0, "train_loaded_steps": 1999300.0, "train_loaded_episodes": 1048.0}
{"step": 21898320, "train_return": 21.0, "train_length": 1722.0, "train_total_steps": 5474580.0, "train_total_episodes": 2780.0, "train_loaded_steps": 1999305.0, "train_loaded_episodes": 1048.0}
{"step": 21905176, "train_return": 20.0, "train_length": 1714.0, "train_total_steps": 5476294.0, "train_total_episodes": 2781.0, "train_loaded_steps": 1999082.0, "train_loaded_episodes": 1048.0}
{"step": 21910872, "kl_loss": 1.302977748298645, "image_loss": 3772.0, "reward_loss": 0.9190748042106628, "discount_loss": 0.0077414898470044135, "model_kl": 1.3029777225494386, "prior_ent": 26.015557424926758, "post_ent": 24.722006845092775, "model_loss": 3773.0881125, "model_loss_scale": 4096.0, "model_grad_norm": 3.989723021697998, "actor_loss": -0.0056345294310696774, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02687845147550106, "critic_loss": 0.9149686922073365, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.207879457706213, "reward_mean": 0.007731739110313356, "reward_std": 0.08329637819528579, "reward_normed_mean": 0.007731739110313356, "reward_normed_std": 0.08329637819528579, "critic_slow": 5.008686793899536, "critic_target": 5.01064584236145, "actor_ent": 1.492870249557495, "actor_ent_scale": 0.0010000000474974513, "critic": 5.010124286270141, "fps": 60.13235181380295}
{"step": 21913596, "train_return": 14.0, "train_length": 2105.0, "train_total_steps": 5478399.0, "train_total_episodes": 2782.0, "train_loaded_steps": 1999132.0, "train_loaded_episodes": 1048.0}
{"step": 21922580, "train_return": 14.0, "train_length": 2246.0, "train_total_steps": 5480645.0, "train_total_episodes": 2783.0, "train_loaded_steps": 1999386.0, "train_loaded_episodes": 1048.0}
{"step": 21929944, "train_return": 18.0, "train_length": 1841.0, "train_total_steps": 5482486.0, "train_total_episodes": 2784.0, "train_loaded_steps": 1999367.0, "train_loaded_episodes": 1048.0}
{"step": 21937948, "train_return": 17.0, "train_length": 2001.0, "train_total_steps": 5484487.0, "train_total_episodes": 2785.0, "train_loaded_steps": 1999484.0, "train_loaded_episodes": 1048.0}
{"step": 21945620, "train_return": 16.0, "train_length": 1918.0, "train_total_steps": 5486405.0, "train_total_episodes": 2786.0, "train_loaded_steps": 1999246.0, "train_loaded_episodes": 1048.0}
{"step": 21950872, "kl_loss": 1.3212225421905517, "image_loss": 3772.0, "reward_loss": 0.9190896500587463, "discount_loss": 0.007744275273382664, "model_kl": 1.3212225145339966, "prior_ent": 25.942839654541014, "post_ent": 24.63571096496582, "model_loss": 3773.089955859375, "model_loss_scale": 4096.0, "model_grad_norm": 4.36395152015686, "actor_loss": -0.0045672585372987665, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02817759295552969, "critic_loss": 0.914860224533081, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.20338484191894532, "reward_mean": 0.007663853971054777, "reward_std": 0.08332486721277237, "reward_normed_mean": 0.007663853971054777, "reward_normed_std": 0.08332486721277237, "critic_slow": 4.963771028518677, "critic_target": 4.9663683067321776, "actor_ent": 1.4913153167724609, "actor_ent_scale": 0.0010000000474974513, "critic": 4.965861520385742, "fps": 60.043567333556894}
{"step": 21952616, "train_return": 19.0, "train_length": 1749.0, "train_total_steps": 5488154.0, "train_total_episodes": 2787.0, "train_loaded_steps": 1998743.0, "train_loaded_episodes": 1048.0}
{"step": 21960424, "train_return": 17.0, "train_length": 1952.0, "train_total_steps": 5490106.0, "train_total_episodes": 2788.0, "train_loaded_steps": 1998881.0, "train_loaded_episodes": 1048.0}
{"step": 21967596, "train_return": 20.0, "train_length": 1793.0, "train_total_steps": 5491899.0, "train_total_episodes": 2789.0, "train_loaded_steps": 1998800.0, "train_loaded_episodes": 1048.0}
{"step": 21975680, "train_return": 17.0, "train_length": 2021.0, "train_total_steps": 5493920.0, "train_total_episodes": 2790.0, "train_loaded_steps": 1999011.0, "train_loaded_episodes": 1048.0}
{"step": 21982648, "train_return": 20.0, "train_length": 1742.0, "train_total_steps": 5495662.0, "train_total_episodes": 2791.0, "train_loaded_steps": 1998895.0, "train_loaded_episodes": 1048.0}
{"step": 21990180, "train_return": 18.0, "train_length": 1883.0, "train_total_steps": 5497545.0, "train_total_episodes": 2792.0, "train_loaded_steps": 1998776.0, "train_loaded_episodes": 1048.0}
{"step": 21990872, "kl_loss": 1.3110554843902589, "image_loss": 3772.0, "reward_loss": 0.9190840257644654, "discount_loss": 0.007741488613933325, "model_kl": 1.3110554582595826, "prior_ent": 26.125865167236327, "post_ent": 24.823478173828125, "model_loss": 3773.088926953125, "model_loss_scale": 7359.6928, "model_grad_norm": 4.266748708152771, "actor_loss": -0.005266976899158908, "actor_loss_scale": 59087.2576, "actor_grad_norm": 0.02730474501401186, "critic_loss": 0.9154158206939698, "critic_loss_scale": 59087.2576, "critic_grad_norm": 0.21515739583969115, "reward_mean": 0.007635036152380053, "reward_std": 0.08308963771462441, "reward_normed_mean": 0.007635036152380053, "reward_normed_std": 0.08308963771462441, "critic_slow": 4.983955942535401, "critic_target": 4.985735367202759, "actor_ent": 1.4771924158096315, "actor_ent_scale": 0.0010000000474974513, "critic": 4.985379965972901, "fps": 59.73735967111743}
{"step": 21997864, "train_return": 19.0, "train_length": 1921.0, "train_total_steps": 5499466.0, "train_total_episodes": 2793.0, "train_loaded_steps": 1998769.0, "train_loaded_episodes": 1048.0}
{"step": 22005228, "train_return": 19.0, "train_length": 1841.0, "train_total_steps": 5501307.0, "train_total_episodes": 2794.0, "train_loaded_steps": 1998685.0, "train_loaded_episodes": 1048.0}
{"step": 22012396, "train_return": 19.0, "train_length": 1792.0, "train_total_steps": 5503099.0, "train_total_episodes": 2795.0, "train_loaded_steps": 1998744.0, "train_loaded_episodes": 1048.0}
{"step": 22012300, "eval_return": 18.0, "eval_length": 1866.0, "eval_total_steps": 72143.0, "eval_total_episodes": 37.0, "eval_loaded_steps": 72180.0, "eval_loaded_episodes": 37.0}
{"step": 22012304, "kl_loss": 1.5175487995147705, "image_loss": 3772.0, "reward_loss": 0.9189398288726807, "discount_loss": 0.0077355001121759415, "model_kl": 1.5175487995147705, "prior_ent": 26.132291793823242, "post_ent": 24.7573299407959, "model_loss": 3773.109375, "model_loss_scale": 16384.0, "model_grad_norm": 5.400793075561523, "actor_loss": 0.017599446699023247, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.027563082054257393, "critic_loss": 0.9095763564109802, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.2135392278432846, "reward_mean": 0.0077157579362392426, "reward_std": 0.08107662200927734, "reward_normed_mean": 0.0077157579362392426, "reward_normed_std": 0.08107662200927734, "critic_slow": 3.9567370414733887, "critic_target": 3.9716744422912598, "actor_ent": 1.431058645248413, "actor_ent_scale": 0.0010000000474974513, "critic": 3.9557416439056396, "fps": 0.0}
{"step": 22020268, "train_return": 16.0, "train_length": 1992.0, "train_total_steps": 5505067.0, "train_total_episodes": 2796.0, "train_loaded_steps": 1998715.0, "train_loaded_episodes": 1048.0}
{"step": 22027752, "train_return": 18.0, "train_length": 1871.0, "train_total_steps": 5506938.0, "train_total_episodes": 2797.0, "train_loaded_steps": 1998605.0, "train_loaded_episodes": 1048.0}
{"step": 22034984, "train_return": 18.0, "train_length": 1808.0, "train_total_steps": 5508746.0, "train_total_episodes": 2798.0, "train_loaded_steps": 1998591.0, "train_loaded_episodes": 1048.0}
{"step": 22043244, "train_return": 15.0, "train_length": 2065.0, "train_total_steps": 5510811.0, "train_total_episodes": 2799.0, "train_loaded_steps": 1998702.0, "train_loaded_episodes": 1048.0}
{"step": 22050076, "train_return": 20.0, "train_length": 1708.0, "train_total_steps": 5512519.0, "train_total_episodes": 2800.0, "train_loaded_steps": 1998750.0, "train_loaded_episodes": 1048.0}
{"step": 22052304, "kl_loss": 1.2995728788375855, "image_loss": 3772.000187890625, "reward_loss": 0.9190726845741272, "discount_loss": 0.007749075143784284, "model_kl": 1.2995728540420532, "prior_ent": 26.165468423461913, "post_ent": 24.871940979003906, "model_loss": 3773.0879890625, "model_loss_scale": 4122.2144, "model_grad_norm": Infinity, "actor_loss": -0.0071287354901607616, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.028490837424993514, "critic_loss": 0.9159109512329101, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.20469661643207074, "reward_mean": 0.007750762938335538, "reward_std": 0.08291002215147018, "reward_normed_mean": 0.007750762938335538, "reward_normed_std": 0.08291002215147018, "critic_slow": 5.017819226837158, "critic_target": 5.017742435455323, "actor_ent": 1.4650937143325806, "actor_ent_scale": 0.0010000000474974513, "critic": 5.017626823806762, "fps": 102.12228721605001}
{"step": 22057776, "train_return": 18.0, "train_length": 1925.0, "train_total_steps": 5514444.0, "train_total_episodes": 2801.0, "train_loaded_steps": 1998790.0, "train_loaded_episodes": 1048.0}
{"step": 22065524, "train_return": 18.0, "train_length": 1937.0, "train_total_steps": 5516381.0, "train_total_episodes": 2802.0, "train_loaded_steps": 1998794.0, "train_loaded_episodes": 1048.0}
{"step": 22073228, "train_return": 17.0, "train_length": 1926.0, "train_total_steps": 5518307.0, "train_total_episodes": 2803.0, "train_loaded_steps": 1998726.0, "train_loaded_episodes": 1048.0}
{"step": 22080956, "train_return": 18.0, "train_length": 1932.0, "train_total_steps": 5520239.0, "train_total_episodes": 2804.0, "train_loaded_steps": 1998672.0, "train_loaded_episodes": 1048.0}
{"step": 22088920, "train_return": 16.0, "train_length": 1991.0, "train_total_steps": 5522230.0, "train_total_episodes": 2805.0, "train_loaded_steps": 1998832.0, "train_loaded_episodes": 1048.0}
{"step": 22092304, "kl_loss": 1.3086388828277589, "image_loss": 3772.0, "reward_loss": 0.9190718194961548, "discount_loss": 0.007746020894497633, "model_kl": 1.3086388603210448, "prior_ent": 26.026797326660155, "post_ent": 24.729128213500978, "model_loss": 3773.08869296875, "model_loss_scale": 4096.0, "model_grad_norm": 3.9213271011352537, "actor_loss": -0.008462324866009294, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.028075280660390854, "critic_loss": 0.9150121982574463, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.17651234349012374, "reward_mean": 0.007701889292709529, "reward_std": 0.0834399207174778, "reward_normed_mean": 0.007701889292709529, "reward_normed_std": 0.0834399207174778, "critic_slow": 5.035986231613159, "critic_target": 5.036695687866211, "actor_ent": 1.4920287019729614, "actor_ent_scale": 0.0010000000474974513, "critic": 5.036640754318237, "fps": 43.66739206041563}
{"step": 22095812, "train_return": 20.0, "train_length": 1723.0, "train_total_steps": 5523953.0, "train_total_episodes": 2806.0, "train_loaded_steps": 1998809.0, "train_loaded_episodes": 1048.0}
{"step": 22104360, "train_return": 15.0, "train_length": 2137.0, "train_total_steps": 5526090.0, "train_total_episodes": 2807.0, "train_loaded_steps": 1999212.0, "train_loaded_episodes": 1048.0}
{"step": 22110996, "train_return": 21.0, "train_length": 1659.0, "train_total_steps": 5527749.0, "train_total_episodes": 2808.0, "train_loaded_steps": 1998807.0, "train_loaded_episodes": 1048.0}
{"step": 22118220, "train_return": 18.0, "train_length": 1806.0, "train_total_steps": 5529555.0, "train_total_episodes": 2809.0, "train_loaded_steps": 1998588.0, "train_loaded_episodes": 1048.0}
{"step": 22125040, "train_return": 20.0, "train_length": 1705.0, "train_total_steps": 5531260.0, "train_total_episodes": 2810.0, "train_loaded_steps": 1998340.0, "train_loaded_episodes": 1048.0}
{"step": 22132304, "kl_loss": 1.3327386838912965, "image_loss": 3772.0, "reward_loss": 0.9190754909515381, "discount_loss": 0.007741473716497421, "model_kl": 1.3327386571884154, "prior_ent": 25.99247656555176, "post_ent": 24.673222381591795, "model_loss": 3773.091082421875, "model_loss_scale": 4096.0, "model_grad_norm": 4.242080954360962, "actor_loss": -0.006332849226873077, "actor_loss_scale": 32768.0, "actor_grad_norm": 0.02747699214220047, "critic_loss": 0.9151170109748841, "critic_loss_scale": 32768.0, "critic_grad_norm": 0.20283669844865798, "reward_mean": 0.0074425482869148255, "reward_std": 0.08235511279702186, "reward_normed_mean": 0.0074425482869148255, "reward_normed_std": 0.08235511279702186, "critic_slow": 4.9933979721069335, "critic_target": 4.9935579662322995, "actor_ent": 1.4881168014526367, "actor_ent_scale": 0.0010000000474974513, "critic": 4.993448764801025, "fps": 102.63945947522649}
{"step": 22132396, "train_return": 19.0, "train_length": 1839.0, "train_total_steps": 5533099.0, "train_total_episodes": 2811.0, "train_loaded_steps": 1998054.0, "train_loaded_episodes": 1048.0}
